Importing module 'gym_38' (/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
[36m[2025-07-03 11:08:38,050][26754] Queried available GPUs: 0
[37m[1m[2025-07-03 11:08:38,050][26754] Environment var CUDA_VISIBLE_DEVICES is 0
PyTorch version 1.13.1
Device count 1
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
Warp 1.0.0-beta.5 initialized:
   CUDA Toolkit: 11.5, Driver: 12.4
   Devices:
     "cpu"    | x86_64
     "cuda:0" | NVIDIA GeForce RTX 4080 Laptop GPU (sm_89)
   Kernel cache: /home/ziyar/.cache/warp/1.0.0-beta.5
[SUBPROCESS] FORCED headless mode for all Sample Factory training: headless=True
[SUBPROCESS] This prevents Isaac Gym viewer conflicts across all processes
[SUBPROCESS] Task action_space_dim: 3
[SUBPROCESS] Target Sample Factory action space: 3D
[SUBPROCESS] Setting num_envs to 4 based on env_agents=4
[SUBPROCESS] Set SF_ENV_AGENTS=4 environment variable
[SUBPROCESS] Config batch_size: 128
[SUBPROCESS] Using MEDIUM CONFIG (4 environments)
Registered quad_with_obstacles_gate and dce_navigation_task_gate in subprocess
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles_gate', '--experiment=gif_exp6', '--train_dir=./train_dir', '--num_workers=1', '--num_envs_per_worker=1', '--env_agents=4', '--obs_key=observations', '--batch_size=128', '--num_batches_to_accumulate=2', '--rollout=32', '--learning_rate=0.0003', '--use_rnn=true', '--rnn_size=128', '--rnn_num_layers=1', '--encoder_mlp_layers', '512', '256', '128', '--gamma=0.98', '--with_wandb=true', '--wandb_project=gate_navigation_dual_camera', '--wandb_user=ziya-ruso-ucl', '--wandb_group=gate_navigation_training', '--wandb_tags', 'aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized', '--save_every_sec=120', '--save_best_every_sec=5', '--train_for_env_steps=100000000']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/utils/cpp_extension.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging  # type: ignore[attr-defined]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Using /home/ziyar/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
Emitting ninja build file /home/ziyar/.cache/torch_extensions/py38_cu117/gymtorch/build.ninja...
Building extension module gymtorch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module gymtorch...
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/graph.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping, Set, Iterable
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/readwrite/graphml.py:346: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  (np.int, "int"), (np.int8, "int"),
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/torch_utils.py:135: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  def get_axis_params(value, axis_idx, x_value=0., dtype=np.float, n_dims=3):
[37m[1785 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task_gate.py:22)
[37m[1785 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Final headless mode: False (dce_navigation_task_gate.py:29)
[37m[1785 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Found SF_ENV_AGENTS environment variable: 4 (dce_navigation_task_gate.py:39)
[37m[1785 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Detected env_agents=4 from environment - setting environment count. (dce_navigation_task_gate.py:45)
[37m[1786 ms][base_task] - INFO : Setting seed: 2595582020 (base_task.py:38)
[37m[1786 ms][navigation_task_gate] - INFO : Building environment for gate navigation task. (navigation_task_gate.py:48)
[37m[1786 ms][navigation_task_gate] - INFO : Sim Name: base_sim, Env Name: gate_env, Robot Name: lmf2, Controller Name: lmf2_position_control (navigation_task_gate.py:49)
[37m[1786 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[1786 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[1786 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[1786 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[1786 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[1786 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[1787 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[1787 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[1787 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[1787 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[1787 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[1787 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[1787 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.34 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 7.65 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 11.31 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.44 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] GIF saving DISABLED
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 4
[AerialGymVecEnv] Detected observation space: 145D
[AerialGymVecEnv] Using GATE NAVIGATION configuration (145D = 17D basic + 64D drone VAE + 64D static camera VAE)
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[37m[2764 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[2764 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[2968 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[2968 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[2968 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[2968 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[2968 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[2968 ms][BaseRobot] - INFO : Initializing controller lmf2_position_control (base_robot.py:29)
[33m[2968 ms][base_multirotor] - WARNING : Creating 4 multirotors. (base_multirotor.py:32)
[37m[2968 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[2968 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[2968 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2968 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2972 ms][asset_loader] - INFO : Loading asset: tree_32.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2981 ms][asset_loader] - INFO : Loading asset: tree_41.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2989 ms][asset_loader] - INFO : Loading asset: tree_60.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2998 ms][asset_loader] - INFO : Loading asset: tree_34.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3007 ms][asset_loader] - INFO : Loading asset: tree_95.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3016 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3017 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3018 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3019 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3020 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3021 ms][asset_loader] - INFO : Loading asset: tree_67.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3029 ms][asset_loader] - INFO : Loading asset: tree_42.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3038 ms][asset_loader] - INFO : Loading asset: tree_17.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3047 ms][asset_loader] - INFO : Loading asset: tree_68.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3055 ms][asset_loader] - INFO : Loading asset: tree_20.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3064 ms][asset_loader] - INFO : Loading asset: tree_89.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3073 ms][asset_loader] - INFO : Loading asset: tree_28.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3082 ms][asset_loader] - INFO : Loading asset: tree_64.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3090 ms][asset_loader] - INFO : Loading asset: tree_36.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3099 ms][asset_loader] - INFO : Loading asset: tree_29.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3108 ms][asset_loader] - INFO : Loading asset: tree_35.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3117 ms][asset_loader] - INFO : Loading asset: tree_1.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3126 ms][asset_loader] - INFO : Loading asset: tree_19.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3135 ms][asset_loader] - INFO : Loading asset: tree_88.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3144 ms][asset_loader] - INFO : Loading asset: tree_55.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3153 ms][env_manager] - INFO : Creating ground plane in Isaac Gym Simulation. (env_manager.py:172)
[37m[3158 ms][env_manager] - INFO : [DONE] Creating ground plane in Isaac Gym Simulation (env_manager.py:174)
[37m[3158 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[3531 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[3531 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[3531 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[3561 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[3569 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[3569 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[3656 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[3656 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[3746 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 11 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[3953 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[3954 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
[37m[4574 ms][navigation_task_gate] - INFO : Setting up static camera for gate navigation... (navigation_task_gate.py:490)
[37m[4574 ms][navigation_task_gate] - INFO : Static camera properties: 480x270, FOV: 87.0Â° (navigation_task_gate.py:509)
[37m[4591 ms][navigation_task_gate] - INFO : âœ“ Static camera setup complete (navigation_task_gate.py:526)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[36m[2025-07-03 11:08:42,828][26866] Env info: EnvInfo(obs_space=Dict('obs': Box(-inf, inf, (145,), float32)), action_space=Box(-1.0, 1.0, (3,), float32), num_agents=4, gpu_actions=True, gpu_observations=True, action_splits=None, all_discrete=None, frameskip=1, reward_shaping_scheme=None, env_info_protocol_version=1)
[33m[2025-07-03 11:08:43,564][26754] In serial mode all components run on the same process. Only use async_rl and serial mode together for debugging.
[36m[2025-07-03 11:08:43,565][26754] Starting experiment with the following configuration:
[36mhelp=False
[36malgo=APPO
[36menv=quad_with_obstacles_gate
[36mexperiment=gif_exp6
[36mtrain_dir=./train_dir
[36mrestart_behavior=resume
[36mdevice=gpu
[36mseed=None
[36mnum_policies=1
[36masync_rl=True
[36mserial_mode=True
[36mbatched_sampling=True
[36mnum_batches_to_accumulate=2
[36mworker_num_splits=1
[36mpolicy_workers_per_policy=1
[36mmax_policy_lag=1000
[36mnum_workers=1
[36mnum_envs_per_worker=1
[36mbatch_size=128
[36mnum_batches_per_epoch=4
[36mnum_epochs=4
[36mrollout=32
[36mrecurrence=32
[36mshuffle_minibatches=False
[36mgamma=0.98
[36mreward_scale=0.1
[36mreward_clip=1000.0
[36mvalue_bootstrap=True
[36mnormalize_returns=True
[36mexploration_loss_coeff=0.001
[36mvalue_loss_coeff=2.0
[36mkl_loss_coeff=0.1
[36mexploration_loss=entropy
[36mgae_lambda=0.95
[36mppo_clip_ratio=0.2
[36mppo_clip_value=1.0
[36mwith_vtrace=False
[36mvtrace_rho=1.0
[36mvtrace_c=1.0
[36moptimizer=adam
[36madam_eps=1e-06
[36madam_beta1=0.9
[36madam_beta2=0.999
[36mmax_grad_norm=1.0
[36mlearning_rate=0.0003
[36mlr_schedule=kl_adaptive_epoch
[36mlr_schedule_kl_threshold=0.016
[36mlr_adaptive_min=1e-06
[36mlr_adaptive_max=0.01
[36mobs_subtract_mean=0.0
[36mobs_scale=1.0
[36mnormalize_input=True
[36mnormalize_input_keys=None
[36mdecorrelate_experience_max_seconds=0
[36mdecorrelate_envs_on_one_worker=True
[36mactor_worker_gpus=[0]
[36mset_workers_cpu_affinity=True
[36mforce_envs_single_thread=False
[36mdefault_niceness=0
[36mlog_to_file=True
[36mexperiment_summaries_interval=10
[36mflush_summaries_interval=30
[36mstats_avg=100
[36msummaries_use_frameskip=True
[36mheartbeat_interval=20
[36mheartbeat_reporting_interval=180
[36mtrain_for_env_steps=100000000
[36mtrain_for_seconds=10000000000
[36msave_every_sec=120
[36mkeep_checkpoints=5
[36mload_checkpoint_kind=latest
[36msave_milestones_sec=-1
[36msave_best_every_sec=5
[36msave_best_metric=reward
[36msave_best_after=100000
[36mbenchmark=False
[36mencoder_mlp_layers=[512, 256, 128]
[36mencoder_conv_architecture=convnet_simple
[36mencoder_conv_mlp_layers=[]
[36muse_rnn=True
[36mrnn_size=128
[36mrnn_type=gru
[36mrnn_num_layers=1
[36mdecoder_mlp_layers=[]
[36mnonlinearity=elu
[36mpolicy_initialization=torch_default
[36mpolicy_init_gain=1.0
[36mactor_critic_share_weights=True
[36madaptive_stddev=True
[36mcontinuous_tanh_scale=0.0
[36minitial_stddev=1.0
[36muse_env_info_cache=False
[36menv_gpu_actions=True
[36menv_gpu_observations=True
[36menv_frameskip=1
[36menv_framestack=1
[36mpixel_format=CHW
[36muse_record_episode_statistics=False
[36mwith_wandb=True
[36mwandb_user=ziya-ruso-ucl
[36mwandb_project=gate_navigation_dual_camera
[36mwandb_group=gate_navigation_training
[36mwandb_job_type=SF
[36mwandb_tags=['aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized']
[36mwith_pbt=False
[36mpbt_mix_policies_in_one_env=True
[36mpbt_period_env_steps=5000000
[36mpbt_start_mutation=20000000
[36mpbt_replace_fraction=0.3
[36mpbt_mutation_rate=0.15
[36mpbt_replace_reward_gap=0.1
[36mpbt_replace_reward_gap_absolute=1e-06
[36mpbt_optimize_gamma=False
[36mpbt_target_objective=true_objective
[36mpbt_perturb_min=1.1
[36mpbt_perturb_max=1.5
[36menv_agents=4
[36mheadless=False
[36msave_gifs=False
[36mobs_key=observations
[36msubtask=None
[36mige_api_version=preview4
[36meval_stats=False
[36maction_space_dim=3
[36mcommand_line=--env=quad_with_obstacles_gate --experiment=gif_exp6 --train_dir=./train_dir --num_workers=1 --num_envs_per_worker=1 --env_agents=4 --obs_key=observations --batch_size=128 --num_batches_to_accumulate=2 --rollout=32 --learning_rate=0.0003 --use_rnn=true --rnn_size=128 --rnn_num_layers=1 --encoder_mlp_layers 512 256 128 --gamma=0.98 --with_wandb=true --wandb_project=gate_navigation_dual_camera --wandb_user=ziya-ruso-ucl --wandb_group=gate_navigation_training --wandb_tags aerial_gym gate_navigation dual_camera x500 sample_factory memory_optimized --save_every_sec=120 --save_best_every_sec=5 --train_for_env_steps=100000000 --headless=false
[36mcli_args={'env': 'quad_with_obstacles_gate', 'experiment': 'gif_exp6', 'train_dir': './train_dir', 'num_batches_to_accumulate': 2, 'num_workers': 1, 'num_envs_per_worker': 1, 'batch_size': 128, 'rollout': 32, 'gamma': 0.98, 'learning_rate': 0.0003, 'train_for_env_steps': 100000000, 'save_every_sec': 120, 'save_best_every_sec': 5, 'encoder_mlp_layers': [512, 256, 128], 'use_rnn': True, 'rnn_size': 128, 'rnn_num_layers': 1, 'with_wandb': True, 'wandb_user': 'ziya-ruso-ucl', 'wandb_project': 'gate_navigation_dual_camera', 'wandb_group': 'gate_navigation_training', 'wandb_tags': ['aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized'], 'env_agents': 4, 'headless': False, 'obs_key': 'observations'}
[36mgit_hash=a54f99d681da80aa6215176cae93d2948a30ac42
[36mgit_repo_name=git@github.com:rusoziya/aerial_gym_simulator.git
[36mwandb_unique_id=gif_exp6_20250703_110834_870236
[36m[2025-07-03 11:08:43,565][26754] Saving configuration to ./train_dir/gif_exp6/config.json...
[36m[2025-07-03 11:08:43,613][26754] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-03 11:08:43,613][26754] Rollout worker 0 uses device cuda:0
[36m[2025-07-03 11:08:43,620][26754] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 11:08:43,620][26754] InferenceWorker_p0-w0: min num requests: 1
[36m[2025-07-03 11:08:43,621][26754] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 11:08:43,622][26754] Starting seed is not provided
[36m[2025-07-03 11:08:43,622][26754] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-03 11:08:43,622][26754] Initializing actor-critic model on device cuda:0
[36m[2025-07-03 11:08:43,623][26754] RunningMeanStd input shape: (145,)
[36m[2025-07-03 11:08:43,624][26754] RunningMeanStd input shape: (1,)
[36m[2025-07-03 11:08:43,652][26754] Created Actor Critic model with architecture:
[36m[2025-07-03 11:08:43,653][26754] ActorCriticSharedWeights(
[36m  (obs_normalizer): ObservationNormalizer(
[36m    (running_mean_std): RunningMeanStdDictInPlace(
[36m      (running_mean_std): ModuleDict(
[36m        (obs): RunningMeanStdInPlace()
[36m      )
[36m    )
[36m  )
[36m  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
[36m  (encoder): MultiInputEncoder(
[36m    (encoders): ModuleDict(
[36m      (obs): MlpEncoder(
[36m        (mlp_head): RecursiveScriptModule(
[36m          original_name=Sequential
[36m          (0): RecursiveScriptModule(original_name=Linear)
[36m          (1): RecursiveScriptModule(original_name=ELU)
[36m          (2): RecursiveScriptModule(original_name=Linear)
[36m          (3): RecursiveScriptModule(original_name=ELU)
[36m          (4): RecursiveScriptModule(original_name=Linear)
[36m          (5): RecursiveScriptModule(original_name=ELU)
[36m        )
[36m      )
[36m    )
[36m  )
[36m  (core): ModelCoreRNN(
[36m    (core): GRU(128, 128)
[36m  )
[36m  (decoder): MlpDecoder(
[36m    (mlp): Identity()
[36m  )
[36m  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
[36m  (action_parameterization): ActionParameterizationDefault(
[36m    (distribution_linear): Linear(in_features=128, out_features=6, bias=True)
[36m  )
[36m)
[36m[2025-07-03 11:08:44,066][26754] Using optimizer <class 'torch.optim.adam.Adam'>
[33m[2025-07-03 11:08:44,067][26754] No checkpoints found
[36m[2025-07-03 11:08:44,067][26754] Did not load from checkpoint, starting from scratch!
[36m[2025-07-03 11:08:44,067][26754] Initialized policy 0 weights for model version 0
[36m[2025-07-03 11:08:44,067][26754] LearnerWorker_p0 finished initialization!
[36m[2025-07-03 11:08:44,067][26754] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 11:08:44,070][26754] Inference worker 0-0 is ready!
[37m[1m[2025-07-03 11:08:44,070][26754] All inference workers are ready! Signal rollout workers to start!
[36m[2025-07-03 11:08:44,070][26754] EnvRunner 0-0 uses policy 0
[37m[11100 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task_gate.py:22)
[37m[11100 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Final headless mode: False (dce_navigation_task_gate.py:29)
[37m[11100 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Found SF_ENV_AGENTS environment variable: 4 (dce_navigation_task_gate.py:39)
[37m[11100 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Detected env_agents=4 from environment - setting environment count. (dce_navigation_task_gate.py:45)
[37m[11100 ms][base_task] - INFO : Setting seed: 2350139774 (base_task.py:38)
[37m[11101 ms][navigation_task_gate] - INFO : Building environment for gate navigation task. (navigation_task_gate.py:48)
[37m[11101 ms][navigation_task_gate] - INFO : Sim Name: base_sim, Env Name: gate_env, Robot Name: lmf2, Controller Name: lmf2_position_control (navigation_task_gate.py:49)
[37m[11101 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[11101 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[11101 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[11101 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[11101 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[11101 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles_gate', '--experiment=gif_exp6', '--train_dir=./train_dir', '--num_workers=1', '--num_envs_per_worker=1', '--env_agents=4', '--obs_key=observations', '--batch_size=128', '--num_batches_to_accumulate=2', '--rollout=32', '--learning_rate=0.0003', '--use_rnn=true', '--rnn_size=128', '--rnn_num_layers=1', '--encoder_mlp_layers', '512', '256', '128', '--gamma=0.98', '--with_wandb=true', '--wandb_project=gate_navigation_dual_camera', '--wandb_user=ziya-ruso-ucl', '--wandb_group=gate_navigation_training', '--wandb_tags', 'aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized', '--save_every_sec=120', '--save_best_every_sec=5', '--train_for_env_steps=100000000']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.62 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 8.26 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 11.48 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.75 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] GIF saving DISABLED
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 4
[AerialGymVecEnv] Detected observation space: 145D
[AerialGymVecEnv] Using GATE NAVIGATION configuration (145D = 17D basic + 64D drone VAE + 64D static camera VAE)
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[37m[11102 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[11102 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[11102 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[11102 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[11102 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[11102 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[11102 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[37m[12082 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[12082 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[12283 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[12283 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[12283 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[12284 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[12284 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[12284 ms][BaseRobot] - INFO : Initializing controller lmf2_position_control (base_robot.py:29)
[33m[12284 ms][base_multirotor] - WARNING : Creating 4 multirotors. (base_multirotor.py:32)
[37m[12284 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[12284 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[12284 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12284 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12288 ms][asset_loader] - INFO : Loading asset: tree_18.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12297 ms][asset_loader] - INFO : Loading asset: tree_56.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12306 ms][asset_loader] - INFO : Loading asset: tree_65.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12315 ms][asset_loader] - INFO : Loading asset: tree_51.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12324 ms][asset_loader] - INFO : Loading asset: tree_4.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12333 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12334 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12335 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12336 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12337 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12338 ms][asset_loader] - INFO : Loading asset: tree_1.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12347 ms][asset_loader] - INFO : Loading asset: tree_73.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12355 ms][asset_loader] - INFO : Loading asset: tree_84.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12364 ms][asset_loader] - INFO : Loading asset: tree_59.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12373 ms][asset_loader] - INFO : Loading asset: tree_41.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12382 ms][asset_loader] - INFO : Loading asset: tree_76.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12391 ms][asset_loader] - INFO : Loading asset: tree_14.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12399 ms][asset_loader] - INFO : Loading asset: tree_36.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12408 ms][asset_loader] - INFO : Loading asset: tree_7.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12417 ms][asset_loader] - INFO : Loading asset: tree_62.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12426 ms][asset_loader] - INFO : Loading asset: tree_82.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12446 ms][env_manager] - INFO : Creating ground plane in Isaac Gym Simulation. (env_manager.py:172)
[37m[12451 ms][env_manager] - INFO : [DONE] Creating ground plane in Isaac Gym Simulation (env_manager.py:174)
[37m[12451 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[12468 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[12468 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[12468 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[12498 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[12505 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[12505 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[12572 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[12572 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[12668 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 11 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[12864 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[12865 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
[37m[13479 ms][navigation_task_gate] - INFO : Setting up static camera for gate navigation... (navigation_task_gate.py:490)
[37m[13479 ms][navigation_task_gate] - INFO : Static camera properties: 480x270, FOV: 87.0Â° (navigation_task_gate.py:509)
[37m[13496 ms][navigation_task_gate] - INFO : âœ“ Static camera setup complete (navigation_task_gate.py:526)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[37m[14492 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:08:48,863][26754] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 11:08:48,864][26754] Avg episode reward: [(0, '-50.000')]
[33m[16900 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[36m[2025-07-03 11:08:52,380][26754] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 6.8. Samples: 24. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 11:08:52,381][26754] Avg episode reward: [(0, '-50.000')]
[37m[19616 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[20611 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[33m[21808 ms][IGE_viewer_control] - WARNING : Camera follow: False (IGE_viewer_control.py:217)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/nn/modules/module.py:1194: UserWarning: operator() profile_node %104 : int[] = prim::profile_ivalue(%102)
 does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)
  return forward_call(*input, **kwargs)
[37m[22791 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[23000 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[23112 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:08:57,395][26754] Fps is (10 sec: 60.0, 60 sec: 60.0, 300 sec: 60.0). Total num frames: 512. Throughput: 0: 65.2. Samples: 556. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:08:57,395][26754] Avg episode reward: [(0, '-128.545')]
[37m[25741 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[27030 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[27290 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[28657 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:02,394][26754] Fps is (10 sec: 102.3, 60 sec: 75.7, 300 sec: 75.7). Total num frames: 1024. Throughput: 0: 82.8. Samples: 1120. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:09:02,395][26754] Avg episode reward: [(0, '-156.136')]
[37m[29766 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[1m[2025-07-03 11:09:03,694][26754] Heartbeat connected on Batcher_0
[37m[1m[2025-07-03 11:09:03,695][26754] Heartbeat connected on LearnerWorker_p0
[37m[1m[2025-07-03 11:09:03,695][26754] Heartbeat connected on InferenceWorker_p0-w0
[37m[1m[2025-07-03 11:09:03,695][26754] Heartbeat connected on RolloutWorker_w0
[37m[32820 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[33267 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:07,391][26754] Fps is (10 sec: 102.4, 60 sec: 82.9, 300 sec: 82.9). Total num frames: 1536. Throughput: 0: 76.4. Samples: 1416. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[36m[2025-07-03 11:09:07,391][26754] Avg episode reward: [(0, '-139.477')]
[37m[34630 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[36483 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[37348 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[39208 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:12,413][26754] Fps is (10 sec: 102.2, 60 sec: 87.0, 300 sec: 87.0). Total num frames: 2048. Throughput: 0: 85.9. Samples: 2024. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-03 11:09:12,413][26754] Avg episode reward: [(0, '-115.414')]
[37m[39898 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[42420 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[42814 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[42862 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[43031 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:17,386][26754] Fps is (10 sec: 102.5, 60 sec: 89.8, 300 sec: 89.8). Total num frames: 2560. Throughput: 0: 92.0. Samples: 2624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:09:17,386][26754] Avg episode reward: [(0, '-115.024')]
[37m[45513 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[46803 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[47750 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[48371 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[48679 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:22,418][26754] Fps is (10 sec: 102.3, 60 sec: 91.6, 300 sec: 91.6). Total num frames: 3072. Throughput: 0: 87.3. Samples: 2928. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 11:09:22,418][26754] Avg episode reward: [(0, '-131.881')]
[37m[50927 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[52822 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:27,387][26754] Fps is (10 sec: 102.4, 60 sec: 93.0, 300 sec: 93.0). Total num frames: 3584. Throughput: 0: 91.9. Samples: 3540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:09:27,387][26754] Avg episode reward: [(0, '-135.724')]
[37m[54909 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[55139 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[55981 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[56462 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[58607 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:32,386][26754] Fps is (10 sec: 102.7, 60 sec: 94.1, 300 sec: 94.1). Total num frames: 4096. Throughput: 0: 95.3. Samples: 4148. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:09:32,387][26754] Avg episode reward: [(0, '-130.168')]
[37m[60000 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[61025 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[61263 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[64222 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:37,376][26754] Fps is (10 sec: 102.5, 60 sec: 95.0, 300 sec: 95.0). Total num frames: 4608. Throughput: 0: 98.6. Samples: 4460. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:09:37,376][26754] Avg episode reward: [(0, '-139.543')]
[37m[65290 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[66827 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[67970 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:42,388][26754] Fps is (10 sec: 102.4, 60 sec: 95.7, 300 sec: 95.7). Total num frames: 5120. Throughput: 0: 100.4. Samples: 5072. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 11:09:42,389][26754] Avg episode reward: [(0, '-140.845')]
[37m[69775 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[70124 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[71709 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[73642 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[73692 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[74011 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[74292 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[74341 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:47,389][26754] Fps is (10 sec: 102.3, 60 sec: 96.2, 300 sec: 96.2). Total num frames: 5632. Throughput: 0: 100.8. Samples: 5656. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:09:47,390][26754] Avg episode reward: [(0, '-145.149')]
[37m[75444 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[76831 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[78046 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[78283 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[78492 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:52,410][26754] Fps is (10 sec: 102.2, 60 sec: 102.3, 300 sec: 96.7). Total num frames: 6144. Throughput: 0: 100.8. Samples: 5956. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-03 11:09:52,410][26754] Avg episode reward: [(0, '-146.154')]
[37m[79530 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[81535 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[82064 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[82813 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[83574 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:09:57,395][26754] Fps is (10 sec: 102.3, 60 sec: 102.4, 300 sec: 97.1). Total num frames: 6656. Throughput: 0: 101.1. Samples: 6572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:09:57,395][26754] Avg episode reward: [(0, '-149.027')]
[37m[87578 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[87665 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[88845 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:02,391][26754] Fps is (10 sec: 102.6, 60 sec: 102.4, 300 sec: 97.5). Total num frames: 7168. Throughput: 0: 101.0. Samples: 7168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:10:02,391][26754] Avg episode reward: [(0, '-152.192')]
[37m[90201 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[92927 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[93182 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[93341 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[93798 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:07,383][26754] Fps is (10 sec: 102.5, 60 sec: 102.4, 300 sec: 97.8). Total num frames: 7680. Throughput: 0: 101.0. Samples: 7468. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:10:07,383][26754] Avg episode reward: [(0, '-153.419')]
[37m[94543 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[97508 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[98183 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[98618 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:12,450][26754] Fps is (10 sec: 101.8, 60 sec: 102.3, 300 sec: 98.0). Total num frames: 8192. Throughput: 0: 100.6. Samples: 8072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:10:12,450][26754] Avg episode reward: [(0, '-156.758')]
[37m[100359 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[100814 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[101766 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[102692 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[104268 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:17,388][26754] Fps is (10 sec: 51.2, 60 sec: 93.9, 300 sec: 92.5). Total num frames: 8192. Throughput: 0: 100.6. Samples: 8676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:10:17,388][26754] Avg episode reward: [(0, '-158.336')]
[37m[106127 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[107457 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[107971 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[108918 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[109418 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:22,427][26754] Fps is (10 sec: 51.3, 60 sec: 93.9, 300 sec: 93.0). Total num frames: 8704. Throughput: 0: 100.2. Samples: 8976. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[36m[2025-07-03 11:10:22,427][26754] Avg episode reward: [(0, '-161.765')]
[37m[113057 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:27,399][26754] Fps is (10 sec: 102.3, 60 sec: 93.8, 300 sec: 93.5). Total num frames: 9216. Throughput: 0: 99.4. Samples: 9544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:10:27,399][26754] Avg episode reward: [(0, '-163.141')]
[37m[114720 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[115403 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[119221 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:32,379][26754] Fps is (10 sec: 102.9, 60 sec: 93.9, 300 sec: 94.0). Total num frames: 9728. Throughput: 0: 99.3. Samples: 10124. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:10:32,379][26754] Avg episode reward: [(0, '-164.499')]
[37m[119423 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[119636 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[119724 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[122862 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:37,393][26754] Fps is (10 sec: 102.5, 60 sec: 93.8, 300 sec: 94.4). Total num frames: 10240. Throughput: 0: 99.0. Samples: 10408. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 11:10:37,393][26754] Avg episode reward: [(0, '-165.511')]
[37m[124439 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[1m[2025-07-03 11:10:37,447][26754] Saving ./train_dir/gif_exp6/checkpoint_p0/checkpoint_000000320_10240.pth...
[37m[125335 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[127824 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[127981 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:42,385][26754] Fps is (10 sec: 102.3, 60 sec: 93.9, 300 sec: 94.7). Total num frames: 10752. Throughput: 0: 99.0. Samples: 11024. Policy #0 lag: (min: 4.0, avg: 4.5, max: 20.0)
[36m[2025-07-03 11:10:42,386][26754] Avg episode reward: [(0, '-167.016')]
[37m[129579 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[131086 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[131303 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[134005 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[134054 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[134226 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:47,384][26754] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 95.0). Total num frames: 11264. Throughput: 0: 98.8. Samples: 11612. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:10:47,385][26754] Avg episode reward: [(0, '-171.324')]
[37m[136022 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[137410 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[137459 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:52,389][26754] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 95.3). Total num frames: 11776. Throughput: 0: 98.7. Samples: 11912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:10:52,389][26754] Avg episode reward: [(0, '-169.506')]
[37m[139581 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[140375 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[143016 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[143275 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[143549 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:10:57,409][26754] Fps is (10 sec: 102.2, 60 sec: 93.8, 300 sec: 95.6). Total num frames: 12288. Throughput: 0: 98.9. Samples: 12520. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:10:57,409][26754] Avg episode reward: [(0, '-166.441')]
[37m[144456 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[148587 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:02,386][26754] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 95.9). Total num frames: 12800. Throughput: 0: 97.5. Samples: 13064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:11:02,387][26754] Avg episode reward: [(0, '-166.122')]
[37m[150070 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[151036 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:07,384][26754] Fps is (10 sec: 102.6, 60 sec: 93.9, 300 sec: 96.1). Total num frames: 13312. Throughput: 0: 96.6. Samples: 13320. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[36m[2025-07-03 11:11:07,385][26754] Avg episode reward: [(0, '-173.052')]
[37m[154914 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[155201 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[156073 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[157410 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[157460 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:12,405][26754] Fps is (10 sec: 102.2, 60 sec: 93.9, 300 sec: 96.3). Total num frames: 13824. Throughput: 0: 95.9. Samples: 13860. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-03 11:11:12,405][26754] Avg episode reward: [(0, '-176.747')]
[37m[159751 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[159800 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[160714 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[161802 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[163896 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:17,390][26754] Fps is (10 sec: 102.3, 60 sec: 102.4, 300 sec: 96.5). Total num frames: 14336. Throughput: 0: 96.2. Samples: 14452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:11:17,390][26754] Avg episode reward: [(0, '-173.669')]
[37m[165130 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[166031 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[166318 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[168415 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[168697 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:22,380][26754] Fps is (10 sec: 102.7, 60 sec: 102.5, 300 sec: 96.7). Total num frames: 14848. Throughput: 0: 96.5. Samples: 14748. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-03 11:11:22,381][26754] Avg episode reward: [(0, '-171.525')]
[37m[169578 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[172189 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[173150 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[174172 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:27,406][26754] Fps is (10 sec: 102.2, 60 sec: 102.4, 300 sec: 96.9). Total num frames: 15360. Throughput: 0: 95.5. Samples: 15324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:11:27,406][26754] Avg episode reward: [(0, '-171.841')]
[37m[175558 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[177141 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[177333 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[177388 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[178122 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[178414 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:32,410][26754] Fps is (10 sec: 102.1, 60 sec: 102.3, 300 sec: 97.0). Total num frames: 15872. Throughput: 0: 95.1. Samples: 15896. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[36m[2025-07-03 11:11:32,410][26754] Avg episode reward: [(0, '-169.493')]
[37m[180301 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[182418 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[183678 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:37,408][26754] Fps is (10 sec: 102.4, 60 sec: 102.4, 300 sec: 97.2). Total num frames: 16384. Throughput: 0: 95.1. Samples: 16192. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-03 11:11:37,408][26754] Avg episode reward: [(0, '-168.059')]
[37m[185207 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[185258 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[186850 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[188852 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[189396 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:42,403][26754] Fps is (10 sec: 51.2, 60 sec: 93.8, 300 sec: 94.4). Total num frames: 16384. Throughput: 0: 94.4. Samples: 16768. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-03 11:11:42,404][26754] Avg episode reward: [(0, '-167.076')]
[37m[189532 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[193148 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[193471 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:47,378][26754] Fps is (10 sec: 51.4, 60 sec: 93.9, 300 sec: 94.6). Total num frames: 16896. Throughput: 0: 95.0. Samples: 17336. Policy #0 lag: (min: 4.0, avg: 4.5, max: 20.0)
[36m[2025-07-03 11:11:47,378][26754] Avg episode reward: [(0, '-167.663')]
[37m[194663 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[194718 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[198443 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[199348 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:52,398][26754] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 94.8). Total num frames: 17408. Throughput: 0: 95.1. Samples: 17600. Policy #0 lag: (min: 4.0, avg: 4.5, max: 20.0)
[36m[2025-07-03 11:11:52,398][26754] Avg episode reward: [(0, '-168.338')]
[37m[200334 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[201068 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[202255 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:11:57,385][26754] Fps is (10 sec: 102.3, 60 sec: 93.9, 300 sec: 95.1). Total num frames: 17920. Throughput: 0: 95.0. Samples: 18132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:11:57,385][26754] Avg episode reward: [(0, '-167.937')]
[37m[205612 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[207411 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[208064 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[208423 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:02,397][26754] Fps is (10 sec: 102.4, 60 sec: 93.8, 300 sec: 95.2). Total num frames: 18432. Throughput: 0: 93.9. Samples: 18680. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:12:02,398][26754] Avg episode reward: [(0, '-165.063')]
[37m[210490 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[212514 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:07,395][26754] Fps is (10 sec: 102.3, 60 sec: 93.8, 300 sec: 95.4). Total num frames: 18944. Throughput: 0: 93.3. Samples: 18948. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:12:07,396][26754] Avg episode reward: [(0, '-163.796')]
[37m[215138 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[215260 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[216935 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[217023 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:12,401][26754] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 95.6). Total num frames: 19456. Throughput: 0: 93.3. Samples: 19520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:12:12,401][26754] Avg episode reward: [(0, '-161.665')]
[37m[219820 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[220205 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[221038 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[223939 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:17,419][26754] Fps is (10 sec: 102.2, 60 sec: 93.8, 300 sec: 95.7). Total num frames: 19968. Throughput: 0: 93.8. Samples: 20116. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:12:17,419][26754] Avg episode reward: [(0, '-157.967')]
[37m[224921 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[225721 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[226778 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[228351 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[228669 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:22,386][26754] Fps is (10 sec: 102.6, 60 sec: 93.9, 300 sec: 95.9). Total num frames: 20480. Throughput: 0: 93.8. Samples: 20412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:12:22,386][26754] Avg episode reward: [(0, '-156.703')]
[37m[231300 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[232058 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[233393 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[233976 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:27,403][26754] Fps is (10 sec: 102.6, 60 sec: 93.9, 300 sec: 96.1). Total num frames: 20992. Throughput: 0: 93.3. Samples: 20968. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:12:27,404][26754] Avg episode reward: [(0, '-155.403')]
[37m[234495 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[238960 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[239347 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[239400 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:32,407][26754] Fps is (10 sec: 102.2, 60 sec: 93.9, 300 sec: 96.2). Total num frames: 21504. Throughput: 0: 92.7. Samples: 21508. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 11:12:32,408][26754] Avg episode reward: [(0, '-150.946')]
[37m[239628 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[239724 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[244288 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:37,406][26754] Fps is (10 sec: 51.2, 60 sec: 85.3, 300 sec: 94.1). Total num frames: 21504. Throughput: 0: 92.7. Samples: 21772. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 11:12:37,406][26754] Avg episode reward: [(0, '-149.340')]
[37m[1m[2025-07-03 11:12:37,445][26754] Saving ./train_dir/gif_exp6/checkpoint_p0/checkpoint_000000672_21504.pth...
[37m[244896 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[245530 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[245768 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[248503 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[249376 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:42,382][26754] Fps is (10 sec: 51.3, 60 sec: 93.9, 300 sec: 94.3). Total num frames: 22016. Throughput: 0: 94.1. Samples: 22368. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 11:12:42,382][26754] Avg episode reward: [(0, '-147.326')]
[37m[250020 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[251484 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[253112 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:47,410][26754] Fps is (10 sec: 102.4, 60 sec: 93.8, 300 sec: 94.4). Total num frames: 22528. Throughput: 0: 95.2. Samples: 22964. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:12:47,411][26754] Avg episode reward: [(0, '-145.960')]
[37m[255137 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[256811 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[257699 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[258505 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:52,406][26754] Fps is (10 sec: 102.2, 60 sec: 93.9, 300 sec: 94.6). Total num frames: 23040. Throughput: 0: 95.8. Samples: 23260. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 11:12:52,406][26754] Avg episode reward: [(0, '-145.186')]
[37m[259454 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[262052 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[262144 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[263041 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[263228 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:12:57,386][26754] Fps is (10 sec: 102.7, 60 sec: 93.9, 300 sec: 94.8). Total num frames: 23552. Throughput: 0: 95.1. Samples: 23800. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 11:12:57,386][26754] Avg episode reward: [(0, '-143.480')]
[37m[265712 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[268668 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[269097 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:13:02,383][26754] Fps is (10 sec: 102.6, 60 sec: 93.9, 300 sec: 94.9). Total num frames: 24064. Throughput: 0: 94.8. Samples: 24380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:13:02,383][26754] Avg episode reward: [(0, '-140.692')]
[37m[269513 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[272154 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[274117 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:13:07,407][26754] Fps is (10 sec: 102.2, 60 sec: 93.8, 300 sec: 95.1). Total num frames: 24576. Throughput: 0: 94.7. Samples: 24676. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 11:13:07,407][26754] Avg episode reward: [(0, '-141.846')]
[37m[274768 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[276213 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[277950 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[278940 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:13:12,401][26754] Fps is (10 sec: 102.2, 60 sec: 93.9, 300 sec: 95.2). Total num frames: 25088. Throughput: 0: 95.7. Samples: 25276. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:13:12,401][26754] Avg episode reward: [(0, '-139.333')]
[37m[279482 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[281101 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[282147 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:13:17,383][26754] Fps is (10 sec: 102.6, 60 sec: 93.9, 300 sec: 95.3). Total num frames: 25600. Throughput: 0: 96.9. Samples: 25868. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 11:13:17,384][26754] Avg episode reward: [(0, '-137.201')]
[37m[285457 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[286035 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[286278 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[287366 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[287797 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[288304 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:13:22,395][26754] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 95.5). Total num frames: 26112. Throughput: 0: 96.7. Samples: 26124. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-03 11:13:22,396][26754] Avg episode reward: [(0, '-134.753')]
[37m[290281 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[290900 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[293617 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[293886 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[293937 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:13:27,376][26754] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 95.6). Total num frames: 26624. Throughput: 0: 96.4. Samples: 26704. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 11:13:27,376][26754] Avg episode reward: [(0, '-136.086')]
[37m[295866 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[295919 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:13:32,379][26754] Fps is (10 sec: 102.6, 60 sec: 93.9, 300 sec: 95.7). Total num frames: 27136. Throughput: 0: 96.7. Samples: 27312. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 11:13:32,379][26754] Avg episode reward: [(0, '-134.495')]
[37m[299549 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[299782 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[300823 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[301648 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[304018 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[304106 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:13:37,395][26754] Fps is (10 sec: 102.2, 60 sec: 102.4, 300 sec: 95.8). Total num frames: 27648. Throughput: 0: 96.8. Samples: 27616. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 11:13:37,395][26754] Avg episode reward: [(0, '-131.616')]
[37m[305251 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[306187 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[1m[2025-07-03 11:13:40,658][26754] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 26754], exiting...
[37m[1m[2025-07-03 11:13:40,659][26754] Runner profile tree view:
[37m[1mmain_loop: 297.0372
[37m[1m[2025-07-03 11:13:40,659][26754] Collected {0: 27648}, FPS: 93.1