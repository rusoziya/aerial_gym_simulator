Importing module 'gym_38' (/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
[36m[2025-06-29 11:33:01,859][60274] Queried available GPUs: 0
[37m[1m[2025-06-29 11:33:01,859][60274] Environment var CUDA_VISIBLE_DEVICES is 0
PyTorch version 1.13.1
Device count 1
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
Warp 1.0.0-beta.5 initialized:
   CUDA Toolkit: 11.5, Driver: 12.4
   Devices:
     "cpu"    | x86_64
     "cuda:0" | NVIDIA GeForce RTX 4080 Laptop GPU (sm_89)
   Kernel cache: /home/ziyar/.cache/warp/1.0.0-beta.5
Registered dce_navigation_task in subprocess
[isaacgym:gymutil.py] Unknown args:  ['--env=dce_navigation_task', '--train_for_env_steps=100000000', '--experiment=team_entity_test', '--async_rl=True', '--use_env_info_cache=False', '--normalize_input=True']
Not connected to PVD
+++ Using GPU PhysX
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/utils/cpp_extension.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging  # type: ignore[attr-defined]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Using /home/ziyar/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
Emitting ninja build file /home/ziyar/.cache/torch_extensions/py38_cu117/gymtorch/build.ninja...
Building extension module gymtorch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module gymtorch...
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/graph.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping, Set, Iterable
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/readwrite/graphml.py:346: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  (np.int, "int"), (np.int8, "int"),
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/torch_utils.py:135: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  def get_axis_params(value, axis_idx, x_value=0., dtype=np.float, n_dims=3):
[31m[2209 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - CRITICAL : Setting number of environments to 4 for parallel training. (dce_navigation_task.py:18)
[31m[2209 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - CRITICAL : Enabling viewer for visual training feedback. (dce_navigation_task.py:34)
[37m[2209 ms][base_task] - INFO : Setting seed: 1124675751 (base_task.py:38)
[37m[2210 ms][navigation_task] - INFO : Building environment for navigation task. (navigation_task.py:44)
[37m[2210 ms][navigation_task] - INFO : Sim Name: base_sim, Env Name: env_with_obstacles, Robot Name: lmf2, Controller Name: lmf2_velocity_control (navigation_task.py:45)
[37m[2210 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[2210 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[2210 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[2210 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[2210 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[2210 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[2211 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[2211 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[2211 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[2211 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[2211 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[2211 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[2211 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[37m[3364 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[3364 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[3641 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[3641 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[3641 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[3641 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[3641 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[3641 ms][BaseRobot] - INFO : Initializing controller lmf2_velocity_control (base_robot.py:29)
[33m[3641 ms][base_multirotor] - WARNING : Creating 4 multirotors. (base_multirotor.py:32)
[37m[3641 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[3642 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[3642 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3642 ms][asset_loader] - INFO : Loading asset: panel.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3644 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3646 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3647 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3650 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3651 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3652 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3654 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3655 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3656 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3657 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3658 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3660 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[4085 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[4085 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[4085 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[4093 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[4100 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[4100 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[4203 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[4203 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[4232 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 9 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.96 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 8.38 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 14.61 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 6.57 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[33m[4449 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[4450 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[36m[2025-06-29 11:33:07,219][60389] Env info: EnvInfo(obs_space=Dict('image_obs': Box(-1.0, 1.0, (1, 135, 240), float32), 'observations': Box(-1.0, 1.0, (81,), float32)), action_space=Box(-1.0, 1.0, (4,), float32), num_agents=4, gpu_actions=True, gpu_observations=True, action_splits=None, all_discrete=None, frameskip=1, reward_shaping_scheme=None, env_info_protocol_version=1)
[36m[2025-06-29 11:33:08,171][60274] Automatically setting recurrence to 32
[33m[2025-06-29 11:33:08,172][60274] In serial mode all components run on the same process. Only use async_rl and serial mode together for debugging.
[36m[2025-06-29 11:33:08,172][60274] Starting experiment with the following configuration:
[36mhelp=False
[36malgo=APPO
[36menv=dce_navigation_task
[36mexperiment=team_entity_test
[36mtrain_dir=/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir
[36mrestart_behavior=overwrite
[36mdevice=gpu
[36mseed=None
[36mnum_policies=1
[36masync_rl=True
[36mserial_mode=True
[36mbatched_sampling=True
[36mnum_batches_to_accumulate=2
[36mworker_num_splits=1
[36mpolicy_workers_per_policy=1
[36mmax_policy_lag=1000
[36mnum_workers=1
[36mnum_envs_per_worker=1
[36mbatch_size=1024
[36mnum_batches_per_epoch=4
[36mnum_epochs=4
[36mrollout=32
[36mrecurrence=32
[36mshuffle_minibatches=True
[36mgamma=0.98
[36mreward_scale=0.1
[36mreward_clip=1000.0
[36mvalue_bootstrap=True
[36mnormalize_returns=True
[36mexploration_loss_coeff=0.0
[36mvalue_loss_coeff=2.0
[36mkl_loss_coeff=0.1
[36mexploration_loss=entropy
[36mgae_lambda=0.95
[36mppo_clip_ratio=0.2
[36mppo_clip_value=1.0
[36mwith_vtrace=False
[36mvtrace_rho=1.0
[36mvtrace_c=1.0
[36moptimizer=adam
[36madam_eps=1e-06
[36madam_beta1=0.9
[36madam_beta2=0.999
[36mmax_grad_norm=1.0
[36mlearning_rate=0.0001
[36mlr_schedule=kl_adaptive_epoch
[36mlr_schedule_kl_threshold=0.016
[36mlr_adaptive_min=1e-06
[36mlr_adaptive_max=0.01
[36mobs_subtract_mean=0.0
[36mobs_scale=1.0
[36mnormalize_input=True
[36mnormalize_input_keys=None
[36mdecorrelate_experience_max_seconds=0
[36mdecorrelate_envs_on_one_worker=True
[36mactor_worker_gpus=[0]
[36mset_workers_cpu_affinity=True
[36mforce_envs_single_thread=False
[36mdefault_niceness=0
[36mlog_to_file=True
[36mexperiment_summaries_interval=10
[36mflush_summaries_interval=30
[36mstats_avg=100
[36msummaries_use_frameskip=True
[36mheartbeat_interval=20
[36mheartbeat_reporting_interval=180
[36mtrain_for_env_steps=100000000
[36mtrain_for_seconds=10000000000
[36msave_every_sec=120
[36mkeep_checkpoints=2
[36mload_checkpoint_kind=latest
[36msave_milestones_sec=-1
[36msave_best_every_sec=5
[36msave_best_metric=reward
[36msave_best_after=1000000
[36mbenchmark=False
[36mencoder_mlp_layers=[256, 128, 64]
[36mencoder_conv_architecture=convnet_simple
[36mencoder_conv_mlp_layers=[512]
[36muse_rnn=True
[36mrnn_size=64
[36mrnn_type=gru
[36mrnn_num_layers=1
[36mdecoder_mlp_layers=[]
[36mnonlinearity=elu
[36mpolicy_initialization=torch_default
[36mpolicy_init_gain=1.0
[36mactor_critic_share_weights=True
[36madaptive_stddev=True
[36mcontinuous_tanh_scale=0.0
[36minitial_stddev=1.0
[36muse_env_info_cache=False
[36menv_gpu_actions=True
[36menv_gpu_observations=True
[36menv_frameskip=1
[36menv_framestack=1
[36mpixel_format=CHW
[36muse_record_episode_statistics=False
[36mwith_wandb=True
[36mwandb_user=ziya-ruso-ucl
[36mwandb_project=aerialgym-dce-navigation
[36mwandb_group=dce_navigation_training
[36mwandb_job_type=SF
[36mwandb_tags=['aerial_gym', 'dce', 'navigation', 'sample_factory']
[36mwith_pbt=False
[36mpbt_mix_policies_in_one_env=True
[36mpbt_period_env_steps=5000000
[36mpbt_start_mutation=20000000
[36mpbt_replace_fraction=0.3
[36mpbt_mutation_rate=0.15
[36mpbt_replace_reward_gap=0.1
[36mpbt_replace_reward_gap_absolute=1e-06
[36mpbt_optimize_gamma=False
[36mpbt_target_objective=true_objective
[36mpbt_perturb_min=1.1
[36mpbt_perturb_max=1.5
[36menv_agents=-1
[36mobs_key=obs
[36msubtask=None
[36mige_api_version=preview4
[36meval_stats=False
[36mcommand_line=--env=dce_navigation_task --train_for_env_steps=100000000 --experiment=team_entity_test --async_rl=True --use_env_info_cache=False --normalize_input=True
[36mcli_args={'env': 'dce_navigation_task', 'experiment': 'team_entity_test', 'async_rl': True, 'normalize_input': True, 'train_for_env_steps': 100000000, 'use_env_info_cache': False}
[36mgit_hash=7f35eed17f2afcde33e3a7aec669b48e9e8e34cd
[36mgit_repo_name=https://github.com/ntnu-arl/aerial_gym_simulator.git
[36mwandb_unique_id=team_entity_test_20250629_113258_278340
[36m[2025-06-29 11:33:08,173][60274] Saving configuration to /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/config.json...
[36m[2025-06-29 11:33:08,235][60274] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-06-29 11:33:08,235][60274] Rollout worker 0 uses device cuda:0
[36m[2025-06-29 11:33:08,576][60274] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-06-29 11:33:08,576][60274] InferenceWorker_p0-w0: min num requests: 1
[36m[2025-06-29 11:33:08,577][60274] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-06-29 11:33:08,578][60274] Starting seed is not provided
[36m[2025-06-29 11:33:08,578][60274] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-06-29 11:33:08,578][60274] Initializing actor-critic model on device cuda:0
[36m[2025-06-29 11:33:08,579][60274] RunningMeanStd input shape: (1, 135, 240)
[36m[2025-06-29 11:33:08,579][60274] RunningMeanStd input shape: (81,)
[36m[2025-06-29 11:33:08,580][60274] RunningMeanStd input shape: (1,)
[36m[2025-06-29 11:33:08,590][60274] ConvEncoder: input_channels=1
[36m[2025-06-29 11:33:08,685][60274] Conv encoder output size: 512
[36m[2025-06-29 11:33:08,700][60274] Created Actor Critic model with architecture:
[36m[2025-06-29 11:33:08,700][60274] ActorCriticSharedWeights(
[36m  (obs_normalizer): ObservationNormalizer(
[36m    (running_mean_std): RunningMeanStdDictInPlace(
[36m      (running_mean_std): ModuleDict(
[36m        (image_obs): RunningMeanStdInPlace()
[36m        (observations): RunningMeanStdInPlace()
[36m      )
[36m    )
[36m  )
[36m  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
[36m  (encoder): CustomEncoder(
[36m    (encoders): ModuleDict(
[36m      (image_obs): ConvEncoder(
[36m        (enc): RecursiveScriptModule(
[36m          original_name=ConvEncoderImpl
[36m          (conv_head): RecursiveScriptModule(
[36m            original_name=Sequential
[36m            (0): RecursiveScriptModule(original_name=Conv2d)
[36m            (1): RecursiveScriptModule(original_name=ELU)
[36m            (2): RecursiveScriptModule(original_name=Conv2d)
[36m            (3): RecursiveScriptModule(original_name=ELU)
[36m            (4): RecursiveScriptModule(original_name=Conv2d)
[36m            (5): RecursiveScriptModule(original_name=ELU)
[36m          )
[36m          (mlp_layers): RecursiveScriptModule(
[36m            original_name=Sequential
[36m            (0): RecursiveScriptModule(original_name=Linear)
[36m            (1): RecursiveScriptModule(original_name=ELU)
[36m          )
[36m        )
[36m      )
[36m    )
[36m    (mlp_head_custom): RecursiveScriptModule(
[36m      original_name=Sequential
[36m      (0): RecursiveScriptModule(original_name=Linear)
[36m      (1): RecursiveScriptModule(original_name=ELU)
[36m      (2): RecursiveScriptModule(original_name=Linear)
[36m      (3): RecursiveScriptModule(original_name=ELU)
[36m      (4): RecursiveScriptModule(original_name=Linear)
[36m      (5): RecursiveScriptModule(original_name=ELU)
[36m    )
[36m  )
[36m  (core): ModelCoreRNN(
[36m    (core): GRU(64, 64)
[36m  )
[36m  (decoder): MlpDecoder(
[36m    (mlp): Identity()
[36m  )
[36m  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
[36m  (action_parameterization): ActionParameterizationDefault(
[36m    (distribution_linear): Linear(in_features=64, out_features=8, bias=True)
[36m  )
[36m)
[36m[2025-06-29 11:33:09,197][60274] Using optimizer <class 'torch.optim.adam.Adam'>
[33m[2025-06-29 11:33:09,198][60274] No checkpoints found
[36m[2025-06-29 11:33:09,198][60274] Did not load from checkpoint, starting from scratch!
[36m[2025-06-29 11:33:09,198][60274] Initialized policy 0 weights for model version 0
[36m[2025-06-29 11:33:09,198][60274] LearnerWorker_p0 finished initialization!
[36m[2025-06-29 11:33:09,198][60274] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-06-29 11:33:09,525][60274] Inference worker 0-0 is ready!
[37m[1m[2025-06-29 11:33:09,525][60274] All inference workers are ready! Signal rollout workers to start!
[36m[2025-06-29 11:33:09,526][60274] EnvRunner 0-0 uses policy 0
[31m[14751 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - CRITICAL : Setting number of environments to 4 for parallel training. (dce_navigation_task.py:18)
[31m[14751 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - CRITICAL : Enabling viewer for visual training feedback. (dce_navigation_task.py:34)
[37m[14751 ms][base_task] - INFO : Setting seed: 2060365981 (base_task.py:38)
[37m[14752 ms][navigation_task] - INFO : Building environment for navigation task. (navigation_task.py:44)
[37m[14752 ms][navigation_task] - INFO : Sim Name: base_sim, Env Name: env_with_obstacles, Robot Name: lmf2, Controller Name: lmf2_velocity_control (navigation_task.py:45)
[37m[14752 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[14752 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[14752 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[14752 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[14752 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[14752 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[14753 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[14753 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[14753 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[14753 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[14753 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[14753 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[14753 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[isaacgym:gymutil.py] Unknown args:  ['--env=dce_navigation_task', '--train_for_env_steps=100000000', '--experiment=team_entity_test', '--async_rl=True', '--use_env_info_cache=False', '--normalize_input=True']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 2.05 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 8.96 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 13.01 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 6.42 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[37m[15879 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[15884 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[16110 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[16111 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[16111 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[16111 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[16111 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[16111 ms][BaseRobot] - INFO : Initializing controller lmf2_velocity_control (base_robot.py:29)
[33m[16111 ms][base_multirotor] - WARNING : Creating 4 multirotors. (base_multirotor.py:32)
[37m[16111 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[16111 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[16111 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16112 ms][asset_loader] - INFO : Loading asset: panel.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16115 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16118 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16120 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16121 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16122 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16124 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16125 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16127 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16128 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16130 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16131 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[16133 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[16155 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[16155 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[16155 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[16163 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[16170 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[16170 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[16278 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[16278 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[16302 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 9 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[16530 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[16531 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[36m[2025-06-29 11:33:12,299][60274] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[31m[19621 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[19622 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0, 1, 2, 3], device='cuda:0') (navigation_task.py:196)
[31m[19622 ms][navigation_task] - CRITICAL : Time at crash: tensor([1, 1, 1, 1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 11:33:16,016][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 3.2. Samples: 12. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:33:16,017][60274] Avg episode reward: [(0, '-100.000')]
[36m[2025-06-29 11:33:20,991][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 12.0. Samples: 104. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:33:20,991][60274] Avg episode reward: [(0, '-91.918')]
[36m[2025-06-29 11:33:26,020][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 27.1. Samples: 372. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:33:26,021][60274] Avg episode reward: [(0, '-95.041')]
[37m[1m[2025-06-29 11:33:28,670][60274] Heartbeat connected on Batcher_0
[37m[1m[2025-06-29 11:33:28,670][60274] Heartbeat connected on LearnerWorker_p0
[37m[1m[2025-06-29 11:33:28,671][60274] Heartbeat connected on InferenceWorker_p0-w0
[37m[1m[2025-06-29 11:33:28,671][60274] Heartbeat connected on RolloutWorker_w0
[36m[2025-06-29 11:33:31,035][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 35.7. Samples: 668. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:33:31,036][60274] Avg episode reward: [(0, '-94.725')]
[36m[2025-06-29 11:33:35,971][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 34.3. Samples: 812. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:33:35,971][60274] Avg episode reward: [(0, '-96.553')]
[36m[2025-06-29 11:33:41,003][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 38.7. Samples: 1112. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:33:41,004][60274] Avg episode reward: [(0, '-95.792')]
[36m[2025-06-29 11:33:46,013][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 41.5. Samples: 1400. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:33:46,014][60274] Avg episode reward: [(0, '-97.304')]
[36m[2025-06-29 11:33:50,994][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 41.1. Samples: 1592. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:33:50,994][60274] Avg episode reward: [(0, '-96.103')]
[36m[2025-06-29 11:33:56,004][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 44.3. Samples: 1936. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:33:56,004][60274] Avg episode reward: [(0, '-95.435')]
[36m[2025-06-29 11:34:00,966][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 49.7. Samples: 2248. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:34:00,966][60274] Avg episode reward: [(0, '-96.774')]
[36m[2025-06-29 11:34:05,960][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 51.4. Samples: 2416. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:34:05,960][60274] Avg episode reward: [(0, '-97.645')]
[36m[2025-06-29 11:34:10,953][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 55.2. Samples: 2852. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:34:10,953][60274] Avg episode reward: [(0, '-97.339')]
[36m[2025-06-29 11:34:15,986][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 58.2. Samples: 3284. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:34:15,986][60274] Avg episode reward: [(0, '-98.614')]
[36m[2025-06-29 11:34:20,974][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 60.4. Samples: 3528. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-06-29 11:34:20,974][60274] Avg episode reward: [(0, '-98.643')]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/nn/modules/module.py:1194: UserWarning: operator() profile_node %104 : int[] = prim::profile_ivalue(%102)
 does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)
  return forward_call(*input, **kwargs)
[36m[2025-06-29 11:34:26,743][60274] Fps is (10 sec: 380.8, 60 sec: 67.5, 300 sec: 55.0). Total num frames: 4096. Throughput: 0: 63.8. Samples: 4028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:34:26,744][60274] Avg episode reward: [(0, '-97.422')]
[36m[2025-06-29 11:34:30,988][60274] Fps is (10 sec: 409.0, 60 sec: 68.3, 300 sec: 52.1). Total num frames: 4096. Throughput: 0: 66.2. Samples: 4376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:34:30,989][60274] Avg episode reward: [(0, '-99.869')]
[31m[99883 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[99883 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[99883 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 11:34:35,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 48.9). Total num frames: 4096. Throughput: 0: 67.1. Samples: 4612. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:34:35,989][60274] Avg episode reward: [(0, '-98.881')]
[36m[2025-06-29 11:34:40,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 46.2). Total num frames: 4096. Throughput: 0: 70.4. Samples: 5104. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:34:40,997][60274] Avg episode reward: [(0, '-98.844')]
[36m[2025-06-29 11:34:45,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 43.7). Total num frames: 4096. Throughput: 0: 72.7. Samples: 5520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:34:45,984][60274] Avg episode reward: [(0, '-98.307')]
[36m[2025-06-29 11:34:50,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 41.5). Total num frames: 4096. Throughput: 0: 72.9. Samples: 5700. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:34:50,985][60274] Avg episode reward: [(0, '-98.572')]
[36m[2025-06-29 11:34:56,019][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 39.5). Total num frames: 4096. Throughput: 0: 71.2. Samples: 6060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:34:56,020][60274] Avg episode reward: [(0, '-99.072')]
[36m[2025-06-29 11:35:00,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 37.7). Total num frames: 4096. Throughput: 0: 69.5. Samples: 6408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:35:00,964][60274] Avg episode reward: [(0, '-99.341')]
[37m[1m[2025-06-29 11:35:01,032][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000016_4096.pth...
[36m[2025-06-29 11:35:05,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 36.0). Total num frames: 4096. Throughput: 0: 68.0. Samples: 6588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:35:05,951][60274] Avg episode reward: [(0, '-98.481')]
[36m[2025-06-29 11:35:10,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 34.5). Total num frames: 4096. Throughput: 0: 68.8. Samples: 7072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:35:10,983][60274] Avg episode reward: [(0, '-98.356')]
[36m[2025-06-29 11:35:15,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 33.1). Total num frames: 4096. Throughput: 0: 69.6. Samples: 7508. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:35:15,961][60274] Avg episode reward: [(0, '-98.045')]
[36m[2025-06-29 11:35:20,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 31.8). Total num frames: 4096. Throughput: 0: 69.1. Samples: 7720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:35:20,975][60274] Avg episode reward: [(0, '-98.291')]
[36m[2025-06-29 11:35:26,226][60274] Fps is (10 sec: 399.0, 60 sec: 68.9, 300 sec: 61.2). Total num frames: 8192. Throughput: 0: 67.3. Samples: 8148. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:35:26,227][60274] Avg episode reward: [(0, '-99.152')]
[36m[2025-06-29 11:35:30,959][60274] Fps is (10 sec: 410.2, 60 sec: 68.3, 300 sec: 59.1). Total num frames: 8192. Throughput: 0: 66.4. Samples: 8508. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:35:30,960][60274] Avg episode reward: [(0, '-98.069')]
[36m[2025-06-29 11:35:35,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 57.0). Total num frames: 8192. Throughput: 0: 67.3. Samples: 8728. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:35:35,951][60274] Avg episode reward: [(0, '-98.168')]
[36m[2025-06-29 11:35:40,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.1). Total num frames: 8192. Throughput: 0: 68.8. Samples: 9152. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:35:40,949][60274] Avg episode reward: [(0, '-97.468')]
[36m[2025-06-29 11:35:45,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 53.3). Total num frames: 8192. Throughput: 0: 70.6. Samples: 9584. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:35:45,967][60274] Avg episode reward: [(0, '-98.294')]
[36m[2025-06-29 11:35:50,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 51.6). Total num frames: 8192. Throughput: 0: 71.4. Samples: 9804. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:35:50,974][60274] Avg episode reward: [(0, '-98.839')]
[36m[2025-06-29 11:35:55,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 50.1). Total num frames: 8192. Throughput: 0: 71.3. Samples: 10280. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:35:55,974][60274] Avg episode reward: [(0, '-98.262')]
[36m[2025-06-29 11:36:00,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 48.6). Total num frames: 8192. Throughput: 0: 71.5. Samples: 10728. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:36:00,983][60274] Avg episode reward: [(0, '-98.666')]
[36m[2025-06-29 11:36:06,033][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 47.2). Total num frames: 8192. Throughput: 0: 71.6. Samples: 10944. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:36:06,034][60274] Avg episode reward: [(0, '-98.836')]
[31m[195107 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[195107 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[195108 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 11:36:10,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 45.9). Total num frames: 8192. Throughput: 0: 72.4. Samples: 11388. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:36:10,963][60274] Avg episode reward: [(0, '-97.603')]
[36m[2025-06-29 11:36:16,049][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 44.6). Total num frames: 8192. Throughput: 0: 73.1. Samples: 11804. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:36:16,049][60274] Avg episode reward: [(0, '-97.899')]
[36m[2025-06-29 11:36:20,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 43.4). Total num frames: 8192. Throughput: 0: 72.7. Samples: 12004. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 11:36:20,983][60274] Avg episode reward: [(0, '-97.564')]
[36m[2025-06-29 11:36:26,015][60274] Fps is (10 sec: 411.0, 60 sec: 68.5, 300 sec: 63.4). Total num frames: 12288. Throughput: 0: 72.0. Samples: 12396. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 11:36:26,015][60274] Avg episode reward: [(0, '-96.873')]
[36m[2025-06-29 11:36:30,990][60274] Fps is (10 sec: 409.3, 60 sec: 68.2, 300 sec: 61.8). Total num frames: 12288. Throughput: 0: 71.9. Samples: 12820. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 11:36:30,990][60274] Avg episode reward: [(0, '-99.272')]
[36m[2025-06-29 11:36:35,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 60.3). Total num frames: 12288. Throughput: 0: 71.6. Samples: 13028. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 11:36:35,981][60274] Avg episode reward: [(0, '-98.802')]
[36m[2025-06-29 11:36:40,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 58.9). Total num frames: 12288. Throughput: 0: 72.1. Samples: 13524. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 11:36:40,970][60274] Avg episode reward: [(0, '-98.383')]
[36m[2025-06-29 11:36:45,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 57.5). Total num frames: 12288. Throughput: 0: 73.3. Samples: 14024. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 11:36:45,956][60274] Avg episode reward: [(0, '-97.338')]
[36m[2025-06-29 11:36:50,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 56.2). Total num frames: 12288. Throughput: 0: 74.0. Samples: 14272. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 11:36:50,982][60274] Avg episode reward: [(0, '-98.644')]
[36m[2025-06-29 11:36:55,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 54.9). Total num frames: 12288. Throughput: 0: 74.8. Samples: 14756. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 11:36:55,973][60274] Avg episode reward: [(0, '-97.065')]
[36m[2025-06-29 11:37:00,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 53.7). Total num frames: 12288. Throughput: 0: 76.3. Samples: 15232. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 11:37:00,966][60274] Avg episode reward: [(0, '-98.155')]
[37m[1m[2025-06-29 11:37:01,015][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000048_12288.pth...
[36m[2025-06-29 11:37:05,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 52.6). Total num frames: 12288. Throughput: 0: 77.2. Samples: 15476. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 11:37:05,974][60274] Avg episode reward: [(0, '-96.829')]
[36m[2025-06-29 11:37:10,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 51.5). Total num frames: 12288. Throughput: 0: 79.1. Samples: 15952. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 11:37:10,961][60274] Avg episode reward: [(0, '-97.661')]
[36m[2025-06-29 11:37:15,965][60274] Fps is (10 sec: 410.0, 60 sec: 136.7, 300 sec: 67.2). Total num frames: 16384. Throughput: 0: 79.4. Samples: 16392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:37:15,966][60274] Avg episode reward: [(0, '-98.021')]
[36m[2025-06-29 11:37:20,982][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 65.9). Total num frames: 16384. Throughput: 0: 79.6. Samples: 16612. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:37:20,982][60274] Avg episode reward: [(0, '-97.398')]
[36m[2025-06-29 11:37:25,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 64.6). Total num frames: 16384. Throughput: 0: 79.2. Samples: 17088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:37:25,973][60274] Avg episode reward: [(0, '-96.480')]
[36m[2025-06-29 11:37:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 63.3). Total num frames: 16384. Throughput: 0: 78.8. Samples: 17572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:37:30,989][60274] Avg episode reward: [(0, '-96.788')]
[36m[2025-06-29 11:37:35,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 62.1). Total num frames: 16384. Throughput: 0: 78.8. Samples: 17816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:37:35,978][60274] Avg episode reward: [(0, '-97.495')]
[36m[2025-06-29 11:37:40,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 61.0). Total num frames: 16384. Throughput: 0: 78.6. Samples: 18292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:37:40,982][60274] Avg episode reward: [(0, '-99.651')]
[36m[2025-06-29 11:37:45,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 59.9). Total num frames: 16384. Throughput: 0: 78.5. Samples: 18764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:37:45,951][60274] Avg episode reward: [(0, '-96.708')]
[36m[2025-06-29 11:37:50,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 58.8). Total num frames: 16384. Throughput: 0: 78.4. Samples: 19004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:37:50,987][60274] Avg episode reward: [(0, '-98.651')]
[36m[2025-06-29 11:37:55,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 57.8). Total num frames: 16384. Throughput: 0: 78.4. Samples: 19480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:37:55,985][60274] Avg episode reward: [(0, '-97.319')]
[36m[2025-06-29 11:38:00,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 56.8). Total num frames: 16384. Throughput: 0: 79.2. Samples: 19956. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:00,989][60274] Avg episode reward: [(0, '-97.550')]
[36m[2025-06-29 11:38:05,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.8). Total num frames: 16384. Throughput: 0: 79.6. Samples: 20192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:05,978][60274] Avg episode reward: [(0, '-96.816')]
[31m[316192 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[316193 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[316193 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 11:38:10,974][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 69.4). Total num frames: 20480. Throughput: 0: 77.7. Samples: 20584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:10,974][60274] Avg episode reward: [(0, '-97.766')]
[31m[320075 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[320075 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[320075 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 11:38:16,003][60274] Fps is (10 sec: 408.6, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 20480. Throughput: 0: 77.9. Samples: 21080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:16,003][60274] Avg episode reward: [(0, '-97.180')]
[31m[321645 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[321645 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[321645 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 11:38:20,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 20480. Throughput: 0: 78.3. Samples: 21340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:20,967][60274] Avg episode reward: [(0, '-96.709')]
[36m[2025-06-29 11:38:25,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 20480. Throughput: 0: 78.8. Samples: 21836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:25,960][60274] Avg episode reward: [(0, '-95.965')]
[36m[2025-06-29 11:38:30,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 20480. Throughput: 0: 79.2. Samples: 22328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:30,956][60274] Avg episode reward: [(0, '-94.064')]
[36m[2025-06-29 11:38:35,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 20480. Throughput: 0: 79.1. Samples: 22560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:35,958][60274] Avg episode reward: [(0, '-94.057')]
[31m[343400 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[343401 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[343401 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 11:38:40,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 20480. Throughput: 0: 79.4. Samples: 23052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:40,973][60274] Avg episode reward: [(0, '-93.650')]
[36m[2025-06-29 11:38:45,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 20480. Throughput: 0: 79.7. Samples: 23540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:45,953][60274] Avg episode reward: [(0, '-93.051')]
[36m[2025-06-29 11:38:50,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 20480. Throughput: 0: 79.8. Samples: 23780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:50,969][60274] Avg episode reward: [(0, '-93.155')]
[36m[2025-06-29 11:38:55,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 20480. Throughput: 0: 81.5. Samples: 24248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:38:55,954][60274] Avg episode reward: [(0, '-94.383')]
[36m[2025-06-29 11:39:00,978][60274] Fps is (10 sec: 409.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 24576. Throughput: 0: 80.1. Samples: 24684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:39:00,979][60274] Avg episode reward: [(0, '-93.173')]
[37m[1m[2025-06-29 11:39:01,042][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000096_24576.pth...
[36m[2025-06-29 11:39:01,097][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000016_4096.pth
[36m[2025-06-29 11:39:05,965][60274] Fps is (10 sec: 409.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 24576. Throughput: 0: 79.7. Samples: 24928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:39:05,966][60274] Avg episode reward: [(0, '-93.971')]
[36m[2025-06-29 11:39:10,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 24576. Throughput: 0: 79.2. Samples: 25404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:39:10,986][60274] Avg episode reward: [(0, '-92.053')]
[36m[2025-06-29 11:39:15,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 24576. Throughput: 0: 79.9. Samples: 25924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:39:15,984][60274] Avg episode reward: [(0, '-92.061')]
[36m[2025-06-29 11:39:20,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.6). Total num frames: 24576. Throughput: 0: 79.8. Samples: 26156. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:39:20,996][60274] Avg episode reward: [(0, '-92.770')]
[36m[2025-06-29 11:39:25,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 24576. Throughput: 0: 80.2. Samples: 26664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:39:25,993][60274] Avg episode reward: [(0, '-94.992')]
[36m[2025-06-29 11:39:30,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 24576. Throughput: 0: 79.7. Samples: 27128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:39:30,979][60274] Avg episode reward: [(0, '-95.293')]
[36m[2025-06-29 11:39:35,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 24576. Throughput: 0: 80.0. Samples: 27380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:39:35,969][60274] Avg episode reward: [(0, '-93.529')]
[36m[2025-06-29 11:39:40,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 24576. Throughput: 0: 80.2. Samples: 27860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:39:40,964][60274] Avg episode reward: [(0, '-93.359')]
[36m[2025-06-29 11:39:45,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 24576. Throughput: 0: 81.1. Samples: 28336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:39:45,985][60274] Avg episode reward: [(0, '-93.119')]
[36m[2025-06-29 11:39:50,962][60274] Fps is (10 sec: 409.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 28672. Throughput: 0: 81.4. Samples: 28592. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 11:39:50,962][60274] Avg episode reward: [(0, '-93.781')]
[36m[2025-06-29 11:39:55,984][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 28672. Throughput: 0: 80.8. Samples: 29040. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 11:39:55,985][60274] Avg episode reward: [(0, '-91.243')]
[36m[2025-06-29 11:40:00,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 28672. Throughput: 0: 80.0. Samples: 29524. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 11:40:00,978][60274] Avg episode reward: [(0, '-91.524')]
[36m[2025-06-29 11:40:06,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 28672. Throughput: 0: 80.5. Samples: 29780. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 11:40:06,004][60274] Avg episode reward: [(0, '-92.203')]
[36m[2025-06-29 11:40:10,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 28672. Throughput: 0: 79.6. Samples: 30248. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 11:40:10,997][60274] Avg episode reward: [(0, '-89.698')]
[36m[2025-06-29 11:40:15,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 28672. Throughput: 0: 80.8. Samples: 30760. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 11:40:15,955][60274] Avg episode reward: [(0, '-89.666')]
[36m[2025-06-29 11:40:20,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 28672. Throughput: 0: 80.9. Samples: 31020. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 11:40:20,956][60274] Avg episode reward: [(0, '-89.758')]
[36m[2025-06-29 11:40:25,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 28672. Throughput: 0: 81.5. Samples: 31528. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 11:40:25,967][60274] Avg episode reward: [(0, '-88.816')]
[36m[2025-06-29 11:40:30,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 28672. Throughput: 0: 81.8. Samples: 32016. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 11:40:30,958][60274] Avg episode reward: [(0, '-91.069')]
[36m[2025-06-29 11:40:35,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 28672. Throughput: 0: 81.4. Samples: 32256. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 11:40:35,956][60274] Avg episode reward: [(0, '-91.081')]
[36m[2025-06-29 11:40:40,977][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 32768. Throughput: 0: 82.5. Samples: 32752. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 11:40:40,977][60274] Avg episode reward: [(0, '-91.294')]
[36m[2025-06-29 11:40:45,984][60274] Fps is (10 sec: 408.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 32768. Throughput: 0: 81.6. Samples: 33196. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 11:40:45,985][60274] Avg episode reward: [(0, '-91.968')]
[36m[2025-06-29 11:40:50,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 32768. Throughput: 0: 81.2. Samples: 33432. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 11:40:50,993][60274] Avg episode reward: [(0, '-91.196')]
[36m[2025-06-29 11:40:55,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 32768. Throughput: 0: 81.6. Samples: 33916. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 11:40:55,957][60274] Avg episode reward: [(0, '-91.296')]
[36m[2025-06-29 11:41:00,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 32768. Throughput: 0: 80.8. Samples: 34396. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 11:41:00,977][60274] Avg episode reward: [(0, '-91.727')]
[37m[1m[2025-06-29 11:41:01,031][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000128_32768.pth...
[36m[2025-06-29 11:41:01,089][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000048_12288.pth
[36m[2025-06-29 11:41:06,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 32768. Throughput: 0: 80.4. Samples: 34640. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 11:41:06,000][60274] Avg episode reward: [(0, '-95.869')]
[36m[2025-06-29 11:41:10,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 32768. Throughput: 0: 80.2. Samples: 35136. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 11:41:10,957][60274] Avg episode reward: [(0, '-93.371')]
[36m[2025-06-29 11:41:15,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 32768. Throughput: 0: 80.5. Samples: 35640. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 11:41:15,982][60274] Avg episode reward: [(0, '-94.617')]
[36m[2025-06-29 11:41:20,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 32768. Throughput: 0: 80.3. Samples: 35868. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 11:41:20,947][60274] Avg episode reward: [(0, '-94.949')]
[36m[2025-06-29 11:41:25,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 32768. Throughput: 0: 80.3. Samples: 36364. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 11:41:25,952][60274] Avg episode reward: [(0, '-94.017')]
[36m[2025-06-29 11:41:31,294][60274] Fps is (10 sec: 395.9, 60 sec: 135.8, 300 sec: 83.2). Total num frames: 36864. Throughput: 0: 80.5. Samples: 36844. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:41:31,295][60274] Avg episode reward: [(0, '-88.861')]
[36m[2025-06-29 11:41:35,955][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 36864. Throughput: 0: 80.1. Samples: 37032. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:41:35,955][60274] Avg episode reward: [(0, '-89.440')]
[36m[2025-06-29 11:41:41,009][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 36864. Throughput: 0: 79.8. Samples: 37512. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:41:41,010][60274] Avg episode reward: [(0, '-87.584')]
[36m[2025-06-29 11:41:45,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 36864. Throughput: 0: 80.2. Samples: 38004. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:41:45,980][60274] Avg episode reward: [(0, '-84.675')]
[36m[2025-06-29 11:41:50,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 36864. Throughput: 0: 80.2. Samples: 38244. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:41:50,959][60274] Avg episode reward: [(0, '-84.413')]
[36m[2025-06-29 11:41:55,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 36864. Throughput: 0: 79.9. Samples: 38732. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:41:55,989][60274] Avg episode reward: [(0, '-84.567')]
[36m[2025-06-29 11:42:00,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 36864. Throughput: 0: 79.4. Samples: 39212. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:42:00,981][60274] Avg episode reward: [(0, '-85.833')]
[36m[2025-06-29 11:42:05,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 36864. Throughput: 0: 79.6. Samples: 39452. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:42:05,983][60274] Avg episode reward: [(0, '-84.171')]
[36m[2025-06-29 11:42:10,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 36864. Throughput: 0: 79.7. Samples: 39952. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:42:10,952][60274] Avg episode reward: [(0, '-84.257')]
[36m[2025-06-29 11:42:15,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 36864. Throughput: 0: 80.8. Samples: 40452. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:42:15,956][60274] Avg episode reward: [(0, '-81.952')]
[36m[2025-06-29 11:42:20,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 36864. Throughput: 0: 81.2. Samples: 40688. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 11:42:20,988][60274] Avg episode reward: [(0, '-81.618')]
[36m[2025-06-29 11:42:25,970][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 40960. Throughput: 0: 80.3. Samples: 41124. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 11:42:25,970][60274] Avg episode reward: [(0, '-80.640')]
[36m[2025-06-29 11:42:30,946][60274] Fps is (10 sec: 411.3, 60 sec: 68.7, 300 sec: 83.3). Total num frames: 40960. Throughput: 0: 79.9. Samples: 41596. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 11:42:30,947][60274] Avg episode reward: [(0, '-78.703')]
[36m[2025-06-29 11:42:35,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 40960. Throughput: 0: 79.9. Samples: 41840. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 11:42:35,990][60274] Avg episode reward: [(0, '-80.787')]
[36m[2025-06-29 11:42:40,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 40960. Throughput: 0: 80.1. Samples: 42332. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 11:42:40,954][60274] Avg episode reward: [(0, '-83.285')]
[36m[2025-06-29 11:42:45,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 40960. Throughput: 0: 79.4. Samples: 42784. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 11:42:45,989][60274] Avg episode reward: [(0, '-78.958')]
[36m[2025-06-29 11:42:50,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 40960. Throughput: 0: 79.5. Samples: 43028. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 11:42:50,948][60274] Avg episode reward: [(0, '-82.465')]
[36m[2025-06-29 11:42:55,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 40960. Throughput: 0: 79.3. Samples: 43520. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 11:42:55,953][60274] Avg episode reward: [(0, '-80.223')]
[36m[2025-06-29 11:43:00,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 40960. Throughput: 0: 78.8. Samples: 43996. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 11:43:00,948][60274] Avg episode reward: [(0, '-82.554')]
[37m[1m[2025-06-29 11:43:00,998][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000160_40960.pth...
[36m[2025-06-29 11:43:01,062][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000096_24576.pth
[36m[2025-06-29 11:43:05,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 40960. Throughput: 0: 78.4. Samples: 44216. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 11:43:05,987][60274] Avg episode reward: [(0, '-79.016')]
[36m[2025-06-29 11:43:11,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 40960. Throughput: 0: 79.9. Samples: 44720. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 11:43:11,000][60274] Avg episode reward: [(0, '-80.287')]
[36m[2025-06-29 11:43:15,972][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 45056. Throughput: 0: 79.0. Samples: 45152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:43:15,972][60274] Avg episode reward: [(0, '-78.836')]
[36m[2025-06-29 11:43:20,964][60274] Fps is (10 sec: 411.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 45056. Throughput: 0: 79.1. Samples: 45396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:43:20,964][60274] Avg episode reward: [(0, '-79.608')]
[36m[2025-06-29 11:43:25,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 45056. Throughput: 0: 78.8. Samples: 45880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:43:25,964][60274] Avg episode reward: [(0, '-77.918')]
[36m[2025-06-29 11:43:30,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 45056. Throughput: 0: 79.4. Samples: 46356. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:43:30,978][60274] Avg episode reward: [(0, '-77.626')]
[36m[2025-06-29 11:43:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 45056. Throughput: 0: 79.5. Samples: 46608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:43:35,981][60274] Avg episode reward: [(0, '-78.108')]
[36m[2025-06-29 11:43:40,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 45056. Throughput: 0: 78.9. Samples: 47072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:43:40,975][60274] Avg episode reward: [(0, '-74.327')]
[36m[2025-06-29 11:43:45,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 45056. Throughput: 0: 79.6. Samples: 47576. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:43:45,949][60274] Avg episode reward: [(0, '-73.927')]
[36m[2025-06-29 11:43:50,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 45056. Throughput: 0: 80.2. Samples: 47824. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:43:50,973][60274] Avg episode reward: [(0, '-72.700')]
[36m[2025-06-29 11:43:56,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 45056. Throughput: 0: 79.9. Samples: 48316. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:43:56,005][60274] Avg episode reward: [(0, '-70.047')]
[36m[2025-06-29 11:44:00,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 45056. Throughput: 0: 81.3. Samples: 48808. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:44:00,949][60274] Avg episode reward: [(0, '-69.059')]
[36m[2025-06-29 11:44:05,975][60274] Fps is (10 sec: 410.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 49152. Throughput: 0: 81.5. Samples: 49064. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 11:44:05,975][60274] Avg episode reward: [(0, '-68.920')]
[36m[2025-06-29 11:44:10,955][60274] Fps is (10 sec: 409.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 49152. Throughput: 0: 80.8. Samples: 49516. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 11:44:10,955][60274] Avg episode reward: [(0, '-70.312')]
[36m[2025-06-29 11:44:15,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 49152. Throughput: 0: 80.9. Samples: 49996. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 11:44:15,976][60274] Avg episode reward: [(0, '-65.417')]
[36m[2025-06-29 11:44:20,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 49152. Throughput: 0: 80.9. Samples: 50244. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 11:44:20,948][60274] Avg episode reward: [(0, '-69.264')]
[36m[2025-06-29 11:44:25,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 49152. Throughput: 0: 81.4. Samples: 50736. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 11:44:25,989][60274] Avg episode reward: [(0, '-64.301')]
[36m[2025-06-29 11:44:30,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 49152. Throughput: 0: 80.6. Samples: 51204. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 11:44:30,988][60274] Avg episode reward: [(0, '-65.235')]
[36m[2025-06-29 11:44:35,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 49152. Throughput: 0: 80.8. Samples: 51460. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 11:44:35,948][60274] Avg episode reward: [(0, '-60.572')]
[36m[2025-06-29 11:44:40,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 49152. Throughput: 0: 80.7. Samples: 51944. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 11:44:40,961][60274] Avg episode reward: [(0, '-63.769')]
[36m[2025-06-29 11:44:45,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 49152. Throughput: 0: 80.5. Samples: 52432. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 11:44:45,976][60274] Avg episode reward: [(0, '-60.997')]
[36m[2025-06-29 11:44:50,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 49152. Throughput: 0: 80.2. Samples: 52672. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 11:44:50,975][60274] Avg episode reward: [(0, '-60.588')]
[36m[2025-06-29 11:44:56,216][60274] Fps is (10 sec: 400.0, 60 sec: 136.1, 300 sec: 83.2). Total num frames: 53248. Throughput: 0: 80.4. Samples: 53156. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:44:56,217][60274] Avg episode reward: [(0, '-59.008')]
[36m[2025-06-29 11:45:00,969][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 53248. Throughput: 0: 79.7. Samples: 53580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:45:00,969][60274] Avg episode reward: [(0, '-55.971')]
[37m[1m[2025-06-29 11:45:01,028][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000208_53248.pth...
[36m[2025-06-29 11:45:01,084][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000128_32768.pth
[36m[2025-06-29 11:45:05,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 53248. Throughput: 0: 79.1. Samples: 53804. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:45:05,957][60274] Avg episode reward: [(0, '-56.944')]
[36m[2025-06-29 11:45:10,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 53248. Throughput: 0: 79.2. Samples: 54296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:45:10,961][60274] Avg episode reward: [(0, '-53.537')]
[36m[2025-06-29 11:45:15,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 53248. Throughput: 0: 80.1. Samples: 54808. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:45:15,979][60274] Avg episode reward: [(0, '-48.448')]
[36m[2025-06-29 11:45:21,014][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 53248. Throughput: 0: 79.7. Samples: 55052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:45:21,015][60274] Avg episode reward: [(0, '-52.045')]
[36m[2025-06-29 11:45:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 53248. Throughput: 0: 79.7. Samples: 55532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:45:25,957][60274] Avg episode reward: [(0, '-51.147')]
[36m[2025-06-29 11:45:30,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 53248. Throughput: 0: 79.7. Samples: 56016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:45:30,960][60274] Avg episode reward: [(0, '-52.801')]
[36m[2025-06-29 11:45:35,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 53248. Throughput: 0: 79.9. Samples: 56264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:45:35,954][60274] Avg episode reward: [(0, '-54.353')]
[36m[2025-06-29 11:45:40,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 53248. Throughput: 0: 80.4. Samples: 56756. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:45:40,994][60274] Avg episode reward: [(0, '-54.279')]
[36m[2025-06-29 11:45:45,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 53248. Throughput: 0: 81.5. Samples: 57248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:45:45,962][60274] Avg episode reward: [(0, '-51.844')]
[36m[2025-06-29 11:45:50,949][60274] Fps is (10 sec: 411.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 57344. Throughput: 0: 81.0. Samples: 57448. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 11:45:50,949][60274] Avg episode reward: [(0, '-52.750')]
[36m[2025-06-29 11:45:55,961][60274] Fps is (10 sec: 409.6, 60 sec: 68.6, 300 sec: 83.3). Total num frames: 57344. Throughput: 0: 81.0. Samples: 57940. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 11:45:55,961][60274] Avg episode reward: [(0, '-48.332')]
[36m[2025-06-29 11:46:00,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 57344. Throughput: 0: 80.4. Samples: 58424. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 11:46:00,979][60274] Avg episode reward: [(0, '-48.564')]
[36m[2025-06-29 11:46:05,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 57344. Throughput: 0: 79.8. Samples: 58640. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 11:46:05,958][60274] Avg episode reward: [(0, '-49.356')]
[36m[2025-06-29 11:46:10,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 57344. Throughput: 0: 79.7. Samples: 59120. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 11:46:10,962][60274] Avg episode reward: [(0, '-47.885')]
[36m[2025-06-29 11:46:15,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 57344. Throughput: 0: 79.6. Samples: 59600. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 11:46:15,961][60274] Avg episode reward: [(0, '-47.204')]
[36m[2025-06-29 11:46:20,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 57344. Throughput: 0: 79.5. Samples: 59844. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 11:46:20,992][60274] Avg episode reward: [(0, '-46.054')]
[36m[2025-06-29 11:46:25,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 57344. Throughput: 0: 79.1. Samples: 60312. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 11:46:25,965][60274] Avg episode reward: [(0, '-43.482')]
[36m[2025-06-29 11:46:30,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 57344. Throughput: 0: 79.0. Samples: 60804. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 11:46:30,983][60274] Avg episode reward: [(0, '-46.471')]
[36m[2025-06-29 11:46:35,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 57344. Throughput: 0: 80.1. Samples: 61052. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 11:46:35,969][60274] Avg episode reward: [(0, '-43.170')]
[36m[2025-06-29 11:46:40,973][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 61440. Throughput: 0: 78.8. Samples: 61488. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:46:40,974][60274] Avg episode reward: [(0, '-44.927')]
[36m[2025-06-29 11:46:45,978][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 61440. Throughput: 0: 79.4. Samples: 61996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:46:45,979][60274] Avg episode reward: [(0, '-40.809')]
[36m[2025-06-29 11:46:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 61440. Throughput: 0: 80.0. Samples: 62240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:46:50,976][60274] Avg episode reward: [(0, '-42.782')]
[36m[2025-06-29 11:46:55,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 61440. Throughput: 0: 80.0. Samples: 62720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:46:55,978][60274] Avg episode reward: [(0, '-43.931')]
[36m[2025-06-29 11:47:00,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 61440. Throughput: 0: 79.9. Samples: 63196. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:00,968][60274] Avg episode reward: [(0, '-39.815')]
[37m[1m[2025-06-29 11:47:01,027][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000240_61440.pth...
[36m[2025-06-29 11:47:01,088][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000160_40960.pth
[36m[2025-06-29 11:47:05,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 61440. Throughput: 0: 79.8. Samples: 63432. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:05,982][60274] Avg episode reward: [(0, '-38.277')]
[36m[2025-06-29 11:47:10,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 61440. Throughput: 0: 80.0. Samples: 63912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:10,951][60274] Avg episode reward: [(0, '-41.910')]
[36m[2025-06-29 11:47:15,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 61440. Throughput: 0: 80.0. Samples: 64404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:15,962][60274] Avg episode reward: [(0, '-34.625')]
[36m[2025-06-29 11:47:20,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 61440. Throughput: 0: 79.4. Samples: 64628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:20,990][60274] Avg episode reward: [(0, '-34.667')]
[36m[2025-06-29 11:47:25,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 61440. Throughput: 0: 80.9. Samples: 65128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:25,987][60274] Avg episode reward: [(0, '-32.611')]
[36m[2025-06-29 11:47:30,996][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 65536. Throughput: 0: 78.8. Samples: 65544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:30,997][60274] Avg episode reward: [(0, '-30.238')]
[36m[2025-06-29 11:47:35,966][60274] Fps is (10 sec: 410.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 65536. Throughput: 0: 78.9. Samples: 65788. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:35,966][60274] Avg episode reward: [(0, '-31.115')]
[36m[2025-06-29 11:47:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 65536. Throughput: 0: 79.0. Samples: 66272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:40,947][60274] Avg episode reward: [(0, '-28.212')]
[36m[2025-06-29 11:47:45,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 65536. Throughput: 0: 79.7. Samples: 66780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:45,948][60274] Avg episode reward: [(0, '-23.148')]
[36m[2025-06-29 11:47:50,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 65536. Throughput: 0: 79.8. Samples: 67024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:50,979][60274] Avg episode reward: [(0, '-26.744')]
[36m[2025-06-29 11:47:55,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 65536. Throughput: 0: 80.2. Samples: 67524. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:47:55,997][60274] Avg episode reward: [(0, '-24.184')]
[36m[2025-06-29 11:48:00,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 65536. Throughput: 0: 80.1. Samples: 68008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:48:00,956][60274] Avg episode reward: [(0, '-22.365')]
[36m[2025-06-29 11:48:05,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 65536. Throughput: 0: 80.7. Samples: 68260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:48:05,981][60274] Avg episode reward: [(0, '-20.044')]
[36m[2025-06-29 11:48:10,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 65536. Throughput: 0: 81.2. Samples: 68780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:48:10,967][60274] Avg episode reward: [(0, '-18.085')]
[36m[2025-06-29 11:48:15,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 65536. Throughput: 0: 83.1. Samples: 69280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:48:15,956][60274] Avg episode reward: [(0, '-17.505')]
[36m[2025-06-29 11:48:20,953][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 69632. Throughput: 0: 83.0. Samples: 69524. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 11:48:20,953][60274] Avg episode reward: [(0, '-18.491')]
[36m[2025-06-29 11:48:25,964][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 69632. Throughput: 0: 82.2. Samples: 69972. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 11:48:25,964][60274] Avg episode reward: [(0, '-18.874')]
[36m[2025-06-29 11:48:30,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 69632. Throughput: 0: 81.6. Samples: 70452. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 11:48:30,963][60274] Avg episode reward: [(0, '-22.203')]
[36m[2025-06-29 11:48:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 69632. Throughput: 0: 81.7. Samples: 70700. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 11:48:35,972][60274] Avg episode reward: [(0, '-15.423')]
[36m[2025-06-29 11:48:40,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 69632. Throughput: 0: 81.7. Samples: 71196. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 11:48:40,962][60274] Avg episode reward: [(0, '-16.415')]
[36m[2025-06-29 11:48:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 69632. Throughput: 0: 81.8. Samples: 71688. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 11:48:45,969][60274] Avg episode reward: [(0, '-15.442')]
[36m[2025-06-29 11:48:50,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 69632. Throughput: 0: 81.8. Samples: 71940. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 11:48:50,955][60274] Avg episode reward: [(0, '-16.315')]
[36m[2025-06-29 11:48:55,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 69632. Throughput: 0: 81.5. Samples: 72444. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 11:48:55,949][60274] Avg episode reward: [(0, '-14.851')]
[36m[2025-06-29 11:49:00,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 69632. Throughput: 0: 81.2. Samples: 72932. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 11:49:00,956][60274] Avg episode reward: [(0, '-11.988')]
[37m[1m[2025-06-29 11:49:01,024][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000272_69632.pth...
[36m[2025-06-29 11:49:01,081][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000208_53248.pth
[36m[2025-06-29 11:49:05,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 69632. Throughput: 0: 81.1. Samples: 73176. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 11:49:05,986][60274] Avg episode reward: [(0, '-14.686')]
[36m[2025-06-29 11:49:10,958][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 73728. Throughput: 0: 82.1. Samples: 73664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:49:10,958][60274] Avg episode reward: [(0, '-10.958')]
[36m[2025-06-29 11:49:16,006][60274] Fps is (10 sec: 408.7, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 73728. Throughput: 0: 80.7. Samples: 74088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:49:16,007][60274] Avg episode reward: [(0, '-11.091')]
[36m[2025-06-29 11:49:20,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 73728. Throughput: 0: 80.5. Samples: 74324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:49:21,000][60274] Avg episode reward: [(0, '-7.234')]
[36m[2025-06-29 11:49:25,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 73728. Throughput: 0: 80.6. Samples: 74824. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:49:25,960][60274] Avg episode reward: [(0, '-11.785')]
[36m[2025-06-29 11:49:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 73728. Throughput: 0: 80.7. Samples: 75320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:49:30,973][60274] Avg episode reward: [(0, '-12.002')]
[36m[2025-06-29 11:49:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 73728. Throughput: 0: 80.7. Samples: 75572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:49:35,981][60274] Avg episode reward: [(0, '-14.147')]
[36m[2025-06-29 11:49:40,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 73728. Throughput: 0: 80.4. Samples: 76060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:49:40,950][60274] Avg episode reward: [(0, '-11.134')]
[36m[2025-06-29 11:49:45,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 73728. Throughput: 0: 80.7. Samples: 76564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:49:45,967][60274] Avg episode reward: [(0, '-11.428')]
[36m[2025-06-29 11:49:50,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.5). Total num frames: 73728. Throughput: 0: 80.6. Samples: 76804. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:49:50,991][60274] Avg episode reward: [(0, '-15.397')]
[36m[2025-06-29 11:49:55,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 73728. Throughput: 0: 80.2. Samples: 77272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:49:55,973][60274] Avg episode reward: [(0, '-18.744')]
[36m[2025-06-29 11:50:01,680][60274] Fps is (10 sec: 383.2, 60 sec: 134.9, 300 sec: 83.1). Total num frames: 77824. Throughput: 0: 80.7. Samples: 77772. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:01,680][60274] Avg episode reward: [(0, '-16.727')]
[36m[2025-06-29 11:50:05,951][60274] Fps is (10 sec: 410.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 77824. Throughput: 0: 80.8. Samples: 77956. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:05,951][60274] Avg episode reward: [(0, '-12.073')]
[36m[2025-06-29 11:50:10,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 77824. Throughput: 0: 80.4. Samples: 78440. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:10,949][60274] Avg episode reward: [(0, '-17.796')]
[36m[2025-06-29 11:50:15,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 77824. Throughput: 0: 80.3. Samples: 78936. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:15,983][60274] Avg episode reward: [(0, '-15.247')]
[36m[2025-06-29 11:50:20,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 77824. Throughput: 0: 80.3. Samples: 79184. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:20,987][60274] Avg episode reward: [(0, '-15.356')]
[36m[2025-06-29 11:50:26,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 77824. Throughput: 0: 80.3. Samples: 79676. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:26,002][60274] Avg episode reward: [(0, '-18.636')]
[36m[2025-06-29 11:50:30,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 77824. Throughput: 0: 79.3. Samples: 80136. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:30,995][60274] Avg episode reward: [(0, '-14.846')]
[36m[2025-06-29 11:50:35,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 77824. Throughput: 0: 79.4. Samples: 80376. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:35,978][60274] Avg episode reward: [(0, '-14.025')]
[36m[2025-06-29 11:50:40,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 77824. Throughput: 0: 79.8. Samples: 80860. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:40,961][60274] Avg episode reward: [(0, '-16.524')]
[36m[2025-06-29 11:50:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 77824. Throughput: 0: 80.5. Samples: 81336. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:45,969][60274] Avg episode reward: [(0, '-18.209')]
[36m[2025-06-29 11:50:50,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 77824. Throughput: 0: 80.2. Samples: 81564. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:50:50,947][60274] Avg episode reward: [(0, '-21.644')]
[36m[2025-06-29 11:50:55,955][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 81920. Throughput: 0: 78.8. Samples: 81988. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:50:55,955][60274] Avg episode reward: [(0, '-18.130')]
[36m[2025-06-29 11:51:00,960][60274] Fps is (10 sec: 409.1, 60 sec: 69.1, 300 sec: 83.3). Total num frames: 81920. Throughput: 0: 78.9. Samples: 82484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:51:00,960][60274] Avg episode reward: [(0, '-22.922')]
[37m[1m[2025-06-29 11:51:01,008][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000320_81920.pth...
[36m[2025-06-29 11:51:01,064][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000240_61440.pth
[36m[2025-06-29 11:51:05,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 81920. Throughput: 0: 78.7. Samples: 82724. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:51:05,950][60274] Avg episode reward: [(0, '-20.419')]
[36m[2025-06-29 11:51:10,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 81920. Throughput: 0: 78.9. Samples: 83224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:51:10,988][60274] Avg episode reward: [(0, '-18.163')]
[36m[2025-06-29 11:51:15,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 81920. Throughput: 0: 79.0. Samples: 83692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:51:15,993][60274] Avg episode reward: [(0, '-18.070')]
[36m[2025-06-29 11:51:20,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 81920. Throughput: 0: 79.0. Samples: 83928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:51:20,946][60274] Avg episode reward: [(0, '-15.847')]
[36m[2025-06-29 11:51:26,010][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 81920. Throughput: 0: 78.9. Samples: 84416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:51:26,010][60274] Avg episode reward: [(0, '-16.291')]
[36m[2025-06-29 11:51:30,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 81920. Throughput: 0: 78.6. Samples: 84872. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:51:30,952][60274] Avg episode reward: [(0, '-17.323')]
[36m[2025-06-29 11:51:35,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 81920. Throughput: 0: 78.7. Samples: 85104. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:51:35,952][60274] Avg episode reward: [(0, '-15.151')]
[36m[2025-06-29 11:51:40,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 81920. Throughput: 0: 80.4. Samples: 85608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:51:40,989][60274] Avg episode reward: [(0, '-12.816')]
[36m[2025-06-29 11:51:45,982][60274] Fps is (10 sec: 408.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 86016. Throughput: 0: 79.3. Samples: 86056. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:51:45,982][60274] Avg episode reward: [(0, '-12.080')]
[36m[2025-06-29 11:51:50,972][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 86016. Throughput: 0: 79.9. Samples: 86320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:51:50,972][60274] Avg episode reward: [(0, '-13.820')]
[36m[2025-06-29 11:51:55,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 86016. Throughput: 0: 79.9. Samples: 86816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:51:55,958][60274] Avg episode reward: [(0, '-8.578')]
[36m[2025-06-29 11:52:00,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 86016. Throughput: 0: 80.7. Samples: 87320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:00,957][60274] Avg episode reward: [(0, '-11.080')]
[36m[2025-06-29 11:52:05,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 86016. Throughput: 0: 80.7. Samples: 87560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:05,948][60274] Avg episode reward: [(0, '-11.254')]
[36m[2025-06-29 11:52:10,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 86016. Throughput: 0: 80.2. Samples: 88024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:10,987][60274] Avg episode reward: [(0, '-10.492')]
[36m[2025-06-29 11:52:15,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 86016. Throughput: 0: 81.1. Samples: 88524. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:15,962][60274] Avg episode reward: [(0, '-14.506')]
[36m[2025-06-29 11:52:20,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 86016. Throughput: 0: 81.4. Samples: 88768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:20,958][60274] Avg episode reward: [(0, '-11.781')]
[36m[2025-06-29 11:52:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 86016. Throughput: 0: 81.7. Samples: 89280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:25,956][60274] Avg episode reward: [(0, '-13.457')]
[36m[2025-06-29 11:52:30,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 86016. Throughput: 0: 82.5. Samples: 89768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:30,986][60274] Avg episode reward: [(0, '-11.821')]
[36m[2025-06-29 11:52:35,967][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 90112. Throughput: 0: 82.1. Samples: 90016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:35,967][60274] Avg episode reward: [(0, '-11.078')]
[36m[2025-06-29 11:52:40,987][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 90112. Throughput: 0: 81.2. Samples: 90472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:40,987][60274] Avg episode reward: [(0, '-9.869')]
[36m[2025-06-29 11:52:45,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 90112. Throughput: 0: 80.8. Samples: 90956. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:45,973][60274] Avg episode reward: [(0, '-9.927')]
[36m[2025-06-29 11:52:50,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 90112. Throughput: 0: 80.9. Samples: 91204. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:50,992][60274] Avg episode reward: [(0, '-7.169')]
[36m[2025-06-29 11:52:55,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 90112. Throughput: 0: 81.5. Samples: 91688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:52:55,967][60274] Avg episode reward: [(0, '-8.390')]
[36m[2025-06-29 11:53:00,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 90112. Throughput: 0: 81.1. Samples: 92176. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:53:00,980][60274] Avg episode reward: [(0, '-11.230')]
[37m[1m[2025-06-29 11:53:01,030][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000352_90112.pth...
[36m[2025-06-29 11:53:01,085][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000272_69632.pth
[36m[2025-06-29 11:53:05,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 90112. Throughput: 0: 80.8. Samples: 92404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:53:05,952][60274] Avg episode reward: [(0, '-10.142')]
[36m[2025-06-29 11:53:10,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 90112. Throughput: 0: 80.3. Samples: 92892. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:53:10,958][60274] Avg episode reward: [(0, '-10.855')]
[36m[2025-06-29 11:53:15,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 90112. Throughput: 0: 80.5. Samples: 93392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:53:15,997][60274] Avg episode reward: [(0, '-8.363')]
[36m[2025-06-29 11:53:20,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 90112. Throughput: 0: 80.4. Samples: 93636. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:53:20,966][60274] Avg episode reward: [(0, '-10.467')]
[36m[2025-06-29 11:53:26,039][60274] Fps is (10 sec: 407.9, 60 sec: 136.3, 300 sec: 83.3). Total num frames: 94208. Throughput: 0: 81.1. Samples: 94124. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:53:26,040][60274] Avg episode reward: [(0, '-12.560')]
[36m[2025-06-29 11:53:30,966][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 94208. Throughput: 0: 80.2. Samples: 94564. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:53:30,966][60274] Avg episode reward: [(0, '-12.083')]
[36m[2025-06-29 11:53:35,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 94208. Throughput: 0: 80.0. Samples: 94804. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:53:35,970][60274] Avg episode reward: [(0, '-9.265')]
[36m[2025-06-29 11:53:40,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 94208. Throughput: 0: 79.9. Samples: 95284. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:53:40,959][60274] Avg episode reward: [(0, '-10.627')]
[36m[2025-06-29 11:53:45,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 94208. Throughput: 0: 80.4. Samples: 95796. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:53:45,977][60274] Avg episode reward: [(0, '-11.558')]
[36m[2025-06-29 11:53:50,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 94208. Throughput: 0: 80.9. Samples: 96044. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:53:50,963][60274] Avg episode reward: [(0, '-8.092')]
[36m[2025-06-29 11:53:55,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 94208. Throughput: 0: 81.3. Samples: 96552. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:53:55,973][60274] Avg episode reward: [(0, '-7.769')]
[36m[2025-06-29 11:54:00,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 94208. Throughput: 0: 81.0. Samples: 97036. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:54:00,978][60274] Avg episode reward: [(0, '-7.409')]
[36m[2025-06-29 11:54:05,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 94208. Throughput: 0: 81.0. Samples: 97280. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:54:05,972][60274] Avg episode reward: [(0, '-7.832')]
[36m[2025-06-29 11:54:10,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 94208. Throughput: 0: 81.0. Samples: 97760. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:54:10,948][60274] Avg episode reward: [(0, '-5.843')]
[36m[2025-06-29 11:54:15,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 94208. Throughput: 0: 82.1. Samples: 98256. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 11:54:15,958][60274] Avg episode reward: [(0, '-5.438')]
[36m[2025-06-29 11:54:20,954][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 98304. Throughput: 0: 80.4. Samples: 98420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:54:20,955][60274] Avg episode reward: [(0, '-6.166')]
[36m[2025-06-29 11:54:25,964][60274] Fps is (10 sec: 409.4, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 98304. Throughput: 0: 80.8. Samples: 98920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:54:25,964][60274] Avg episode reward: [(0, '-5.325')]
[36m[2025-06-29 11:54:30,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 98304. Throughput: 0: 80.3. Samples: 99408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:54:30,974][60274] Avg episode reward: [(0, '-4.907')]
[36m[2025-06-29 11:54:35,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 98304. Throughput: 0: 79.9. Samples: 99640. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:54:35,950][60274] Avg episode reward: [(0, '-4.485')]
[36m[2025-06-29 11:54:40,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 98304. Throughput: 0: 79.4. Samples: 100128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:54:40,985][60274] Avg episode reward: [(0, '-3.622')]
[36m[2025-06-29 11:54:45,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 98304. Throughput: 0: 80.0. Samples: 100632. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:54:45,956][60274] Avg episode reward: [(0, '-4.282')]
[36m[2025-06-29 11:54:50,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 98304. Throughput: 0: 79.8. Samples: 100872. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:54:50,969][60274] Avg episode reward: [(0, '-1.610')]
[36m[2025-06-29 11:54:55,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 98304. Throughput: 0: 80.1. Samples: 101368. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:54:55,978][60274] Avg episode reward: [(0, '0.153')]
[36m[2025-06-29 11:55:00,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 98304. Throughput: 0: 79.4. Samples: 101832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:55:00,975][60274] Avg episode reward: [(0, '0.733')]
[37m[1m[2025-06-29 11:55:01,022][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000384_98304.pth...
[36m[2025-06-29 11:55:01,078][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000320_81920.pth
[36m[2025-06-29 11:55:05,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 98304. Throughput: 0: 80.9. Samples: 102064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:55:05,990][60274] Avg episode reward: [(0, '0.532')]
[36m[2025-06-29 11:55:10,978][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 102400. Throughput: 0: 79.4. Samples: 102496. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 11:55:10,979][60274] Avg episode reward: [(0, '1.084')]
[36m[2025-06-29 11:55:15,990][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 102400. Throughput: 0: 79.9. Samples: 103004. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 11:55:15,990][60274] Avg episode reward: [(0, '4.779')]
[36m[2025-06-29 11:55:20,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 102400. Throughput: 0: 79.9. Samples: 103240. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 11:55:20,993][60274] Avg episode reward: [(0, '5.619')]
[36m[2025-06-29 11:55:25,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 102400. Throughput: 0: 80.1. Samples: 103732. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 11:55:25,986][60274] Avg episode reward: [(0, '6.131')]
[36m[2025-06-29 11:55:30,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 102400. Throughput: 0: 79.9. Samples: 104232. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 11:55:30,988][60274] Avg episode reward: [(0, '5.819')]
[36m[2025-06-29 11:55:35,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 102400. Throughput: 0: 80.0. Samples: 104472. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 11:55:35,967][60274] Avg episode reward: [(0, '3.166')]
[36m[2025-06-29 11:55:40,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 102400. Throughput: 0: 79.6. Samples: 104948. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 11:55:40,969][60274] Avg episode reward: [(0, '1.341')]
[36m[2025-06-29 11:55:45,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 102400. Throughput: 0: 80.3. Samples: 105444. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 11:55:45,962][60274] Avg episode reward: [(0, '1.607')]
[36m[2025-06-29 11:55:50,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 102400. Throughput: 0: 80.8. Samples: 105700. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 11:55:50,985][60274] Avg episode reward: [(0, '4.320')]
[36m[2025-06-29 11:55:55,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 102400. Throughput: 0: 81.9. Samples: 106180. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 11:55:55,979][60274] Avg episode reward: [(0, '2.905')]
[36m[2025-06-29 11:56:00,976][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 106496. Throughput: 0: 80.5. Samples: 106624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:00,976][60274] Avg episode reward: [(0, '5.670')]
[36m[2025-06-29 11:56:05,978][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 106496. Throughput: 0: 80.7. Samples: 106872. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:05,979][60274] Avg episode reward: [(0, '2.296')]
[36m[2025-06-29 11:56:10,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 106496. Throughput: 0: 80.2. Samples: 107340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:10,968][60274] Avg episode reward: [(0, '6.228')]
[36m[2025-06-29 11:56:15,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 106496. Throughput: 0: 80.2. Samples: 107840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:15,964][60274] Avg episode reward: [(0, '6.357')]
[36m[2025-06-29 11:56:20,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 106496. Throughput: 0: 79.6. Samples: 108052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:20,965][60274] Avg episode reward: [(0, '8.477')]
[36m[2025-06-29 11:56:25,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 106496. Throughput: 0: 79.3. Samples: 108520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:25,991][60274] Avg episode reward: [(0, '6.715')]
[36m[2025-06-29 11:56:30,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 106496. Throughput: 0: 78.8. Samples: 108992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:30,994][60274] Avg episode reward: [(0, '6.382')]
[36m[2025-06-29 11:56:35,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 106496. Throughput: 0: 78.7. Samples: 109240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:35,955][60274] Avg episode reward: [(0, '7.330')]
[36m[2025-06-29 11:56:40,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 106496. Throughput: 0: 78.6. Samples: 109716. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:40,966][60274] Avg episode reward: [(0, '6.899')]
[36m[2025-06-29 11:56:45,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 106496. Throughput: 0: 79.1. Samples: 110184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:45,990][60274] Avg episode reward: [(0, '8.576')]
[36m[2025-06-29 11:56:51,140][60274] Fps is (10 sec: 402.6, 60 sec: 136.2, 300 sec: 83.3). Total num frames: 110592. Throughput: 0: 78.9. Samples: 110436. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:51,140][60274] Avg episode reward: [(0, '5.436')]
[36m[2025-06-29 11:56:55,980][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 110592. Throughput: 0: 78.0. Samples: 110852. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:56:55,980][60274] Avg episode reward: [(0, '5.678')]
[36m[2025-06-29 11:57:00,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 110592. Throughput: 0: 77.8. Samples: 111344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:57:00,990][60274] Avg episode reward: [(0, '4.586')]
[37m[1m[2025-06-29 11:57:00,993][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000432_110592.pth...
[36m[2025-06-29 11:57:01,111][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000352_90112.pth
[36m[2025-06-29 11:57:05,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 110592. Throughput: 0: 77.9. Samples: 111560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:57:05,984][60274] Avg episode reward: [(0, '6.433')]
[36m[2025-06-29 11:57:10,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 110592. Throughput: 0: 78.0. Samples: 112028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:57:10,968][60274] Avg episode reward: [(0, '3.441')]
[36m[2025-06-29 11:57:15,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 110592. Throughput: 0: 78.5. Samples: 112524. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:57:15,999][60274] Avg episode reward: [(0, '2.501')]
[36m[2025-06-29 11:57:20,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 110592. Throughput: 0: 78.3. Samples: 112764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:57:20,983][60274] Avg episode reward: [(0, '0.710')]
[36m[2025-06-29 11:57:25,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 110592. Throughput: 0: 78.1. Samples: 113232. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:57:25,978][60274] Avg episode reward: [(0, '3.282')]
[36m[2025-06-29 11:57:30,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 110592. Throughput: 0: 79.0. Samples: 113736. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:57:30,967][60274] Avg episode reward: [(0, '4.048')]
[36m[2025-06-29 11:57:35,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 110592. Throughput: 0: 79.0. Samples: 113980. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:57:35,997][60274] Avg episode reward: [(0, '0.716')]
[36m[2025-06-29 11:57:40,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 110592. Throughput: 0: 80.6. Samples: 114480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 11:57:40,984][60274] Avg episode reward: [(0, '0.157')]
[36m[2025-06-29 11:57:45,959][60274] Fps is (10 sec: 411.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 114688. Throughput: 0: 79.7. Samples: 114928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:57:45,959][60274] Avg episode reward: [(0, '-3.066')]
[36m[2025-06-29 11:57:50,987][60274] Fps is (10 sec: 409.4, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 114688. Throughput: 0: 80.2. Samples: 115168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:57:50,987][60274] Avg episode reward: [(0, '-3.959')]
[36m[2025-06-29 11:57:55,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 114688. Throughput: 0: 80.2. Samples: 115636. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:57:55,947][60274] Avg episode reward: [(0, '-4.056')]
[36m[2025-06-29 11:58:00,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 114688. Throughput: 0: 79.9. Samples: 116116. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:00,982][60274] Avg episode reward: [(0, '-4.388')]
[36m[2025-06-29 11:58:05,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 114688. Throughput: 0: 80.2. Samples: 116372. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:05,990][60274] Avg episode reward: [(0, '-7.287')]
[36m[2025-06-29 11:58:10,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 114688. Throughput: 0: 81.1. Samples: 116880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:10,959][60274] Avg episode reward: [(0, '-4.901')]
[36m[2025-06-29 11:58:15,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 114688. Throughput: 0: 81.4. Samples: 117396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:15,953][60274] Avg episode reward: [(0, '-7.257')]
[36m[2025-06-29 11:58:20,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 114688. Throughput: 0: 81.5. Samples: 117648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:20,984][60274] Avg episode reward: [(0, '-5.060')]
[36m[2025-06-29 11:58:25,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 114688. Throughput: 0: 81.2. Samples: 118132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:25,968][60274] Avg episode reward: [(0, '-7.667')]
[36m[2025-06-29 11:58:30,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 114688. Throughput: 0: 82.0. Samples: 118620. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:30,963][60274] Avg episode reward: [(0, '-8.364')]
[36m[2025-06-29 11:58:35,977][60274] Fps is (10 sec: 409.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 118784. Throughput: 0: 80.9. Samples: 118808. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:35,977][60274] Avg episode reward: [(0, '-10.506')]
[36m[2025-06-29 11:58:40,985][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 118784. Throughput: 0: 81.2. Samples: 119292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:40,985][60274] Avg episode reward: [(0, '-10.997')]
[33m[1547107 ms][navigation_task] - WARNING : Curriculum Level: 36, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[1547108 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.00537109375
[33mCrash Rate: 0.71484375
[33mTimeout Rate: 0.27978515625 (navigation_task.py:265)
[33m[1547108 ms][navigation_task] - WARNING : 
[33mSuccesses: 11
[33mCrashes : 1464
[33mTimeouts: 573 (navigation_task.py:268)
[36m[2025-06-29 11:58:45,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 118784. Throughput: 0: 80.9. Samples: 119756. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:45,981][60274] Avg episode reward: [(0, '-11.243')]
[36m[2025-06-29 11:58:50,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 118784. Throughput: 0: 80.5. Samples: 119996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:50,988][60274] Avg episode reward: [(0, '-12.086')]
[36m[2025-06-29 11:58:55,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 118784. Throughput: 0: 80.5. Samples: 120500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:58:55,954][60274] Avg episode reward: [(0, '-7.375')]
[36m[2025-06-29 11:59:00,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 118784. Throughput: 0: 80.2. Samples: 121004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:00,949][60274] Avg episode reward: [(0, '-9.751')]
[37m[1m[2025-06-29 11:59:00,997][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000464_118784.pth...
[36m[2025-06-29 11:59:01,053][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000384_98304.pth
[36m[2025-06-29 11:59:06,013][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 118784. Throughput: 0: 80.1. Samples: 121256. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:06,013][60274] Avg episode reward: [(0, '-12.007')]
[36m[2025-06-29 11:59:10,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 118784. Throughput: 0: 80.0. Samples: 121732. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:10,988][60274] Avg episode reward: [(0, '-10.429')]
[36m[2025-06-29 11:59:15,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 118784. Throughput: 0: 80.5. Samples: 122244. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:15,972][60274] Avg episode reward: [(0, '-12.409')]
[36m[2025-06-29 11:59:20,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 118784. Throughput: 0: 82.2. Samples: 122504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:20,948][60274] Avg episode reward: [(0, '-12.344')]
[36m[2025-06-29 11:59:25,981][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 122880. Throughput: 0: 81.5. Samples: 122960. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:25,982][60274] Avg episode reward: [(0, '-7.756')]
[36m[2025-06-29 11:59:30,949][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 122880. Throughput: 0: 82.5. Samples: 123464. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:30,949][60274] Avg episode reward: [(0, '-6.964')]
[36m[2025-06-29 11:59:35,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 122880. Throughput: 0: 82.5. Samples: 123708. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:35,979][60274] Avg episode reward: [(0, '-2.142')]
[36m[2025-06-29 11:59:40,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 122880. Throughput: 0: 82.0. Samples: 124192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:40,996][60274] Avg episode reward: [(0, '-2.020')]
[36m[2025-06-29 11:59:45,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 122880. Throughput: 0: 81.8. Samples: 124684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:45,955][60274] Avg episode reward: [(0, '-3.648')]
[36m[2025-06-29 11:59:50,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 122880. Throughput: 0: 81.7. Samples: 124932. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:50,991][60274] Avg episode reward: [(0, '0.247')]
[36m[2025-06-29 11:59:55,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 122880. Throughput: 0: 82.0. Samples: 125420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 11:59:55,984][60274] Avg episode reward: [(0, '-0.878')]
[36m[2025-06-29 12:00:00,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 122880. Throughput: 0: 81.5. Samples: 125912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:00,993][60274] Avg episode reward: [(0, '-6.330')]
[36m[2025-06-29 12:00:05,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 122880. Throughput: 0: 81.3. Samples: 126164. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:05,956][60274] Avg episode reward: [(0, '-4.526')]
[36m[2025-06-29 12:00:10,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 122880. Throughput: 0: 82.4. Samples: 126668. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:10,974][60274] Avg episode reward: [(0, '-2.760')]
[36m[2025-06-29 12:00:15,951][60274] Fps is (10 sec: 409.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 126976. Throughput: 0: 80.5. Samples: 127088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:15,952][60274] Avg episode reward: [(0, '-0.233')]
[36m[2025-06-29 12:00:20,954][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 126976. Throughput: 0: 81.0. Samples: 127352. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:20,954][60274] Avg episode reward: [(0, '1.698')]
[36m[2025-06-29 12:00:25,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 126976. Throughput: 0: 81.1. Samples: 127840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:25,969][60274] Avg episode reward: [(0, '1.979')]
[36m[2025-06-29 12:00:30,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 126976. Throughput: 0: 81.4. Samples: 128348. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:30,960][60274] Avg episode reward: [(0, '3.157')]
[36m[2025-06-29 12:00:35,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 126976. Throughput: 0: 81.5. Samples: 128596. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:35,950][60274] Avg episode reward: [(0, '-1.373')]
[36m[2025-06-29 12:00:40,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 126976. Throughput: 0: 81.3. Samples: 129076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:40,965][60274] Avg episode reward: [(0, '1.602')]
[36m[2025-06-29 12:00:45,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 126976. Throughput: 0: 81.0. Samples: 129556. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:45,987][60274] Avg episode reward: [(0, '-3.792')]
[36m[2025-06-29 12:00:50,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 126976. Throughput: 0: 80.5. Samples: 129788. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:50,953][60274] Avg episode reward: [(0, '-1.361')]
[36m[2025-06-29 12:00:55,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 126976. Throughput: 0: 80.4. Samples: 130284. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:00:55,973][60274] Avg episode reward: [(0, '-2.058')]
[36m[2025-06-29 12:01:00,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 126976. Throughput: 0: 81.5. Samples: 130760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:01:00,983][60274] Avg episode reward: [(0, '2.427')]
[37m[1m[2025-06-29 12:01:01,031][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000496_126976.pth...
[36m[2025-06-29 12:01:01,086][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000432_110592.pth
[36m[2025-06-29 12:01:05,992][60274] Fps is (10 sec: 408.8, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 131072. Throughput: 0: 80.7. Samples: 130988. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:01:05,993][60274] Avg episode reward: [(0, '2.430')]
[36m[2025-06-29 12:01:10,982][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 131072. Throughput: 0: 79.6. Samples: 131424. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:01:10,983][60274] Avg episode reward: [(0, '4.458')]
[36m[2025-06-29 12:01:15,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 131072. Throughput: 0: 79.3. Samples: 131920. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:01:15,976][60274] Avg episode reward: [(0, '2.245')]
[36m[2025-06-29 12:01:20,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 131072. Throughput: 0: 79.3. Samples: 132164. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:01:20,964][60274] Avg episode reward: [(0, '2.757')]
[36m[2025-06-29 12:01:25,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 131072. Throughput: 0: 79.4. Samples: 132648. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:01:25,951][60274] Avg episode reward: [(0, '0.887')]
[36m[2025-06-29 12:01:30,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 131072. Throughput: 0: 79.6. Samples: 133136. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:01:30,967][60274] Avg episode reward: [(0, '0.652')]
[36m[2025-06-29 12:01:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 131072. Throughput: 0: 79.8. Samples: 133380. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:01:35,981][60274] Avg episode reward: [(0, '0.559')]
[36m[2025-06-29 12:01:40,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 131072. Throughput: 0: 79.9. Samples: 133876. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:01:40,953][60274] Avg episode reward: [(0, '-5.394')]
[36m[2025-06-29 12:01:45,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 131072. Throughput: 0: 80.7. Samples: 134392. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:01:45,970][60274] Avg episode reward: [(0, '-2.847')]
[36m[2025-06-29 12:01:50,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 131072. Throughput: 0: 81.3. Samples: 134644. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:01:50,967][60274] Avg episode reward: [(0, '1.958')]
[36m[2025-06-29 12:01:55,993][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 135168. Throughput: 0: 82.7. Samples: 135148. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:01:55,994][60274] Avg episode reward: [(0, '0.725')]
[36m[2025-06-29 12:02:00,985][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 135168. Throughput: 0: 81.3. Samples: 135580. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:02:00,986][60274] Avg episode reward: [(0, '0.182')]
[36m[2025-06-29 12:02:05,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 135168. Throughput: 0: 81.2. Samples: 135816. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:02:05,962][60274] Avg episode reward: [(0, '0.152')]
[36m[2025-06-29 12:02:10,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 135168. Throughput: 0: 81.2. Samples: 136304. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:02:10,951][60274] Avg episode reward: [(0, '-5.189')]
[36m[2025-06-29 12:02:15,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 135168. Throughput: 0: 81.4. Samples: 136800. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:02:15,996][60274] Avg episode reward: [(0, '-2.754')]
[36m[2025-06-29 12:02:20,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 135168. Throughput: 0: 81.6. Samples: 137048. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:02:20,958][60274] Avg episode reward: [(0, '-6.008')]
[36m[2025-06-29 12:02:25,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 135168. Throughput: 0: 81.6. Samples: 137548. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:02:25,961][60274] Avg episode reward: [(0, '1.117')]
[31m[1773102 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1773102 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[1773102 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 12:02:30,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 135168. Throughput: 0: 81.3. Samples: 138052. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:02:30,988][60274] Avg episode reward: [(0, '-4.725')]
[36m[2025-06-29 12:02:35,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 135168. Throughput: 0: 81.1. Samples: 138296. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:02:35,992][60274] Avg episode reward: [(0, '-4.895')]
[36m[2025-06-29 12:02:40,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 135168. Throughput: 0: 80.7. Samples: 138780. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:02:40,978][60274] Avg episode reward: [(0, '-5.849')]
[36m[2025-06-29 12:02:46,002][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 139264. Throughput: 0: 81.9. Samples: 139268. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:02:46,003][60274] Avg episode reward: [(0, '-3.504')]
[36m[2025-06-29 12:02:50,947][60274] Fps is (10 sec: 410.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 139264. Throughput: 0: 81.4. Samples: 139476. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:02:50,948][60274] Avg episode reward: [(0, '-3.946')]
[36m[2025-06-29 12:02:55,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 139264. Throughput: 0: 81.6. Samples: 139976. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:02:55,972][60274] Avg episode reward: [(0, '-1.722')]
[36m[2025-06-29 12:03:00,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 139264. Throughput: 0: 80.9. Samples: 140440. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:03:00,983][60274] Avg episode reward: [(0, '-2.105')]
[37m[1m[2025-06-29 12:03:01,030][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000544_139264.pth...
[36m[2025-06-29 12:03:01,084][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000464_118784.pth
[36m[2025-06-29 12:03:05,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 139264. Throughput: 0: 80.2. Samples: 140656. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:03:05,962][60274] Avg episode reward: [(0, '-2.936')]
[36m[2025-06-29 12:03:10,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 139264. Throughput: 0: 79.9. Samples: 141144. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:03:10,985][60274] Avg episode reward: [(0, '-0.273')]
[36m[2025-06-29 12:03:15,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 139264. Throughput: 0: 80.1. Samples: 141656. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:03:15,976][60274] Avg episode reward: [(0, '-0.783')]
[36m[2025-06-29 12:03:20,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 139264. Throughput: 0: 80.4. Samples: 141912. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:03:20,975][60274] Avg episode reward: [(0, '-1.652')]
[36m[2025-06-29 12:03:25,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 139264. Throughput: 0: 80.8. Samples: 142416. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:03:25,999][60274] Avg episode reward: [(0, '-0.589')]
[31m[1832511 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1832511 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[1832511 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 12:03:30,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 139264. Throughput: 0: 81.1. Samples: 142912. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:03:30,953][60274] Avg episode reward: [(0, '0.785')]
[36m[2025-06-29 12:03:35,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 139264. Throughput: 0: 81.7. Samples: 143156. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:03:35,965][60274] Avg episode reward: [(0, '-0.698')]
[36m[2025-06-29 12:03:40,978][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 143360. Throughput: 0: 80.1. Samples: 143580. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:03:40,979][60274] Avg episode reward: [(0, '-1.301')]
[31m[1851016 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1851017 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[1851017 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 12:03:45,991][60274] Fps is (10 sec: 408.5, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 143360. Throughput: 0: 80.7. Samples: 144072. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:03:45,991][60274] Avg episode reward: [(0, '0.013')]
[36m[2025-06-29 12:03:50,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 143360. Throughput: 0: 81.1. Samples: 144304. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:03:50,949][60274] Avg episode reward: [(0, '-1.609')]
[36m[2025-06-29 12:03:55,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 143360. Throughput: 0: 81.4. Samples: 144804. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:03:55,955][60274] Avg episode reward: [(0, '-3.424')]
[36m[2025-06-29 12:04:00,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 143360. Throughput: 0: 80.7. Samples: 145288. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:04:00,979][60274] Avg episode reward: [(0, '-3.361')]
[36m[2025-06-29 12:04:05,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 143360. Throughput: 0: 80.6. Samples: 145540. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:04:05,960][60274] Avg episode reward: [(0, '-1.813')]
[36m[2025-06-29 12:04:10,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 143360. Throughput: 0: 80.7. Samples: 146048. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:04:10,994][60274] Avg episode reward: [(0, '-1.612')]
[36m[2025-06-29 12:04:15,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 143360. Throughput: 0: 80.8. Samples: 146548. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:04:15,960][60274] Avg episode reward: [(0, '-5.809')]
[36m[2025-06-29 12:04:21,002][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 143360. Throughput: 0: 80.6. Samples: 146784. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:04:21,002][60274] Avg episode reward: [(0, '-4.229')]
[36m[2025-06-29 12:04:26,011][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 143360. Throughput: 0: 81.7. Samples: 147260. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:04:26,011][60274] Avg episode reward: [(0, '-0.182')]
[36m[2025-06-29 12:04:30,972][60274] Fps is (10 sec: 410.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 147456. Throughput: 0: 80.1. Samples: 147676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:04:30,972][60274] Avg episode reward: [(0, '-1.071')]
[36m[2025-06-29 12:04:35,990][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 147456. Throughput: 0: 80.6. Samples: 147936. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:04:35,991][60274] Avg episode reward: [(0, '-3.285')]
[36m[2025-06-29 12:04:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 147456. Throughput: 0: 80.5. Samples: 148428. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:04:40,981][60274] Avg episode reward: [(0, '-8.057')]
[36m[2025-06-29 12:04:45,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 147456. Throughput: 0: 81.0. Samples: 148932. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:04:45,962][60274] Avg episode reward: [(0, '-8.648')]
[36m[2025-06-29 12:04:50,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 147456. Throughput: 0: 80.9. Samples: 149180. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:04:50,964][60274] Avg episode reward: [(0, '-5.352')]
[36m[2025-06-29 12:04:55,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 147456. Throughput: 0: 80.5. Samples: 149668. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:04:55,954][60274] Avg episode reward: [(0, '-7.279')]
[36m[2025-06-29 12:05:00,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 147456. Throughput: 0: 79.9. Samples: 150144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:00,992][60274] Avg episode reward: [(0, '-3.875')]
[37m[1m[2025-06-29 12:05:01,065][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000576_147456.pth...
[36m[2025-06-29 12:05:01,123][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000496_126976.pth
[36m[2025-06-29 12:05:05,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 147456. Throughput: 0: 80.0. Samples: 150384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:05,989][60274] Avg episode reward: [(0, '-8.377')]
[36m[2025-06-29 12:05:10,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 147456. Throughput: 0: 80.2. Samples: 150864. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:10,970][60274] Avg episode reward: [(0, '-7.087')]
[36m[2025-06-29 12:05:15,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 147456. Throughput: 0: 82.2. Samples: 151376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:15,974][60274] Avg episode reward: [(0, '-4.207')]
[36m[2025-06-29 12:05:20,979][60274] Fps is (10 sec: 409.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 151552. Throughput: 0: 80.6. Samples: 151560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:20,979][60274] Avg episode reward: [(0, '-4.069')]
[36m[2025-06-29 12:05:25,952][60274] Fps is (10 sec: 410.5, 60 sec: 136.7, 300 sec: 83.3). Total num frames: 151552. Throughput: 0: 80.8. Samples: 152060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:25,952][60274] Avg episode reward: [(0, '-6.541')]
[36m[2025-06-29 12:05:30,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 151552. Throughput: 0: 80.3. Samples: 152544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:30,962][60274] Avg episode reward: [(0, '-5.533')]
[36m[2025-06-29 12:05:35,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 151552. Throughput: 0: 80.1. Samples: 152784. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:35,952][60274] Avg episode reward: [(0, '-3.700')]
[36m[2025-06-29 12:05:40,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 151552. Throughput: 0: 80.4. Samples: 153288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:40,971][60274] Avg episode reward: [(0, '-0.886')]
[36m[2025-06-29 12:05:45,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 151552. Throughput: 0: 80.8. Samples: 153776. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:45,970][60274] Avg episode reward: [(0, '-0.599')]
[36m[2025-06-29 12:05:50,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 151552. Throughput: 0: 81.1. Samples: 154032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:50,989][60274] Avg episode reward: [(0, '4.438')]
[36m[2025-06-29 12:05:55,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 151552. Throughput: 0: 81.3. Samples: 154524. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:05:55,978][60274] Avg episode reward: [(0, '3.068')]
[36m[2025-06-29 12:06:00,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 151552. Throughput: 0: 81.1. Samples: 155028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:00,985][60274] Avg episode reward: [(0, '6.884')]
[36m[2025-06-29 12:06:05,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 151552. Throughput: 0: 82.6. Samples: 155276. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:05,978][60274] Avg episode reward: [(0, '7.502')]
[36m[2025-06-29 12:06:10,963][60274] Fps is (10 sec: 410.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 155648. Throughput: 0: 80.7. Samples: 155692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:10,963][60274] Avg episode reward: [(0, '9.999')]
[36m[2025-06-29 12:06:15,957][60274] Fps is (10 sec: 410.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 155648. Throughput: 0: 81.3. Samples: 156204. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:15,957][60274] Avg episode reward: [(0, '7.912')]
[36m[2025-06-29 12:06:20,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 155648. Throughput: 0: 81.2. Samples: 156440. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:20,960][60274] Avg episode reward: [(0, '11.338')]
[36m[2025-06-29 12:06:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 155648. Throughput: 0: 81.1. Samples: 156940. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:25,980][60274] Avg episode reward: [(0, '13.866')]
[36m[2025-06-29 12:06:30,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 155648. Throughput: 0: 80.5. Samples: 157396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:30,965][60274] Avg episode reward: [(0, '13.137')]
[36m[2025-06-29 12:06:35,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 155648. Throughput: 0: 79.8. Samples: 157620. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:35,964][60274] Avg episode reward: [(0, '13.810')]
[36m[2025-06-29 12:06:40,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 155648. Throughput: 0: 80.2. Samples: 158132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:40,970][60274] Avg episode reward: [(0, '10.773')]
[36m[2025-06-29 12:06:45,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 155648. Throughput: 0: 80.2. Samples: 158636. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:45,988][60274] Avg episode reward: [(0, '9.566')]
[36m[2025-06-29 12:06:50,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 155648. Throughput: 0: 80.1. Samples: 158880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:50,956][60274] Avg episode reward: [(0, '5.926')]
[36m[2025-06-29 12:06:55,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 155648. Throughput: 0: 81.6. Samples: 159364. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:06:55,953][60274] Avg episode reward: [(0, '13.451')]
[31m[2044115 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[2044115 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[2044115 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 12:07:00,959][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 159744. Throughput: 0: 79.7. Samples: 159792. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:07:00,959][60274] Avg episode reward: [(0, '15.679')]
[37m[1m[2025-06-29 12:07:01,005][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000624_159744.pth...
[36m[2025-06-29 12:07:01,060][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000544_139264.pth
[36m[2025-06-29 12:07:05,987][60274] Fps is (10 sec: 408.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 159744. Throughput: 0: 79.9. Samples: 160036. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:07:05,988][60274] Avg episode reward: [(0, '13.550')]
[36m[2025-06-29 12:07:10,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 159744. Throughput: 0: 80.2. Samples: 160548. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:07:10,977][60274] Avg episode reward: [(0, '12.638')]
[36m[2025-06-29 12:07:15,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 159744. Throughput: 0: 81.1. Samples: 161044. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:07:15,961][60274] Avg episode reward: [(0, '10.920')]
[36m[2025-06-29 12:07:20,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 159744. Throughput: 0: 81.5. Samples: 161288. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:07:20,957][60274] Avg episode reward: [(0, '14.426')]
[36m[2025-06-29 12:07:25,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 159744. Throughput: 0: 81.3. Samples: 161788. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:07:25,951][60274] Avg episode reward: [(0, '8.288')]
[36m[2025-06-29 12:07:30,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 159744. Throughput: 0: 81.3. Samples: 162292. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:07:30,975][60274] Avg episode reward: [(0, '12.219')]
[36m[2025-06-29 12:07:35,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 159744. Throughput: 0: 81.2. Samples: 162536. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:07:35,973][60274] Avg episode reward: [(0, '9.229')]
[36m[2025-06-29 12:07:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 159744. Throughput: 0: 81.2. Samples: 163016. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:07:40,947][60274] Avg episode reward: [(0, '11.639')]
[36m[2025-06-29 12:07:45,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 159744. Throughput: 0: 82.4. Samples: 163500. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:07:45,983][60274] Avg episode reward: [(0, '8.917')]
[36m[2025-06-29 12:07:50,956][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 163840. Throughput: 0: 82.7. Samples: 163756. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:07:50,956][60274] Avg episode reward: [(0, '10.845')]
[36m[2025-06-29 12:07:55,967][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 163840. Throughput: 0: 80.8. Samples: 164184. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:07:55,967][60274] Avg episode reward: [(0, '8.213')]
[36m[2025-06-29 12:08:00,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 163840. Throughput: 0: 80.7. Samples: 164676. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:08:00,963][60274] Avg episode reward: [(0, '10.633')]
[36m[2025-06-29 12:08:05,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 163840. Throughput: 0: 80.5. Samples: 164912. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:08:05,955][60274] Avg episode reward: [(0, '5.665')]
[36m[2025-06-29 12:08:10,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 163840. Throughput: 0: 80.1. Samples: 165392. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:08:10,967][60274] Avg episode reward: [(0, '15.093')]
[36m[2025-06-29 12:08:15,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 163840. Throughput: 0: 79.4. Samples: 165864. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:08:15,957][60274] Avg episode reward: [(0, '13.649')]
[36m[2025-06-29 12:08:20,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 163840. Throughput: 0: 79.6. Samples: 166116. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:08:20,965][60274] Avg episode reward: [(0, '11.432')]
[36m[2025-06-29 12:08:25,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 163840. Throughput: 0: 79.8. Samples: 166608. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:08:25,988][60274] Avg episode reward: [(0, '10.698')]
[36m[2025-06-29 12:08:30,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 163840. Throughput: 0: 79.5. Samples: 167076. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:08:30,983][60274] Avg episode reward: [(0, '9.723')]
[36m[2025-06-29 12:08:35,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 163840. Throughput: 0: 79.4. Samples: 167328. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:08:35,959][60274] Avg episode reward: [(0, '17.796')]
[36m[2025-06-29 12:08:41,319][60274] Fps is (10 sec: 396.3, 60 sec: 135.7, 300 sec: 83.2). Total num frames: 167936. Throughput: 0: 80.4. Samples: 167832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:08:41,319][60274] Avg episode reward: [(0, '12.818')]
[36m[2025-06-29 12:08:45,948][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 167936. Throughput: 0: 80.1. Samples: 168280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:08:45,949][60274] Avg episode reward: [(0, '16.427')]
[36m[2025-06-29 12:08:50,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 167936. Throughput: 0: 80.2. Samples: 168520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:08:50,966][60274] Avg episode reward: [(0, '13.451')]
[36m[2025-06-29 12:08:55,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 167936. Throughput: 0: 80.3. Samples: 169004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:08:55,975][60274] Avg episode reward: [(0, '18.005')]
[36m[2025-06-29 12:09:00,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 167936. Throughput: 0: 80.8. Samples: 169500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:09:00,968][60274] Avg episode reward: [(0, '12.819')]
[37m[1m[2025-06-29 12:09:01,014][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000656_167936.pth...
[36m[2025-06-29 12:09:01,069][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000576_147456.pth
[36m[2025-06-29 12:09:05,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 167936. Throughput: 0: 80.5. Samples: 169736. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:09:05,961][60274] Avg episode reward: [(0, '22.667')]
[36m[2025-06-29 12:09:10,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 167936. Throughput: 0: 80.3. Samples: 170220. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:09:10,991][60274] Avg episode reward: [(0, '17.285')]
[36m[2025-06-29 12:09:15,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 167936. Throughput: 0: 80.9. Samples: 170716. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:09:15,983][60274] Avg episode reward: [(0, '22.874')]
[36m[2025-06-29 12:09:20,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 167936. Throughput: 0: 80.3. Samples: 170940. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:09:20,959][60274] Avg episode reward: [(0, '19.855')]
[36m[2025-06-29 12:09:26,008][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 167936. Throughput: 0: 80.2. Samples: 171416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:09:26,008][60274] Avg episode reward: [(0, '22.096')]
[36m[2025-06-29 12:09:30,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 167936. Throughput: 0: 80.5. Samples: 171904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:09:30,965][60274] Avg episode reward: [(0, '19.311')]
[36m[2025-06-29 12:09:35,996][60274] Fps is (10 sec: 410.1, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 172032. Throughput: 0: 79.3. Samples: 172092. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:09:35,996][60274] Avg episode reward: [(0, '18.485')]
[36m[2025-06-29 12:09:40,955][60274] Fps is (10 sec: 410.0, 60 sec: 68.7, 300 sec: 83.3). Total num frames: 172032. Throughput: 0: 79.6. Samples: 172584. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:09:40,955][60274] Avg episode reward: [(0, '18.511')]
[36m[2025-06-29 12:09:45,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 172032. Throughput: 0: 79.8. Samples: 173092. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:09:45,962][60274] Avg episode reward: [(0, '16.960')]
[36m[2025-06-29 12:09:50,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 172032. Throughput: 0: 80.1. Samples: 173340. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:09:50,967][60274] Avg episode reward: [(0, '18.302')]
[36m[2025-06-29 12:09:55,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 172032. Throughput: 0: 80.5. Samples: 173840. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:09:55,963][60274] Avg episode reward: [(0, '15.874')]
[36m[2025-06-29 12:10:00,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 172032. Throughput: 0: 80.4. Samples: 174332. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:10:00,964][60274] Avg episode reward: [(0, '10.855')]
[36m[2025-06-29 12:10:05,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 172032. Throughput: 0: 81.0. Samples: 174588. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:10:05,978][60274] Avg episode reward: [(0, '18.473')]
[36m[2025-06-29 12:10:10,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 172032. Throughput: 0: 81.6. Samples: 175084. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:10:10,977][60274] Avg episode reward: [(0, '18.509')]
[36m[2025-06-29 12:10:15,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 172032. Throughput: 0: 81.5. Samples: 175572. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:10:15,992][60274] Avg episode reward: [(0, '17.450')]
[31m[2244648 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[2244649 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[2244649 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 12:10:20,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 172032. Throughput: 0: 82.7. Samples: 175812. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:10:20,993][60274] Avg episode reward: [(0, '17.077')]
[36m[2025-06-29 12:10:25,977][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 176128. Throughput: 0: 81.4. Samples: 176248. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:10:25,977][60274] Avg episode reward: [(0, '18.458')]
[36m[2025-06-29 12:10:30,957][60274] Fps is (10 sec: 411.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 176128. Throughput: 0: 81.0. Samples: 176736. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:10:30,957][60274] Avg episode reward: [(0, '16.190')]
[36m[2025-06-29 12:10:35,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 176128. Throughput: 0: 80.9. Samples: 176980. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:10:35,954][60274] Avg episode reward: [(0, '16.693')]
[36m[2025-06-29 12:10:40,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 176128. Throughput: 0: 80.6. Samples: 177468. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:10:40,960][60274] Avg episode reward: [(0, '16.647')]
[36m[2025-06-29 12:10:45,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 176128. Throughput: 0: 80.2. Samples: 177944. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:10:45,973][60274] Avg episode reward: [(0, '23.454')]
[36m[2025-06-29 12:10:50,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 176128. Throughput: 0: 80.0. Samples: 178192. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:10:51,000][60274] Avg episode reward: [(0, '22.470')]
[36m[2025-06-29 12:10:55,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 176128. Throughput: 0: 79.5. Samples: 178660. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:10:55,957][60274] Avg episode reward: [(0, '23.595')]
[36m[2025-06-29 12:11:00,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 176128. Throughput: 0: 79.4. Samples: 179144. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:11:00,990][60274] Avg episode reward: [(0, '28.437')]
[37m[1m[2025-06-29 12:11:01,055][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000688_176128.pth...
[36m[2025-06-29 12:11:01,111][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000624_159744.pth
[36m[2025-06-29 12:11:05,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 176128. Throughput: 0: 79.5. Samples: 179388. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:11:05,970][60274] Avg episode reward: [(0, '26.221')]
[36m[2025-06-29 12:11:10,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 176128. Throughput: 0: 80.2. Samples: 179856. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:11:10,948][60274] Avg episode reward: [(0, '24.107')]
[36m[2025-06-29 12:11:15,969][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 180224. Throughput: 0: 79.2. Samples: 180300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:11:15,969][60274] Avg episode reward: [(0, '26.018')]
[36m[2025-06-29 12:11:20,982][60274] Fps is (10 sec: 408.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 180224. Throughput: 0: 79.1. Samples: 180540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:11:20,982][60274] Avg episode reward: [(0, '27.212')]
[36m[2025-06-29 12:11:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 180224. Throughput: 0: 78.9. Samples: 181020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:11:25,957][60274] Avg episode reward: [(0, '24.531')]
[36m[2025-06-29 12:11:30,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 180224. Throughput: 0: 79.3. Samples: 181512. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:11:30,979][60274] Avg episode reward: [(0, '29.894')]
[36m[2025-06-29 12:11:35,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 180224. Throughput: 0: 79.0. Samples: 181744. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:11:35,949][60274] Avg episode reward: [(0, '30.425')]
[36m[2025-06-29 12:11:40,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 180224. Throughput: 0: 78.9. Samples: 182212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:11:40,984][60274] Avg episode reward: [(0, '19.429')]
[36m[2025-06-29 12:11:45,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 180224. Throughput: 0: 79.1. Samples: 182704. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:11:45,987][60274] Avg episode reward: [(0, '22.207')]
[36m[2025-06-29 12:11:50,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 180224. Throughput: 0: 79.1. Samples: 182948. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:11:50,970][60274] Avg episode reward: [(0, '25.619')]
[36m[2025-06-29 12:11:55,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 180224. Throughput: 0: 79.5. Samples: 183432. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:11:55,953][60274] Avg episode reward: [(0, '20.943')]
[36m[2025-06-29 12:12:00,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 180224. Throughput: 0: 80.6. Samples: 183924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:12:00,958][60274] Avg episode reward: [(0, '28.047')]
[36m[2025-06-29 12:12:06,011][60274] Fps is (10 sec: 407.2, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 184320. Throughput: 0: 80.5. Samples: 184164. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:06,012][60274] Avg episode reward: [(0, '29.395')]
[36m[2025-06-29 12:12:10,946][60274] Fps is (10 sec: 410.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 184320. Throughput: 0: 79.6. Samples: 184600. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:10,947][60274] Avg episode reward: [(0, '29.534')]
[36m[2025-06-29 12:12:15,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 184320. Throughput: 0: 79.2. Samples: 185076. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:15,968][60274] Avg episode reward: [(0, '30.765')]
[36m[2025-06-29 12:12:20,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 184320. Throughput: 0: 79.6. Samples: 185328. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:20,950][60274] Avg episode reward: [(0, '32.253')]
[36m[2025-06-29 12:12:25,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 184320. Throughput: 0: 80.4. Samples: 185828. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:25,948][60274] Avg episode reward: [(0, '32.264')]
[36m[2025-06-29 12:12:30,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 184320. Throughput: 0: 80.4. Samples: 186324. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:30,993][60274] Avg episode reward: [(0, '33.106')]
[31m[2378603 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[2378603 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[2378603 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 12:12:35,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 184320. Throughput: 0: 80.4. Samples: 186564. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:35,963][60274] Avg episode reward: [(0, '22.522')]
[36m[2025-06-29 12:12:40,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 184320. Throughput: 0: 80.5. Samples: 187056. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:40,993][60274] Avg episode reward: [(0, '24.892')]
[36m[2025-06-29 12:12:45,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 184320. Throughput: 0: 80.5. Samples: 187548. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:45,987][60274] Avg episode reward: [(0, '28.924')]
[36m[2025-06-29 12:12:50,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 184320. Throughput: 0: 80.6. Samples: 187788. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:50,966][60274] Avg episode reward: [(0, '26.308')]
[36m[2025-06-29 12:12:55,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 184320. Throughput: 0: 81.7. Samples: 188276. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:12:55,960][60274] Avg episode reward: [(0, '30.099')]
[36m[2025-06-29 12:13:00,970][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 188416. Throughput: 0: 80.4. Samples: 188692. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:13:00,971][60274] Avg episode reward: [(0, '28.731')]
[37m[1m[2025-06-29 12:13:01,021][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000736_188416.pth...
[36m[2025-06-29 12:13:01,076][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000656_167936.pth
[36m[2025-06-29 12:13:05,957][60274] Fps is (10 sec: 409.7, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 188416. Throughput: 0: 79.9. Samples: 188924. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:13:05,958][60274] Avg episode reward: [(0, '34.386')]
[36m[2025-06-29 12:13:10,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 188416. Throughput: 0: 79.7. Samples: 189416. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:13:10,954][60274] Avg episode reward: [(0, '37.265')]
[36m[2025-06-29 12:13:15,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 188416. Throughput: 0: 79.7. Samples: 189912. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:13:15,987][60274] Avg episode reward: [(0, '32.655')]
[36m[2025-06-29 12:13:20,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 188416. Throughput: 0: 79.7. Samples: 190152. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:13:20,994][60274] Avg episode reward: [(0, '37.373')]
[36m[2025-06-29 12:13:25,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 188416. Throughput: 0: 79.3. Samples: 190624. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:13:25,966][60274] Avg episode reward: [(0, '36.079')]
[36m[2025-06-29 12:13:30,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 188416. Throughput: 0: 79.2. Samples: 191108. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:13:30,957][60274] Avg episode reward: [(0, '45.753')]
[36m[2025-06-29 12:13:35,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 188416. Throughput: 0: 79.2. Samples: 191352. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:13:35,972][60274] Avg episode reward: [(0, '41.543')]
[36m[2025-06-29 12:13:40,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 188416. Throughput: 0: 78.8. Samples: 191824. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:13:40,967][60274] Avg episode reward: [(0, '44.805')]
[36m[2025-06-29 12:13:45,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 188416. Throughput: 0: 80.2. Samples: 192300. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:13:45,980][60274] Avg episode reward: [(0, '34.943')]
[36m[2025-06-29 12:13:50,954][60274] Fps is (10 sec: 410.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 192512. Throughput: 0: 79.9. Samples: 192520. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 12:13:50,954][60274] Avg episode reward: [(0, '33.029')]
[36m[2025-06-29 12:13:55,963][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 192512. Throughput: 0: 79.5. Samples: 192992. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 12:13:55,964][60274] Avg episode reward: [(0, '35.879')]
[36m[2025-06-29 12:14:00,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 192512. Throughput: 0: 79.8. Samples: 193504. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 12:14:00,988][60274] Avg episode reward: [(0, '34.615')]
[36m[2025-06-29 12:14:05,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 192512. Throughput: 0: 80.1. Samples: 193756. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 12:14:05,976][60274] Avg episode reward: [(0, '32.265')]
[36m[2025-06-29 12:14:10,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 192512. Throughput: 0: 80.4. Samples: 194244. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 12:14:10,983][60274] Avg episode reward: [(0, '38.323')]
[36m[2025-06-29 12:14:15,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 192512. Throughput: 0: 80.3. Samples: 194724. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 12:14:15,984][60274] Avg episode reward: [(0, '40.425')]
[36m[2025-06-29 12:14:20,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 192512. Throughput: 0: 80.6. Samples: 194980. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 12:14:20,979][60274] Avg episode reward: [(0, '44.762')]
[36m[2025-06-29 12:14:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 192512. Throughput: 0: 81.6. Samples: 195496. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 12:14:25,966][60274] Avg episode reward: [(0, '44.023')]
[36m[2025-06-29 12:14:30,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 192512. Throughput: 0: 81.5. Samples: 195964. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 12:14:30,949][60274] Avg episode reward: [(0, '45.688')]
[36m[2025-06-29 12:14:35,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 192512. Throughput: 0: 81.7. Samples: 196196. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 12:14:35,963][60274] Avg episode reward: [(0, '40.561')]
[36m[2025-06-29 12:14:40,980][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 196608. Throughput: 0: 80.9. Samples: 196636. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:14:40,981][60274] Avg episode reward: [(0, '44.552')]
[36m[2025-06-29 12:14:45,988][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 196608. Throughput: 0: 80.9. Samples: 197144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:14:45,988][60274] Avg episode reward: [(0, '52.453')]
[36m[2025-06-29 12:14:50,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 196608. Throughput: 0: 80.8. Samples: 197392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:14:50,967][60274] Avg episode reward: [(0, '49.303')]
[36m[2025-06-29 12:14:55,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 196608. Throughput: 0: 80.9. Samples: 197884. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:14:55,954][60274] Avg episode reward: [(0, '48.795')]
[36m[2025-06-29 12:15:00,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 196608. Throughput: 0: 81.2. Samples: 198380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:15:00,987][60274] Avg episode reward: [(0, '50.973')]
[37m[1m[2025-06-29 12:15:01,034][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000768_196608.pth...
[36m[2025-06-29 12:15:01,088][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000688_176128.pth
[36m[2025-06-29 12:15:05,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 196608. Throughput: 0: 81.1. Samples: 198628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:15:05,957][60274] Avg episode reward: [(0, '54.556')]
[36m[2025-06-29 12:15:10,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 196608. Throughput: 0: 80.4. Samples: 199116. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:15:10,978][60274] Avg episode reward: [(0, '50.961')]
[36m[2025-06-29 12:15:15,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 196608. Throughput: 0: 80.4. Samples: 199584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:15:15,951][60274] Avg episode reward: [(0, '55.517')]
[36m[2025-06-29 12:15:20,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 196608. Throughput: 0: 80.5. Samples: 199820. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:15:20,978][60274] Avg episode reward: [(0, '54.526')]
[36m[2025-06-29 12:15:25,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 196608. Throughput: 0: 81.8. Samples: 200316. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:15:25,984][60274] Avg episode reward: [(0, '52.973')]
[36m[2025-06-29 12:15:30,974][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 200704. Throughput: 0: 80.2. Samples: 200752. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:15:30,974][60274] Avg episode reward: [(0, '53.944')]
[36m[2025-06-29 12:15:35,956][60274] Fps is (10 sec: 410.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 200704. Throughput: 0: 80.1. Samples: 200996. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:15:35,956][60274] Avg episode reward: [(0, '60.335')]
[36m[2025-06-29 12:15:40,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 200704. Throughput: 0: 79.5. Samples: 201460. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:15:40,956][60274] Avg episode reward: [(0, '63.929')]
[36m[2025-06-29 12:15:45,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 200704. Throughput: 0: 80.1. Samples: 201984. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:15:45,989][60274] Avg episode reward: [(0, '66.146')]
[36m[2025-06-29 12:15:50,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 200704. Throughput: 0: 80.0. Samples: 202232. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:15:50,999][60274] Avg episode reward: [(0, '62.234')]
[36m[2025-06-29 12:15:56,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 200704. Throughput: 0: 80.4. Samples: 202736. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:15:56,004][60274] Avg episode reward: [(0, '64.449')]
[36m[2025-06-29 12:16:00,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 200704. Throughput: 0: 80.9. Samples: 203228. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:16:00,969][60274] Avg episode reward: [(0, '63.119')]
[36m[2025-06-29 12:16:05,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 200704. Throughput: 0: 81.6. Samples: 203492. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:16:05,967][60274] Avg episode reward: [(0, '61.007')]
[36m[2025-06-29 12:16:10,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 200704. Throughput: 0: 81.9. Samples: 204000. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:16:10,953][60274] Avg episode reward: [(0, '62.081')]
[36m[2025-06-29 12:16:15,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 200704. Throughput: 0: 83.8. Samples: 204520. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:16:15,955][60274] Avg episode reward: [(0, '61.303')]
[36m[2025-06-29 12:16:20,963][60274] Fps is (10 sec: 409.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 204800. Throughput: 0: 83.6. Samples: 204760. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:16:20,963][60274] Avg episode reward: [(0, '58.350')]
[36m[2025-06-29 12:16:25,970][60274] Fps is (10 sec: 409.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 204800. Throughput: 0: 82.9. Samples: 205192. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:16:25,970][60274] Avg episode reward: [(0, '57.191')]
[36m[2025-06-29 12:16:30,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 204800. Throughput: 0: 81.4. Samples: 205644. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:16:30,974][60274] Avg episode reward: [(0, '49.963')]
[36m[2025-06-29 12:16:35,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 204800. Throughput: 0: 81.0. Samples: 205876. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:16:35,970][60274] Avg episode reward: [(0, '47.465')]
[36m[2025-06-29 12:16:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 204800. Throughput: 0: 80.5. Samples: 206356. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:16:40,947][60274] Avg episode reward: [(0, '45.814')]
[36m[2025-06-29 12:16:45,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 204800. Throughput: 0: 80.6. Samples: 206852. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:16:45,948][60274] Avg episode reward: [(0, '45.552')]
[36m[2025-06-29 12:16:50,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 204800. Throughput: 0: 80.3. Samples: 207104. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:16:50,955][60274] Avg episode reward: [(0, '37.986')]
[36m[2025-06-29 12:16:55,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 204800. Throughput: 0: 80.1. Samples: 207608. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:16:55,989][60274] Avg episode reward: [(0, '35.299')]
[36m[2025-06-29 12:17:00,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 204800. Throughput: 0: 79.2. Samples: 208084. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:17:00,950][60274] Avg episode reward: [(0, '34.098')]
[37m[1m[2025-06-29 12:17:00,997][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000800_204800.pth...
[36m[2025-06-29 12:17:01,052][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000736_188416.pth
[36m[2025-06-29 12:17:05,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 204800. Throughput: 0: 79.0. Samples: 208316. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:17:05,974][60274] Avg episode reward: [(0, '38.528')]
[36m[2025-06-29 12:17:11,107][60274] Fps is (10 sec: 403.3, 60 sec: 136.2, 300 sec: 83.3). Total num frames: 208896. Throughput: 0: 80.0. Samples: 208804. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:17:11,108][60274] Avg episode reward: [(0, '45.272')]
[36m[2025-06-29 12:17:15,949][60274] Fps is (10 sec: 410.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 208896. Throughput: 0: 79.7. Samples: 209228. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:17:15,949][60274] Avg episode reward: [(0, '41.102')]
[36m[2025-06-29 12:17:20,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 208896. Throughput: 0: 79.9. Samples: 209468. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:17:20,952][60274] Avg episode reward: [(0, '41.207')]
[36m[2025-06-29 12:17:25,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 208896. Throughput: 0: 80.3. Samples: 209968. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:17:25,949][60274] Avg episode reward: [(0, '43.438')]
[36m[2025-06-29 12:17:30,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 208896. Throughput: 0: 79.6. Samples: 210436. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:17:30,967][60274] Avg episode reward: [(0, '39.400')]
[36m[2025-06-29 12:17:35,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 208896. Throughput: 0: 79.5. Samples: 210684. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:17:35,969][60274] Avg episode reward: [(0, '43.235')]
[36m[2025-06-29 12:17:40,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 208896. Throughput: 0: 79.4. Samples: 211180. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:17:40,950][60274] Avg episode reward: [(0, '41.458')]
[36m[2025-06-29 12:17:45,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 208896. Throughput: 0: 79.9. Samples: 211684. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:17:45,991][60274] Avg episode reward: [(0, '39.684')]
[36m[2025-06-29 12:17:50,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 208896. Throughput: 0: 80.1. Samples: 211920. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:17:50,952][60274] Avg episode reward: [(0, '38.102')]
[36m[2025-06-29 12:17:55,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 208896. Throughput: 0: 80.4. Samples: 212412. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:17:55,961][60274] Avg episode reward: [(0, '40.850')]
[36m[2025-06-29 12:18:00,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 208896. Throughput: 0: 81.4. Samples: 212896. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:18:00,989][60274] Avg episode reward: [(0, '37.895')]
[36m[2025-06-29 12:18:05,993][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 212992. Throughput: 0: 80.5. Samples: 213092. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:18:05,993][60274] Avg episode reward: [(0, '44.264')]
[36m[2025-06-29 12:18:10,970][60274] Fps is (10 sec: 410.4, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 212992. Throughput: 0: 80.1. Samples: 213572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:18:10,970][60274] Avg episode reward: [(0, '48.076')]
[36m[2025-06-29 12:18:15,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 212992. Throughput: 0: 80.0. Samples: 214036. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:18:15,964][60274] Avg episode reward: [(0, '46.232')]
[36m[2025-06-29 12:18:20,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 212992. Throughput: 0: 79.8. Samples: 214276. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:18:20,964][60274] Avg episode reward: [(0, '47.497')]
[36m[2025-06-29 12:18:25,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 212992. Throughput: 0: 79.6. Samples: 214764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:18:25,978][60274] Avg episode reward: [(0, '51.442')]
[36m[2025-06-29 12:18:30,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 212992. Throughput: 0: 79.7. Samples: 215268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:18:30,980][60274] Avg episode reward: [(0, '58.935')]
[36m[2025-06-29 12:18:35,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 212992. Throughput: 0: 79.9. Samples: 215516. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:18:35,968][60274] Avg episode reward: [(0, '58.386')]
[36m[2025-06-29 12:18:40,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 212992. Throughput: 0: 79.8. Samples: 216004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:18:40,989][60274] Avg episode reward: [(0, '55.102')]
[36m[2025-06-29 12:18:45,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 212992. Throughput: 0: 80.2. Samples: 216504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:18:45,972][60274] Avg episode reward: [(0, '57.782')]
[36m[2025-06-29 12:18:50,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 212992. Throughput: 0: 81.4. Samples: 216752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:18:50,971][60274] Avg episode reward: [(0, '61.906')]
[36m[2025-06-29 12:18:55,983][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 217088. Throughput: 0: 80.1. Samples: 217176. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:18:55,983][60274] Avg episode reward: [(0, '66.811')]
[36m[2025-06-29 12:19:00,977][60274] Fps is (10 sec: 409.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 217088. Throughput: 0: 80.6. Samples: 217664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:19:00,977][60274] Avg episode reward: [(0, '55.234')]
[37m[1m[2025-06-29 12:19:01,027][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000848_217088.pth...
[36m[2025-06-29 12:19:01,082][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000768_196608.pth
[36m[2025-06-29 12:19:05,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 217088. Throughput: 0: 80.5. Samples: 217900. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:19:05,963][60274] Avg episode reward: [(0, '53.268')]
[36m[2025-06-29 12:19:10,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 217088. Throughput: 0: 80.1. Samples: 218368. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:19:10,973][60274] Avg episode reward: [(0, '51.013')]
[36m[2025-06-29 12:19:15,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 217088. Throughput: 0: 79.4. Samples: 218840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:19:15,986][60274] Avg episode reward: [(0, '47.055')]
[36m[2025-06-29 12:19:20,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 217088. Throughput: 0: 79.4. Samples: 219092. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:19:20,981][60274] Avg episode reward: [(0, '52.027')]
[36m[2025-06-29 12:19:25,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 217088. Throughput: 0: 79.7. Samples: 219588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:19:25,946][60274] Avg episode reward: [(0, '51.009')]
[36m[2025-06-29 12:19:30,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 217088. Throughput: 0: 79.6. Samples: 220088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:19:30,987][60274] Avg episode reward: [(0, '48.726')]
[36m[2025-06-29 12:19:36,006][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 217088. Throughput: 0: 79.5. Samples: 220332. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:19:36,006][60274] Avg episode reward: [(0, '52.601')]
[36m[2025-06-29 12:19:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 217088. Throughput: 0: 81.2. Samples: 220828. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:19:40,947][60274] Avg episode reward: [(0, '50.947')]
[36m[2025-06-29 12:19:45,992][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 221184. Throughput: 0: 80.0. Samples: 221264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:19:45,992][60274] Avg episode reward: [(0, '46.492')]
[36m[2025-06-29 12:19:50,985][60274] Fps is (10 sec: 408.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 221184. Throughput: 0: 80.3. Samples: 221516. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:19:50,986][60274] Avg episode reward: [(0, '56.032')]
[36m[2025-06-29 12:19:55,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 221184. Throughput: 0: 80.7. Samples: 222000. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:19:55,973][60274] Avg episode reward: [(0, '44.764')]
[36m[2025-06-29 12:20:00,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 221184. Throughput: 0: 81.7. Samples: 222512. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:20:00,955][60274] Avg episode reward: [(0, '40.130')]
[36m[2025-06-29 12:20:05,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 221184. Throughput: 0: 81.5. Samples: 222756. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:20:05,964][60274] Avg episode reward: [(0, '38.332')]
[36m[2025-06-29 12:20:10,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 221184. Throughput: 0: 81.2. Samples: 223240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:20:10,948][60274] Avg episode reward: [(0, '37.449')]
[36m[2025-06-29 12:20:15,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 221184. Throughput: 0: 80.8. Samples: 223720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:20:15,961][60274] Avg episode reward: [(0, '28.465')]
[36m[2025-06-29 12:20:20,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 221184. Throughput: 0: 80.2. Samples: 223940. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:20:20,996][60274] Avg episode reward: [(0, '30.770')]
[36m[2025-06-29 12:20:25,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 221184. Throughput: 0: 79.5. Samples: 224408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:20:25,954][60274] Avg episode reward: [(0, '29.460')]
[36m[2025-06-29 12:20:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 221184. Throughput: 0: 80.4. Samples: 224880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:20:30,973][60274] Avg episode reward: [(0, '29.759')]
[36m[2025-06-29 12:20:35,973][60274] Fps is (10 sec: 408.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 225280. Throughput: 0: 80.2. Samples: 225124. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:20:35,974][60274] Avg episode reward: [(0, '32.098')]
[36m[2025-06-29 12:20:40,966][60274] Fps is (10 sec: 409.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 225280. Throughput: 0: 78.9. Samples: 225552. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:20:40,966][60274] Avg episode reward: [(0, '27.063')]
[36m[2025-06-29 12:20:45,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 225280. Throughput: 0: 78.3. Samples: 226036. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:20:45,963][60274] Avg episode reward: [(0, '26.836')]
[36m[2025-06-29 12:20:50,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 225280. Throughput: 0: 78.2. Samples: 226272. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:20:50,951][60274] Avg episode reward: [(0, '26.133')]
[36m[2025-06-29 12:20:55,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 225280. Throughput: 0: 78.4. Samples: 226768. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:20:55,973][60274] Avg episode reward: [(0, '34.021')]
[36m[2025-06-29 12:21:00,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 225280. Throughput: 0: 78.7. Samples: 227260. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:21:00,965][60274] Avg episode reward: [(0, '32.473')]
[37m[1m[2025-06-29 12:21:01,012][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000880_225280.pth...
[36m[2025-06-29 12:21:01,068][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000800_204800.pth
[36m[2025-06-29 12:21:05,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 225280. Throughput: 0: 79.3. Samples: 227508. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:21:05,989][60274] Avg episode reward: [(0, '35.712')]
[36m[2025-06-29 12:21:10,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 225280. Throughput: 0: 79.2. Samples: 227972. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:21:10,947][60274] Avg episode reward: [(0, '33.455')]
[36m[2025-06-29 12:21:15,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 225280. Throughput: 0: 80.0. Samples: 228480. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:21:15,968][60274] Avg episode reward: [(0, '33.315')]
[36m[2025-06-29 12:21:20,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 225280. Throughput: 0: 80.1. Samples: 228728. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:21:20,954][60274] Avg episode reward: [(0, '31.721')]
[36m[2025-06-29 12:21:25,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 225280. Throughput: 0: 81.4. Samples: 229216. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:21:25,985][60274] Avg episode reward: [(0, '28.459')]
[36m[2025-06-29 12:21:30,967][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 229376. Throughput: 0: 80.5. Samples: 229660. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:21:30,967][60274] Avg episode reward: [(0, '34.562')]
[36m[2025-06-29 12:21:35,986][60274] Fps is (10 sec: 409.5, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 229376. Throughput: 0: 80.6. Samples: 229900. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:21:35,987][60274] Avg episode reward: [(0, '34.407')]
[36m[2025-06-29 12:21:40,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 229376. Throughput: 0: 80.2. Samples: 230380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:21:40,984][60274] Avg episode reward: [(0, '35.743')]
[36m[2025-06-29 12:21:45,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 229376. Throughput: 0: 80.1. Samples: 230868. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:21:45,990][60274] Avg episode reward: [(0, '32.135')]
[36m[2025-06-29 12:21:50,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 229376. Throughput: 0: 80.1. Samples: 231108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:21:50,957][60274] Avg episode reward: [(0, '38.028')]
[36m[2025-06-29 12:21:55,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 229376. Throughput: 0: 80.4. Samples: 231592. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:21:55,948][60274] Avg episode reward: [(0, '37.559')]
[36m[2025-06-29 12:22:00,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 229376. Throughput: 0: 79.8. Samples: 232068. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:22:00,952][60274] Avg episode reward: [(0, '42.207')]
[36m[2025-06-29 12:22:05,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 229376. Throughput: 0: 79.8. Samples: 232320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:22:05,981][60274] Avg episode reward: [(0, '48.473')]
[36m[2025-06-29 12:22:10,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 229376. Throughput: 0: 79.7. Samples: 232800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:22:10,978][60274] Avg episode reward: [(0, '36.805')]
[36m[2025-06-29 12:22:15,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 229376. Throughput: 0: 80.6. Samples: 233288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:22:15,959][60274] Avg episode reward: [(0, '42.043')]
[36m[2025-06-29 12:22:20,961][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 233472. Throughput: 0: 79.6. Samples: 233480. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:22:20,961][60274] Avg episode reward: [(0, '47.735')]
[36m[2025-06-29 12:22:25,972][60274] Fps is (10 sec: 409.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 233472. Throughput: 0: 79.8. Samples: 233972. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:22:25,973][60274] Avg episode reward: [(0, '44.236')]
[31m[2972076 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[2972076 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[2972076 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 12:22:31,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 233472. Throughput: 0: 79.9. Samples: 234464. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:22:31,005][60274] Avg episode reward: [(0, '42.532')]
[36m[2025-06-29 12:22:35,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 233472. Throughput: 0: 79.6. Samples: 234692. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:22:35,966][60274] Avg episode reward: [(0, '44.919')]
[36m[2025-06-29 12:22:40,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 233472. Throughput: 0: 79.2. Samples: 235156. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:22:40,971][60274] Avg episode reward: [(0, '45.379')]
[36m[2025-06-29 12:22:45,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 233472. Throughput: 0: 79.4. Samples: 235644. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:22:45,973][60274] Avg episode reward: [(0, '43.248')]
[36m[2025-06-29 12:22:50,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 233472. Throughput: 0: 79.2. Samples: 235884. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:22:50,990][60274] Avg episode reward: [(0, '43.824')]
[36m[2025-06-29 12:22:55,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 233472. Throughput: 0: 79.8. Samples: 236392. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:22:55,971][60274] Avg episode reward: [(0, '43.007')]
[36m[2025-06-29 12:23:00,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 233472. Throughput: 0: 80.0. Samples: 236888. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:23:00,976][60274] Avg episode reward: [(0, '48.417')]
[37m[1m[2025-06-29 12:23:01,024][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000912_233472.pth...
[36m[2025-06-29 12:23:01,078][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000848_217088.pth
[36m[2025-06-29 12:23:05,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 233472. Throughput: 0: 81.0. Samples: 237124. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 12:23:05,954][60274] Avg episode reward: [(0, '40.916')]
[36m[2025-06-29 12:23:10,970][60274] Fps is (10 sec: 409.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 237568. Throughput: 0: 80.1. Samples: 237576. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:23:10,970][60274] Avg episode reward: [(0, '43.057')]
[36m[2025-06-29 12:23:15,978][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 237568. Throughput: 0: 80.0. Samples: 238064. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:23:15,978][60274] Avg episode reward: [(0, '47.263')]
[36m[2025-06-29 12:23:20,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 237568. Throughput: 0: 80.5. Samples: 238316. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:23:20,972][60274] Avg episode reward: [(0, '41.712')]
[36m[2025-06-29 12:23:25,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 237568. Throughput: 0: 81.0. Samples: 238800. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:23:25,958][60274] Avg episode reward: [(0, '43.318')]
[36m[2025-06-29 12:23:30,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 237568. Throughput: 0: 80.4. Samples: 239264. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:23:30,980][60274] Avg episode reward: [(0, '44.841')]
[36m[2025-06-29 12:23:36,013][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 237568. Throughput: 0: 80.5. Samples: 239508. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:23:36,014][60274] Avg episode reward: [(0, '49.381')]
[36m[2025-06-29 12:23:40,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 237568. Throughput: 0: 80.3. Samples: 240004. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:23:40,950][60274] Avg episode reward: [(0, '47.044')]
[36m[2025-06-29 12:23:45,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 237568. Throughput: 0: 80.7. Samples: 240520. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:23:45,998][60274] Avg episode reward: [(0, '53.167')]
[36m[2025-06-29 12:23:50,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 237568. Throughput: 0: 80.8. Samples: 240764. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:23:50,980][60274] Avg episode reward: [(0, '48.867')]
[36m[2025-06-29 12:23:55,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 237568. Throughput: 0: 82.2. Samples: 241276. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 12:23:55,964][60274] Avg episode reward: [(0, '51.661')]
[36m[2025-06-29 12:24:00,970][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 241664. Throughput: 0: 80.9. Samples: 241704. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:24:00,970][60274] Avg episode reward: [(0, '52.141')]
[36m[2025-06-29 12:24:05,977][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 241664. Throughput: 0: 80.7. Samples: 241948. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:24:05,977][60274] Avg episode reward: [(0, '55.321')]
[36m[2025-06-29 12:24:10,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 241664. Throughput: 0: 80.2. Samples: 242412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:24:10,979][60274] Avg episode reward: [(0, '43.498')]
[36m[2025-06-29 12:24:15,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 241664. Throughput: 0: 80.4. Samples: 242884. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:24:15,989][60274] Avg episode reward: [(0, '47.669')]
[36m[2025-06-29 12:24:20,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 241664. Throughput: 0: 80.8. Samples: 243140. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:24:20,953][60274] Avg episode reward: [(0, '48.358')]
[36m[2025-06-29 12:24:25,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 241664. Throughput: 0: 80.5. Samples: 243628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:24:25,967][60274] Avg episode reward: [(0, '45.026')]
[36m[2025-06-29 12:24:30,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 241664. Throughput: 0: 80.2. Samples: 244128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:24:30,968][60274] Avg episode reward: [(0, '50.433')]
[36m[2025-06-29 12:24:35,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 241664. Throughput: 0: 80.0. Samples: 244360. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:24:35,947][60274] Avg episode reward: [(0, '48.872')]
[36m[2025-06-29 12:24:40,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 241664. Throughput: 0: 79.6. Samples: 244860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:24:40,984][60274] Avg episode reward: [(0, '45.280')]
[36m[2025-06-29 12:24:45,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 241664. Throughput: 0: 81.0. Samples: 245348. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:24:45,955][60274] Avg episode reward: [(0, '42.505')]
[36m[2025-06-29 12:24:51,095][60274] Fps is (10 sec: 405.1, 60 sec: 136.3, 300 sec: 83.3). Total num frames: 245760. Throughput: 0: 80.8. Samples: 245592. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:24:51,095][60274] Avg episode reward: [(0, '45.741')]
[36m[2025-06-29 12:24:55,966][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 245760. Throughput: 0: 80.4. Samples: 246028. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:24:55,966][60274] Avg episode reward: [(0, '42.198')]
[36m[2025-06-29 12:25:00,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 245760. Throughput: 0: 81.1. Samples: 246532. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:25:00,954][60274] Avg episode reward: [(0, '52.986')]
[37m[1m[2025-06-29 12:25:01,002][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000960_245760.pth...
[36m[2025-06-29 12:25:01,056][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000880_225280.pth
[36m[2025-06-29 12:25:05,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 245760. Throughput: 0: 80.8. Samples: 246780. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:25:05,986][60274] Avg episode reward: [(0, '56.008')]
[36m[2025-06-29 12:25:10,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 245760. Throughput: 0: 81.1. Samples: 247276. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:25:10,971][60274] Avg episode reward: [(0, '49.525')]
[36m[2025-06-29 12:25:15,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 245760. Throughput: 0: 81.2. Samples: 247784. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:25:15,970][60274] Avg episode reward: [(0, '49.801')]
[36m[2025-06-29 12:25:20,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 245760. Throughput: 0: 81.7. Samples: 248040. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:25:20,964][60274] Avg episode reward: [(0, '41.001')]
[36m[2025-06-29 12:25:25,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 245760. Throughput: 0: 81.8. Samples: 248540. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:25:25,986][60274] Avg episode reward: [(0, '37.537')]
[36m[2025-06-29 12:25:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 245760. Throughput: 0: 81.7. Samples: 249028. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:25:30,973][60274] Avg episode reward: [(0, '37.541')]
[36m[2025-06-29 12:25:35,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 245760. Throughput: 0: 82.0. Samples: 249272. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:25:35,969][60274] Avg episode reward: [(0, '36.213')]
[36m[2025-06-29 12:25:41,229][60274] Fps is (10 sec: 399.4, 60 sec: 136.0, 300 sec: 83.2). Total num frames: 249856. Throughput: 0: 82.6. Samples: 249768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:25:41,229][60274] Avg episode reward: [(0, '38.313')]
[36m[2025-06-29 12:25:45,979][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 249856. Throughput: 0: 81.7. Samples: 250212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:25:45,979][60274] Avg episode reward: [(0, '37.670')]
[36m[2025-06-29 12:25:50,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 249856. Throughput: 0: 81.5. Samples: 250444. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:25:50,948][60274] Avg episode reward: [(0, '42.157')]
[36m[2025-06-29 12:25:55,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 249856. Throughput: 0: 80.8. Samples: 250912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:25:55,988][60274] Avg episode reward: [(0, '41.059')]
[36m[2025-06-29 12:26:00,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 249856. Throughput: 0: 80.4. Samples: 251404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:26:00,971][60274] Avg episode reward: [(0, '47.240')]
[36m[2025-06-29 12:26:05,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 249856. Throughput: 0: 80.1. Samples: 251648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:26:05,991][60274] Avg episode reward: [(0, '46.145')]
[36m[2025-06-29 12:26:10,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 249856. Throughput: 0: 80.0. Samples: 252136. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:26:10,947][60274] Avg episode reward: [(0, '48.535')]
[36m[2025-06-29 12:26:15,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 249856. Throughput: 0: 80.0. Samples: 252628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:26:15,966][60274] Avg episode reward: [(0, '41.455')]
[36m[2025-06-29 12:26:20,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 249856. Throughput: 0: 79.7. Samples: 252860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:26:20,970][60274] Avg episode reward: [(0, '38.421')]
[36m[2025-06-29 12:26:25,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 249856. Throughput: 0: 79.8. Samples: 253336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:26:25,959][60274] Avg episode reward: [(0, '42.874')]
[36m[2025-06-29 12:26:30,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 249856. Throughput: 0: 79.9. Samples: 253804. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:26:30,949][60274] Avg episode reward: [(0, '40.858')]
[36m[2025-06-29 12:26:35,979][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 253952. Throughput: 0: 78.5. Samples: 253980. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 12:26:35,979][60274] Avg episode reward: [(0, '39.248')]
[36m[2025-06-29 12:26:40,954][60274] Fps is (10 sec: 409.4, 60 sec: 68.6, 300 sec: 83.3). Total num frames: 253952. Throughput: 0: 79.3. Samples: 254480. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 12:26:40,955][60274] Avg episode reward: [(0, '44.543')]
[36m[2025-06-29 12:26:45,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 253952. Throughput: 0: 79.4. Samples: 254976. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 12:26:45,984][60274] Avg episode reward: [(0, '31.188')]
[36m[2025-06-29 12:26:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 253952. Throughput: 0: 79.2. Samples: 255212. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 12:26:50,976][60274] Avg episode reward: [(0, '34.540')]
[36m[2025-06-29 12:26:55,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 253952. Throughput: 0: 79.1. Samples: 255696. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 12:26:55,964][60274] Avg episode reward: [(0, '28.334')]
[36m[2025-06-29 12:27:00,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 253952. Throughput: 0: 79.1. Samples: 256188. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 12:27:00,992][60274] Avg episode reward: [(0, '35.887')]
[37m[1m[2025-06-29 12:27:01,051][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000992_253952.pth...
[36m[2025-06-29 12:27:01,108][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000912_233472.pth
[36m[2025-06-29 12:27:05,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 253952. Throughput: 0: 79.0. Samples: 256416. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 12:27:05,985][60274] Avg episode reward: [(0, '41.334')]
[36m[2025-06-29 12:27:10,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 253952. Throughput: 0: 79.9. Samples: 256932. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 12:27:10,986][60274] Avg episode reward: [(0, '45.013')]
[36m[2025-06-29 12:27:15,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 253952. Throughput: 0: 80.8. Samples: 257440. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 12:27:15,956][60274] Avg episode reward: [(0, '38.933')]
[36m[2025-06-29 12:27:20,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 253952. Throughput: 0: 82.3. Samples: 257680. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 12:27:20,964][60274] Avg episode reward: [(0, '40.047')]
[36m[2025-06-29 12:27:25,958][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 258048. Throughput: 0: 81.2. Samples: 258136. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:27:25,959][60274] Avg episode reward: [(0, '39.075')]
[36m[2025-06-29 12:27:30,967][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 258048. Throughput: 0: 81.1. Samples: 258624. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:27:30,967][60274] Avg episode reward: [(0, '29.051')]
[36m[2025-06-29 12:27:35,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 258048. Throughput: 0: 81.2. Samples: 258868. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:27:35,977][60274] Avg episode reward: [(0, '32.615')]
[36m[2025-06-29 12:27:40,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 258048. Throughput: 0: 81.1. Samples: 259344. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:27:40,955][60274] Avg episode reward: [(0, '20.093')]
[36m[2025-06-29 12:27:45,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 258048. Throughput: 0: 81.2. Samples: 259840. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:27:45,985][60274] Avg episode reward: [(0, '24.050')]
[36m[2025-06-29 12:27:50,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 258048. Throughput: 0: 81.4. Samples: 260076. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:27:50,962][60274] Avg episode reward: [(0, '26.843')]
[36m[2025-06-29 12:27:55,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 258048. Throughput: 0: 80.9. Samples: 260572. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:27:55,967][60274] Avg episode reward: [(0, '28.297')]
[36m[2025-06-29 12:28:00,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 258048. Throughput: 0: 80.6. Samples: 261068. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:28:00,982][60274] Avg episode reward: [(0, '37.476')]
[36m[2025-06-29 12:28:05,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 258048. Throughput: 0: 81.0. Samples: 261324. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:28:05,960][60274] Avg episode reward: [(0, '41.587')]
[36m[2025-06-29 12:28:10,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 258048. Throughput: 0: 82.2. Samples: 261832. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:28:10,947][60274] Avg episode reward: [(0, '33.601')]
[36m[2025-06-29 12:28:15,981][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 262144. Throughput: 0: 80.7. Samples: 262256. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:28:15,981][60274] Avg episode reward: [(0, '35.536')]
[36m[2025-06-29 12:28:20,993][60274] Fps is (10 sec: 407.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 262144. Throughput: 0: 80.7. Samples: 262500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:28:20,993][60274] Avg episode reward: [(0, '32.160')]
[36m[2025-06-29 12:28:25,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 262144. Throughput: 0: 80.8. Samples: 262980. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:28:25,967][60274] Avg episode reward: [(0, '35.695')]
[36m[2025-06-29 12:28:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 262144. Throughput: 0: 80.9. Samples: 263480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:28:30,973][60274] Avg episode reward: [(0, '40.672')]
[36m[2025-06-29 12:28:35,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 262144. Throughput: 0: 80.8. Samples: 263716. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:28:35,988][60274] Avg episode reward: [(0, '37.453')]
[36m[2025-06-29 12:28:40,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 262144. Throughput: 0: 80.7. Samples: 264204. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:28:40,960][60274] Avg episode reward: [(0, '40.020')]
[36m[2025-06-29 12:28:45,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 262144. Throughput: 0: 80.4. Samples: 264684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:28:45,949][60274] Avg episode reward: [(0, '38.054')]
[36m[2025-06-29 12:28:50,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 262144. Throughput: 0: 79.7. Samples: 264912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:28:50,996][60274] Avg episode reward: [(0, '38.666')]
[36m[2025-06-29 12:28:55,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 262144. Throughput: 0: 78.9. Samples: 265384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:28:55,986][60274] Avg episode reward: [(0, '37.552')]
[36m[2025-06-29 12:29:00,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 262144. Throughput: 0: 80.7. Samples: 265888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:29:00,985][60274] Avg episode reward: [(0, '39.609')]
[37m[1m[2025-06-29 12:29:01,036][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001024_262144.pth...
[36m[2025-06-29 12:29:01,091][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000960_245760.pth
[31m[3368321 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[3368321 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[3368321 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 12:29:05,966][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 266240. Throughput: 0: 80.3. Samples: 266112. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:05,967][60274] Avg episode reward: [(0, '38.939')]
[36m[2025-06-29 12:29:10,990][60274] Fps is (10 sec: 409.4, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 266240. Throughput: 0: 79.5. Samples: 266560. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:10,990][60274] Avg episode reward: [(0, '42.706')]
[36m[2025-06-29 12:29:15,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 266240. Throughput: 0: 79.1. Samples: 267036. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:15,947][60274] Avg episode reward: [(0, '47.817')]
[36m[2025-06-29 12:29:20,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 266240. Throughput: 0: 79.1. Samples: 267272. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:20,947][60274] Avg episode reward: [(0, '51.540')]
[36m[2025-06-29 12:29:25,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 266240. Throughput: 0: 79.3. Samples: 267772. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:25,957][60274] Avg episode reward: [(0, '57.448')]
[36m[2025-06-29 12:29:30,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 266240. Throughput: 0: 78.8. Samples: 268232. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:30,948][60274] Avg episode reward: [(0, '60.013')]
[36m[2025-06-29 12:29:35,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 266240. Throughput: 0: 79.2. Samples: 268476. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:35,970][60274] Avg episode reward: [(0, '56.599')]
[36m[2025-06-29 12:29:40,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 266240. Throughput: 0: 79.2. Samples: 268948. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:40,991][60274] Avg episode reward: [(0, '58.107')]
[36m[2025-06-29 12:29:45,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 266240. Throughput: 0: 79.3. Samples: 269456. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:45,957][60274] Avg episode reward: [(0, '60.712')]
[36m[2025-06-29 12:29:50,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 266240. Throughput: 0: 79.9. Samples: 269708. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:50,985][60274] Avg episode reward: [(0, '51.380')]
[36m[2025-06-29 12:29:55,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 266240. Throughput: 0: 80.5. Samples: 270184. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:29:55,999][60274] Avg episode reward: [(0, '62.458')]
[36m[2025-06-29 12:30:00,974][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 270336. Throughput: 0: 79.2. Samples: 270604. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:30:00,975][60274] Avg episode reward: [(0, '58.468')]
[36m[2025-06-29 12:30:05,958][60274] Fps is (10 sec: 411.3, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 270336. Throughput: 0: 79.7. Samples: 270860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:30:05,958][60274] Avg episode reward: [(0, '58.395')]
[36m[2025-06-29 12:30:10,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 270336. Throughput: 0: 78.7. Samples: 271312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:30:10,951][60274] Avg episode reward: [(0, '49.920')]
[36m[2025-06-29 12:30:15,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 270336. Throughput: 0: 79.5. Samples: 271812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:30:15,956][60274] Avg episode reward: [(0, '59.999')]
[36m[2025-06-29 12:30:20,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 270336. Throughput: 0: 79.4. Samples: 272048. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:30:20,961][60274] Avg episode reward: [(0, '64.576')]
[36m[2025-06-29 12:30:25,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 270336. Throughput: 0: 80.4. Samples: 272564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:30:25,978][60274] Avg episode reward: [(0, '59.665')]
[36m[2025-06-29 12:30:30,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 270336. Throughput: 0: 79.8. Samples: 273048. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:30:30,975][60274] Avg episode reward: [(0, '68.910')]
[36m[2025-06-29 12:30:35,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.5). Total num frames: 270336. Throughput: 0: 79.6. Samples: 273292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:30:35,990][60274] Avg episode reward: [(0, '68.398')]
[36m[2025-06-29 12:30:40,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 270336. Throughput: 0: 79.6. Samples: 273760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:30:40,952][60274] Avg episode reward: [(0, '67.287')]
[36m[2025-06-29 12:30:45,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 270336. Throughput: 0: 80.9. Samples: 274244. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:30:45,989][60274] Avg episode reward: [(0, '66.824')]
[36m[2025-06-29 12:30:51,005][60274] Fps is (10 sec: 407.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 274432. Throughput: 0: 79.5. Samples: 274440. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:30:51,005][60274] Avg episode reward: [(0, '64.741')]
[36m[2025-06-29 12:30:55,982][60274] Fps is (10 sec: 409.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 274432. Throughput: 0: 80.2. Samples: 274924. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:30:55,982][60274] Avg episode reward: [(0, '74.867')]
[36m[2025-06-29 12:31:00,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 274432. Throughput: 0: 80.2. Samples: 275420. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:31:00,952][60274] Avg episode reward: [(0, '70.919')]
[37m[1m[2025-06-29 12:31:00,999][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001072_274432.pth...
[36m[2025-06-29 12:31:01,061][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000000992_253952.pth
[36m[2025-06-29 12:31:05,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 274432. Throughput: 0: 80.4. Samples: 275664. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:31:05,951][60274] Avg episode reward: [(0, '67.440')]
[36m[2025-06-29 12:31:10,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 274432. Throughput: 0: 79.9. Samples: 276156. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:31:10,959][60274] Avg episode reward: [(0, '65.971')]
[36m[2025-06-29 12:31:15,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 274432. Throughput: 0: 80.3. Samples: 276664. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:31:15,990][60274] Avg episode reward: [(0, '60.173')]
[36m[2025-06-29 12:31:20,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 274432. Throughput: 0: 80.5. Samples: 276916. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:31:20,998][60274] Avg episode reward: [(0, '68.726')]
[36m[2025-06-29 12:31:25,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 274432. Throughput: 0: 81.5. Samples: 277428. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:31:25,959][60274] Avg episode reward: [(0, '61.671')]
[36m[2025-06-29 12:31:30,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 274432. Throughput: 0: 81.8. Samples: 277924. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:31:30,985][60274] Avg episode reward: [(0, '59.223')]
[36m[2025-06-29 12:31:35,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 274432. Throughput: 0: 82.5. Samples: 278152. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:31:35,993][60274] Avg episode reward: [(0, '63.505')]
[36m[2025-06-29 12:31:40,977][60274] Fps is (10 sec: 409.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 278528. Throughput: 0: 81.0. Samples: 278568. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:31:40,978][60274] Avg episode reward: [(0, '61.309')]
[36m[2025-06-29 12:31:45,953][60274] Fps is (10 sec: 411.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 278528. Throughput: 0: 81.7. Samples: 279096. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:31:45,953][60274] Avg episode reward: [(0, '63.021')]
[36m[2025-06-29 12:31:50,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 278528. Throughput: 0: 81.6. Samples: 279336. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:31:50,954][60274] Avg episode reward: [(0, '65.640')]
[36m[2025-06-29 12:31:55,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 278528. Throughput: 0: 82.1. Samples: 279852. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:31:55,991][60274] Avg episode reward: [(0, '64.199')]
[36m[2025-06-29 12:32:00,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 278528. Throughput: 0: 81.9. Samples: 280348. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:32:00,982][60274] Avg episode reward: [(0, '57.174')]
[36m[2025-06-29 12:32:05,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 278528. Throughput: 0: 82.0. Samples: 280604. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:32:05,958][60274] Avg episode reward: [(0, '52.021')]
[36m[2025-06-29 12:32:10,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 278528. Throughput: 0: 81.3. Samples: 281088. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:32:10,978][60274] Avg episode reward: [(0, '46.644')]
[36m[2025-06-29 12:32:15,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 278528. Throughput: 0: 81.2. Samples: 281576. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:32:15,948][60274] Avg episode reward: [(0, '48.365')]
[36m[2025-06-29 12:32:20,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 278528. Throughput: 0: 81.9. Samples: 281836. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:32:20,977][60274] Avg episode reward: [(0, '43.249')]
[36m[2025-06-29 12:32:25,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 278528. Throughput: 0: 83.6. Samples: 282332. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 12:32:25,976][60274] Avg episode reward: [(0, '49.582')]
[36m[2025-06-29 12:32:30,998][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 282624. Throughput: 0: 81.2. Samples: 282752. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 12:32:30,998][60274] Avg episode reward: [(0, '55.233')]
[36m[2025-06-29 12:32:35,980][60274] Fps is (10 sec: 409.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 282624. Throughput: 0: 81.1. Samples: 282988. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 12:32:35,980][60274] Avg episode reward: [(0, '63.467')]
[36m[2025-06-29 12:32:40,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 282624. Throughput: 0: 80.1. Samples: 283456. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 12:32:40,968][60274] Avg episode reward: [(0, '54.522')]
[36m[2025-06-29 12:32:45,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 282624. Throughput: 0: 79.9. Samples: 283944. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 12:32:45,977][60274] Avg episode reward: [(0, '61.857')]
[36m[2025-06-29 12:32:50,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 282624. Throughput: 0: 79.5. Samples: 284184. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 12:32:50,963][60274] Avg episode reward: [(0, '55.980')]
[36m[2025-06-29 12:32:55,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 282624. Throughput: 0: 79.4. Samples: 284660. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 12:32:55,977][60274] Avg episode reward: [(0, '60.535')]
[36m[2025-06-29 12:33:00,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 282624. Throughput: 0: 78.9. Samples: 285128. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 12:33:00,988][60274] Avg episode reward: [(0, '72.552')]
[37m[1m[2025-06-29 12:33:01,046][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001104_282624.pth...
[36m[2025-06-29 12:33:01,104][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001024_262144.pth
[36m[2025-06-29 12:33:05,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 282624. Throughput: 0: 78.3. Samples: 285360. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 12:33:05,987][60274] Avg episode reward: [(0, '64.859')]
[36m[2025-06-29 12:33:10,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 282624. Throughput: 0: 78.4. Samples: 285860. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 12:33:10,949][60274] Avg episode reward: [(0, '67.233')]
[36m[2025-06-29 12:33:15,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 282624. Throughput: 0: 80.2. Samples: 286360. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 12:33:15,974][60274] Avg episode reward: [(0, '74.377')]
[36m[2025-06-29 12:33:20,970][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 286720. Throughput: 0: 80.1. Samples: 286592. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:33:20,970][60274] Avg episode reward: [(0, '77.959')]
[36m[2025-06-29 12:33:25,990][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 286720. Throughput: 0: 79.0. Samples: 287012. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:33:25,990][60274] Avg episode reward: [(0, '68.060')]
[36m[2025-06-29 12:33:30,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 286720. Throughput: 0: 78.4. Samples: 287472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:33:30,949][60274] Avg episode reward: [(0, '71.462')]
[36m[2025-06-29 12:33:35,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 286720. Throughput: 0: 78.4. Samples: 287712. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:33:35,986][60274] Avg episode reward: [(0, '75.777')]
[36m[2025-06-29 12:33:40,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 286720. Throughput: 0: 78.9. Samples: 288208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:33:40,973][60274] Avg episode reward: [(0, '73.831')]
[36m[2025-06-29 12:33:45,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 286720. Throughput: 0: 79.2. Samples: 288688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:33:45,960][60274] Avg episode reward: [(0, '78.164')]
[36m[2025-06-29 12:33:50,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 286720. Throughput: 0: 79.4. Samples: 288932. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:33:50,955][60274] Avg episode reward: [(0, '81.242')]
[36m[2025-06-29 12:33:56,009][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 286720. Throughput: 0: 78.3. Samples: 289388. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:33:56,009][60274] Avg episode reward: [(0, '86.703')]
[36m[2025-06-29 12:34:00,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 286720. Throughput: 0: 77.5. Samples: 289844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:34:00,957][60274] Avg episode reward: [(0, '86.556')]
[36m[2025-06-29 12:34:05,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 286720. Throughput: 0: 77.1. Samples: 290060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:34:05,952][60274] Avg episode reward: [(0, '81.103')]
[36m[2025-06-29 12:34:10,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 286720. Throughput: 0: 78.9. Samples: 290560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:34:10,984][60274] Avg episode reward: [(0, '78.708')]
[36m[2025-06-29 12:34:15,981][60274] Fps is (10 sec: 408.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 290816. Throughput: 0: 78.3. Samples: 291000. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 12:34:15,982][60274] Avg episode reward: [(0, '76.465')]
[36m[2025-06-29 12:34:20,980][60274] Fps is (10 sec: 409.8, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 290816. Throughput: 0: 78.7. Samples: 291252. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 12:34:20,980][60274] Avg episode reward: [(0, '84.342')]
[36m[2025-06-29 12:34:25,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 290816. Throughput: 0: 78.5. Samples: 291740. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 12:34:25,974][60274] Avg episode reward: [(0, '70.037')]
[36m[2025-06-29 12:34:30,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 290816. Throughput: 0: 78.2. Samples: 292208. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 12:34:30,962][60274] Avg episode reward: [(0, '71.520')]
[36m[2025-06-29 12:34:35,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 290816. Throughput: 0: 78.1. Samples: 292448. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 12:34:35,976][60274] Avg episode reward: [(0, '71.442')]
[36m[2025-06-29 12:34:40,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 290816. Throughput: 0: 78.9. Samples: 292936. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 12:34:40,952][60274] Avg episode reward: [(0, '75.223')]
[36m[2025-06-29 12:34:45,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 290816. Throughput: 0: 79.9. Samples: 293440. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 12:34:45,950][60274] Avg episode reward: [(0, '74.583')]
[36m[2025-06-29 12:34:50,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 290816. Throughput: 0: 80.4. Samples: 293680. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 12:34:50,964][60274] Avg episode reward: [(0, '69.693')]
[36m[2025-06-29 12:34:55,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 290816. Throughput: 0: 79.8. Samples: 294148. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 12:34:55,956][60274] Avg episode reward: [(0, '71.885')]
[36m[2025-06-29 12:35:00,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 290816. Throughput: 0: 80.8. Samples: 294636. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 12:35:00,957][60274] Avg episode reward: [(0, '75.965')]
[37m[1m[2025-06-29 12:35:01,018][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001136_290816.pth...
[36m[2025-06-29 12:35:01,082][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001072_274432.pth
[36m[2025-06-29 12:35:05,970][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 294912. Throughput: 0: 80.1. Samples: 294856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:05,971][60274] Avg episode reward: [(0, '70.902')]
[36m[2025-06-29 12:35:10,947][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 294912. Throughput: 0: 78.5. Samples: 295272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:10,947][60274] Avg episode reward: [(0, '74.070')]
[36m[2025-06-29 12:35:15,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 294912. Throughput: 0: 78.5. Samples: 295740. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:15,968][60274] Avg episode reward: [(0, '78.109')]
[36m[2025-06-29 12:35:20,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 294912. Throughput: 0: 78.3. Samples: 295968. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:20,950][60274] Avg episode reward: [(0, '80.574')]
[36m[2025-06-29 12:35:25,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 294912. Throughput: 0: 78.1. Samples: 296452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:25,972][60274] Avg episode reward: [(0, '80.635')]
[36m[2025-06-29 12:35:30,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 294912. Throughput: 0: 77.5. Samples: 296932. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:30,983][60274] Avg episode reward: [(0, '80.714')]
[36m[2025-06-29 12:35:35,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 294912. Throughput: 0: 77.5. Samples: 297168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:35,958][60274] Avg episode reward: [(0, '81.233')]
[36m[2025-06-29 12:35:40,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 294912. Throughput: 0: 78.1. Samples: 297664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:40,969][60274] Avg episode reward: [(0, '82.540')]
[36m[2025-06-29 12:35:45,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 294912. Throughput: 0: 77.8. Samples: 298140. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:45,991][60274] Avg episode reward: [(0, '88.755')]
[36m[2025-06-29 12:35:50,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 294912. Throughput: 0: 77.7. Samples: 298356. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:50,989][60274] Avg episode reward: [(0, '92.500')]
[36m[2025-06-29 12:35:55,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 294912. Throughput: 0: 79.4. Samples: 298848. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:35:55,968][60274] Avg episode reward: [(0, '96.917')]
[36m[2025-06-29 12:36:00,993][60274] Fps is (10 sec: 409.4, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 299008. Throughput: 0: 79.1. Samples: 299300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:00,993][60274] Avg episode reward: [(0, '95.315')]
[33m[3787437 ms][navigation_task] - WARNING : Curriculum Level: 36, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[3787437 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.12060546875
[33mCrash Rate: 0.298828125
[33mTimeout Rate: 0.58056640625 (navigation_task.py:265)
[33m[3787437 ms][navigation_task] - WARNING : 
[33mSuccesses: 247
[33mCrashes : 612
[33mTimeouts: 1189 (navigation_task.py:268)
[36m[2025-06-29 12:36:05,965][60274] Fps is (10 sec: 409.7, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 299008. Throughput: 0: 79.1. Samples: 299528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:05,965][60274] Avg episode reward: [(0, '102.952')]
[36m[2025-06-29 12:36:10,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 299008. Throughput: 0: 79.1. Samples: 300012. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:10,956][60274] Avg episode reward: [(0, '97.993')]
[36m[2025-06-29 12:36:15,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 299008. Throughput: 0: 79.3. Samples: 300500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:15,983][60274] Avg episode reward: [(0, '97.907')]
[36m[2025-06-29 12:36:20,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 299008. Throughput: 0: 79.6. Samples: 300752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:20,959][60274] Avg episode reward: [(0, '97.699')]
[36m[2025-06-29 12:36:25,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 299008. Throughput: 0: 78.9. Samples: 301216. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:25,987][60274] Avg episode reward: [(0, '101.205')]
[36m[2025-06-29 12:36:30,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 299008. Throughput: 0: 79.3. Samples: 301708. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:30,957][60274] Avg episode reward: [(0, '102.507')]
[36m[2025-06-29 12:36:35,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 299008. Throughput: 0: 80.1. Samples: 301956. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:35,959][60274] Avg episode reward: [(0, '101.233')]
[36m[2025-06-29 12:36:40,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 299008. Throughput: 0: 79.5. Samples: 302428. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:40,986][60274] Avg episode reward: [(0, '102.169')]
[36m[2025-06-29 12:36:45,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 299008. Throughput: 0: 80.7. Samples: 302928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:45,971][60274] Avg episode reward: [(0, '101.335')]
[36m[2025-06-29 12:36:51,008][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 303104. Throughput: 0: 79.7. Samples: 303120. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:51,008][60274] Avg episode reward: [(0, '88.496')]
[36m[2025-06-29 12:36:55,987][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 303104. Throughput: 0: 79.9. Samples: 303608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:36:55,988][60274] Avg episode reward: [(0, '91.823')]
[36m[2025-06-29 12:37:00,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 303104. Throughput: 0: 79.9. Samples: 304096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:00,962][60274] Avg episode reward: [(0, '86.063')]
[37m[1m[2025-06-29 12:37:01,012][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001184_303104.pth...
[36m[2025-06-29 12:37:01,067][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001104_282624.pth
[36m[2025-06-29 12:37:05,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 303104. Throughput: 0: 79.4. Samples: 304324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:05,959][60274] Avg episode reward: [(0, '77.595')]
[36m[2025-06-29 12:37:10,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 303104. Throughput: 0: 80.0. Samples: 304812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:10,949][60274] Avg episode reward: [(0, '84.787')]
[36m[2025-06-29 12:37:15,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 303104. Throughput: 0: 79.2. Samples: 305272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:15,963][60274] Avg episode reward: [(0, '86.471')]
[36m[2025-06-29 12:37:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 303104. Throughput: 0: 79.2. Samples: 305520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:20,985][60274] Avg episode reward: [(0, '85.889')]
[36m[2025-06-29 12:37:25,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 303104. Throughput: 0: 79.5. Samples: 306004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:25,969][60274] Avg episode reward: [(0, '79.568')]
[36m[2025-06-29 12:37:30,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 303104. Throughput: 0: 78.8. Samples: 306472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:30,970][60274] Avg episode reward: [(0, '74.123')]
[36m[2025-06-29 12:37:35,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 303104. Throughput: 0: 79.8. Samples: 306708. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:35,966][60274] Avg episode reward: [(0, '67.228')]
[36m[2025-06-29 12:37:40,980][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 307200. Throughput: 0: 80.0. Samples: 307208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:40,980][60274] Avg episode reward: [(0, '66.967')]
[36m[2025-06-29 12:37:45,987][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 307200. Throughput: 0: 79.0. Samples: 307652. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:45,988][60274] Avg episode reward: [(0, '64.462')]
[36m[2025-06-29 12:37:50,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 307200. Throughput: 0: 79.7. Samples: 307912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:50,990][60274] Avg episode reward: [(0, '67.444')]
[36m[2025-06-29 12:37:55,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 307200. Throughput: 0: 79.0. Samples: 308368. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:37:55,979][60274] Avg episode reward: [(0, '71.768')]
[36m[2025-06-29 12:38:00,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 307200. Throughput: 0: 79.8. Samples: 308864. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:00,969][60274] Avg episode reward: [(0, '74.715')]
[36m[2025-06-29 12:38:05,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 307200. Throughput: 0: 80.1. Samples: 309124. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:05,972][60274] Avg episode reward: [(0, '68.002')]
[36m[2025-06-29 12:38:10,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 307200. Throughput: 0: 80.1. Samples: 309608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:10,989][60274] Avg episode reward: [(0, '72.809')]
[36m[2025-06-29 12:38:15,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 307200. Throughput: 0: 80.4. Samples: 310088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:15,958][60274] Avg episode reward: [(0, '77.957')]
[36m[2025-06-29 12:38:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 307200. Throughput: 0: 80.8. Samples: 310344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:20,985][60274] Avg episode reward: [(0, '72.582')]
[36m[2025-06-29 12:38:25,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 307200. Throughput: 0: 80.9. Samples: 310844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:25,950][60274] Avg episode reward: [(0, '78.664')]
[36m[2025-06-29 12:38:30,989][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 311296. Throughput: 0: 81.2. Samples: 311304. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:30,990][60274] Avg episode reward: [(0, '81.726')]
[36m[2025-06-29 12:38:36,000][60274] Fps is (10 sec: 407.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 311296. Throughput: 0: 80.5. Samples: 311536. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:36,000][60274] Avg episode reward: [(0, '84.593')]
[36m[2025-06-29 12:38:40,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 311296. Throughput: 0: 81.3. Samples: 312028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:40,978][60274] Avg episode reward: [(0, '91.937')]
[36m[2025-06-29 12:38:45,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 311296. Throughput: 0: 80.8. Samples: 312500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:45,973][60274] Avg episode reward: [(0, '89.781')]
[36m[2025-06-29 12:38:50,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 311296. Throughput: 0: 80.5. Samples: 312748. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:50,989][60274] Avg episode reward: [(0, '87.059')]
[36m[2025-06-29 12:38:55,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 311296. Throughput: 0: 80.2. Samples: 313216. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:38:55,956][60274] Avg episode reward: [(0, '91.385')]
[36m[2025-06-29 12:39:00,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 311296. Throughput: 0: 79.9. Samples: 313684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:00,961][60274] Avg episode reward: [(0, '88.948')]
[37m[1m[2025-06-29 12:39:01,014][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001216_311296.pth...
[36m[2025-06-29 12:39:01,073][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001136_290816.pth
[36m[2025-06-29 12:39:05,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 311296. Throughput: 0: 79.3. Samples: 313912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:05,990][60274] Avg episode reward: [(0, '88.387')]
[36m[2025-06-29 12:39:10,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 311296. Throughput: 0: 78.0. Samples: 314356. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:10,981][60274] Avg episode reward: [(0, '93.462')]
[36m[2025-06-29 12:39:15,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 311296. Throughput: 0: 78.7. Samples: 314844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:15,982][60274] Avg episode reward: [(0, '93.480')]
[36m[2025-06-29 12:39:20,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 311296. Throughput: 0: 79.2. Samples: 315096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:20,960][60274] Avg episode reward: [(0, '87.640')]
[36m[2025-06-29 12:39:25,961][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 315392. Throughput: 0: 77.6. Samples: 315520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:25,962][60274] Avg episode reward: [(0, '93.339')]
[36m[2025-06-29 12:39:30,988][60274] Fps is (10 sec: 408.4, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 315392. Throughput: 0: 77.8. Samples: 316000. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:30,989][60274] Avg episode reward: [(0, '88.232')]
[36m[2025-06-29 12:39:35,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 315392. Throughput: 0: 77.7. Samples: 316244. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:35,970][60274] Avg episode reward: [(0, '92.063')]
[36m[2025-06-29 12:39:40,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 315392. Throughput: 0: 77.9. Samples: 316724. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:40,969][60274] Avg episode reward: [(0, '87.519')]
[36m[2025-06-29 12:39:45,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 315392. Throughput: 0: 77.9. Samples: 317192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:45,979][60274] Avg episode reward: [(0, '84.489')]
[36m[2025-06-29 12:39:50,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 315392. Throughput: 0: 78.4. Samples: 317436. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:50,949][60274] Avg episode reward: [(0, '77.722')]
[36m[2025-06-29 12:39:55,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 315392. Throughput: 0: 79.4. Samples: 317928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:39:55,985][60274] Avg episode reward: [(0, '81.388')]
[36m[2025-06-29 12:40:00,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 315392. Throughput: 0: 79.3. Samples: 318412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:40:00,989][60274] Avg episode reward: [(0, '79.747')]
[36m[2025-06-29 12:40:05,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 315392. Throughput: 0: 79.0. Samples: 318652. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:40:05,953][60274] Avg episode reward: [(0, '76.036')]
[36m[2025-06-29 12:40:10,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 315392. Throughput: 0: 80.3. Samples: 319132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:40:10,947][60274] Avg episode reward: [(0, '81.205')]
[36m[2025-06-29 12:40:15,993][60274] Fps is (10 sec: 407.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 319488. Throughput: 0: 79.1. Samples: 319560. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:40:15,993][60274] Avg episode reward: [(0, '81.111')]
[36m[2025-06-29 12:40:20,953][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 319488. Throughput: 0: 78.7. Samples: 319784. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:40:20,954][60274] Avg episode reward: [(0, '77.491')]
[36m[2025-06-29 12:40:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 319488. Throughput: 0: 78.6. Samples: 320260. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:40:25,979][60274] Avg episode reward: [(0, '69.432')]
[36m[2025-06-29 12:40:30,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 319488. Throughput: 0: 79.0. Samples: 320748. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:40:30,980][60274] Avg episode reward: [(0, '71.550')]
[36m[2025-06-29 12:40:36,011][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 319488. Throughput: 0: 78.6. Samples: 320980. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:40:36,011][60274] Avg episode reward: [(0, '78.799')]
[36m[2025-06-29 12:40:40,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 319488. Throughput: 0: 78.0. Samples: 321436. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:40:40,976][60274] Avg episode reward: [(0, '74.084')]
[36m[2025-06-29 12:40:45,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 319488. Throughput: 0: 78.6. Samples: 321944. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:40:45,948][60274] Avg episode reward: [(0, '76.704')]
[36m[2025-06-29 12:40:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 319488. Throughput: 0: 78.8. Samples: 322200. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:40:50,976][60274] Avg episode reward: [(0, '77.516')]
[36m[2025-06-29 12:40:55,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 319488. Throughput: 0: 79.0. Samples: 322688. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:40:55,984][60274] Avg episode reward: [(0, '73.334')]
[36m[2025-06-29 12:41:00,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 319488. Throughput: 0: 80.4. Samples: 323176. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:41:00,964][60274] Avg episode reward: [(0, '78.723')]
[37m[1m[2025-06-29 12:41:01,017][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001248_319488.pth...
[36m[2025-06-29 12:41:01,071][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001184_303104.pth
[36m[2025-06-29 12:41:06,072][60274] Fps is (10 sec: 406.0, 60 sec: 136.3, 300 sec: 83.3). Total num frames: 323584. Throughput: 0: 80.4. Samples: 323412. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:06,073][60274] Avg episode reward: [(0, '74.470')]
[36m[2025-06-29 12:41:10,983][60274] Fps is (10 sec: 408.8, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 323584. Throughput: 0: 79.8. Samples: 323852. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:10,984][60274] Avg episode reward: [(0, '84.035')]
[36m[2025-06-29 12:41:15,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 323584. Throughput: 0: 79.4. Samples: 324320. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:15,949][60274] Avg episode reward: [(0, '78.440')]
[36m[2025-06-29 12:41:20,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 323584. Throughput: 0: 79.5. Samples: 324556. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:20,971][60274] Avg episode reward: [(0, '75.710')]
[36m[2025-06-29 12:41:25,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 323584. Throughput: 0: 80.2. Samples: 325044. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:25,971][60274] Avg episode reward: [(0, '80.652')]
[36m[2025-06-29 12:41:30,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 323584. Throughput: 0: 79.2. Samples: 325508. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:30,968][60274] Avg episode reward: [(0, '84.650')]
[36m[2025-06-29 12:41:35,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 323584. Throughput: 0: 78.8. Samples: 325748. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:35,975][60274] Avg episode reward: [(0, '87.936')]
[36m[2025-06-29 12:41:40,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 323584. Throughput: 0: 79.1. Samples: 326244. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:40,963][60274] Avg episode reward: [(0, '91.259')]
[36m[2025-06-29 12:41:45,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 323584. Throughput: 0: 78.9. Samples: 326728. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:45,957][60274] Avg episode reward: [(0, '86.749')]
[36m[2025-06-29 12:41:50,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 323584. Throughput: 0: 78.9. Samples: 326956. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:50,981][60274] Avg episode reward: [(0, '82.956')]
[36m[2025-06-29 12:41:55,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 323584. Throughput: 0: 79.6. Samples: 327432. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 12:41:55,966][60274] Avg episode reward: [(0, '86.546')]
[36m[2025-06-29 12:42:00,958][60274] Fps is (10 sec: 410.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 327680. Throughput: 0: 78.3. Samples: 327844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:00,958][60274] Avg episode reward: [(0, '79.010')]
[36m[2025-06-29 12:42:05,955][60274] Fps is (10 sec: 410.1, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 327680. Throughput: 0: 78.3. Samples: 328080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:05,955][60274] Avg episode reward: [(0, '79.139')]
[36m[2025-06-29 12:42:10,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 327680. Throughput: 0: 78.3. Samples: 328568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:10,990][60274] Avg episode reward: [(0, '72.622')]
[36m[2025-06-29 12:42:15,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 327680. Throughput: 0: 78.5. Samples: 329040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:15,958][60274] Avg episode reward: [(0, '74.011')]
[36m[2025-06-29 12:42:20,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 327680. Throughput: 0: 78.5. Samples: 329280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:20,987][60274] Avg episode reward: [(0, '76.755')]
[36m[2025-06-29 12:42:25,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 327680. Throughput: 0: 78.4. Samples: 329772. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:25,950][60274] Avg episode reward: [(0, '82.555')]
[36m[2025-06-29 12:42:30,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 327680. Throughput: 0: 78.2. Samples: 330248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:30,969][60274] Avg episode reward: [(0, '79.726')]
[36m[2025-06-29 12:42:35,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 327680. Throughput: 0: 78.4. Samples: 330480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:35,949][60274] Avg episode reward: [(0, '78.674')]
[36m[2025-06-29 12:42:40,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 327680. Throughput: 0: 78.5. Samples: 330964. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:40,963][60274] Avg episode reward: [(0, '83.120')]
[36m[2025-06-29 12:42:45,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 327680. Throughput: 0: 80.2. Samples: 331456. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:45,983][60274] Avg episode reward: [(0, '76.762')]
[36m[2025-06-29 12:42:50,956][60274] Fps is (10 sec: 409.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 331776. Throughput: 0: 80.3. Samples: 331692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:50,957][60274] Avg episode reward: [(0, '79.275')]
[36m[2025-06-29 12:42:55,964][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 331776. Throughput: 0: 79.2. Samples: 332128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:42:55,965][60274] Avg episode reward: [(0, '82.531')]
[36m[2025-06-29 12:43:00,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 331776. Throughput: 0: 79.6. Samples: 332620. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:43:00,953][60274] Avg episode reward: [(0, '76.683')]
[37m[1m[2025-06-29 12:43:01,001][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001296_331776.pth...
[36m[2025-06-29 12:43:01,058][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001216_311296.pth
[36m[2025-06-29 12:43:05,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 331776. Throughput: 0: 79.7. Samples: 332868. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:43:05,994][60274] Avg episode reward: [(0, '78.423')]
[36m[2025-06-29 12:43:10,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 331776. Throughput: 0: 80.0. Samples: 333372. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:43:10,970][60274] Avg episode reward: [(0, '77.903')]
[36m[2025-06-29 12:43:15,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 331776. Throughput: 0: 80.3. Samples: 333864. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:43:15,981][60274] Avg episode reward: [(0, '78.511')]
[36m[2025-06-29 12:43:20,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 331776. Throughput: 0: 80.8. Samples: 334120. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:43:20,973][60274] Avg episode reward: [(0, '76.162')]
[36m[2025-06-29 12:43:25,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 331776. Throughput: 0: 80.9. Samples: 334604. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:43:25,983][60274] Avg episode reward: [(0, '71.792')]
[36m[2025-06-29 12:43:30,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 331776. Throughput: 0: 80.3. Samples: 335072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:43:30,996][60274] Avg episode reward: [(0, '80.839')]
[36m[2025-06-29 12:43:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 331776. Throughput: 0: 80.2. Samples: 335304. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:43:35,981][60274] Avg episode reward: [(0, '77.414')]
[36m[2025-06-29 12:43:41,012][60274] Fps is (10 sec: 408.9, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 335872. Throughput: 0: 81.3. Samples: 335792. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:43:41,012][60274] Avg episode reward: [(0, '80.212')]
[36m[2025-06-29 12:43:45,955][60274] Fps is (10 sec: 410.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 335872. Throughput: 0: 80.2. Samples: 336228. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:43:45,956][60274] Avg episode reward: [(0, '78.676')]
[36m[2025-06-29 12:43:50,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 335872. Throughput: 0: 80.3. Samples: 336480. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:43:50,948][60274] Avg episode reward: [(0, '76.244')]
[36m[2025-06-29 12:43:55,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 335872. Throughput: 0: 80.1. Samples: 336980. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:43:55,988][60274] Avg episode reward: [(0, '86.548')]
[36m[2025-06-29 12:44:00,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 335872. Throughput: 0: 79.9. Samples: 337460. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:44:00,960][60274] Avg episode reward: [(0, '80.398')]
[36m[2025-06-29 12:44:05,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 335872. Throughput: 0: 79.8. Samples: 337712. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:44:05,978][60274] Avg episode reward: [(0, '85.828')]
[36m[2025-06-29 12:44:10,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 335872. Throughput: 0: 80.2. Samples: 338212. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:44:10,993][60274] Avg episode reward: [(0, '85.462')]
[36m[2025-06-29 12:44:15,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 335872. Throughput: 0: 80.7. Samples: 338700. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:44:15,979][60274] Avg episode reward: [(0, '85.227')]
[36m[2025-06-29 12:44:20,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 335872. Throughput: 0: 80.9. Samples: 338944. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:44:20,964][60274] Avg episode reward: [(0, '91.912')]
[36m[2025-06-29 12:44:25,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 335872. Throughput: 0: 81.2. Samples: 339440. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:44:25,958][60274] Avg episode reward: [(0, '86.924')]
[36m[2025-06-29 12:44:31,656][60274] Fps is (10 sec: 383.1, 60 sec: 135.0, 300 sec: 83.1). Total num frames: 339968. Throughput: 0: 80.8. Samples: 339920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:44:31,656][60274] Avg episode reward: [(0, '91.364')]
[36m[2025-06-29 12:44:35,966][60274] Fps is (10 sec: 409.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 339968. Throughput: 0: 80.6. Samples: 340108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:44:35,967][60274] Avg episode reward: [(0, '85.279')]
[36m[2025-06-29 12:44:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 339968. Throughput: 0: 80.8. Samples: 340612. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:44:40,947][60274] Avg episode reward: [(0, '94.979')]
[36m[2025-06-29 12:44:45,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 339968. Throughput: 0: 81.1. Samples: 341108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:44:45,968][60274] Avg episode reward: [(0, '91.818')]
[36m[2025-06-29 12:44:50,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 339968. Throughput: 0: 80.9. Samples: 341352. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:44:50,956][60274] Avg episode reward: [(0, '91.621')]
[36m[2025-06-29 12:44:55,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 339968. Throughput: 0: 80.6. Samples: 341836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:44:55,952][60274] Avg episode reward: [(0, '100.401')]
[36m[2025-06-29 12:45:00,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 339968. Throughput: 0: 80.3. Samples: 342312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:00,948][60274] Avg episode reward: [(0, '100.709')]
[37m[1m[2025-06-29 12:45:00,995][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001328_339968.pth...
[36m[2025-06-29 12:45:01,051][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001248_319488.pth
[36m[2025-06-29 12:45:05,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 339968. Throughput: 0: 80.1. Samples: 342552. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:05,987][60274] Avg episode reward: [(0, '90.464')]
[36m[2025-06-29 12:45:10,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 339968. Throughput: 0: 79.3. Samples: 343012. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:10,992][60274] Avg episode reward: [(0, '90.874')]
[36m[2025-06-29 12:45:15,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 339968. Throughput: 0: 81.0. Samples: 343508. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:15,968][60274] Avg episode reward: [(0, '98.687')]
[36m[2025-06-29 12:45:20,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 339968. Throughput: 0: 81.0. Samples: 343756. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:20,977][60274] Avg episode reward: [(0, '92.131')]
[36m[2025-06-29 12:45:25,951][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 344064. Throughput: 0: 79.5. Samples: 344188. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:25,951][60274] Avg episode reward: [(0, '99.105')]
[36m[2025-06-29 12:45:30,986][60274] Fps is (10 sec: 409.2, 60 sec: 69.0, 300 sec: 83.3). Total num frames: 344064. Throughput: 0: 79.3. Samples: 344680. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:30,986][60274] Avg episode reward: [(0, '107.947')]
[36m[2025-06-29 12:45:36,011][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 344064. Throughput: 0: 79.4. Samples: 344928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:36,011][60274] Avg episode reward: [(0, '107.040')]
[36m[2025-06-29 12:45:40,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 344064. Throughput: 0: 79.3. Samples: 345408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:40,984][60274] Avg episode reward: [(0, '104.314')]
[36m[2025-06-29 12:45:45,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 344064. Throughput: 0: 79.6. Samples: 345896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:45,976][60274] Avg episode reward: [(0, '106.285')]
[36m[2025-06-29 12:45:50,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 344064. Throughput: 0: 79.9. Samples: 346144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:50,971][60274] Avg episode reward: [(0, '104.756')]
[36m[2025-06-29 12:45:55,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 344064. Throughput: 0: 80.8. Samples: 346648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:45:55,976][60274] Avg episode reward: [(0, '103.851')]
[36m[2025-06-29 12:46:00,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 344064. Throughput: 0: 81.0. Samples: 347152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:46:00,976][60274] Avg episode reward: [(0, '109.187')]
[36m[2025-06-29 12:46:05,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 344064. Throughput: 0: 81.0. Samples: 347404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:46:05,993][60274] Avg episode reward: [(0, '114.048')]
[36m[2025-06-29 12:46:10,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 344064. Throughput: 0: 82.4. Samples: 347900. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:46:10,976][60274] Avg episode reward: [(0, '116.283')]
[36m[2025-06-29 12:46:15,959][60274] Fps is (10 sec: 410.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 348160. Throughput: 0: 81.4. Samples: 348340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:46:15,960][60274] Avg episode reward: [(0, '118.871')]
[36m[2025-06-29 12:46:20,983][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 348160. Throughput: 0: 80.8. Samples: 348560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:46:20,984][60274] Avg episode reward: [(0, '119.302')]
[36m[2025-06-29 12:46:25,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 348160. Throughput: 0: 80.8. Samples: 349040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:46:25,948][60274] Avg episode reward: [(0, '111.904')]
[36m[2025-06-29 12:46:30,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 348160. Throughput: 0: 81.0. Samples: 349540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:46:30,983][60274] Avg episode reward: [(0, '117.993')]
[36m[2025-06-29 12:46:35,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 348160. Throughput: 0: 80.7. Samples: 349772. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:46:35,951][60274] Avg episode reward: [(0, '119.867')]
[36m[2025-06-29 12:46:40,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 348160. Throughput: 0: 79.8. Samples: 350240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:46:40,964][60274] Avg episode reward: [(0, '115.824')]
[36m[2025-06-29 12:46:45,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 348160. Throughput: 0: 79.4. Samples: 350724. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:46:45,989][60274] Avg episode reward: [(0, '123.173')]
[36m[2025-06-29 12:46:50,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 348160. Throughput: 0: 79.6. Samples: 350984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:46:50,990][60274] Avg episode reward: [(0, '126.496')]
[36m[2025-06-29 12:46:55,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 348160. Throughput: 0: 79.5. Samples: 351476. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:46:55,948][60274] Avg episode reward: [(0, '126.512')]
[36m[2025-06-29 12:47:00,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 348160. Throughput: 0: 80.6. Samples: 351968. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:00,989][60274] Avg episode reward: [(0, '130.551')]
[37m[1m[2025-06-29 12:47:01,039][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001360_348160.pth...
[36m[2025-06-29 12:47:01,097][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001296_331776.pth
[36m[2025-06-29 12:47:05,980][60274] Fps is (10 sec: 408.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 352256. Throughput: 0: 81.1. Samples: 352208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:05,980][60274] Avg episode reward: [(0, '135.805')]
[36m[2025-06-29 12:47:10,987][60274] Fps is (10 sec: 409.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 352256. Throughput: 0: 79.7. Samples: 352628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:10,987][60274] Avg episode reward: [(0, '130.552')]
[36m[2025-06-29 12:47:16,008][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 352256. Throughput: 0: 79.5. Samples: 353120. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:16,009][60274] Avg episode reward: [(0, '134.134')]
[36m[2025-06-29 12:47:20,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 352256. Throughput: 0: 79.8. Samples: 353364. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:20,956][60274] Avg episode reward: [(0, '128.875')]
[36m[2025-06-29 12:47:25,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 352256. Throughput: 0: 80.6. Samples: 353864. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:25,949][60274] Avg episode reward: [(0, '122.575')]
[36m[2025-06-29 12:47:30,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 352256. Throughput: 0: 80.6. Samples: 354352. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:30,987][60274] Avg episode reward: [(0, '120.305')]
[36m[2025-06-29 12:47:35,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 352256. Throughput: 0: 80.4. Samples: 354600. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:35,973][60274] Avg episode reward: [(0, '112.532')]
[36m[2025-06-29 12:47:40,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 352256. Throughput: 0: 80.1. Samples: 355084. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:40,983][60274] Avg episode reward: [(0, '117.575')]
[36m[2025-06-29 12:47:45,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 352256. Throughput: 0: 80.1. Samples: 355572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:45,984][60274] Avg episode reward: [(0, '119.169')]
[36m[2025-06-29 12:47:50,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 352256. Throughput: 0: 80.2. Samples: 355816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:47:50,972][60274] Avg episode reward: [(0, '115.140')]
[36m[2025-06-29 12:47:55,989][60274] Fps is (10 sec: 409.4, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 356352. Throughput: 0: 82.1. Samples: 356324. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:47:55,989][60274] Avg episode reward: [(0, '108.987')]
[36m[2025-06-29 12:48:00,967][60274] Fps is (10 sec: 409.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 356352. Throughput: 0: 81.5. Samples: 356784. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:48:00,967][60274] Avg episode reward: [(0, '104.521')]
[36m[2025-06-29 12:48:05,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 356352. Throughput: 0: 81.4. Samples: 357032. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:48:05,991][60274] Avg episode reward: [(0, '99.142')]
[36m[2025-06-29 12:48:10,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 356352. Throughput: 0: 81.4. Samples: 357528. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:48:10,970][60274] Avg episode reward: [(0, '96.704')]
[36m[2025-06-29 12:48:15,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 356352. Throughput: 0: 81.7. Samples: 358028. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:48:15,955][60274] Avg episode reward: [(0, '91.791')]
[36m[2025-06-29 12:48:20,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 356352. Throughput: 0: 81.8. Samples: 358284. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:48:20,989][60274] Avg episode reward: [(0, '98.162')]
[36m[2025-06-29 12:48:25,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 356352. Throughput: 0: 82.2. Samples: 358780. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:48:25,962][60274] Avg episode reward: [(0, '93.826')]
[36m[2025-06-29 12:48:30,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 356352. Throughput: 0: 82.0. Samples: 359264. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:48:30,989][60274] Avg episode reward: [(0, '107.020')]
[36m[2025-06-29 12:48:35,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 356352. Throughput: 0: 81.9. Samples: 359500. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:48:35,966][60274] Avg episode reward: [(0, '103.964')]
[36m[2025-06-29 12:48:40,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 356352. Throughput: 0: 81.7. Samples: 359996. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 12:48:40,954][60274] Avg episode reward: [(0, '107.294')]
[36m[2025-06-29 12:48:45,978][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 360448. Throughput: 0: 81.6. Samples: 360456. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:48:45,979][60274] Avg episode reward: [(0, '101.565')]
[36m[2025-06-29 12:48:50,991][60274] Fps is (10 sec: 408.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 360448. Throughput: 0: 81.1. Samples: 360680. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:48:50,991][60274] Avg episode reward: [(0, '100.171')]
[36m[2025-06-29 12:48:55,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 360448. Throughput: 0: 81.2. Samples: 361180. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:48:55,965][60274] Avg episode reward: [(0, '96.661')]
[36m[2025-06-29 12:49:00,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 360448. Throughput: 0: 81.0. Samples: 361676. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:49:00,986][60274] Avg episode reward: [(0, '87.861')]
[37m[1m[2025-06-29 12:49:01,055][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001408_360448.pth...
[36m[2025-06-29 12:49:01,109][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001328_339968.pth
[36m[2025-06-29 12:49:05,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 360448. Throughput: 0: 80.6. Samples: 361908. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:49:05,973][60274] Avg episode reward: [(0, '90.642')]
[36m[2025-06-29 12:49:10,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 360448. Throughput: 0: 80.1. Samples: 362384. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:49:10,962][60274] Avg episode reward: [(0, '96.596')]
[36m[2025-06-29 12:49:15,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 360448. Throughput: 0: 80.4. Samples: 362880. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:49:15,988][60274] Avg episode reward: [(0, '103.226')]
[36m[2025-06-29 12:49:20,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 360448. Throughput: 0: 80.7. Samples: 363132. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:49:20,973][60274] Avg episode reward: [(0, '106.786')]
[36m[2025-06-29 12:49:25,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.6). Total num frames: 360448. Throughput: 0: 80.2. Samples: 363608. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:49:25,981][60274] Avg episode reward: [(0, '112.544')]
[36m[2025-06-29 12:49:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 360448. Throughput: 0: 80.6. Samples: 364084. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:49:30,990][60274] Avg episode reward: [(0, '106.409')]
[36m[2025-06-29 12:49:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 360448. Throughput: 0: 81.1. Samples: 364328. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 12:49:35,981][60274] Avg episode reward: [(0, '105.933')]
[36m[2025-06-29 12:49:40,973][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 364544. Throughput: 0: 79.0. Samples: 364736. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:49:40,974][60274] Avg episode reward: [(0, '104.770')]
[36m[2025-06-29 12:49:45,989][60274] Fps is (10 sec: 409.3, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 364544. Throughput: 0: 78.9. Samples: 365228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:49:45,989][60274] Avg episode reward: [(0, '108.815')]
[36m[2025-06-29 12:49:50,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 364544. Throughput: 0: 79.1. Samples: 365464. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:49:50,953][60274] Avg episode reward: [(0, '110.937')]
[36m[2025-06-29 12:49:55,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 364544. Throughput: 0: 79.6. Samples: 365968. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:49:55,995][60274] Avg episode reward: [(0, '125.053')]
[36m[2025-06-29 12:50:00,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 364544. Throughput: 0: 79.4. Samples: 366452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:50:00,982][60274] Avg episode reward: [(0, '119.149')]
[36m[2025-06-29 12:50:05,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 364544. Throughput: 0: 79.0. Samples: 366684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:50:05,958][60274] Avg episode reward: [(0, '129.028')]
[36m[2025-06-29 12:50:10,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 364544. Throughput: 0: 79.5. Samples: 367184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:50:10,958][60274] Avg episode reward: [(0, '121.145')]
[36m[2025-06-29 12:50:15,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 364544. Throughput: 0: 79.7. Samples: 367668. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:50:15,970][60274] Avg episode reward: [(0, '124.970')]
[36m[2025-06-29 12:50:20,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 364544. Throughput: 0: 79.3. Samples: 367896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:50:20,962][60274] Avg episode reward: [(0, '118.591')]
[36m[2025-06-29 12:50:25,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 364544. Throughput: 0: 81.3. Samples: 368396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:50:25,976][60274] Avg episode reward: [(0, '116.178')]
[36m[2025-06-29 12:50:30,959][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 368640. Throughput: 0: 80.2. Samples: 368836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:50:30,959][60274] Avg episode reward: [(0, '110.322')]
[36m[2025-06-29 12:50:35,967][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 368640. Throughput: 0: 80.2. Samples: 369072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:50:35,967][60274] Avg episode reward: [(0, '112.363')]
[36m[2025-06-29 12:50:40,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 368640. Throughput: 0: 79.6. Samples: 369548. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:50:40,964][60274] Avg episode reward: [(0, '114.736')]
[36m[2025-06-29 12:50:45,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 368640. Throughput: 0: 79.8. Samples: 370044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:50:45,989][60274] Avg episode reward: [(0, '113.776')]
[36m[2025-06-29 12:50:50,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 368640. Throughput: 0: 80.3. Samples: 370296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:50:50,947][60274] Avg episode reward: [(0, '120.257')]
[36m[2025-06-29 12:50:55,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 368640. Throughput: 0: 80.7. Samples: 370816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:50:55,979][60274] Avg episode reward: [(0, '128.960')]
[36m[2025-06-29 12:51:00,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 368640. Throughput: 0: 80.7. Samples: 371300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:00,989][60274] Avg episode reward: [(0, '117.165')]
[37m[1m[2025-06-29 12:51:01,041][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001440_368640.pth...
[36m[2025-06-29 12:51:01,097][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001360_348160.pth
[36m[2025-06-29 12:51:05,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 368640. Throughput: 0: 80.8. Samples: 371536. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:05,990][60274] Avg episode reward: [(0, '129.587')]
[36m[2025-06-29 12:51:10,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 368640. Throughput: 0: 80.8. Samples: 372032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:10,977][60274] Avg episode reward: [(0, '119.966')]
[36m[2025-06-29 12:51:15,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 368640. Throughput: 0: 81.8. Samples: 372516. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:15,964][60274] Avg episode reward: [(0, '112.972')]
[36m[2025-06-29 12:51:20,952][60274] Fps is (10 sec: 410.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 372736. Throughput: 0: 81.6. Samples: 372744. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:20,952][60274] Avg episode reward: [(0, '118.424')]
[36m[2025-06-29 12:51:25,971][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 372736. Throughput: 0: 81.4. Samples: 373212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:25,971][60274] Avg episode reward: [(0, '117.794')]
[36m[2025-06-29 12:51:30,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 372736. Throughput: 0: 81.3. Samples: 373700. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:30,980][60274] Avg episode reward: [(0, '127.397')]
[36m[2025-06-29 12:51:35,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 372736. Throughput: 0: 81.2. Samples: 373952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:35,977][60274] Avg episode reward: [(0, '115.815')]
[36m[2025-06-29 12:51:40,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 372736. Throughput: 0: 80.2. Samples: 374424. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:40,974][60274] Avg episode reward: [(0, '121.927')]
[36m[2025-06-29 12:51:45,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 372736. Throughput: 0: 80.4. Samples: 374916. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:45,985][60274] Avg episode reward: [(0, '117.520')]
[36m[2025-06-29 12:51:50,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 372736. Throughput: 0: 80.6. Samples: 375160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:50,948][60274] Avg episode reward: [(0, '118.963')]
[36m[2025-06-29 12:51:55,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 372736. Throughput: 0: 80.7. Samples: 375660. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:51:55,952][60274] Avg episode reward: [(0, '122.050')]
[36m[2025-06-29 12:52:00,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 372736. Throughput: 0: 80.9. Samples: 376156. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:52:00,971][60274] Avg episode reward: [(0, '124.591')]
[36m[2025-06-29 12:52:05,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 372736. Throughput: 0: 81.4. Samples: 376408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:52:05,948][60274] Avg episode reward: [(0, '120.329')]
[36m[2025-06-29 12:52:10,987][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 376832. Throughput: 0: 80.6. Samples: 376840. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 12:52:10,987][60274] Avg episode reward: [(0, '120.936')]
[36m[2025-06-29 12:52:15,976][60274] Fps is (10 sec: 408.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 376832. Throughput: 0: 81.2. Samples: 377352. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 12:52:15,976][60274] Avg episode reward: [(0, '117.695')]
[36m[2025-06-29 12:52:20,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 376832. Throughput: 0: 80.7. Samples: 377580. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 12:52:20,958][60274] Avg episode reward: [(0, '118.205')]
[36m[2025-06-29 12:52:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 376832. Throughput: 0: 80.1. Samples: 378028. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 12:52:25,966][60274] Avg episode reward: [(0, '120.015')]
[36m[2025-06-29 12:52:30,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 376832. Throughput: 0: 79.7. Samples: 378504. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 12:52:30,982][60274] Avg episode reward: [(0, '129.785')]
[36m[2025-06-29 12:52:35,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 376832. Throughput: 0: 79.8. Samples: 378752. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 12:52:35,956][60274] Avg episode reward: [(0, '128.986')]
[36m[2025-06-29 12:52:40,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 376832. Throughput: 0: 79.2. Samples: 379228. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 12:52:40,992][60274] Avg episode reward: [(0, '126.940')]
[36m[2025-06-29 12:52:45,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 376832. Throughput: 0: 79.0. Samples: 379712. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 12:52:45,975][60274] Avg episode reward: [(0, '126.311')]
[36m[2025-06-29 12:52:50,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 376832. Throughput: 0: 78.6. Samples: 379944. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 12:52:50,954][60274] Avg episode reward: [(0, '133.226')]
[36m[2025-06-29 12:52:55,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 376832. Throughput: 0: 80.0. Samples: 380436. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 12:52:55,952][60274] Avg episode reward: [(0, '128.688')]
[36m[2025-06-29 12:53:01,310][60274] Fps is (10 sec: 395.5, 60 sec: 135.8, 300 sec: 83.2). Total num frames: 380928. Throughput: 0: 78.5. Samples: 380912. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:01,311][60274] Avg episode reward: [(0, '130.397')]
[37m[1m[2025-06-29 12:53:01,358][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001488_380928.pth...
[36m[2025-06-29 12:53:01,426][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001408_360448.pth
[36m[2025-06-29 12:53:05,984][60274] Fps is (10 sec: 408.3, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 380928. Throughput: 0: 77.9. Samples: 381088. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:05,985][60274] Avg episode reward: [(0, '134.390')]
[36m[2025-06-29 12:53:10,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 380928. Throughput: 0: 78.9. Samples: 381580. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:10,966][60274] Avg episode reward: [(0, '127.810')]
[36m[2025-06-29 12:53:15,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 380928. Throughput: 0: 79.6. Samples: 382088. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:15,982][60274] Avg episode reward: [(0, '118.953')]
[36m[2025-06-29 12:53:20,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 380928. Throughput: 0: 79.6. Samples: 382332. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:20,956][60274] Avg episode reward: [(0, '130.485')]
[36m[2025-06-29 12:53:25,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 380928. Throughput: 0: 79.4. Samples: 382796. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:25,953][60274] Avg episode reward: [(0, '136.557')]
[36m[2025-06-29 12:53:30,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 380928. Throughput: 0: 79.9. Samples: 383308. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:30,961][60274] Avg episode reward: [(0, '123.036')]
[36m[2025-06-29 12:53:35,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 380928. Throughput: 0: 80.1. Samples: 383548. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:35,949][60274] Avg episode reward: [(0, '122.627')]
[36m[2025-06-29 12:53:40,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 380928. Throughput: 0: 79.6. Samples: 384016. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:40,953][60274] Avg episode reward: [(0, '116.833')]
[36m[2025-06-29 12:53:45,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 380928. Throughput: 0: 80.4. Samples: 384500. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:45,963][60274] Avg episode reward: [(0, '116.837')]
[36m[2025-06-29 12:53:50,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 380928. Throughput: 0: 81.2. Samples: 384740. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 12:53:50,985][60274] Avg episode reward: [(0, '112.092')]
[36m[2025-06-29 12:53:55,979][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 385024. Throughput: 0: 79.6. Samples: 385164. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:53:55,979][60274] Avg episode reward: [(0, '128.290')]
[36m[2025-06-29 12:54:00,983][60274] Fps is (10 sec: 409.6, 60 sec: 68.6, 300 sec: 83.3). Total num frames: 385024. Throughput: 0: 79.3. Samples: 385656. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:54:00,984][60274] Avg episode reward: [(0, '127.706')]
[36m[2025-06-29 12:54:05,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 385024. Throughput: 0: 79.3. Samples: 385900. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:54:05,963][60274] Avg episode reward: [(0, '135.383')]
[36m[2025-06-29 12:54:10,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 385024. Throughput: 0: 80.0. Samples: 386396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:54:10,962][60274] Avg episode reward: [(0, '136.185')]
[36m[2025-06-29 12:54:15,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 385024. Throughput: 0: 79.7. Samples: 386896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:54:15,978][60274] Avg episode reward: [(0, '134.112')]
[36m[2025-06-29 12:54:20,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 385024. Throughput: 0: 80.1. Samples: 387156. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:54:20,981][60274] Avg episode reward: [(0, '131.820')]
[36m[2025-06-29 12:54:26,013][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 385024. Throughput: 0: 79.9. Samples: 387616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:54:26,013][60274] Avg episode reward: [(0, '129.847')]
[36m[2025-06-29 12:54:30,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 385024. Throughput: 0: 79.6. Samples: 388084. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:54:30,978][60274] Avg episode reward: [(0, '137.225')]
[36m[2025-06-29 12:54:35,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 385024. Throughput: 0: 79.6. Samples: 388320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:54:35,965][60274] Avg episode reward: [(0, '133.709')]
[36m[2025-06-29 12:54:40,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 385024. Throughput: 0: 81.5. Samples: 388832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:54:40,976][60274] Avg episode reward: [(0, '139.297')]
[36m[2025-06-29 12:54:45,955][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 389120. Throughput: 0: 80.1. Samples: 389260. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:54:45,956][60274] Avg episode reward: [(0, '143.283')]
[36m[2025-06-29 12:54:50,960][60274] Fps is (10 sec: 410.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 389120. Throughput: 0: 79.9. Samples: 389496. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:54:50,960][60274] Avg episode reward: [(0, '146.179')]
[36m[2025-06-29 12:54:55,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 389120. Throughput: 0: 79.5. Samples: 389972. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:54:55,950][60274] Avg episode reward: [(0, '156.476')]
[36m[2025-06-29 12:55:00,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 389120. Throughput: 0: 79.0. Samples: 390448. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:55:00,953][60274] Avg episode reward: [(0, '158.897')]
[37m[1m[2025-06-29 12:55:01,001][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001520_389120.pth...
[36m[2025-06-29 12:55:01,056][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001440_368640.pth
[36m[2025-06-29 12:55:05,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 389120. Throughput: 0: 78.5. Samples: 390688. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:55:05,988][60274] Avg episode reward: [(0, '168.832')]
[36m[2025-06-29 12:55:10,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 389120. Throughput: 0: 79.4. Samples: 391184. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:55:10,955][60274] Avg episode reward: [(0, '161.334')]
[36m[2025-06-29 12:55:15,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 389120. Throughput: 0: 80.0. Samples: 391680. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:55:15,947][60274] Avg episode reward: [(0, '152.115')]
[36m[2025-06-29 12:55:20,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 389120. Throughput: 0: 80.1. Samples: 391924. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:55:20,959][60274] Avg episode reward: [(0, '161.875')]
[36m[2025-06-29 12:55:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 389120. Throughput: 0: 79.1. Samples: 392388. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:55:25,956][60274] Avg episode reward: [(0, '165.783')]
[36m[2025-06-29 12:55:30,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 389120. Throughput: 0: 79.9. Samples: 392860. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 12:55:30,990][60274] Avg episode reward: [(0, '174.718')]
[36m[2025-06-29 12:55:35,950][60274] Fps is (10 sec: 409.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 393216. Throughput: 0: 79.7. Samples: 393084. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:55:35,951][60274] Avg episode reward: [(0, '161.686')]
[36m[2025-06-29 12:55:40,991][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 393216. Throughput: 0: 79.1. Samples: 393536. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:55:40,991][60274] Avg episode reward: [(0, '167.616')]
[36m[2025-06-29 12:55:45,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 393216. Throughput: 0: 79.4. Samples: 394024. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:55:45,972][60274] Avg episode reward: [(0, '163.608')]
[36m[2025-06-29 12:55:50,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 393216. Throughput: 0: 79.7. Samples: 394272. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:55:50,973][60274] Avg episode reward: [(0, '164.564')]
[36m[2025-06-29 12:55:55,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 393216. Throughput: 0: 79.0. Samples: 394740. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:55:55,986][60274] Avg episode reward: [(0, '160.066')]
[36m[2025-06-29 12:56:00,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 393216. Throughput: 0: 79.2. Samples: 395248. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:56:00,993][60274] Avg episode reward: [(0, '161.833')]
[36m[2025-06-29 12:56:05,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 393216. Throughput: 0: 79.0. Samples: 395480. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:56:05,950][60274] Avg episode reward: [(0, '163.918')]
[36m[2025-06-29 12:56:10,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 393216. Throughput: 0: 79.6. Samples: 395972. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:56:10,955][60274] Avg episode reward: [(0, '163.560')]
[36m[2025-06-29 12:56:15,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 393216. Throughput: 0: 79.8. Samples: 396452. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:56:15,977][60274] Avg episode reward: [(0, '152.474')]
[36m[2025-06-29 12:56:20,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 393216. Throughput: 0: 80.2. Samples: 396696. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 12:56:20,990][60274] Avg episode reward: [(0, '158.235')]
[36m[2025-06-29 12:56:26,606][60274] Fps is (10 sec: 385.4, 60 sec: 135.1, 300 sec: 83.1). Total num frames: 397312. Throughput: 0: 79.8. Samples: 397176. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:56:26,607][60274] Avg episode reward: [(0, '156.062')]
[36m[2025-06-29 12:56:30,963][60274] Fps is (10 sec: 410.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 397312. Throughput: 0: 80.0. Samples: 397624. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:56:30,963][60274] Avg episode reward: [(0, '151.335')]
[36m[2025-06-29 12:56:35,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 397312. Throughput: 0: 80.3. Samples: 397884. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:56:35,974][60274] Avg episode reward: [(0, '153.150')]
[36m[2025-06-29 12:56:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 397312. Throughput: 0: 79.9. Samples: 398336. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:56:40,982][60274] Avg episode reward: [(0, '153.806')]
[36m[2025-06-29 12:56:45,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 397312. Throughput: 0: 79.7. Samples: 398832. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:56:45,977][60274] Avg episode reward: [(0, '153.185')]
[36m[2025-06-29 12:56:50,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 397312. Throughput: 0: 80.0. Samples: 399080. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:56:50,957][60274] Avg episode reward: [(0, '159.969')]
[36m[2025-06-29 12:56:55,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 397312. Throughput: 0: 79.8. Samples: 399564. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:56:55,962][60274] Avg episode reward: [(0, '154.155')]
[36m[2025-06-29 12:57:00,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 397312. Throughput: 0: 79.5. Samples: 400028. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:57:00,964][60274] Avg episode reward: [(0, '157.696')]
[37m[1m[2025-06-29 12:57:01,018][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001552_397312.pth...
[36m[2025-06-29 12:57:01,079][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001488_380928.pth
[36m[2025-06-29 12:57:06,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 397312. Throughput: 0: 78.8. Samples: 400244. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:57:06,000][60274] Avg episode reward: [(0, '169.355')]
[36m[2025-06-29 12:57:10,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 397312. Throughput: 0: 79.7. Samples: 400712. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:57:10,963][60274] Avg episode reward: [(0, '166.686')]
[36m[2025-06-29 12:57:15,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 397312. Throughput: 0: 78.9. Samples: 401176. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 12:57:15,958][60274] Avg episode reward: [(0, '162.372')]
[36m[2025-06-29 12:57:20,969][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 401408. Throughput: 0: 78.5. Samples: 401416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:57:20,969][60274] Avg episode reward: [(0, '162.776')]
[36m[2025-06-29 12:57:25,962][60274] Fps is (10 sec: 409.4, 60 sec: 69.0, 300 sec: 83.3). Total num frames: 401408. Throughput: 0: 77.9. Samples: 401840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:57:25,963][60274] Avg episode reward: [(0, '170.917')]
[31m[5074480 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[5074480 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[5074480 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 12:57:30,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 401408. Throughput: 0: 77.9. Samples: 402336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:57:30,972][60274] Avg episode reward: [(0, '175.672')]
[36m[2025-06-29 12:57:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 401408. Throughput: 0: 77.7. Samples: 402576. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:57:35,972][60274] Avg episode reward: [(0, '171.165')]
[36m[2025-06-29 12:57:40,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 401408. Throughput: 0: 77.5. Samples: 403052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:57:40,948][60274] Avg episode reward: [(0, '165.766')]
[36m[2025-06-29 12:57:45,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 401408. Throughput: 0: 78.0. Samples: 403540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:57:45,995][60274] Avg episode reward: [(0, '156.186')]
[36m[2025-06-29 12:57:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 401408. Throughput: 0: 78.4. Samples: 403768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:57:50,961][60274] Avg episode reward: [(0, '161.041')]
[36m[2025-06-29 12:57:55,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 401408. Throughput: 0: 78.6. Samples: 404248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:57:55,967][60274] Avg episode reward: [(0, '161.480')]
[36m[2025-06-29 12:58:00,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 401408. Throughput: 0: 79.6. Samples: 404756. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:58:00,957][60274] Avg episode reward: [(0, '147.803')]
[36m[2025-06-29 12:58:05,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 401408. Throughput: 0: 79.7. Samples: 405004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:58:05,989][60274] Avg episode reward: [(0, '159.592')]
[36m[2025-06-29 12:58:10,988][60274] Fps is (10 sec: 408.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 405504. Throughput: 0: 80.8. Samples: 405476. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:58:10,988][60274] Avg episode reward: [(0, '157.622')]
[36m[2025-06-29 12:58:15,990][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 405504. Throughput: 0: 79.0. Samples: 405892. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:58:15,991][60274] Avg episode reward: [(0, '153.429')]
[36m[2025-06-29 12:58:20,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 405504. Throughput: 0: 78.7. Samples: 406120. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:58:20,979][60274] Avg episode reward: [(0, '155.268')]
[36m[2025-06-29 12:58:25,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 405504. Throughput: 0: 79.1. Samples: 406612. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:58:25,951][60274] Avg episode reward: [(0, '154.512')]
[36m[2025-06-29 12:58:30,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 405504. Throughput: 0: 78.5. Samples: 407068. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:58:30,957][60274] Avg episode reward: [(0, '153.324')]
[36m[2025-06-29 12:58:35,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 405504. Throughput: 0: 78.7. Samples: 407312. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:58:35,967][60274] Avg episode reward: [(0, '155.734')]
[36m[2025-06-29 12:58:40,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 405504. Throughput: 0: 79.1. Samples: 407808. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:58:40,950][60274] Avg episode reward: [(0, '151.116')]
[36m[2025-06-29 12:58:45,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 405504. Throughput: 0: 78.4. Samples: 408288. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:58:45,990][60274] Avg episode reward: [(0, '144.926')]
[36m[2025-06-29 12:58:50,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 405504. Throughput: 0: 78.1. Samples: 408520. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:58:50,980][60274] Avg episode reward: [(0, '145.842')]
[36m[2025-06-29 12:58:55,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 405504. Throughput: 0: 78.1. Samples: 408988. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:58:55,975][60274] Avg episode reward: [(0, '138.860')]
[36m[2025-06-29 12:59:00,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 405504. Throughput: 0: 79.7. Samples: 409480. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 12:59:00,984][60274] Avg episode reward: [(0, '133.950')]
[37m[1m[2025-06-29 12:59:01,054][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001584_405504.pth...
[36m[2025-06-29 12:59:01,109][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001520_389120.pth
[36m[2025-06-29 12:59:05,987][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 409600. Throughput: 0: 78.7. Samples: 409664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:59:05,987][60274] Avg episode reward: [(0, '140.662')]
[36m[2025-06-29 12:59:10,991][60274] Fps is (10 sec: 409.3, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 409600. Throughput: 0: 78.3. Samples: 410140. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:59:10,992][60274] Avg episode reward: [(0, '139.329')]
[36m[2025-06-29 12:59:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 409600. Throughput: 0: 78.5. Samples: 410600. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:59:15,953][60274] Avg episode reward: [(0, '129.268')]
[36m[2025-06-29 12:59:20,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 409600. Throughput: 0: 78.5. Samples: 410844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:59:20,961][60274] Avg episode reward: [(0, '127.583')]
[36m[2025-06-29 12:59:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 409600. Throughput: 0: 77.6. Samples: 411300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:59:25,956][60274] Avg episode reward: [(0, '132.212')]
[36m[2025-06-29 12:59:30,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 409600. Throughput: 0: 77.9. Samples: 411792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:59:30,990][60274] Avg episode reward: [(0, '139.202')]
[36m[2025-06-29 12:59:35,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 409600. Throughput: 0: 77.8. Samples: 412024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:59:35,993][60274] Avg episode reward: [(0, '144.649')]
[36m[2025-06-29 12:59:40,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 409600. Throughput: 0: 78.5. Samples: 412520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:59:40,965][60274] Avg episode reward: [(0, '140.224')]
[36m[2025-06-29 12:59:45,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 409600. Throughput: 0: 78.5. Samples: 413012. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:59:45,961][60274] Avg episode reward: [(0, '149.148')]
[36m[2025-06-29 12:59:50,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 409600. Throughput: 0: 80.2. Samples: 413272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 12:59:50,956][60274] Avg episode reward: [(0, '153.249')]
[31m[5219749 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[5219749 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[5219749 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 12:59:55,970][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 413696. Throughput: 0: 79.2. Samples: 413704. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 12:59:55,970][60274] Avg episode reward: [(0, '153.274')]
[36m[2025-06-29 13:00:01,001][60274] Fps is (10 sec: 407.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 413696. Throughput: 0: 79.4. Samples: 414176. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:00:01,001][60274] Avg episode reward: [(0, '158.692')]
[36m[2025-06-29 13:00:05,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 413696. Throughput: 0: 79.2. Samples: 414408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:00:05,978][60274] Avg episode reward: [(0, '157.254')]
[36m[2025-06-29 13:00:10,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 413696. Throughput: 0: 79.8. Samples: 414892. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:00:10,973][60274] Avg episode reward: [(0, '166.226')]
[36m[2025-06-29 13:00:15,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 413696. Throughput: 0: 79.9. Samples: 415384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:00:15,974][60274] Avg episode reward: [(0, '155.843')]
[36m[2025-06-29 13:00:20,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 413696. Throughput: 0: 80.0. Samples: 415620. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:00:20,970][60274] Avg episode reward: [(0, '145.780')]
[36m[2025-06-29 13:00:25,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 413696. Throughput: 0: 79.7. Samples: 416108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:00:25,968][60274] Avg episode reward: [(0, '133.977')]
[36m[2025-06-29 13:00:30,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 413696. Throughput: 0: 79.8. Samples: 416604. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:00:30,966][60274] Avg episode reward: [(0, '140.373')]
[36m[2025-06-29 13:00:35,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 413696. Throughput: 0: 79.7. Samples: 416860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:00:35,988][60274] Avg episode reward: [(0, '139.863')]
[36m[2025-06-29 13:00:40,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 413696. Throughput: 0: 80.7. Samples: 417336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:00:40,979][60274] Avg episode reward: [(0, '140.145')]
[36m[2025-06-29 13:00:45,971][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 417792. Throughput: 0: 80.6. Samples: 417800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:00:45,971][60274] Avg episode reward: [(0, '143.180')]
[36m[2025-06-29 13:00:50,978][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 417792. Throughput: 0: 80.1. Samples: 418012. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:00:50,978][60274] Avg episode reward: [(0, '136.652')]
[36m[2025-06-29 13:00:55,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 417792. Throughput: 0: 80.1. Samples: 418496. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:00:55,981][60274] Avg episode reward: [(0, '147.408')]
[36m[2025-06-29 13:01:00,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 417792. Throughput: 0: 80.4. Samples: 419004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:00,991][60274] Avg episode reward: [(0, '147.072')]
[37m[1m[2025-06-29 13:01:00,994][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001632_417792.pth...
[36m[2025-06-29 13:01:01,052][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001552_397312.pth
[36m[2025-06-29 13:01:05,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 417792. Throughput: 0: 80.2. Samples: 419228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:05,972][60274] Avg episode reward: [(0, '155.408')]
[36m[2025-06-29 13:01:10,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 417792. Throughput: 0: 80.0. Samples: 419708. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:10,951][60274] Avg episode reward: [(0, '152.776')]
[36m[2025-06-29 13:01:15,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 417792. Throughput: 0: 80.4. Samples: 420224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:15,984][60274] Avg episode reward: [(0, '142.921')]
[36m[2025-06-29 13:01:20,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 417792. Throughput: 0: 80.3. Samples: 420472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:20,973][60274] Avg episode reward: [(0, '146.516')]
[36m[2025-06-29 13:01:25,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 417792. Throughput: 0: 80.3. Samples: 420948. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:25,963][60274] Avg episode reward: [(0, '145.565')]
[36m[2025-06-29 13:01:30,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 417792. Throughput: 0: 80.8. Samples: 421436. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:30,969][60274] Avg episode reward: [(0, '142.924')]
[36m[2025-06-29 13:01:36,666][60274] Fps is (10 sec: 382.7, 60 sec: 135.0, 300 sec: 83.1). Total num frames: 421888. Throughput: 0: 80.1. Samples: 421672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:36,666][60274] Avg episode reward: [(0, '140.928')]
[36m[2025-06-29 13:01:40,990][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 421888. Throughput: 0: 80.1. Samples: 422100. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:40,990][60274] Avg episode reward: [(0, '142.217')]
[36m[2025-06-29 13:01:45,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 421888. Throughput: 0: 79.7. Samples: 422588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:45,966][60274] Avg episode reward: [(0, '134.707')]
[36m[2025-06-29 13:01:50,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 421888. Throughput: 0: 79.6. Samples: 422812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:50,983][60274] Avg episode reward: [(0, '131.914')]
[36m[2025-06-29 13:01:55,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 421888. Throughput: 0: 79.5. Samples: 423288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:01:55,976][60274] Avg episode reward: [(0, '138.945')]
[36m[2025-06-29 13:02:00,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 421888. Throughput: 0: 78.4. Samples: 423748. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:02:00,952][60274] Avg episode reward: [(0, '141.663')]
[36m[2025-06-29 13:02:05,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 421888. Throughput: 0: 78.4. Samples: 424000. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:02:05,976][60274] Avg episode reward: [(0, '152.816')]
[36m[2025-06-29 13:02:10,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 421888. Throughput: 0: 78.5. Samples: 424484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:02:10,999][60274] Avg episode reward: [(0, '164.417')]
[36m[2025-06-29 13:02:15,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 421888. Throughput: 0: 77.9. Samples: 424944. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:02:15,990][60274] Avg episode reward: [(0, '160.663')]
[36m[2025-06-29 13:02:20,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 421888. Throughput: 0: 79.3. Samples: 425184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:02:20,961][60274] Avg episode reward: [(0, '172.064')]
[36m[2025-06-29 13:02:25,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 421888. Throughput: 0: 79.2. Samples: 425664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:02:25,963][60274] Avg episode reward: [(0, '173.041')]
[36m[2025-06-29 13:02:30,981][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 425984. Throughput: 0: 78.2. Samples: 426108. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:02:30,981][60274] Avg episode reward: [(0, '166.885')]
[36m[2025-06-29 13:02:35,955][60274] Fps is (10 sec: 409.9, 60 sec: 69.1, 300 sec: 83.3). Total num frames: 425984. Throughput: 0: 78.6. Samples: 426348. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:02:35,955][60274] Avg episode reward: [(0, '168.826')]
[36m[2025-06-29 13:02:40,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 425984. Throughput: 0: 78.4. Samples: 426816. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:02:40,985][60274] Avg episode reward: [(0, '170.791')]
[36m[2025-06-29 13:02:45,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 425984. Throughput: 0: 78.7. Samples: 427288. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:02:45,948][60274] Avg episode reward: [(0, '168.277')]
[36m[2025-06-29 13:02:50,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 425984. Throughput: 0: 79.0. Samples: 427552. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:02:50,953][60274] Avg episode reward: [(0, '163.449')]
[36m[2025-06-29 13:02:55,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 425984. Throughput: 0: 78.6. Samples: 428020. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:02:55,973][60274] Avg episode reward: [(0, '168.471')]
[36m[2025-06-29 13:03:00,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 425984. Throughput: 0: 78.6. Samples: 428480. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:03:00,969][60274] Avg episode reward: [(0, '165.061')]
[37m[1m[2025-06-29 13:03:01,016][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001664_425984.pth...
[36m[2025-06-29 13:03:01,071][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001584_405504.pth
[36m[2025-06-29 13:03:05,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 425984. Throughput: 0: 78.5. Samples: 428720. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:03:05,981][60274] Avg episode reward: [(0, '169.544')]
[36m[2025-06-29 13:03:10,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 425984. Throughput: 0: 78.6. Samples: 429200. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:03:10,966][60274] Avg episode reward: [(0, '168.323')]
[36m[2025-06-29 13:03:15,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 425984. Throughput: 0: 79.2. Samples: 429672. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:03:15,980][60274] Avg episode reward: [(0, '175.882')]
[36m[2025-06-29 13:03:21,227][60274] Fps is (10 sec: 399.2, 60 sec: 135.9, 300 sec: 83.2). Total num frames: 430080. Throughput: 0: 78.6. Samples: 429908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:03:21,227][60274] Avg episode reward: [(0, '179.882')]
[36m[2025-06-29 13:03:25,989][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 430080. Throughput: 0: 78.4. Samples: 430344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:03:25,989][60274] Avg episode reward: [(0, '175.924')]
[36m[2025-06-29 13:03:30,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 430080. Throughput: 0: 79.0. Samples: 430844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:03:30,983][60274] Avg episode reward: [(0, '177.598')]
[36m[2025-06-29 13:03:35,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 430080. Throughput: 0: 78.7. Samples: 431096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:03:35,976][60274] Avg episode reward: [(0, '174.444')]
[36m[2025-06-29 13:03:40,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 430080. Throughput: 0: 78.9. Samples: 431568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:03:40,948][60274] Avg episode reward: [(0, '168.184')]
[36m[2025-06-29 13:03:45,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 430080. Throughput: 0: 79.2. Samples: 432044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:03:45,978][60274] Avg episode reward: [(0, '160.606')]
[36m[2025-06-29 13:03:50,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 430080. Throughput: 0: 79.3. Samples: 432288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:03:50,952][60274] Avg episode reward: [(0, '167.206')]
[36m[2025-06-29 13:03:55,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 430080. Throughput: 0: 79.2. Samples: 432764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:03:55,976][60274] Avg episode reward: [(0, '171.441')]
[36m[2025-06-29 13:04:00,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 430080. Throughput: 0: 79.0. Samples: 433228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:04:00,987][60274] Avg episode reward: [(0, '173.446')]
[36m[2025-06-29 13:04:05,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 430080. Throughput: 0: 79.4. Samples: 433460. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:04:05,977][60274] Avg episode reward: [(0, '168.726')]
[36m[2025-06-29 13:04:10,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 430080. Throughput: 0: 79.4. Samples: 433916. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:04:10,964][60274] Avg episode reward: [(0, '169.234')]
[36m[2025-06-29 13:04:15,974][60274] Fps is (10 sec: 409.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 434176. Throughput: 0: 77.6. Samples: 434336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:04:15,974][60274] Avg episode reward: [(0, '174.288')]
[36m[2025-06-29 13:04:20,970][60274] Fps is (10 sec: 409.3, 60 sec: 68.6, 300 sec: 83.3). Total num frames: 434176. Throughput: 0: 77.4. Samples: 434580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:04:20,970][60274] Avg episode reward: [(0, '183.222')]
[36m[2025-06-29 13:04:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 434176. Throughput: 0: 77.9. Samples: 435072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:04:25,956][60274] Avg episode reward: [(0, '179.445')]
[36m[2025-06-29 13:04:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 434176. Throughput: 0: 78.6. Samples: 435580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:04:30,973][60274] Avg episode reward: [(0, '178.206')]
[36m[2025-06-29 13:04:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 434176. Throughput: 0: 79.0. Samples: 435844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:04:35,981][60274] Avg episode reward: [(0, '182.258')]
[36m[2025-06-29 13:04:40,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 434176. Throughput: 0: 79.3. Samples: 436332. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:04:40,992][60274] Avg episode reward: [(0, '182.760')]
[36m[2025-06-29 13:04:45,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 434176. Throughput: 0: 79.4. Samples: 436800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:04:45,970][60274] Avg episode reward: [(0, '182.289')]
[36m[2025-06-29 13:04:50,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 434176. Throughput: 0: 79.8. Samples: 437048. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:04:50,960][60274] Avg episode reward: [(0, '172.380')]
[36m[2025-06-29 13:04:55,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 434176. Throughput: 0: 80.4. Samples: 437536. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:04:55,988][60274] Avg episode reward: [(0, '178.226')]
[36m[2025-06-29 13:05:00,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 434176. Throughput: 0: 81.5. Samples: 438004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:05:00,992][60274] Avg episode reward: [(0, '174.848')]
[37m[1m[2025-06-29 13:05:01,041][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001696_434176.pth...
[36m[2025-06-29 13:05:01,096][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001632_417792.pth
[36m[2025-06-29 13:05:05,954][60274] Fps is (10 sec: 411.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 438272. Throughput: 0: 81.5. Samples: 438248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:05,954][60274] Avg episode reward: [(0, '169.430')]
[36m[2025-06-29 13:05:10,950][60274] Fps is (10 sec: 411.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 438272. Throughput: 0: 80.0. Samples: 438672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:10,950][60274] Avg episode reward: [(0, '181.459')]
[36m[2025-06-29 13:05:15,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 438272. Throughput: 0: 79.4. Samples: 439152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:15,954][60274] Avg episode reward: [(0, '173.282')]
[36m[2025-06-29 13:05:20,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 438272. Throughput: 0: 78.8. Samples: 439388. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:20,962][60274] Avg episode reward: [(0, '164.798')]
[36m[2025-06-29 13:05:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 438272. Throughput: 0: 78.1. Samples: 439844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:25,966][60274] Avg episode reward: [(0, '172.369')]
[36m[2025-06-29 13:05:30,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 438272. Throughput: 0: 78.0. Samples: 440308. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:30,956][60274] Avg episode reward: [(0, '181.121')]
[36m[2025-06-29 13:05:35,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 438272. Throughput: 0: 77.6. Samples: 440540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:35,986][60274] Avg episode reward: [(0, '189.526')]
[36m[2025-06-29 13:05:40,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 438272. Throughput: 0: 77.5. Samples: 441020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:40,959][60274] Avg episode reward: [(0, '199.890')]
[36m[2025-06-29 13:05:45,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 438272. Throughput: 0: 77.6. Samples: 441496. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:45,971][60274] Avg episode reward: [(0, '180.313')]
[36m[2025-06-29 13:05:50,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 438272. Throughput: 0: 77.2. Samples: 441724. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:50,971][60274] Avg episode reward: [(0, '173.186')]
[36m[2025-06-29 13:05:55,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 438272. Throughput: 0: 78.9. Samples: 442224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:05:55,973][60274] Avg episode reward: [(0, '169.732')]
[36m[2025-06-29 13:06:00,969][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 442368. Throughput: 0: 77.6. Samples: 442644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:06:00,969][60274] Avg episode reward: [(0, '148.799')]
[36m[2025-06-29 13:06:05,989][60274] Fps is (10 sec: 408.9, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 442368. Throughput: 0: 77.5. Samples: 442876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:06:05,989][60274] Avg episode reward: [(0, '152.439')]
[36m[2025-06-29 13:06:10,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 442368. Throughput: 0: 77.5. Samples: 443332. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:06:10,961][60274] Avg episode reward: [(0, '150.425')]
[36m[2025-06-29 13:06:15,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 442368. Throughput: 0: 78.3. Samples: 443832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:06:15,971][60274] Avg episode reward: [(0, '147.328')]
[36m[2025-06-29 13:06:20,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 442368. Throughput: 0: 78.5. Samples: 444072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:06:20,971][60274] Avg episode reward: [(0, '139.463')]
[36m[2025-06-29 13:06:25,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 442368. Throughput: 0: 78.3. Samples: 444548. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:06:25,994][60274] Avg episode reward: [(0, '144.416')]
[36m[2025-06-29 13:06:30,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.6). Total num frames: 442368. Throughput: 0: 78.9. Samples: 445048. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:06:30,991][60274] Avg episode reward: [(0, '137.625')]
[36m[2025-06-29 13:06:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 442368. Throughput: 0: 79.3. Samples: 445292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:06:35,973][60274] Avg episode reward: [(0, '141.591')]
[36m[2025-06-29 13:06:40,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 442368. Throughput: 0: 78.9. Samples: 445776. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:06:40,988][60274] Avg episode reward: [(0, '139.931')]
[36m[2025-06-29 13:06:45,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 442368. Throughput: 0: 80.6. Samples: 446268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:06:45,957][60274] Avg episode reward: [(0, '149.038')]
[36m[2025-06-29 13:06:50,946][60274] Fps is (10 sec: 411.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 446464. Throughput: 0: 80.0. Samples: 446472. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:06:50,947][60274] Avg episode reward: [(0, '148.652')]
[36m[2025-06-29 13:06:55,980][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 446464. Throughput: 0: 80.0. Samples: 446932. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:06:55,980][60274] Avg episode reward: [(0, '147.799')]
[36m[2025-06-29 13:07:00,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 446464. Throughput: 0: 79.7. Samples: 447420. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:07:00,968][60274] Avg episode reward: [(0, '151.025')]
[37m[1m[2025-06-29 13:07:01,023][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001744_446464.pth...
[36m[2025-06-29 13:07:01,084][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001664_425984.pth
[36m[2025-06-29 13:07:05,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 446464. Throughput: 0: 79.6. Samples: 447652. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:07:05,959][60274] Avg episode reward: [(0, '153.126')]
[36m[2025-06-29 13:07:10,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 446464. Throughput: 0: 80.0. Samples: 448148. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:07:10,985][60274] Avg episode reward: [(0, '155.949')]
[36m[2025-06-29 13:07:15,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 446464. Throughput: 0: 79.9. Samples: 448640. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:07:15,958][60274] Avg episode reward: [(0, '159.696')]
[36m[2025-06-29 13:07:20,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 446464. Throughput: 0: 80.1. Samples: 448896. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:07:20,967][60274] Avg episode reward: [(0, '157.744')]
[36m[2025-06-29 13:07:25,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 446464. Throughput: 0: 79.7. Samples: 449360. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:07:25,971][60274] Avg episode reward: [(0, '152.956')]
[36m[2025-06-29 13:07:30,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 446464. Throughput: 0: 80.0. Samples: 449868. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:07:30,976][60274] Avg episode reward: [(0, '156.574')]
[36m[2025-06-29 13:07:35,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 446464. Throughput: 0: 81.1. Samples: 450124. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:07:35,998][60274] Avg episode reward: [(0, '163.315')]
[36m[2025-06-29 13:07:40,961][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 450560. Throughput: 0: 80.8. Samples: 450568. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 13:07:40,961][60274] Avg episode reward: [(0, '170.540')]
[36m[2025-06-29 13:07:45,971][60274] Fps is (10 sec: 410.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 450560. Throughput: 0: 81.0. Samples: 451064. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 13:07:45,971][60274] Avg episode reward: [(0, '172.187')]
[36m[2025-06-29 13:07:50,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 450560. Throughput: 0: 81.5. Samples: 451320. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 13:07:50,989][60274] Avg episode reward: [(0, '174.947')]
[36m[2025-06-29 13:07:55,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 450560. Throughput: 0: 81.5. Samples: 451816. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 13:07:55,982][60274] Avg episode reward: [(0, '184.024')]
[36m[2025-06-29 13:08:00,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 450560. Throughput: 0: 81.4. Samples: 452304. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 13:08:00,981][60274] Avg episode reward: [(0, '176.949')]
[36m[2025-06-29 13:08:05,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 450560. Throughput: 0: 81.4. Samples: 452560. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 13:08:05,954][60274] Avg episode reward: [(0, '181.976')]
[36m[2025-06-29 13:08:10,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 450560. Throughput: 0: 82.1. Samples: 453056. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 13:08:10,970][60274] Avg episode reward: [(0, '179.487')]
[36m[2025-06-29 13:08:15,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.5). Total num frames: 450560. Throughput: 0: 81.6. Samples: 453540. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 13:08:15,990][60274] Avg episode reward: [(0, '181.658')]
[36m[2025-06-29 13:08:20,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 450560. Throughput: 0: 81.4. Samples: 453784. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 13:08:20,974][60274] Avg episode reward: [(0, '174.632')]
[36m[2025-06-29 13:08:25,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 450560. Throughput: 0: 81.9. Samples: 454256. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 13:08:25,990][60274] Avg episode reward: [(0, '181.607')]
[36m[2025-06-29 13:08:30,975][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 454656. Throughput: 0: 81.0. Samples: 454708. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:08:30,975][60274] Avg episode reward: [(0, '177.433')]
[36m[2025-06-29 13:08:35,950][60274] Fps is (10 sec: 411.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 454656. Throughput: 0: 80.8. Samples: 454952. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:08:35,950][60274] Avg episode reward: [(0, '179.191')]
[36m[2025-06-29 13:08:40,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 454656. Throughput: 0: 80.7. Samples: 455448. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:08:40,965][60274] Avg episode reward: [(0, '182.082')]
[36m[2025-06-29 13:08:46,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 454656. Throughput: 0: 80.7. Samples: 455936. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:08:46,000][60274] Avg episode reward: [(0, '181.850')]
[36m[2025-06-29 13:08:50,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 454656. Throughput: 0: 80.2. Samples: 456172. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:08:50,974][60274] Avg episode reward: [(0, '183.490')]
[36m[2025-06-29 13:08:55,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 454656. Throughput: 0: 79.6. Samples: 456636. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:08:55,949][60274] Avg episode reward: [(0, '180.937')]
[36m[2025-06-29 13:09:00,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 454656. Throughput: 0: 78.8. Samples: 457088. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:09:00,998][60274] Avg episode reward: [(0, '174.910')]
[37m[1m[2025-06-29 13:09:01,055][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001776_454656.pth...
[36m[2025-06-29 13:09:01,110][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001696_434176.pth
[36m[2025-06-29 13:09:05,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 454656. Throughput: 0: 78.6. Samples: 457320. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:09:05,987][60274] Avg episode reward: [(0, '165.347')]
[36m[2025-06-29 13:09:10,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 454656. Throughput: 0: 79.3. Samples: 457824. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:09:10,989][60274] Avg episode reward: [(0, '152.110')]
[36m[2025-06-29 13:09:16,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 454656. Throughput: 0: 80.2. Samples: 458320. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:09:16,001][60274] Avg episode reward: [(0, '147.338')]
[36m[2025-06-29 13:09:21,566][60274] Fps is (10 sec: 387.2, 60 sec: 135.2, 300 sec: 83.1). Total num frames: 458752. Throughput: 0: 78.7. Samples: 458544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:09:21,567][60274] Avg episode reward: [(0, '143.110')]
[36m[2025-06-29 13:09:26,000][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 458752. Throughput: 0: 78.2. Samples: 458972. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:09:26,001][60274] Avg episode reward: [(0, '150.419')]
[36m[2025-06-29 13:09:30,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 458752. Throughput: 0: 78.3. Samples: 459456. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:09:30,976][60274] Avg episode reward: [(0, '143.945')]
[36m[2025-06-29 13:09:35,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 458752. Throughput: 0: 78.2. Samples: 459692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:09:35,971][60274] Avg episode reward: [(0, '143.019')]
[36m[2025-06-29 13:09:40,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 458752. Throughput: 0: 78.4. Samples: 460164. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:09:40,975][60274] Avg episode reward: [(0, '140.831')]
[36m[2025-06-29 13:09:45,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 458752. Throughput: 0: 79.5. Samples: 460664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:09:45,963][60274] Avg episode reward: [(0, '143.527')]
[36m[2025-06-29 13:09:50,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 458752. Throughput: 0: 79.8. Samples: 460912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:09:50,986][60274] Avg episode reward: [(0, '136.779')]
[36m[2025-06-29 13:09:55,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 458752. Throughput: 0: 79.3. Samples: 461388. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:09:55,953][60274] Avg episode reward: [(0, '143.130')]
[36m[2025-06-29 13:10:00,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 458752. Throughput: 0: 79.0. Samples: 461876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:10:00,991][60274] Avg episode reward: [(0, '144.912')]
[36m[2025-06-29 13:10:05,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 458752. Throughput: 0: 80.6. Samples: 462124. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:10:05,991][60274] Avg episode reward: [(0, '144.536')]
[36m[2025-06-29 13:10:10,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 458752. Throughput: 0: 80.7. Samples: 462600. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:10:10,960][60274] Avg episode reward: [(0, '155.296')]
[36m[2025-06-29 13:10:15,977][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 462848. Throughput: 0: 79.5. Samples: 463032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:10:15,977][60274] Avg episode reward: [(0, '157.174')]
[36m[2025-06-29 13:10:20,978][60274] Fps is (10 sec: 408.9, 60 sec: 68.9, 300 sec: 83.3). Total num frames: 462848. Throughput: 0: 79.5. Samples: 463272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:10:20,978][60274] Avg episode reward: [(0, '157.872')]
[36m[2025-06-29 13:10:25,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 462848. Throughput: 0: 79.8. Samples: 463752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:10:25,948][60274] Avg episode reward: [(0, '157.891')]
[36m[2025-06-29 13:10:30,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 462848. Throughput: 0: 79.2. Samples: 464228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:10:30,966][60274] Avg episode reward: [(0, '158.927')]
[36m[2025-06-29 13:10:35,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 462848. Throughput: 0: 79.1. Samples: 464472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:10:35,975][60274] Avg episode reward: [(0, '145.818')]
[36m[2025-06-29 13:10:40,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 462848. Throughput: 0: 79.0. Samples: 464944. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:10:40,969][60274] Avg episode reward: [(0, '153.829')]
[36m[2025-06-29 13:10:45,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 462848. Throughput: 0: 78.9. Samples: 465424. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:10:45,985][60274] Avg episode reward: [(0, '147.965')]
[36m[2025-06-29 13:10:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 462848. Throughput: 0: 78.5. Samples: 465656. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:10:50,961][60274] Avg episode reward: [(0, '152.962')]
[36m[2025-06-29 13:10:55,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 462848. Throughput: 0: 78.5. Samples: 466132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:10:55,969][60274] Avg episode reward: [(0, '159.419')]
[36m[2025-06-29 13:11:00,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 462848. Throughput: 0: 79.8. Samples: 466624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:11:00,979][60274] Avg episode reward: [(0, '165.357')]
[37m[1m[2025-06-29 13:11:01,027][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001808_462848.pth...
[36m[2025-06-29 13:11:01,085][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001744_446464.pth
[36m[2025-06-29 13:11:05,956][60274] Fps is (10 sec: 410.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 466944. Throughput: 0: 79.8. Samples: 466860. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:11:05,956][60274] Avg episode reward: [(0, '165.042')]
[36m[2025-06-29 13:11:10,986][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 466944. Throughput: 0: 78.7. Samples: 467296. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:11:10,986][60274] Avg episode reward: [(0, '168.046')]
[31m[5899584 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[5899585 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[5899585 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:11:16,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 466944. Throughput: 0: 79.2. Samples: 467796. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:11:16,008][60274] Avg episode reward: [(0, '162.427')]
[36m[2025-06-29 13:11:20,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 466944. Throughput: 0: 79.1. Samples: 468028. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:11:20,954][60274] Avg episode reward: [(0, '168.676')]
[36m[2025-06-29 13:11:25,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 466944. Throughput: 0: 79.1. Samples: 468504. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:11:25,960][60274] Avg episode reward: [(0, '162.808')]
[36m[2025-06-29 13:11:30,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 466944. Throughput: 0: 78.8. Samples: 468972. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:11:30,990][60274] Avg episode reward: [(0, '158.113')]
[36m[2025-06-29 13:11:35,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 466944. Throughput: 0: 79.5. Samples: 469236. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:11:35,982][60274] Avg episode reward: [(0, '157.602')]
[36m[2025-06-29 13:11:40,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 466944. Throughput: 0: 79.5. Samples: 469708. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:11:40,978][60274] Avg episode reward: [(0, '169.206')]
[36m[2025-06-29 13:11:45,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 466944. Throughput: 0: 79.4. Samples: 470196. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:11:45,981][60274] Avg episode reward: [(0, '172.702')]
[36m[2025-06-29 13:11:50,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 466944. Throughput: 0: 79.8. Samples: 470452. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:11:50,947][60274] Avg episode reward: [(0, '176.604')]
[36m[2025-06-29 13:11:56,097][60274] Fps is (10 sec: 404.9, 60 sec: 136.2, 300 sec: 83.3). Total num frames: 471040. Throughput: 0: 81.2. Samples: 470960. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:11:56,098][60274] Avg episode reward: [(0, '175.815')]
[36m[2025-06-29 13:12:00,949][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 471040. Throughput: 0: 79.9. Samples: 471388. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:12:00,949][60274] Avg episode reward: [(0, '173.793')]
[36m[2025-06-29 13:12:05,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 471040. Throughput: 0: 80.1. Samples: 471632. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:12:05,957][60274] Avg episode reward: [(0, '168.803')]
[36m[2025-06-29 13:12:10,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 471040. Throughput: 0: 79.7. Samples: 472092. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:12:10,975][60274] Avg episode reward: [(0, '163.976')]
[36m[2025-06-29 13:12:15,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 471040. Throughput: 0: 80.5. Samples: 472592. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:12:15,965][60274] Avg episode reward: [(0, '164.245')]
[36m[2025-06-29 13:12:20,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 471040. Throughput: 0: 80.0. Samples: 472836. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:12:20,989][60274] Avg episode reward: [(0, '168.622')]
[36m[2025-06-29 13:12:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 471040. Throughput: 0: 80.4. Samples: 473324. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:12:25,957][60274] Avg episode reward: [(0, '175.261')]
[36m[2025-06-29 13:12:30,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 471040. Throughput: 0: 80.6. Samples: 473824. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:12:30,980][60274] Avg episode reward: [(0, '169.511')]
[36m[2025-06-29 13:12:35,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 471040. Throughput: 0: 80.6. Samples: 474080. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:12:35,953][60274] Avg episode reward: [(0, '172.148')]
[36m[2025-06-29 13:12:40,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 471040. Throughput: 0: 80.0. Samples: 474548. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:12:40,971][60274] Avg episode reward: [(0, '184.103')]
[36m[2025-06-29 13:12:45,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 471040. Throughput: 0: 80.9. Samples: 475028. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:12:45,969][60274] Avg episode reward: [(0, '172.824')]
[36m[2025-06-29 13:12:50,990][60274] Fps is (10 sec: 408.8, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 475136. Throughput: 0: 79.7. Samples: 475220. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:12:50,990][60274] Avg episode reward: [(0, '171.225')]
[31m[6000310 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[6000311 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[6000311 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:12:55,990][60274] Fps is (10 sec: 408.7, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 475136. Throughput: 0: 80.0. Samples: 475692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:12:55,990][60274] Avg episode reward: [(0, '158.417')]
[36m[2025-06-29 13:13:00,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 475136. Throughput: 0: 79.3. Samples: 476160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:13:00,955][60274] Avg episode reward: [(0, '165.477')]
[37m[1m[2025-06-29 13:13:01,007][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001856_475136.pth...
[36m[2025-06-29 13:13:01,062][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001776_454656.pth
[36m[2025-06-29 13:13:05,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 475136. Throughput: 0: 78.9. Samples: 476384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:13:05,970][60274] Avg episode reward: [(0, '159.694')]
[36m[2025-06-29 13:13:10,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 475136. Throughput: 0: 78.0. Samples: 476836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:13:10,983][60274] Avg episode reward: [(0, '156.530')]
[33m[6018422 ms][navigation_task] - WARNING : Curriculum Level: 36, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[6018422 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.50048828125
[33mCrash Rate: 0.2724609375
[33mTimeout Rate: 0.22705078125 (navigation_task.py:265)
[33m[6018422 ms][navigation_task] - WARNING : 
[33mSuccesses: 1025
[33mCrashes : 558
[33mTimeouts: 465 (navigation_task.py:268)
[36m[2025-06-29 13:13:15,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 475136. Throughput: 0: 78.1. Samples: 477336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:13:15,954][60274] Avg episode reward: [(0, '162.781')]
[36m[2025-06-29 13:13:20,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 475136. Throughput: 0: 77.9. Samples: 477588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:13:20,974][60274] Avg episode reward: [(0, '150.162')]
[36m[2025-06-29 13:13:25,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 475136. Throughput: 0: 78.5. Samples: 478080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:13:25,987][60274] Avg episode reward: [(0, '159.296')]
[36m[2025-06-29 13:13:30,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 475136. Throughput: 0: 79.1. Samples: 478588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:13:30,970][60274] Avg episode reward: [(0, '150.718')]
[36m[2025-06-29 13:13:35,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 475136. Throughput: 0: 80.1. Samples: 478824. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:13:35,975][60274] Avg episode reward: [(0, '150.251')]
[36m[2025-06-29 13:13:40,950][60274] Fps is (10 sec: 410.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 479232. Throughput: 0: 79.4. Samples: 479264. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:13:40,951][60274] Avg episode reward: [(0, '155.475')]
[36m[2025-06-29 13:13:46,003][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 479232. Throughput: 0: 79.6. Samples: 479744. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:13:46,003][60274] Avg episode reward: [(0, '148.325')]
[36m[2025-06-29 13:13:50,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 479232. Throughput: 0: 80.2. Samples: 479992. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:13:50,984][60274] Avg episode reward: [(0, '146.079')]
[36m[2025-06-29 13:13:55,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 479232. Throughput: 0: 80.9. Samples: 480472. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:13:55,950][60274] Avg episode reward: [(0, '144.919')]
[36m[2025-06-29 13:14:00,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 479232. Throughput: 0: 80.6. Samples: 480964. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:14:00,960][60274] Avg episode reward: [(0, '146.382')]
[36m[2025-06-29 13:14:05,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 479232. Throughput: 0: 80.7. Samples: 481216. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:14:05,951][60274] Avg episode reward: [(0, '132.686')]
[36m[2025-06-29 13:14:10,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 479232. Throughput: 0: 80.5. Samples: 481700. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:14:10,954][60274] Avg episode reward: [(0, '130.909')]
[36m[2025-06-29 13:14:15,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.6). Total num frames: 479232. Throughput: 0: 79.6. Samples: 482172. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:14:15,992][60274] Avg episode reward: [(0, '130.289')]
[36m[2025-06-29 13:14:21,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 479232. Throughput: 0: 79.5. Samples: 482404. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:14:21,008][60274] Avg episode reward: [(0, '118.859')]
[36m[2025-06-29 13:14:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 479232. Throughput: 0: 80.1. Samples: 482872. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:14:25,979][60274] Avg episode reward: [(0, '115.718')]
[36m[2025-06-29 13:14:30,957][60274] Fps is (10 sec: 411.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 483328. Throughput: 0: 79.9. Samples: 483336. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:14:30,958][60274] Avg episode reward: [(0, '120.133')]
[36m[2025-06-29 13:14:36,001][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 483328. Throughput: 0: 78.9. Samples: 483544. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:14:36,001][60274] Avg episode reward: [(0, '127.691')]
[36m[2025-06-29 13:14:40,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 483328. Throughput: 0: 78.8. Samples: 484020. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:14:40,976][60274] Avg episode reward: [(0, '121.572')]
[36m[2025-06-29 13:14:45,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 483328. Throughput: 0: 78.4. Samples: 484496. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:14:45,983][60274] Avg episode reward: [(0, '120.662')]
[36m[2025-06-29 13:14:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 483328. Throughput: 0: 78.1. Samples: 484732. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:14:50,976][60274] Avg episode reward: [(0, '118.439')]
[36m[2025-06-29 13:14:55,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 483328. Throughput: 0: 78.5. Samples: 485232. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:14:55,974][60274] Avg episode reward: [(0, '102.318')]
[36m[2025-06-29 13:15:00,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 483328. Throughput: 0: 78.7. Samples: 485712. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:15:00,949][60274] Avg episode reward: [(0, '114.825')]
[37m[1m[2025-06-29 13:15:00,999][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001888_483328.pth...
[36m[2025-06-29 13:15:01,055][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001808_462848.pth
[36m[2025-06-29 13:15:05,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 483328. Throughput: 0: 78.7. Samples: 485944. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:15:05,963][60274] Avg episode reward: [(0, '103.052')]
[36m[2025-06-29 13:15:10,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 483328. Throughput: 0: 79.0. Samples: 486428. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:15:10,981][60274] Avg episode reward: [(0, '112.607')]
[36m[2025-06-29 13:15:15,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 483328. Throughput: 0: 79.7. Samples: 486924. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:15:15,967][60274] Avg episode reward: [(0, '114.611')]
[36m[2025-06-29 13:15:20,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 483328. Throughput: 0: 80.8. Samples: 487176. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:15:20,960][60274] Avg episode reward: [(0, '106.194')]
[31m[6149735 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[6149736 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[6149736 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:15:25,990][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 487424. Throughput: 0: 79.8. Samples: 487612. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:15:25,990][60274] Avg episode reward: [(0, '107.756')]
[36m[2025-06-29 13:15:30,982][60274] Fps is (10 sec: 408.7, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 487424. Throughput: 0: 79.3. Samples: 488064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:15:30,982][60274] Avg episode reward: [(0, '121.347')]
[36m[2025-06-29 13:15:35,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 487424. Throughput: 0: 79.1. Samples: 488292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:15:35,956][60274] Avg episode reward: [(0, '101.235')]
[36m[2025-06-29 13:15:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 487424. Throughput: 0: 78.4. Samples: 488760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:15:40,981][60274] Avg episode reward: [(0, '106.019')]
[36m[2025-06-29 13:15:45,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 487424. Throughput: 0: 79.0. Samples: 489268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:15:45,989][60274] Avg episode reward: [(0, '121.780')]
[36m[2025-06-29 13:15:50,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 487424. Throughput: 0: 79.2. Samples: 489508. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:15:50,952][60274] Avg episode reward: [(0, '113.522')]
[36m[2025-06-29 13:15:55,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 487424. Throughput: 0: 79.6. Samples: 490008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:15:55,964][60274] Avg episode reward: [(0, '115.248')]
[36m[2025-06-29 13:16:00,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 487424. Throughput: 0: 79.9. Samples: 490520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:00,956][60274] Avg episode reward: [(0, '113.864')]
[36m[2025-06-29 13:16:05,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 487424. Throughput: 0: 79.9. Samples: 490772. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:05,979][60274] Avg episode reward: [(0, '123.505')]
[31m[6194500 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[6194500 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[6194500 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:16:10,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 487424. Throughput: 0: 81.0. Samples: 491256. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:10,954][60274] Avg episode reward: [(0, '125.192')]
[36m[2025-06-29 13:16:15,960][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 491520. Throughput: 0: 80.3. Samples: 491676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:15,960][60274] Avg episode reward: [(0, '132.186')]
[36m[2025-06-29 13:16:20,948][60274] Fps is (10 sec: 409.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 491520. Throughput: 0: 80.4. Samples: 491908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:20,948][60274] Avg episode reward: [(0, '130.166')]
[36m[2025-06-29 13:16:25,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 491520. Throughput: 0: 81.2. Samples: 492412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:25,957][60274] Avg episode reward: [(0, '139.632')]
[36m[2025-06-29 13:16:30,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 491520. Throughput: 0: 80.9. Samples: 492904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:30,950][60274] Avg episode reward: [(0, '145.214')]
[36m[2025-06-29 13:16:35,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 491520. Throughput: 0: 81.3. Samples: 493168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:35,990][60274] Avg episode reward: [(0, '155.505')]
[36m[2025-06-29 13:16:40,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 491520. Throughput: 0: 81.2. Samples: 493660. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:40,962][60274] Avg episode reward: [(0, '162.600')]
[36m[2025-06-29 13:16:45,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 491520. Throughput: 0: 80.5. Samples: 494144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:45,956][60274] Avg episode reward: [(0, '164.280')]
[31m[6231452 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[6231452 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[6231452 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:16:50,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 491520. Throughput: 0: 80.8. Samples: 494404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:50,955][60274] Avg episode reward: [(0, '166.352')]
[36m[2025-06-29 13:16:55,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 491520. Throughput: 0: 80.3. Samples: 494872. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:16:55,985][60274] Avg episode reward: [(0, '171.511')]
[36m[2025-06-29 13:17:00,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 491520. Throughput: 0: 82.0. Samples: 495364. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:00,956][60274] Avg episode reward: [(0, '167.966')]
[37m[1m[2025-06-29 13:17:01,009][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001920_491520.pth...
[36m[2025-06-29 13:17:01,072][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001856_475136.pth
[36m[2025-06-29 13:17:05,992][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 495616. Throughput: 0: 81.9. Samples: 495596. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:05,993][60274] Avg episode reward: [(0, '171.574')]
[36m[2025-06-29 13:17:10,996][60274] Fps is (10 sec: 408.0, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 495616. Throughput: 0: 80.2. Samples: 496024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:10,996][60274] Avg episode reward: [(0, '169.737')]
[36m[2025-06-29 13:17:15,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 495616. Throughput: 0: 80.5. Samples: 496528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:15,950][60274] Avg episode reward: [(0, '173.857')]
[36m[2025-06-29 13:17:20,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 495616. Throughput: 0: 80.4. Samples: 496784. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:20,990][60274] Avg episode reward: [(0, '182.247')]
[36m[2025-06-29 13:17:25,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 495616. Throughput: 0: 79.7. Samples: 497248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:25,976][60274] Avg episode reward: [(0, '187.620')]
[36m[2025-06-29 13:17:30,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 495616. Throughput: 0: 80.2. Samples: 497756. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:30,974][60274] Avg episode reward: [(0, '176.882')]
[36m[2025-06-29 13:17:35,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 495616. Throughput: 0: 79.8. Samples: 497996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:35,951][60274] Avg episode reward: [(0, '186.329')]
[36m[2025-06-29 13:17:40,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 495616. Throughput: 0: 80.3. Samples: 498484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:40,964][60274] Avg episode reward: [(0, '187.457')]
[36m[2025-06-29 13:17:45,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 495616. Throughput: 0: 80.4. Samples: 498984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:45,968][60274] Avg episode reward: [(0, '185.789')]
[36m[2025-06-29 13:17:50,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 495616. Throughput: 0: 80.9. Samples: 499236. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:17:50,981][60274] Avg episode reward: [(0, '177.289')]
[31m[6300915 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[6300916 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[6300916 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:17:55,968][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 499712. Throughput: 0: 82.2. Samples: 499720. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:17:55,969][60274] Avg episode reward: [(0, '180.904')]
[36m[2025-06-29 13:18:00,951][60274] Fps is (10 sec: 410.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 499712. Throughput: 0: 80.5. Samples: 500152. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:18:00,952][60274] Avg episode reward: [(0, '172.574')]
[36m[2025-06-29 13:18:05,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 499712. Throughput: 0: 80.3. Samples: 500396. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:18:05,961][60274] Avg episode reward: [(0, '174.845')]
[36m[2025-06-29 13:18:10,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 499712. Throughput: 0: 80.9. Samples: 500884. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:18:10,948][60274] Avg episode reward: [(0, '164.706')]
[31m[6320998 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[6320998 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[6320999 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:18:15,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 499712. Throughput: 0: 79.9. Samples: 501352. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:18:15,965][60274] Avg episode reward: [(0, '166.104')]
[36m[2025-06-29 13:18:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 499712. Throughput: 0: 79.5. Samples: 501576. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:18:20,985][60274] Avg episode reward: [(0, '170.458')]
[36m[2025-06-29 13:18:25,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 499712. Throughput: 0: 79.2. Samples: 502048. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:18:25,978][60274] Avg episode reward: [(0, '170.251')]
[36m[2025-06-29 13:18:30,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 499712. Throughput: 0: 79.3. Samples: 502552. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:18:30,959][60274] Avg episode reward: [(0, '161.233')]
[36m[2025-06-29 13:18:36,009][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 499712. Throughput: 0: 79.2. Samples: 502800. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:18:36,009][60274] Avg episode reward: [(0, '165.849')]
[36m[2025-06-29 13:18:40,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 499712. Throughput: 0: 78.7. Samples: 503260. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:18:40,953][60274] Avg episode reward: [(0, '158.778')]
[36m[2025-06-29 13:18:45,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 499712. Throughput: 0: 79.4. Samples: 503724. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:18:45,950][60274] Avg episode reward: [(0, '148.727')]
[36m[2025-06-29 13:18:50,956][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 503808. Throughput: 0: 78.2. Samples: 503916. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:18:50,956][60274] Avg episode reward: [(0, '151.606')]
[36m[2025-06-29 13:18:55,975][60274] Fps is (10 sec: 408.6, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 503808. Throughput: 0: 77.6. Samples: 504380. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:18:55,975][60274] Avg episode reward: [(0, '160.251')]
[36m[2025-06-29 13:19:00,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 503808. Throughput: 0: 78.2. Samples: 504872. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:19:00,983][60274] Avg episode reward: [(0, '156.506')]
[37m[1m[2025-06-29 13:19:01,033][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001968_503808.pth...
[36m[2025-06-29 13:19:01,090][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001888_483328.pth
[36m[2025-06-29 13:19:05,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 503808. Throughput: 0: 78.3. Samples: 505100. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:19:05,998][60274] Avg episode reward: [(0, '152.318')]
[36m[2025-06-29 13:19:10,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 503808. Throughput: 0: 78.2. Samples: 505568. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:19:10,969][60274] Avg episode reward: [(0, '144.408')]
[36m[2025-06-29 13:19:15,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 503808. Throughput: 0: 78.0. Samples: 506064. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:19:15,978][60274] Avg episode reward: [(0, '161.264')]
[36m[2025-06-29 13:19:20,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 503808. Throughput: 0: 77.7. Samples: 506296. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:19:20,999][60274] Avg episode reward: [(0, '154.653')]
[36m[2025-06-29 13:19:25,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 503808. Throughput: 0: 78.2. Samples: 506780. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:19:25,985][60274] Avg episode reward: [(0, '153.345')]
[36m[2025-06-29 13:19:30,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 503808. Throughput: 0: 79.3. Samples: 507292. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:19:30,968][60274] Avg episode reward: [(0, '162.922')]
[36m[2025-06-29 13:19:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 503808. Throughput: 0: 80.4. Samples: 507536. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:19:35,981][60274] Avg episode reward: [(0, '166.300')]
[36m[2025-06-29 13:19:40,979][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 507904. Throughput: 0: 79.5. Samples: 507956. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:19:40,979][60274] Avg episode reward: [(0, '169.742')]
[36m[2025-06-29 13:19:45,973][60274] Fps is (10 sec: 409.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 507904. Throughput: 0: 79.6. Samples: 508452. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:19:45,973][60274] Avg episode reward: [(0, '167.124')]
[36m[2025-06-29 13:19:50,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 507904. Throughput: 0: 80.3. Samples: 508708. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:19:50,955][60274] Avg episode reward: [(0, '175.498')]
[36m[2025-06-29 13:19:55,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 507904. Throughput: 0: 80.6. Samples: 509196. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:19:55,983][60274] Avg episode reward: [(0, '176.992')]
[36m[2025-06-29 13:20:00,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 507904. Throughput: 0: 80.7. Samples: 509696. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:00,964][60274] Avg episode reward: [(0, '167.915')]
[36m[2025-06-29 13:20:05,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 507904. Throughput: 0: 80.8. Samples: 509928. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:05,963][60274] Avg episode reward: [(0, '176.232')]
[36m[2025-06-29 13:20:10,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 507904. Throughput: 0: 80.6. Samples: 510408. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:10,973][60274] Avg episode reward: [(0, '168.127')]
[36m[2025-06-29 13:20:15,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 507904. Throughput: 0: 80.1. Samples: 510896. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:15,966][60274] Avg episode reward: [(0, '158.252')]
[36m[2025-06-29 13:20:20,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 507904. Throughput: 0: 80.0. Samples: 511136. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:20,988][60274] Avg episode reward: [(0, '160.903')]
[36m[2025-06-29 13:20:25,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 507904. Throughput: 0: 81.7. Samples: 511632. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:25,961][60274] Avg episode reward: [(0, '164.325')]
[36m[2025-06-29 13:20:30,969][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 512000. Throughput: 0: 80.4. Samples: 512068. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:30,970][60274] Avg episode reward: [(0, '175.789')]
[36m[2025-06-29 13:20:35,951][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 512000. Throughput: 0: 80.4. Samples: 512328. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:35,952][60274] Avg episode reward: [(0, '166.687')]
[36m[2025-06-29 13:20:40,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 512000. Throughput: 0: 79.9. Samples: 512792. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:40,994][60274] Avg episode reward: [(0, '162.647')]
[36m[2025-06-29 13:20:45,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 512000. Throughput: 0: 79.9. Samples: 513292. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:45,992][60274] Avg episode reward: [(0, '162.841')]
[36m[2025-06-29 13:20:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 512000. Throughput: 0: 80.2. Samples: 513540. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:50,976][60274] Avg episode reward: [(0, '160.518')]
[36m[2025-06-29 13:20:55,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 512000. Throughput: 0: 80.1. Samples: 514012. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:20:55,980][60274] Avg episode reward: [(0, '164.307')]
[36m[2025-06-29 13:21:00,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 512000. Throughput: 0: 79.4. Samples: 514468. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:21:00,965][60274] Avg episode reward: [(0, '165.275')]
[37m[1m[2025-06-29 13:21:01,014][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002000_512000.pth...
[36m[2025-06-29 13:21:01,068][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001920_491520.pth
[36m[2025-06-29 13:21:05,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 512000. Throughput: 0: 79.3. Samples: 514704. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:21:05,977][60274] Avg episode reward: [(0, '166.896')]
[36m[2025-06-29 13:21:10,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 512000. Throughput: 0: 79.3. Samples: 515200. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:21:10,970][60274] Avg episode reward: [(0, '163.619')]
[36m[2025-06-29 13:21:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 512000. Throughput: 0: 79.9. Samples: 515664. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:21:15,952][60274] Avg episode reward: [(0, '146.745')]
[36m[2025-06-29 13:21:21,536][60274] Fps is (10 sec: 387.6, 60 sec: 135.3, 300 sec: 83.1). Total num frames: 516096. Throughput: 0: 78.4. Samples: 515904. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:21:21,537][60274] Avg episode reward: [(0, '145.303')]
[36m[2025-06-29 13:21:25,978][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 516096. Throughput: 0: 78.3. Samples: 516312. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:21:25,978][60274] Avg episode reward: [(0, '147.408')]
[36m[2025-06-29 13:21:30,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 516096. Throughput: 0: 78.5. Samples: 516824. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:21:30,963][60274] Avg episode reward: [(0, '153.269')]
[36m[2025-06-29 13:21:35,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 516096. Throughput: 0: 78.4. Samples: 517068. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:21:35,955][60274] Avg episode reward: [(0, '143.721')]
[36m[2025-06-29 13:21:40,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 516096. Throughput: 0: 78.4. Samples: 517540. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:21:40,963][60274] Avg episode reward: [(0, '147.620')]
[36m[2025-06-29 13:21:45,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 516096. Throughput: 0: 78.9. Samples: 518020. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:21:45,986][60274] Avg episode reward: [(0, '153.964')]
[36m[2025-06-29 13:21:50,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 516096. Throughput: 0: 78.8. Samples: 518248. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:21:50,979][60274] Avg episode reward: [(0, '155.533')]
[36m[2025-06-29 13:21:55,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 516096. Throughput: 0: 78.9. Samples: 518748. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:21:55,966][60274] Avg episode reward: [(0, '153.193')]
[36m[2025-06-29 13:22:00,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 516096. Throughput: 0: 79.1. Samples: 519224. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:22:00,970][60274] Avg episode reward: [(0, '151.820')]
[36m[2025-06-29 13:22:05,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 516096. Throughput: 0: 79.8. Samples: 519452. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:22:05,994][60274] Avg episode reward: [(0, '160.949')]
[36m[2025-06-29 13:22:10,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 516096. Throughput: 0: 80.8. Samples: 519948. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:22:10,978][60274] Avg episode reward: [(0, '161.395')]
[36m[2025-06-29 13:22:15,977][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 520192. Throughput: 0: 79.0. Samples: 520380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:22:15,978][60274] Avg episode reward: [(0, '158.698')]
[36m[2025-06-29 13:22:20,974][60274] Fps is (10 sec: 409.8, 60 sec: 68.9, 300 sec: 83.3). Total num frames: 520192. Throughput: 0: 79.1. Samples: 520628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:22:20,974][60274] Avg episode reward: [(0, '157.595')]
[36m[2025-06-29 13:22:25,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 520192. Throughput: 0: 80.0. Samples: 521140. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:22:25,976][60274] Avg episode reward: [(0, '157.589')]
[36m[2025-06-29 13:22:30,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 520192. Throughput: 0: 79.7. Samples: 521604. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:22:30,965][60274] Avg episode reward: [(0, '161.932')]
[36m[2025-06-29 13:22:36,014][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 520192. Throughput: 0: 80.1. Samples: 521856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:22:36,014][60274] Avg episode reward: [(0, '165.710')]
[36m[2025-06-29 13:22:40,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 520192. Throughput: 0: 79.5. Samples: 522324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:22:40,963][60274] Avg episode reward: [(0, '161.747')]
[36m[2025-06-29 13:22:45,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 520192. Throughput: 0: 79.3. Samples: 522792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:22:45,961][60274] Avg episode reward: [(0, '166.822')]
[36m[2025-06-29 13:22:50,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 520192. Throughput: 0: 79.4. Samples: 523024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:22:50,960][60274] Avg episode reward: [(0, '169.041')]
[31m[6597376 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[6597376 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[6597376 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:22:55,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 520192. Throughput: 0: 79.5. Samples: 523524. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:22:55,957][60274] Avg episode reward: [(0, '167.780')]
[36m[2025-06-29 13:23:00,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 520192. Throughput: 0: 80.2. Samples: 523988. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:23:00,948][60274] Avg episode reward: [(0, '174.783')]
[37m[1m[2025-06-29 13:23:01,016][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002032_520192.pth...
[36m[2025-06-29 13:23:01,081][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000001968_503808.pth
[36m[2025-06-29 13:23:05,988][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 524288. Throughput: 0: 79.5. Samples: 524208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:05,988][60274] Avg episode reward: [(0, '180.324')]
[36m[2025-06-29 13:23:10,991][60274] Fps is (10 sec: 407.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 524288. Throughput: 0: 77.3. Samples: 524620. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:10,991][60274] Avg episode reward: [(0, '179.335')]
[36m[2025-06-29 13:23:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 524288. Throughput: 0: 77.9. Samples: 525108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:15,953][60274] Avg episode reward: [(0, '163.471')]
[36m[2025-06-29 13:23:20,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 524288. Throughput: 0: 77.7. Samples: 525348. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:20,964][60274] Avg episode reward: [(0, '171.396')]
[36m[2025-06-29 13:23:25,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 524288. Throughput: 0: 77.9. Samples: 525828. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:25,962][60274] Avg episode reward: [(0, '177.662')]
[36m[2025-06-29 13:23:30,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 524288. Throughput: 0: 78.5. Samples: 526324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:30,948][60274] Avg episode reward: [(0, '177.684')]
[36m[2025-06-29 13:23:35,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 524288. Throughput: 0: 78.9. Samples: 526572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:35,948][60274] Avg episode reward: [(0, '176.387')]
[36m[2025-06-29 13:23:40,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 524288. Throughput: 0: 78.1. Samples: 527040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:40,975][60274] Avg episode reward: [(0, '170.527')]
[36m[2025-06-29 13:23:45,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 524288. Throughput: 0: 78.4. Samples: 527516. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:45,971][60274] Avg episode reward: [(0, '178.693')]
[36m[2025-06-29 13:23:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 524288. Throughput: 0: 79.0. Samples: 527760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:50,961][60274] Avg episode reward: [(0, '185.136')]
[36m[2025-06-29 13:23:55,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 524288. Throughput: 0: 80.6. Samples: 528244. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:23:55,951][60274] Avg episode reward: [(0, '184.985')]
[36m[2025-06-29 13:24:00,979][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 528384. Throughput: 0: 79.2. Samples: 528672. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 13:24:00,980][60274] Avg episode reward: [(0, '184.073')]
[36m[2025-06-29 13:24:05,985][60274] Fps is (10 sec: 408.2, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 528384. Throughput: 0: 79.1. Samples: 528908. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 13:24:05,985][60274] Avg episode reward: [(0, '185.129')]
[36m[2025-06-29 13:24:10,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 528384. Throughput: 0: 79.5. Samples: 529408. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 13:24:10,993][60274] Avg episode reward: [(0, '191.601')]
[36m[2025-06-29 13:24:15,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 528384. Throughput: 0: 78.8. Samples: 529872. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 13:24:15,949][60274] Avg episode reward: [(0, '197.688')]
[36m[2025-06-29 13:24:20,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 528384. Throughput: 0: 78.7. Samples: 530116. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 13:24:20,984][60274] Avg episode reward: [(0, '197.941')]
[36m[2025-06-29 13:24:25,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 528384. Throughput: 0: 79.2. Samples: 530604. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 13:24:25,959][60274] Avg episode reward: [(0, '200.281')]
[36m[2025-06-29 13:24:30,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 528384. Throughput: 0: 80.0. Samples: 531112. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 13:24:30,948][60274] Avg episode reward: [(0, '185.057')]
[36m[2025-06-29 13:24:35,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 528384. Throughput: 0: 80.0. Samples: 531364. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 13:24:35,990][60274] Avg episode reward: [(0, '188.665')]
[36m[2025-06-29 13:24:40,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 528384. Throughput: 0: 79.9. Samples: 531840. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 13:24:40,968][60274] Avg episode reward: [(0, '184.356')]
[36m[2025-06-29 13:24:45,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 528384. Throughput: 0: 81.2. Samples: 532324. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 13:24:45,952][60274] Avg episode reward: [(0, '178.160')]
[36m[2025-06-29 13:24:50,952][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 532480. Throughput: 0: 80.1. Samples: 532508. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:24:50,952][60274] Avg episode reward: [(0, '176.148')]
[36m[2025-06-29 13:24:55,972][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 532480. Throughput: 0: 79.6. Samples: 532988. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:24:55,972][60274] Avg episode reward: [(0, '164.217')]
[36m[2025-06-29 13:25:00,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 532480. Throughput: 0: 80.4. Samples: 533492. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:25:00,993][60274] Avg episode reward: [(0, '171.998')]
[37m[1m[2025-06-29 13:25:01,064][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002080_532480.pth...
[36m[2025-06-29 13:25:01,124][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002000_512000.pth
[36m[2025-06-29 13:25:05,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 532480. Throughput: 0: 80.3. Samples: 533728. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:25:05,965][60274] Avg episode reward: [(0, '175.042')]
[36m[2025-06-29 13:25:10,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 532480. Throughput: 0: 80.0. Samples: 534204. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:25:10,951][60274] Avg episode reward: [(0, '183.618')]
[36m[2025-06-29 13:25:15,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 532480. Throughput: 0: 79.7. Samples: 534700. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:25:15,950][60274] Avg episode reward: [(0, '174.907')]
[36m[2025-06-29 13:25:20,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 532480. Throughput: 0: 79.1. Samples: 534920. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:25:20,962][60274] Avg episode reward: [(0, '173.385')]
[36m[2025-06-29 13:25:25,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 532480. Throughput: 0: 78.8. Samples: 535388. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:25:25,967][60274] Avg episode reward: [(0, '166.976')]
[36m[2025-06-29 13:25:30,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 532480. Throughput: 0: 78.8. Samples: 535872. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:25:30,961][60274] Avg episode reward: [(0, '167.160')]
[36m[2025-06-29 13:25:35,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 532480. Throughput: 0: 80.3. Samples: 536124. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:25:35,988][60274] Avg episode reward: [(0, '176.230')]
[36m[2025-06-29 13:25:40,983][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 536576. Throughput: 0: 79.9. Samples: 536584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:25:40,983][60274] Avg episode reward: [(0, '177.337')]
[36m[2025-06-29 13:25:45,975][60274] Fps is (10 sec: 410.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 536576. Throughput: 0: 79.1. Samples: 537052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:25:45,976][60274] Avg episode reward: [(0, '171.497')]
[36m[2025-06-29 13:25:50,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 536576. Throughput: 0: 79.2. Samples: 537292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:25:50,988][60274] Avg episode reward: [(0, '174.295')]
[36m[2025-06-29 13:25:55,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 536576. Throughput: 0: 79.3. Samples: 537772. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:25:55,958][60274] Avg episode reward: [(0, '177.194')]
[36m[2025-06-29 13:26:00,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 536576. Throughput: 0: 78.6. Samples: 538240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:00,990][60274] Avg episode reward: [(0, '164.695')]
[36m[2025-06-29 13:26:05,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 536576. Throughput: 0: 79.1. Samples: 538480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:05,949][60274] Avg episode reward: [(0, '158.594')]
[36m[2025-06-29 13:26:10,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 536576. Throughput: 0: 79.0. Samples: 538944. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:10,953][60274] Avg episode reward: [(0, '157.266')]
[36m[2025-06-29 13:26:15,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.6). Total num frames: 536576. Throughput: 0: 78.6. Samples: 539408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:15,974][60274] Avg episode reward: [(0, '161.015')]
[36m[2025-06-29 13:26:20,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 536576. Throughput: 0: 78.4. Samples: 539652. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:20,976][60274] Avg episode reward: [(0, '172.261')]
[36m[2025-06-29 13:26:25,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 536576. Throughput: 0: 78.9. Samples: 540132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:25,948][60274] Avg episode reward: [(0, '168.221')]
[36m[2025-06-29 13:26:31,699][60274] Fps is (10 sec: 382.0, 60 sec: 134.9, 300 sec: 83.1). Total num frames: 540672. Throughput: 0: 78.0. Samples: 540620. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:31,699][60274] Avg episode reward: [(0, '171.370')]
[36m[2025-06-29 13:26:36,004][60274] Fps is (10 sec: 407.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 540672. Throughput: 0: 78.0. Samples: 540804. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:36,005][60274] Avg episode reward: [(0, '171.446')]
[36m[2025-06-29 13:26:40,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 540672. Throughput: 0: 78.3. Samples: 541296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:40,993][60274] Avg episode reward: [(0, '181.950')]
[36m[2025-06-29 13:26:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 540672. Throughput: 0: 78.6. Samples: 541776. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:45,969][60274] Avg episode reward: [(0, '186.912')]
[36m[2025-06-29 13:26:50,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 540672. Throughput: 0: 78.4. Samples: 542012. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:50,973][60274] Avg episode reward: [(0, '190.987')]
[36m[2025-06-29 13:26:55,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 540672. Throughput: 0: 78.7. Samples: 542488. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:26:55,975][60274] Avg episode reward: [(0, '190.380')]
[36m[2025-06-29 13:27:00,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 540672. Throughput: 0: 79.5. Samples: 542984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:00,976][60274] Avg episode reward: [(0, '190.291')]
[37m[1m[2025-06-29 13:27:01,024][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002112_540672.pth...
[36m[2025-06-29 13:27:01,079][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002032_520192.pth
[36m[2025-06-29 13:27:05,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 540672. Throughput: 0: 79.2. Samples: 543216. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:05,997][60274] Avg episode reward: [(0, '191.433')]
[36m[2025-06-29 13:27:10,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 540672. Throughput: 0: 79.4. Samples: 543708. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:10,974][60274] Avg episode reward: [(0, '196.079')]
[36m[2025-06-29 13:27:15,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 540672. Throughput: 0: 80.3. Samples: 544176. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:15,986][60274] Avg episode reward: [(0, '209.486')]
[36m[2025-06-29 13:27:20,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 540672. Throughput: 0: 80.1. Samples: 544408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:20,985][60274] Avg episode reward: [(0, '210.298')]
[36m[2025-06-29 13:27:25,984][60274] Fps is (10 sec: 409.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 544768. Throughput: 0: 78.6. Samples: 544832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:25,984][60274] Avg episode reward: [(0, '216.218')]
[36m[2025-06-29 13:27:30,961][60274] Fps is (10 sec: 410.6, 60 sec: 69.1, 300 sec: 83.3). Total num frames: 544768. Throughput: 0: 78.6. Samples: 545312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:30,961][60274] Avg episode reward: [(0, '216.381')]
[31m[6876667 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[6876667 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[6876667 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:27:35,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 544768. Throughput: 0: 78.9. Samples: 545560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:35,951][60274] Avg episode reward: [(0, '202.263')]
[36m[2025-06-29 13:27:40,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 544768. Throughput: 0: 78.5. Samples: 546020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:40,979][60274] Avg episode reward: [(0, '206.186')]
[36m[2025-06-29 13:27:45,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 544768. Throughput: 0: 78.1. Samples: 546500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:45,974][60274] Avg episode reward: [(0, '183.905')]
[36m[2025-06-29 13:27:50,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 544768. Throughput: 0: 78.3. Samples: 546736. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:50,960][60274] Avg episode reward: [(0, '195.786')]
[36m[2025-06-29 13:27:55,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 544768. Throughput: 0: 77.6. Samples: 547200. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:27:55,963][60274] Avg episode reward: [(0, '189.431')]
[36m[2025-06-29 13:28:00,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 544768. Throughput: 0: 78.0. Samples: 547684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:28:00,951][60274] Avg episode reward: [(0, '197.779')]
[36m[2025-06-29 13:28:05,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 544768. Throughput: 0: 78.5. Samples: 547940. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:28:05,974][60274] Avg episode reward: [(0, '192.859')]
[36m[2025-06-29 13:28:10,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 544768. Throughput: 0: 80.5. Samples: 548452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:28:10,972][60274] Avg episode reward: [(0, '191.254')]
[36m[2025-06-29 13:28:15,958][60274] Fps is (10 sec: 410.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 548864. Throughput: 0: 79.5. Samples: 548888. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:28:15,958][60274] Avg episode reward: [(0, '187.148')]
[36m[2025-06-29 13:28:20,964][60274] Fps is (10 sec: 409.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 548864. Throughput: 0: 79.6. Samples: 549144. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:28:20,964][60274] Avg episode reward: [(0, '194.517')]
[36m[2025-06-29 13:28:25,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 548864. Throughput: 0: 80.3. Samples: 549632. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:28:25,972][60274] Avg episode reward: [(0, '182.429')]
[36m[2025-06-29 13:28:30,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 548864. Throughput: 0: 80.5. Samples: 550120. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:28:30,947][60274] Avg episode reward: [(0, '184.646')]
[36m[2025-06-29 13:28:35,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 548864. Throughput: 0: 80.5. Samples: 550360. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:28:35,956][60274] Avg episode reward: [(0, '181.743')]
[36m[2025-06-29 13:28:40,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 548864. Throughput: 0: 81.0. Samples: 550844. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:28:40,964][60274] Avg episode reward: [(0, '181.872')]
[36m[2025-06-29 13:28:45,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 548864. Throughput: 0: 80.5. Samples: 551308. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:28:45,960][60274] Avg episode reward: [(0, '182.748')]
[36m[2025-06-29 13:28:50,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 548864. Throughput: 0: 80.3. Samples: 551552. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:28:50,953][60274] Avg episode reward: [(0, '181.688')]
[36m[2025-06-29 13:28:55,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 548864. Throughput: 0: 79.4. Samples: 552024. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:28:55,959][60274] Avg episode reward: [(0, '171.578')]
[36m[2025-06-29 13:29:00,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 548864. Throughput: 0: 80.6. Samples: 552516. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:29:00,958][60274] Avg episode reward: [(0, '174.102')]
[37m[1m[2025-06-29 13:29:01,008][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002144_548864.pth...
[36m[2025-06-29 13:29:01,063][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002080_532480.pth
[36m[2025-06-29 13:29:06,496][60274] Fps is (10 sec: 388.7, 60 sec: 135.4, 300 sec: 83.2). Total num frames: 552960. Throughput: 0: 79.4. Samples: 552760. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:06,496][60274] Avg episode reward: [(0, '177.132')]
[36m[2025-06-29 13:29:10,978][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 552960. Throughput: 0: 79.2. Samples: 553196. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:10,979][60274] Avg episode reward: [(0, '171.435')]
[36m[2025-06-29 13:29:15,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 552960. Throughput: 0: 79.1. Samples: 553684. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:15,989][60274] Avg episode reward: [(0, '172.876')]
[36m[2025-06-29 13:29:20,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 552960. Throughput: 0: 79.4. Samples: 553932. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:20,964][60274] Avg episode reward: [(0, '180.722')]
[36m[2025-06-29 13:29:25,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 552960. Throughput: 0: 79.7. Samples: 554432. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:25,976][60274] Avg episode reward: [(0, '180.850')]
[31m[6992705 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[6992705 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[6992706 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:29:30,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 552960. Throughput: 0: 79.6. Samples: 554892. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:30,981][60274] Avg episode reward: [(0, '189.641')]
[36m[2025-06-29 13:29:35,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 552960. Throughput: 0: 79.7. Samples: 555140. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:35,970][60274] Avg episode reward: [(0, '206.418')]
[36m[2025-06-29 13:29:40,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 552960. Throughput: 0: 80.0. Samples: 555624. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:40,963][60274] Avg episode reward: [(0, '195.051')]
[36m[2025-06-29 13:29:45,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 552960. Throughput: 0: 79.7. Samples: 556104. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:45,974][60274] Avg episode reward: [(0, '212.619')]
[36m[2025-06-29 13:29:50,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 552960. Throughput: 0: 80.6. Samples: 556344. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:50,987][60274] Avg episode reward: [(0, '203.262')]
[36m[2025-06-29 13:29:55,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 552960. Throughput: 0: 80.7. Samples: 556824. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:29:55,957][60274] Avg episode reward: [(0, '198.141')]
[36m[2025-06-29 13:30:00,952][60274] Fps is (10 sec: 411.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 557056. Throughput: 0: 79.3. Samples: 557248. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:30:00,952][60274] Avg episode reward: [(0, '203.724')]
[36m[2025-06-29 13:30:05,957][60274] Fps is (10 sec: 409.6, 60 sec: 68.9, 300 sec: 83.3). Total num frames: 557056. Throughput: 0: 79.4. Samples: 557504. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:30:05,957][60274] Avg episode reward: [(0, '194.323')]
[36m[2025-06-29 13:30:10,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 557056. Throughput: 0: 78.8. Samples: 557980. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:30:10,985][60274] Avg episode reward: [(0, '190.196')]
[36m[2025-06-29 13:30:15,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 557056. Throughput: 0: 79.5. Samples: 558468. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:30:15,977][60274] Avg episode reward: [(0, '187.003')]
[36m[2025-06-29 13:30:21,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 557056. Throughput: 0: 79.4. Samples: 558716. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:30:21,003][60274] Avg episode reward: [(0, '182.283')]
[36m[2025-06-29 13:30:25,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 557056. Throughput: 0: 79.4. Samples: 559196. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:30:25,962][60274] Avg episode reward: [(0, '186.509')]
[36m[2025-06-29 13:30:30,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 557056. Throughput: 0: 79.6. Samples: 559684. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:30:30,974][60274] Avg episode reward: [(0, '195.180')]
[36m[2025-06-29 13:30:35,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 557056. Throughput: 0: 79.6. Samples: 559924. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:30:35,965][60274] Avg episode reward: [(0, '189.861')]
[36m[2025-06-29 13:30:40,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 557056. Throughput: 0: 79.3. Samples: 560396. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:30:40,978][60274] Avg episode reward: [(0, '190.385')]
[36m[2025-06-29 13:30:45,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 557056. Throughput: 0: 80.9. Samples: 560892. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 13:30:45,968][60274] Avg episode reward: [(0, '191.203')]
[36m[2025-06-29 13:30:50,960][60274] Fps is (10 sec: 410.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 561152. Throughput: 0: 81.1. Samples: 561152. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 13:30:50,960][60274] Avg episode reward: [(0, '182.162')]
[36m[2025-06-29 13:30:56,001][60274] Fps is (10 sec: 408.3, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 561152. Throughput: 0: 80.3. Samples: 561596. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 13:30:56,001][60274] Avg episode reward: [(0, '178.923')]
[36m[2025-06-29 13:31:00,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 561152. Throughput: 0: 80.4. Samples: 562084. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 13:31:00,972][60274] Avg episode reward: [(0, '169.304')]
[37m[1m[2025-06-29 13:31:01,020][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002192_561152.pth...
[36m[2025-06-29 13:31:01,075][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002112_540672.pth
[36m[2025-06-29 13:31:05,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 561152. Throughput: 0: 80.0. Samples: 562316. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 13:31:05,981][60274] Avg episode reward: [(0, '170.920')]
[36m[2025-06-29 13:31:10,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 561152. Throughput: 0: 79.7. Samples: 562780. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 13:31:10,959][60274] Avg episode reward: [(0, '168.942')]
[36m[2025-06-29 13:31:15,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 561152. Throughput: 0: 79.6. Samples: 563268. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 13:31:15,973][60274] Avg episode reward: [(0, '161.018')]
[36m[2025-06-29 13:31:20,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 561152. Throughput: 0: 79.7. Samples: 563508. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 13:31:20,952][60274] Avg episode reward: [(0, '147.328')]
[36m[2025-06-29 13:31:25,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 561152. Throughput: 0: 80.7. Samples: 564024. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 13:31:25,953][60274] Avg episode reward: [(0, '148.699')]
[36m[2025-06-29 13:31:30,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 561152. Throughput: 0: 81.0. Samples: 564536. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 13:31:30,982][60274] Avg episode reward: [(0, '148.195')]
[36m[2025-06-29 13:31:35,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 561152. Throughput: 0: 80.8. Samples: 564792. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 13:31:35,983][60274] Avg episode reward: [(0, '150.126')]
[36m[2025-06-29 13:31:40,957][60274] Fps is (10 sec: 410.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 565248. Throughput: 0: 81.4. Samples: 565256. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:31:40,958][60274] Avg episode reward: [(0, '149.583')]
[36m[2025-06-29 13:31:45,958][60274] Fps is (10 sec: 410.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 565248. Throughput: 0: 80.3. Samples: 565696. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:31:45,958][60274] Avg episode reward: [(0, '151.067')]
[36m[2025-06-29 13:31:50,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 565248. Throughput: 0: 80.6. Samples: 565940. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:31:50,952][60274] Avg episode reward: [(0, '161.830')]
[36m[2025-06-29 13:31:55,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 565248. Throughput: 0: 81.0. Samples: 566428. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:31:55,982][60274] Avg episode reward: [(0, '162.168')]
[36m[2025-06-29 13:32:00,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 565248. Throughput: 0: 81.0. Samples: 566912. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:32:00,971][60274] Avg episode reward: [(0, '166.808')]
[36m[2025-06-29 13:32:05,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 565248. Throughput: 0: 80.8. Samples: 567148. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:32:05,991][60274] Avg episode reward: [(0, '176.884')]
[36m[2025-06-29 13:32:11,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 565248. Throughput: 0: 79.7. Samples: 567616. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:32:11,005][60274] Avg episode reward: [(0, '180.712')]
[36m[2025-06-29 13:32:15,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 565248. Throughput: 0: 79.4. Samples: 568108. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:32:15,973][60274] Avg episode reward: [(0, '175.349')]
[36m[2025-06-29 13:32:20,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 565248. Throughput: 0: 79.0. Samples: 568344. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:32:20,962][60274] Avg episode reward: [(0, '172.304')]
[36m[2025-06-29 13:32:25,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 565248. Throughput: 0: 79.3. Samples: 568824. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:32:25,957][60274] Avg episode reward: [(0, '176.278')]
[36m[2025-06-29 13:32:31,640][60274] Fps is (10 sec: 383.6, 60 sec: 135.1, 300 sec: 83.1). Total num frames: 569344. Throughput: 0: 78.7. Samples: 569292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:32:31,641][60274] Avg episode reward: [(0, '168.903')]
[36m[2025-06-29 13:32:35,960][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 569344. Throughput: 0: 78.6. Samples: 569476. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:32:35,960][60274] Avg episode reward: [(0, '164.443')]
[36m[2025-06-29 13:32:40,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 569344. Throughput: 0: 78.0. Samples: 569936. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:32:40,976][60274] Avg episode reward: [(0, '178.622')]
[36m[2025-06-29 13:32:45,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 569344. Throughput: 0: 78.2. Samples: 570428. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:32:45,949][60274] Avg episode reward: [(0, '186.132')]
[36m[2025-06-29 13:32:50,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 569344. Throughput: 0: 78.5. Samples: 570680. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:32:50,967][60274] Avg episode reward: [(0, '176.988')]
[36m[2025-06-29 13:32:55,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 569344. Throughput: 0: 78.8. Samples: 571160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:32:55,958][60274] Avg episode reward: [(0, '167.261')]
[36m[2025-06-29 13:33:00,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 569344. Throughput: 0: 78.1. Samples: 571624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:33:00,967][60274] Avg episode reward: [(0, '163.697')]
[37m[1m[2025-06-29 13:33:01,018][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002224_569344.pth...
[36m[2025-06-29 13:33:01,073][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002144_548864.pth
[36m[2025-06-29 13:33:05,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 569344. Throughput: 0: 78.2. Samples: 571864. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:33:05,975][60274] Avg episode reward: [(0, '173.690')]
[36m[2025-06-29 13:33:10,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 569344. Throughput: 0: 78.9. Samples: 572376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:33:10,950][60274] Avg episode reward: [(0, '188.039')]
[36m[2025-06-29 13:33:15,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 569344. Throughput: 0: 80.4. Samples: 572856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:33:15,986][60274] Avg episode reward: [(0, '175.552')]
[36m[2025-06-29 13:33:20,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 569344. Throughput: 0: 80.7. Samples: 573108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:33:20,948][60274] Avg episode reward: [(0, '175.379')]
[36m[2025-06-29 13:33:26,002][60274] Fps is (10 sec: 409.0, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 573440. Throughput: 0: 79.9. Samples: 573532. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:33:26,002][60274] Avg episode reward: [(0, '177.654')]
[36m[2025-06-29 13:33:30,951][60274] Fps is (10 sec: 409.5, 60 sec: 69.1, 300 sec: 83.3). Total num frames: 573440. Throughput: 0: 79.5. Samples: 574004. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:33:30,951][60274] Avg episode reward: [(0, '165.919')]
[36m[2025-06-29 13:33:35,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 573440. Throughput: 0: 79.2. Samples: 574244. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:33:35,985][60274] Avg episode reward: [(0, '163.563')]
[36m[2025-06-29 13:33:40,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 573440. Throughput: 0: 78.8. Samples: 574704. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:33:40,960][60274] Avg episode reward: [(0, '169.747')]
[36m[2025-06-29 13:33:45,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 573440. Throughput: 0: 78.7. Samples: 575168. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:33:45,982][60274] Avg episode reward: [(0, '176.868')]
[36m[2025-06-29 13:33:50,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 573440. Throughput: 0: 78.8. Samples: 575412. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:33:50,974][60274] Avg episode reward: [(0, '161.178')]
[36m[2025-06-29 13:33:55,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 573440. Throughput: 0: 77.9. Samples: 575884. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:33:55,990][60274] Avg episode reward: [(0, '160.996')]
[36m[2025-06-29 13:34:00,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 573440. Throughput: 0: 78.5. Samples: 576388. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:34:00,959][60274] Avg episode reward: [(0, '166.078')]
[36m[2025-06-29 13:34:05,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 573440. Throughput: 0: 78.0. Samples: 576620. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:34:05,968][60274] Avg episode reward: [(0, '170.838')]
[36m[2025-06-29 13:34:10,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 573440. Throughput: 0: 79.9. Samples: 577124. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 13:34:10,961][60274] Avg episode reward: [(0, '172.342')]
[36m[2025-06-29 13:34:15,971][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 577536. Throughput: 0: 78.6. Samples: 577544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:34:15,971][60274] Avg episode reward: [(0, '181.448')]
[36m[2025-06-29 13:34:21,000][60274] Fps is (10 sec: 408.0, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 577536. Throughput: 0: 78.1. Samples: 577760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:34:21,000][60274] Avg episode reward: [(0, '191.116')]
[36m[2025-06-29 13:34:25,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 577536. Throughput: 0: 79.2. Samples: 578268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:34:25,963][60274] Avg episode reward: [(0, '180.913')]
[36m[2025-06-29 13:34:30,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 577536. Throughput: 0: 80.2. Samples: 578776. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:34:30,997][60274] Avg episode reward: [(0, '184.879')]
[36m[2025-06-29 13:34:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 577536. Throughput: 0: 80.1. Samples: 579016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:34:35,972][60274] Avg episode reward: [(0, '194.656')]
[36m[2025-06-29 13:34:41,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 577536. Throughput: 0: 80.7. Samples: 579516. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:34:41,004][60274] Avg episode reward: [(0, '191.415')]
[36m[2025-06-29 13:34:45,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 577536. Throughput: 0: 81.0. Samples: 580032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:34:45,956][60274] Avg episode reward: [(0, '193.765')]
[36m[2025-06-29 13:34:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 577536. Throughput: 0: 80.9. Samples: 580260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:34:50,977][60274] Avg episode reward: [(0, '191.345')]
[36m[2025-06-29 13:34:55,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 577536. Throughput: 0: 80.1. Samples: 580728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:34:55,952][60274] Avg episode reward: [(0, '189.504')]
[36m[2025-06-29 13:35:00,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 577536. Throughput: 0: 81.3. Samples: 581200. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:00,947][60274] Avg episode reward: [(0, '192.522')]
[37m[1m[2025-06-29 13:35:01,016][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002256_577536.pth...
[36m[2025-06-29 13:35:01,073][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002192_561152.pth
[36m[2025-06-29 13:35:06,485][60274] Fps is (10 sec: 388.9, 60 sec: 135.4, 300 sec: 83.2). Total num frames: 581632. Throughput: 0: 80.7. Samples: 581432. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:06,485][60274] Avg episode reward: [(0, '193.913')]
[36m[2025-06-29 13:35:10,985][60274] Fps is (10 sec: 408.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 581632. Throughput: 0: 79.8. Samples: 581860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:10,985][60274] Avg episode reward: [(0, '194.695')]
[36m[2025-06-29 13:35:15,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 581632. Throughput: 0: 79.0. Samples: 582332. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:15,989][60274] Avg episode reward: [(0, '202.388')]
[36m[2025-06-29 13:35:20,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 581632. Throughput: 0: 79.0. Samples: 582572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:20,967][60274] Avg episode reward: [(0, '202.243')]
[36m[2025-06-29 13:35:25,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 581632. Throughput: 0: 78.4. Samples: 583044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:25,983][60274] Avg episode reward: [(0, '200.663')]
[36m[2025-06-29 13:35:30,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 581632. Throughput: 0: 78.1. Samples: 583548. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:30,982][60274] Avg episode reward: [(0, '200.335')]
[36m[2025-06-29 13:35:35,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 581632. Throughput: 0: 78.3. Samples: 583784. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:35,956][60274] Avg episode reward: [(0, '187.837')]
[36m[2025-06-29 13:35:40,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 581632. Throughput: 0: 78.6. Samples: 584268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:40,979][60274] Avg episode reward: [(0, '204.318')]
[36m[2025-06-29 13:35:45,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 581632. Throughput: 0: 79.1. Samples: 584764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:45,986][60274] Avg episode reward: [(0, '202.555')]
[36m[2025-06-29 13:35:50,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 581632. Throughput: 0: 80.5. Samples: 585016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:50,989][60274] Avg episode reward: [(0, '200.504')]
[36m[2025-06-29 13:35:55,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 581632. Throughput: 0: 80.5. Samples: 585484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:35:55,985][60274] Avg episode reward: [(0, '200.754')]
[36m[2025-06-29 13:36:00,972][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 585728. Throughput: 0: 79.8. Samples: 585920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:36:00,972][60274] Avg episode reward: [(0, '197.285')]
[36m[2025-06-29 13:36:05,961][60274] Fps is (10 sec: 410.6, 60 sec: 68.9, 300 sec: 83.3). Total num frames: 585728. Throughput: 0: 79.7. Samples: 586160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:36:05,961][60274] Avg episode reward: [(0, '189.863')]
[36m[2025-06-29 13:36:10,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 585728. Throughput: 0: 80.0. Samples: 586644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:36:10,972][60274] Avg episode reward: [(0, '186.635')]
[36m[2025-06-29 13:36:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 585728. Throughput: 0: 79.6. Samples: 587128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:36:15,952][60274] Avg episode reward: [(0, '200.534')]
[36m[2025-06-29 13:36:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 585728. Throughput: 0: 79.4. Samples: 587360. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:36:20,985][60274] Avg episode reward: [(0, '197.080')]
[36m[2025-06-29 13:36:25,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 585728. Throughput: 0: 79.8. Samples: 587856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:36:25,963][60274] Avg episode reward: [(0, '197.696')]
[36m[2025-06-29 13:36:30,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 585728. Throughput: 0: 79.4. Samples: 588336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:36:30,976][60274] Avg episode reward: [(0, '201.259')]
[36m[2025-06-29 13:36:35,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 585728. Throughput: 0: 79.0. Samples: 588568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:36:35,958][60274] Avg episode reward: [(0, '213.151')]
[36m[2025-06-29 13:36:40,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 585728. Throughput: 0: 79.5. Samples: 589060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:36:40,965][60274] Avg episode reward: [(0, '215.579')]
[36m[2025-06-29 13:36:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 585728. Throughput: 0: 80.3. Samples: 589532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:36:45,969][60274] Avg episode reward: [(0, '212.575')]
[36m[2025-06-29 13:36:50,952][60274] Fps is (10 sec: 410.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 589824. Throughput: 0: 80.0. Samples: 589760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:36:50,952][60274] Avg episode reward: [(0, '202.591')]
[36m[2025-06-29 13:36:55,959][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 589824. Throughput: 0: 79.0. Samples: 590196. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:36:55,960][60274] Avg episode reward: [(0, '211.532')]
[36m[2025-06-29 13:37:00,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 589824. Throughput: 0: 78.8. Samples: 590672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:37:00,948][60274] Avg episode reward: [(0, '218.702')]
[37m[1m[2025-06-29 13:37:00,995][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002304_589824.pth...
[36m[2025-06-29 13:37:01,056][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002224_569344.pth
[36m[2025-06-29 13:37:05,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 589824. Throughput: 0: 78.6. Samples: 590896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:37:05,982][60274] Avg episode reward: [(0, '210.976')]
[36m[2025-06-29 13:37:10,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 589824. Throughput: 0: 78.0. Samples: 591368. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:37:10,960][60274] Avg episode reward: [(0, '205.895')]
[36m[2025-06-29 13:37:15,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 589824. Throughput: 0: 78.3. Samples: 591860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:37:15,986][60274] Avg episode reward: [(0, '206.979')]
[36m[2025-06-29 13:37:21,012][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 589824. Throughput: 0: 78.4. Samples: 592100. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:37:21,013][60274] Avg episode reward: [(0, '217.852')]
[36m[2025-06-29 13:37:25,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.6). Total num frames: 589824. Throughput: 0: 78.2. Samples: 592580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:37:25,983][60274] Avg episode reward: [(0, '214.196')]
[36m[2025-06-29 13:37:30,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 589824. Throughput: 0: 77.9. Samples: 593036. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:37:30,960][60274] Avg episode reward: [(0, '203.589')]
[36m[2025-06-29 13:37:35,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 589824. Throughput: 0: 78.4. Samples: 593288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:37:35,979][60274] Avg episode reward: [(0, '201.231')]
[36m[2025-06-29 13:37:40,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 589824. Throughput: 0: 79.3. Samples: 593764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:37:40,980][60274] Avg episode reward: [(0, '201.685')]
[36m[2025-06-29 13:37:45,983][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 593920. Throughput: 0: 78.2. Samples: 594192. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 13:37:45,983][60274] Avg episode reward: [(0, '203.743')]
[36m[2025-06-29 13:37:50,970][60274] Fps is (10 sec: 410.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 593920. Throughput: 0: 78.5. Samples: 594428. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 13:37:50,970][60274] Avg episode reward: [(0, '205.328')]
[36m[2025-06-29 13:37:55,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 593920. Throughput: 0: 78.2. Samples: 594888. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 13:37:55,981][60274] Avg episode reward: [(0, '199.384')]
[36m[2025-06-29 13:38:00,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 593920. Throughput: 0: 78.3. Samples: 595384. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 13:38:00,986][60274] Avg episode reward: [(0, '201.042')]
[36m[2025-06-29 13:38:05,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 593920. Throughput: 0: 78.8. Samples: 595644. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 13:38:05,985][60274] Avg episode reward: [(0, '207.955')]
[36m[2025-06-29 13:38:10,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 593920. Throughput: 0: 78.5. Samples: 596112. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 13:38:10,987][60274] Avg episode reward: [(0, '189.604')]
[36m[2025-06-29 13:38:15,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 593920. Throughput: 0: 78.9. Samples: 596588. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 13:38:15,987][60274] Avg episode reward: [(0, '179.066')]
[36m[2025-06-29 13:38:20,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 593920. Throughput: 0: 78.8. Samples: 596832. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 13:38:20,971][60274] Avg episode reward: [(0, '173.904')]
[36m[2025-06-29 13:38:25,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 593920. Throughput: 0: 78.9. Samples: 597312. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 13:38:25,967][60274] Avg episode reward: [(0, '178.824')]
[36m[2025-06-29 13:38:30,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 593920. Throughput: 0: 80.2. Samples: 597800. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 13:38:30,958][60274] Avg episode reward: [(0, '173.396')]
[36m[2025-06-29 13:38:35,947][60274] Fps is (10 sec: 410.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 598016. Throughput: 0: 80.0. Samples: 598024. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:38:35,947][60274] Avg episode reward: [(0, '183.168')]
[36m[2025-06-29 13:38:40,985][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 598016. Throughput: 0: 79.1. Samples: 598448. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:38:40,985][60274] Avg episode reward: [(0, '177.322')]
[36m[2025-06-29 13:38:45,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 598016. Throughput: 0: 79.1. Samples: 598944. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:38:45,991][60274] Avg episode reward: [(0, '174.548')]
[36m[2025-06-29 13:38:50,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 598016. Throughput: 0: 78.8. Samples: 599188. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:38:50,960][60274] Avg episode reward: [(0, '172.265')]
[36m[2025-06-29 13:38:55,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 598016. Throughput: 0: 79.3. Samples: 599676. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:38:55,948][60274] Avg episode reward: [(0, '182.113')]
[36m[2025-06-29 13:39:00,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 598016. Throughput: 0: 79.6. Samples: 600168. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:39:00,981][60274] Avg episode reward: [(0, '179.235')]
[37m[1m[2025-06-29 13:39:01,029][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002336_598016.pth...
[36m[2025-06-29 13:39:01,083][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002256_577536.pth
[36m[2025-06-29 13:39:05,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 598016. Throughput: 0: 79.4. Samples: 600404. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:39:05,974][60274] Avg episode reward: [(0, '175.009')]
[36m[2025-06-29 13:39:10,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 598016. Throughput: 0: 79.5. Samples: 600888. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:39:10,952][60274] Avg episode reward: [(0, '181.940')]
[36m[2025-06-29 13:39:15,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 598016. Throughput: 0: 79.5. Samples: 601380. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:39:15,964][60274] Avg episode reward: [(0, '180.046')]
[36m[2025-06-29 13:39:20,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 598016. Throughput: 0: 79.9. Samples: 601620. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:39:20,951][60274] Avg episode reward: [(0, '172.480')]
[36m[2025-06-29 13:39:25,980][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 602112. Throughput: 0: 81.6. Samples: 602120. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:39:25,981][60274] Avg episode reward: [(0, '167.288')]
[36m[2025-06-29 13:39:30,952][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 602112. Throughput: 0: 79.5. Samples: 602520. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:39:30,952][60274] Avg episode reward: [(0, '176.652')]
[36m[2025-06-29 13:39:35,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 602112. Throughput: 0: 79.5. Samples: 602768. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:39:35,968][60274] Avg episode reward: [(0, '178.291')]
[36m[2025-06-29 13:39:40,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 602112. Throughput: 0: 80.1. Samples: 603280. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:39:40,968][60274] Avg episode reward: [(0, '173.399')]
[36m[2025-06-29 13:39:45,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 602112. Throughput: 0: 80.0. Samples: 603764. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:39:45,959][60274] Avg episode reward: [(0, '167.995')]
[36m[2025-06-29 13:39:51,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 602112. Throughput: 0: 80.0. Samples: 604008. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:39:51,001][60274] Avg episode reward: [(0, '173.143')]
[36m[2025-06-29 13:39:55,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 602112. Throughput: 0: 80.2. Samples: 604496. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:39:55,962][60274] Avg episode reward: [(0, '168.821')]
[36m[2025-06-29 13:40:00,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 602112. Throughput: 0: 80.1. Samples: 604984. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:40:00,972][60274] Avg episode reward: [(0, '178.748')]
[36m[2025-06-29 13:40:05,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 602112. Throughput: 0: 80.4. Samples: 605240. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:40:05,948][60274] Avg episode reward: [(0, '178.221')]
[36m[2025-06-29 13:40:10,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 602112. Throughput: 0: 80.3. Samples: 605732. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:40:10,979][60274] Avg episode reward: [(0, '169.155')]
[36m[2025-06-29 13:40:16,079][60274] Fps is (10 sec: 404.3, 60 sec: 136.3, 300 sec: 83.3). Total num frames: 606208. Throughput: 0: 81.7. Samples: 606208. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:40:16,079][60274] Avg episode reward: [(0, '176.901')]
[36m[2025-06-29 13:40:20,967][60274] Fps is (10 sec: 410.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 606208. Throughput: 0: 80.8. Samples: 606404. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:40:20,967][60274] Avg episode reward: [(0, '173.205')]
[36m[2025-06-29 13:40:25,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 606208. Throughput: 0: 80.3. Samples: 606896. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:40:25,985][60274] Avg episode reward: [(0, '175.053')]
[36m[2025-06-29 13:40:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 606208. Throughput: 0: 80.8. Samples: 607404. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:40:30,989][60274] Avg episode reward: [(0, '172.283')]
[36m[2025-06-29 13:40:35,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 606208. Throughput: 0: 81.3. Samples: 607664. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:40:35,966][60274] Avg episode reward: [(0, '182.364')]
[36m[2025-06-29 13:40:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 606208. Throughput: 0: 80.8. Samples: 608132. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:40:40,981][60274] Avg episode reward: [(0, '181.345')]
[36m[2025-06-29 13:40:45,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 606208. Throughput: 0: 81.5. Samples: 608648. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:40:45,947][60274] Avg episode reward: [(0, '181.532')]
[36m[2025-06-29 13:40:51,002][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 606208. Throughput: 0: 80.9. Samples: 608884. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:40:51,002][60274] Avg episode reward: [(0, '184.471')]
[36m[2025-06-29 13:40:55,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 606208. Throughput: 0: 80.7. Samples: 609364. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:40:55,984][60274] Avg episode reward: [(0, '176.930')]
[36m[2025-06-29 13:41:00,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 606208. Throughput: 0: 81.0. Samples: 609844. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 13:41:00,972][60274] Avg episode reward: [(0, '170.966')]
[37m[1m[2025-06-29 13:41:01,021][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002368_606208.pth...
[36m[2025-06-29 13:41:01,076][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002304_589824.pth
[36m[2025-06-29 13:41:06,641][60274] Fps is (10 sec: 384.3, 60 sec: 135.0, 300 sec: 83.1). Total num frames: 610304. Throughput: 0: 80.6. Samples: 610084. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:06,642][60274] Avg episode reward: [(0, '172.903')]
[36m[2025-06-29 13:41:10,956][60274] Fps is (10 sec: 410.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 610304. Throughput: 0: 81.1. Samples: 610544. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:10,956][60274] Avg episode reward: [(0, '165.021')]
[36m[2025-06-29 13:41:15,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 610304. Throughput: 0: 80.9. Samples: 611044. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:15,976][60274] Avg episode reward: [(0, '163.392')]
[36m[2025-06-29 13:41:21,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 610304. Throughput: 0: 80.4. Samples: 611284. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:21,003][60274] Avg episode reward: [(0, '166.664')]
[36m[2025-06-29 13:41:25,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 610304. Throughput: 0: 80.5. Samples: 611756. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:25,977][60274] Avg episode reward: [(0, '175.702')]
[36m[2025-06-29 13:41:30,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 610304. Throughput: 0: 80.1. Samples: 612252. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:30,964][60274] Avg episode reward: [(0, '177.109')]
[36m[2025-06-29 13:41:35,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 610304. Throughput: 0: 80.4. Samples: 612500. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:35,980][60274] Avg episode reward: [(0, '176.411')]
[36m[2025-06-29 13:41:40,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 610304. Throughput: 0: 80.0. Samples: 612960. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:40,952][60274] Avg episode reward: [(0, '172.850')]
[36m[2025-06-29 13:41:45,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 610304. Throughput: 0: 79.7. Samples: 613428. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:45,967][60274] Avg episode reward: [(0, '177.714')]
[36m[2025-06-29 13:41:51,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 610304. Throughput: 0: 80.7. Samples: 613664. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:51,001][60274] Avg episode reward: [(0, '187.146')]
[36m[2025-06-29 13:41:55,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 610304. Throughput: 0: 79.7. Samples: 614132. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 13:41:55,990][60274] Avg episode reward: [(0, '191.917')]
[36m[2025-06-29 13:42:00,986][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 614400. Throughput: 0: 78.6. Samples: 614584. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:42:00,987][60274] Avg episode reward: [(0, '183.453')]
[36m[2025-06-29 13:42:05,980][60274] Fps is (10 sec: 410.0, 60 sec: 69.0, 300 sec: 83.3). Total num frames: 614400. Throughput: 0: 78.6. Samples: 614820. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:42:05,981][60274] Avg episode reward: [(0, '189.473')]
[36m[2025-06-29 13:42:10,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 614400. Throughput: 0: 78.4. Samples: 615284. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:42:10,969][60274] Avg episode reward: [(0, '194.969')]
[36m[2025-06-29 13:42:15,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 614400. Throughput: 0: 78.5. Samples: 615784. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:42:15,973][60274] Avg episode reward: [(0, '198.414')]
[36m[2025-06-29 13:42:20,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 614400. Throughput: 0: 78.9. Samples: 616048. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:42:20,953][60274] Avg episode reward: [(0, '195.710')]
[36m[2025-06-29 13:42:25,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 614400. Throughput: 0: 79.9. Samples: 616560. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:42:25,989][60274] Avg episode reward: [(0, '193.881')]
[31m[7773007 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[7773007 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[7773007 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:42:30,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 614400. Throughput: 0: 80.8. Samples: 617064. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:42:30,977][60274] Avg episode reward: [(0, '202.206')]
[36m[2025-06-29 13:42:35,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 614400. Throughput: 0: 81.3. Samples: 617320. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:42:35,979][60274] Avg episode reward: [(0, '208.628')]
[36m[2025-06-29 13:42:40,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 614400. Throughput: 0: 81.5. Samples: 617796. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:42:40,973][60274] Avg episode reward: [(0, '204.922')]
[31m[7788526 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[7788526 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[7788526 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:42:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 614400. Throughput: 0: 82.6. Samples: 618300. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 13:42:45,969][60274] Avg episode reward: [(0, '203.479')]
[36m[2025-06-29 13:42:50,963][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 618496. Throughput: 0: 81.9. Samples: 618504. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-06-29 13:42:50,963][60274] Avg episode reward: [(0, '205.075')]
[36m[2025-06-29 13:42:55,971][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 618496. Throughput: 0: 82.1. Samples: 618980. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-06-29 13:42:55,971][60274] Avg episode reward: [(0, '209.398')]
[36m[2025-06-29 13:43:00,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 618496. Throughput: 0: 82.0. Samples: 619476. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-06-29 13:43:00,973][60274] Avg episode reward: [(0, '204.254')]
[37m[1m[2025-06-29 13:43:01,021][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002416_618496.pth...
[36m[2025-06-29 13:43:01,076][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002336_598016.pth
[36m[2025-06-29 13:43:05,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 618496. Throughput: 0: 81.0. Samples: 619696. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-06-29 13:43:05,997][60274] Avg episode reward: [(0, '204.816')]
[36m[2025-06-29 13:43:10,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 618496. Throughput: 0: 80.4. Samples: 620176. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-06-29 13:43:10,958][60274] Avg episode reward: [(0, '190.747')]
[36m[2025-06-29 13:43:15,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 618496. Throughput: 0: 79.7. Samples: 620652. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-06-29 13:43:15,974][60274] Avg episode reward: [(0, '181.953')]
[36m[2025-06-29 13:43:20,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 618496. Throughput: 0: 79.8. Samples: 620908. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-06-29 13:43:20,958][60274] Avg episode reward: [(0, '178.011')]
[36m[2025-06-29 13:43:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 618496. Throughput: 0: 79.6. Samples: 621380. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-06-29 13:43:25,980][60274] Avg episode reward: [(0, '169.353')]
[36m[2025-06-29 13:43:30,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 618496. Throughput: 0: 79.3. Samples: 621868. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-06-29 13:43:30,986][60274] Avg episode reward: [(0, '162.016')]
[36m[2025-06-29 13:43:35,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 618496. Throughput: 0: 80.3. Samples: 622116. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-06-29 13:43:35,949][60274] Avg episode reward: [(0, '162.251')]
[36m[2025-06-29 13:43:40,985][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 622592. Throughput: 0: 80.3. Samples: 622596. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 13:43:40,985][60274] Avg episode reward: [(0, '164.163')]
[36m[2025-06-29 13:43:45,982][60274] Fps is (10 sec: 408.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 622592. Throughput: 0: 78.7. Samples: 623020. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 13:43:45,982][60274] Avg episode reward: [(0, '151.962')]
[36m[2025-06-29 13:43:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 622592. Throughput: 0: 79.7. Samples: 623280. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 13:43:50,961][60274] Avg episode reward: [(0, '148.422')]
[36m[2025-06-29 13:43:55,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 622592. Throughput: 0: 79.2. Samples: 623740. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 13:43:55,953][60274] Avg episode reward: [(0, '141.844')]
[36m[2025-06-29 13:44:00,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 622592. Throughput: 0: 79.1. Samples: 624212. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 13:44:00,985][60274] Avg episode reward: [(0, '139.623')]
[36m[2025-06-29 13:44:05,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 622592. Throughput: 0: 78.6. Samples: 624448. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 13:44:05,985][60274] Avg episode reward: [(0, '137.694')]
[36m[2025-06-29 13:44:10,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 622592. Throughput: 0: 78.9. Samples: 624928. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 13:44:10,960][60274] Avg episode reward: [(0, '134.218')]
[36m[2025-06-29 13:44:15,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 622592. Throughput: 0: 79.2. Samples: 625432. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 13:44:15,974][60274] Avg episode reward: [(0, '137.935')]
[36m[2025-06-29 13:44:20,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 622592. Throughput: 0: 79.3. Samples: 625684. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 13:44:20,962][60274] Avg episode reward: [(0, '128.537')]
[36m[2025-06-29 13:44:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 622592. Throughput: 0: 79.4. Samples: 626168. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 13:44:25,956][60274] Avg episode reward: [(0, '129.859')]
[36m[2025-06-29 13:44:31,347][60274] Fps is (10 sec: 394.4, 60 sec: 135.7, 300 sec: 83.2). Total num frames: 626688. Throughput: 0: 80.3. Samples: 626664. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:44:31,347][60274] Avg episode reward: [(0, '138.593')]
[36m[2025-06-29 13:44:35,981][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 626688. Throughput: 0: 79.0. Samples: 626836. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:44:35,981][60274] Avg episode reward: [(0, '128.467')]
[36m[2025-06-29 13:44:40,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 626688. Throughput: 0: 79.1. Samples: 627300. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:44:40,950][60274] Avg episode reward: [(0, '131.207')]
[36m[2025-06-29 13:44:45,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 626688. Throughput: 0: 80.1. Samples: 627816. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:44:45,980][60274] Avg episode reward: [(0, '137.361')]
[36m[2025-06-29 13:44:51,014][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 626688. Throughput: 0: 80.2. Samples: 628060. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:44:51,014][60274] Avg episode reward: [(0, '146.916')]
[36m[2025-06-29 13:44:55,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 626688. Throughput: 0: 80.1. Samples: 628532. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:44:55,958][60274] Avg episode reward: [(0, '144.049')]
[36m[2025-06-29 13:45:00,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 626688. Throughput: 0: 79.6. Samples: 629016. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:45:00,973][60274] Avg episode reward: [(0, '153.356')]
[37m[1m[2025-06-29 13:45:01,039][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002448_626688.pth...
[36m[2025-06-29 13:45:01,094][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002368_606208.pth
[36m[2025-06-29 13:45:05,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 626688. Throughput: 0: 79.3. Samples: 629256. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:45:05,979][60274] Avg episode reward: [(0, '158.951')]
[36m[2025-06-29 13:45:10,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 626688. Throughput: 0: 79.8. Samples: 629760. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:45:10,973][60274] Avg episode reward: [(0, '166.996')]
[36m[2025-06-29 13:45:15,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 626688. Throughput: 0: 80.4. Samples: 630252. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:45:15,970][60274] Avg episode reward: [(0, '162.050')]
[36m[2025-06-29 13:45:20,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 626688. Throughput: 0: 81.4. Samples: 630496. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 13:45:20,953][60274] Avg episode reward: [(0, '164.120')]
[36m[2025-06-29 13:45:25,973][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 630784. Throughput: 0: 80.8. Samples: 630936. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 13:45:25,973][60274] Avg episode reward: [(0, '158.824')]
[36m[2025-06-29 13:45:30,952][60274] Fps is (10 sec: 409.6, 60 sec: 68.7, 300 sec: 83.3). Total num frames: 630784. Throughput: 0: 79.8. Samples: 631404. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 13:45:30,952][60274] Avg episode reward: [(0, '167.241')]
[36m[2025-06-29 13:45:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 630784. Throughput: 0: 80.1. Samples: 631660. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 13:45:35,981][60274] Avg episode reward: [(0, '170.015')]
[36m[2025-06-29 13:45:40,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 630784. Throughput: 0: 80.1. Samples: 632140. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 13:45:40,988][60274] Avg episode reward: [(0, '179.660')]
[36m[2025-06-29 13:45:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 630784. Throughput: 0: 80.1. Samples: 632620. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 13:45:45,969][60274] Avg episode reward: [(0, '179.596')]
[36m[2025-06-29 13:45:50,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 630784. Throughput: 0: 80.2. Samples: 632864. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 13:45:50,958][60274] Avg episode reward: [(0, '188.793')]
[36m[2025-06-29 13:45:55,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 630784. Throughput: 0: 80.1. Samples: 633364. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 13:45:55,984][60274] Avg episode reward: [(0, '185.577')]
[36m[2025-06-29 13:46:00,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 630784. Throughput: 0: 79.7. Samples: 633840. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 13:46:00,977][60274] Avg episode reward: [(0, '181.125')]
[36m[2025-06-29 13:46:05,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 630784. Throughput: 0: 79.3. Samples: 634068. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 13:46:05,987][60274] Avg episode reward: [(0, '190.794')]
[36m[2025-06-29 13:46:10,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 630784. Throughput: 0: 80.6. Samples: 634564. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 13:46:10,988][60274] Avg episode reward: [(0, '200.592')]
[36m[2025-06-29 13:46:15,953][60274] Fps is (10 sec: 411.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 634880. Throughput: 0: 79.4. Samples: 634976. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:46:15,953][60274] Avg episode reward: [(0, '208.072')]
[36m[2025-06-29 13:46:20,975][60274] Fps is (10 sec: 410.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 634880. Throughput: 0: 79.0. Samples: 635216. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:46:20,975][60274] Avg episode reward: [(0, '202.553')]
[31m[8009301 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[8009301 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[8009301 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:46:25,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 634880. Throughput: 0: 79.7. Samples: 635724. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:46:25,961][60274] Avg episode reward: [(0, '213.503')]
[36m[2025-06-29 13:46:30,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 634880. Throughput: 0: 80.4. Samples: 636236. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:46:30,951][60274] Avg episode reward: [(0, '224.772')]
[36m[2025-06-29 13:46:35,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 634880. Throughput: 0: 80.1. Samples: 636472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:46:35,990][60274] Avg episode reward: [(0, '208.197')]
[31m[8025972 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[8025972 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[8025972 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:46:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 634880. Throughput: 0: 79.7. Samples: 636948. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:46:40,981][60274] Avg episode reward: [(0, '201.207')]
[36m[2025-06-29 13:46:45,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 634880. Throughput: 0: 80.5. Samples: 637460. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:46:45,961][60274] Avg episode reward: [(0, '197.983')]
[31m[8033889 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[8033889 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[8033889 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 13:46:50,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 634880. Throughput: 0: 80.5. Samples: 637692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:46:50,993][60274] Avg episode reward: [(0, '181.493')]
[36m[2025-06-29 13:46:55,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 634880. Throughput: 0: 79.9. Samples: 638156. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:46:55,954][60274] Avg episode reward: [(0, '185.295')]
[36m[2025-06-29 13:47:00,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 634880. Throughput: 0: 81.6. Samples: 638648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:47:00,966][60274] Avg episode reward: [(0, '191.383')]
[37m[1m[2025-06-29 13:47:01,013][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002480_634880.pth...
[36m[2025-06-29 13:47:01,067][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002416_618496.pth
[36m[2025-06-29 13:47:05,975][60274] Fps is (10 sec: 408.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 638976. Throughput: 0: 81.6. Samples: 638888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:05,975][60274] Avg episode reward: [(0, '200.736')]
[36m[2025-06-29 13:47:11,013][60274] Fps is (10 sec: 407.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 638976. Throughput: 0: 79.4. Samples: 639300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:11,013][60274] Avg episode reward: [(0, '198.265')]
[36m[2025-06-29 13:47:15,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 638976. Throughput: 0: 78.9. Samples: 639788. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:15,987][60274] Avg episode reward: [(0, '179.331')]
[36m[2025-06-29 13:47:20,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 638976. Throughput: 0: 78.8. Samples: 640020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:20,987][60274] Avg episode reward: [(0, '181.011')]
[36m[2025-06-29 13:47:25,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 638976. Throughput: 0: 78.9. Samples: 640500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:25,988][60274] Avg episode reward: [(0, '168.603')]
[36m[2025-06-29 13:47:30,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 638976. Throughput: 0: 78.5. Samples: 640996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:30,983][60274] Avg episode reward: [(0, '148.037')]
[36m[2025-06-29 13:47:35,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 638976. Throughput: 0: 78.7. Samples: 641232. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:35,968][60274] Avg episode reward: [(0, '150.307')]
[36m[2025-06-29 13:47:40,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 638976. Throughput: 0: 79.1. Samples: 641720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:40,992][60274] Avg episode reward: [(0, '155.504')]
[36m[2025-06-29 13:47:45,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 638976. Throughput: 0: 78.8. Samples: 642192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:45,964][60274] Avg episode reward: [(0, '140.017')]
[36m[2025-06-29 13:47:50,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 638976. Throughput: 0: 78.5. Samples: 642424. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:50,996][60274] Avg episode reward: [(0, '138.560')]
[36m[2025-06-29 13:47:55,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 638976. Throughput: 0: 79.9. Samples: 642892. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:47:55,958][60274] Avg episode reward: [(0, '135.094')]
[36m[2025-06-29 13:48:00,961][60274] Fps is (10 sec: 411.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 643072. Throughput: 0: 78.4. Samples: 643316. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:48:00,961][60274] Avg episode reward: [(0, '129.062')]
[36m[2025-06-29 13:48:05,964][60274] Fps is (10 sec: 409.3, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 643072. Throughput: 0: 78.8. Samples: 643564. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:48:05,964][60274] Avg episode reward: [(0, '129.979')]
[36m[2025-06-29 13:48:10,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 643072. Throughput: 0: 79.0. Samples: 644052. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:48:10,972][60274] Avg episode reward: [(0, '121.026')]
[36m[2025-06-29 13:48:15,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 643072. Throughput: 0: 79.0. Samples: 644548. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:48:15,949][60274] Avg episode reward: [(0, '127.194')]
[36m[2025-06-29 13:48:20,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 643072. Throughput: 0: 79.2. Samples: 644796. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:48:20,993][60274] Avg episode reward: [(0, '127.163')]
[36m[2025-06-29 13:48:25,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 643072. Throughput: 0: 79.7. Samples: 645308. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:48:25,996][60274] Avg episode reward: [(0, '140.224')]
[36m[2025-06-29 13:48:30,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 643072. Throughput: 0: 79.9. Samples: 645788. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:48:30,968][60274] Avg episode reward: [(0, '138.719')]
[36m[2025-06-29 13:48:35,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 643072. Throughput: 0: 80.3. Samples: 646036. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:48:35,958][60274] Avg episode reward: [(0, '156.871')]
[36m[2025-06-29 13:48:40,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 643072. Throughput: 0: 81.0. Samples: 646540. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:48:40,978][60274] Avg episode reward: [(0, '144.913')]
[36m[2025-06-29 13:48:45,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 643072. Throughput: 0: 82.6. Samples: 647036. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 13:48:45,988][60274] Avg episode reward: [(0, '136.783')]
[36m[2025-06-29 13:48:50,952][60274] Fps is (10 sec: 410.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 647168. Throughput: 0: 81.1. Samples: 647212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:48:50,952][60274] Avg episode reward: [(0, '136.535')]
[36m[2025-06-29 13:48:55,947][60274] Fps is (10 sec: 411.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 647168. Throughput: 0: 81.6. Samples: 647720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:48:55,948][60274] Avg episode reward: [(0, '153.668')]
[36m[2025-06-29 13:49:00,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 647168. Throughput: 0: 80.6. Samples: 648176. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:49:00,979][60274] Avg episode reward: [(0, '160.596')]
[37m[1m[2025-06-29 13:49:01,039][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002528_647168.pth...
[36m[2025-06-29 13:49:01,098][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002448_626688.pth
[36m[2025-06-29 13:49:05,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 647168. Throughput: 0: 80.5. Samples: 648416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:49:05,967][60274] Avg episode reward: [(0, '160.617')]
[36m[2025-06-29 13:49:10,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 647168. Throughput: 0: 79.6. Samples: 648888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:49:10,949][60274] Avg episode reward: [(0, '167.231')]
[36m[2025-06-29 13:49:15,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 647168. Throughput: 0: 78.9. Samples: 649340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:49:15,985][60274] Avg episode reward: [(0, '174.315')]
[36m[2025-06-29 13:49:20,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 647168. Throughput: 0: 79.1. Samples: 649596. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:49:20,978][60274] Avg episode reward: [(0, '183.998')]
[36m[2025-06-29 13:49:25,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 647168. Throughput: 0: 78.3. Samples: 650064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:49:25,994][60274] Avg episode reward: [(0, '187.318')]
[33m[8193758 ms][navigation_task] - WARNING : Curriculum Level: 36, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[8193758 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.595703125
[33mCrash Rate: 0.29931640625
[33mTimeout Rate: 0.10498046875 (navigation_task.py:265)
[33m[8193758 ms][navigation_task] - WARNING : 
[33mSuccesses: 1220
[33mCrashes : 613
[33mTimeouts: 215 (navigation_task.py:268)
[36m[2025-06-29 13:49:30,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 647168. Throughput: 0: 77.9. Samples: 650540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:49:30,961][60274] Avg episode reward: [(0, '176.980')]
[36m[2025-06-29 13:49:35,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 647168. Throughput: 0: 79.0. Samples: 650768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:49:35,969][60274] Avg episode reward: [(0, '182.200')]
[36m[2025-06-29 13:49:40,946][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 651264. Throughput: 0: 78.2. Samples: 651240. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:49:40,946][60274] Avg episode reward: [(0, '180.652')]
[36m[2025-06-29 13:49:45,953][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 651264. Throughput: 0: 77.5. Samples: 651660. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:49:45,954][60274] Avg episode reward: [(0, '171.015')]
[36m[2025-06-29 13:49:50,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 651264. Throughput: 0: 77.7. Samples: 651912. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:49:50,954][60274] Avg episode reward: [(0, '170.138')]
[36m[2025-06-29 13:49:55,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 651264. Throughput: 0: 78.0. Samples: 652400. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:49:55,989][60274] Avg episode reward: [(0, '165.729')]
[36m[2025-06-29 13:50:00,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 651264. Throughput: 0: 78.9. Samples: 652888. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:50:00,973][60274] Avg episode reward: [(0, '171.638')]
[36m[2025-06-29 13:50:05,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 651264. Throughput: 0: 78.7. Samples: 653140. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:50:05,991][60274] Avg episode reward: [(0, '164.542')]
[36m[2025-06-29 13:50:10,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 651264. Throughput: 0: 78.5. Samples: 653596. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:50:10,960][60274] Avg episode reward: [(0, '161.901')]
[36m[2025-06-29 13:50:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 651264. Throughput: 0: 79.2. Samples: 654104. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:50:15,953][60274] Avg episode reward: [(0, '155.191')]
[36m[2025-06-29 13:50:20,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 651264. Throughput: 0: 79.9. Samples: 654364. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:50:20,982][60274] Avg episode reward: [(0, '155.678')]
[36m[2025-06-29 13:50:25,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 651264. Throughput: 0: 79.9. Samples: 654840. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 13:50:25,989][60274] Avg episode reward: [(0, '160.819')]
[36m[2025-06-29 13:50:31,234][60274] Fps is (10 sec: 399.5, 60 sec: 135.9, 300 sec: 83.2). Total num frames: 655360. Throughput: 0: 81.4. Samples: 655344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:50:31,234][60274] Avg episode reward: [(0, '173.088')]
[36m[2025-06-29 13:50:35,948][60274] Fps is (10 sec: 411.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 655360. Throughput: 0: 80.5. Samples: 655536. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:50:35,949][60274] Avg episode reward: [(0, '173.341')]
[36m[2025-06-29 13:50:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 655360. Throughput: 0: 80.2. Samples: 656004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:50:40,947][60274] Avg episode reward: [(0, '154.283')]
[36m[2025-06-29 13:50:45,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 655360. Throughput: 0: 80.4. Samples: 656504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:50:45,950][60274] Avg episode reward: [(0, '160.120')]
[36m[2025-06-29 13:50:50,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 655360. Throughput: 0: 79.9. Samples: 656736. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:50:50,973][60274] Avg episode reward: [(0, '150.074')]
[36m[2025-06-29 13:50:55,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 655360. Throughput: 0: 80.3. Samples: 657212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:50:55,969][60274] Avg episode reward: [(0, '145.269')]
[36m[2025-06-29 13:51:00,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 655360. Throughput: 0: 79.2. Samples: 657672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:51:00,986][60274] Avg episode reward: [(0, '151.442')]
[37m[1m[2025-06-29 13:51:01,037][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002560_655360.pth...
[36m[2025-06-29 13:51:01,096][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002480_634880.pth
[36m[2025-06-29 13:51:05,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 655360. Throughput: 0: 79.1. Samples: 657920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:51:05,947][60274] Avg episode reward: [(0, '148.343')]
[36m[2025-06-29 13:51:10,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 655360. Throughput: 0: 79.4. Samples: 658412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:51:10,985][60274] Avg episode reward: [(0, '153.709')]
[36m[2025-06-29 13:51:15,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 655360. Throughput: 0: 79.2. Samples: 658888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:51:15,965][60274] Avg episode reward: [(0, '148.744')]
[36m[2025-06-29 13:51:20,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 655360. Throughput: 0: 79.6. Samples: 659120. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:51:20,973][60274] Avg episode reward: [(0, '162.376')]
[36m[2025-06-29 13:51:25,962][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 659456. Throughput: 0: 78.6. Samples: 659544. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:51:25,963][60274] Avg episode reward: [(0, '159.421')]
[36m[2025-06-29 13:51:30,954][60274] Fps is (10 sec: 410.3, 60 sec: 68.6, 300 sec: 83.3). Total num frames: 659456. Throughput: 0: 78.6. Samples: 660040. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:51:30,954][60274] Avg episode reward: [(0, '169.512')]
[36m[2025-06-29 13:51:35,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 659456. Throughput: 0: 78.5. Samples: 660272. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:51:35,990][60274] Avg episode reward: [(0, '177.418')]
[36m[2025-06-29 13:51:40,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 659456. Throughput: 0: 78.7. Samples: 660752. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:51:40,958][60274] Avg episode reward: [(0, '180.155')]
[36m[2025-06-29 13:51:45,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 659456. Throughput: 0: 78.9. Samples: 661224. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:51:45,982][60274] Avg episode reward: [(0, '177.508')]
[36m[2025-06-29 13:51:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 659456. Throughput: 0: 78.7. Samples: 661464. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:51:50,961][60274] Avg episode reward: [(0, '183.772')]
[36m[2025-06-29 13:51:55,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 659456. Throughput: 0: 79.2. Samples: 661972. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:51:55,955][60274] Avg episode reward: [(0, '181.370')]
[36m[2025-06-29 13:52:00,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 659456. Throughput: 0: 79.4. Samples: 662460. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:52:00,962][60274] Avg episode reward: [(0, '190.977')]
[36m[2025-06-29 13:52:05,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 659456. Throughput: 0: 79.3. Samples: 662688. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:52:05,978][60274] Avg episode reward: [(0, '190.446')]
[36m[2025-06-29 13:52:10,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 659456. Throughput: 0: 79.7. Samples: 663132. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 13:52:10,971][60274] Avg episode reward: [(0, '179.059')]
[36m[2025-06-29 13:52:15,953][60274] Fps is (10 sec: 410.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 663552. Throughput: 0: 78.3. Samples: 663564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:52:15,953][60274] Avg episode reward: [(0, '177.602')]
[36m[2025-06-29 13:52:20,989][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 663552. Throughput: 0: 78.8. Samples: 663816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:52:20,989][60274] Avg episode reward: [(0, '184.242')]
[36m[2025-06-29 13:52:25,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 663552. Throughput: 0: 79.0. Samples: 664308. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:52:25,989][60274] Avg episode reward: [(0, '187.659')]
[36m[2025-06-29 13:52:30,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 663552. Throughput: 0: 79.1. Samples: 664780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:52:30,961][60274] Avg episode reward: [(0, '185.370')]
[36m[2025-06-29 13:52:35,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 663552. Throughput: 0: 78.9. Samples: 665016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:52:35,994][60274] Avg episode reward: [(0, '193.615')]
[36m[2025-06-29 13:52:40,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 663552. Throughput: 0: 78.0. Samples: 665484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:52:40,997][60274] Avg episode reward: [(0, '192.628')]
[36m[2025-06-29 13:52:45,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 663552. Throughput: 0: 77.7. Samples: 665956. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:52:45,957][60274] Avg episode reward: [(0, '202.202')]
[36m[2025-06-29 13:52:50,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 663552. Throughput: 0: 78.0. Samples: 666196. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:52:50,958][60274] Avg episode reward: [(0, '206.881')]
[36m[2025-06-29 13:52:55,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 663552. Throughput: 0: 78.6. Samples: 666672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:52:55,982][60274] Avg episode reward: [(0, '204.357')]
[36m[2025-06-29 13:53:01,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 663552. Throughput: 0: 80.1. Samples: 667172. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:53:01,001][60274] Avg episode reward: [(0, '199.195')]
[37m[1m[2025-06-29 13:53:01,049][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002592_663552.pth...
[36m[2025-06-29 13:53:01,104][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002528_647168.pth
[36m[2025-06-29 13:53:05,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 663552. Throughput: 0: 79.4. Samples: 667388. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:53:05,970][60274] Avg episode reward: [(0, '202.176')]
[36m[2025-06-29 13:53:10,959][60274] Fps is (10 sec: 411.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 667648. Throughput: 0: 78.4. Samples: 667832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:53:10,959][60274] Avg episode reward: [(0, '206.608')]
[36m[2025-06-29 13:53:15,979][60274] Fps is (10 sec: 409.2, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 667648. Throughput: 0: 79.2. Samples: 668344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:53:15,979][60274] Avg episode reward: [(0, '199.736')]
[36m[2025-06-29 13:53:20,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 667648. Throughput: 0: 79.3. Samples: 668584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:53:20,966][60274] Avg episode reward: [(0, '190.567')]
[36m[2025-06-29 13:53:25,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 667648. Throughput: 0: 79.6. Samples: 669064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:53:25,951][60274] Avg episode reward: [(0, '184.041')]
[36m[2025-06-29 13:53:30,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 667648. Throughput: 0: 79.8. Samples: 669548. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:53:30,986][60274] Avg episode reward: [(0, '180.399')]
[36m[2025-06-29 13:53:35,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 667648. Throughput: 0: 80.1. Samples: 669800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:53:35,955][60274] Avg episode reward: [(0, '172.814')]
[36m[2025-06-29 13:53:40,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 667648. Throughput: 0: 80.0. Samples: 670272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:53:40,976][60274] Avg episode reward: [(0, '180.773')]
[36m[2025-06-29 13:53:45,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 667648. Throughput: 0: 79.8. Samples: 670760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:53:45,990][60274] Avg episode reward: [(0, '176.949')]
[36m[2025-06-29 13:53:50,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 667648. Throughput: 0: 80.2. Samples: 670996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:53:50,956][60274] Avg episode reward: [(0, '155.257')]
[36m[2025-06-29 13:53:55,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 667648. Throughput: 0: 80.7. Samples: 671464. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:53:55,981][60274] Avg episode reward: [(0, '170.953')]
[36m[2025-06-29 13:54:00,957][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 671744. Throughput: 0: 78.8. Samples: 671888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:54:00,957][60274] Avg episode reward: [(0, '174.304')]
[36m[2025-06-29 13:54:05,962][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 671744. Throughput: 0: 78.3. Samples: 672108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:54:05,962][60274] Avg episode reward: [(0, '155.539')]
[36m[2025-06-29 13:54:10,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 671744. Throughput: 0: 78.4. Samples: 672596. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:54:10,977][60274] Avg episode reward: [(0, '154.761')]
[36m[2025-06-29 13:54:15,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 671744. Throughput: 0: 78.5. Samples: 673080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:54:15,973][60274] Avg episode reward: [(0, '170.080')]
[36m[2025-06-29 13:54:20,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 671744. Throughput: 0: 78.4. Samples: 673328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:54:20,973][60274] Avg episode reward: [(0, '157.004')]
[36m[2025-06-29 13:54:25,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 671744. Throughput: 0: 78.6. Samples: 673808. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:54:25,983][60274] Avg episode reward: [(0, '164.203')]
[36m[2025-06-29 13:54:30,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 671744. Throughput: 0: 78.8. Samples: 674308. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:54:30,993][60274] Avg episode reward: [(0, '152.095')]
[36m[2025-06-29 13:54:35,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 671744. Throughput: 0: 78.8. Samples: 674544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:54:35,968][60274] Avg episode reward: [(0, '151.840')]
[36m[2025-06-29 13:54:40,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 671744. Throughput: 0: 78.7. Samples: 675004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:54:40,957][60274] Avg episode reward: [(0, '151.733')]
[36m[2025-06-29 13:54:45,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 671744. Throughput: 0: 79.0. Samples: 675444. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:54:45,968][60274] Avg episode reward: [(0, '143.388')]
[36m[2025-06-29 13:54:50,975][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 675840. Throughput: 0: 79.7. Samples: 675696. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:54:50,975][60274] Avg episode reward: [(0, '130.777')]
[36m[2025-06-29 13:54:56,007][60274] Fps is (10 sec: 408.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 675840. Throughput: 0: 77.9. Samples: 676104. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:54:56,008][60274] Avg episode reward: [(0, '121.458')]
[36m[2025-06-29 13:55:00,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 675840. Throughput: 0: 78.1. Samples: 676596. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:55:00,978][60274] Avg episode reward: [(0, '126.964')]
[37m[1m[2025-06-29 13:55:01,029][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002640_675840.pth...
[36m[2025-06-29 13:55:01,085][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002560_655360.pth
[36m[2025-06-29 13:55:05,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 675840. Throughput: 0: 77.9. Samples: 676832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:55:05,974][60274] Avg episode reward: [(0, '132.740')]
[36m[2025-06-29 13:55:10,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 675840. Throughput: 0: 77.9. Samples: 677312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:55:10,978][60274] Avg episode reward: [(0, '134.389')]
[36m[2025-06-29 13:55:15,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 675840. Throughput: 0: 77.2. Samples: 677780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:55:15,983][60274] Avg episode reward: [(0, '144.702')]
[36m[2025-06-29 13:55:21,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 675840. Throughput: 0: 77.1. Samples: 678016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:55:21,003][60274] Avg episode reward: [(0, '146.239')]
[36m[2025-06-29 13:55:25,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 675840. Throughput: 0: 77.8. Samples: 678508. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:55:25,987][60274] Avg episode reward: [(0, '145.663')]
[36m[2025-06-29 13:55:30,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 675840. Throughput: 0: 78.7. Samples: 678984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:55:30,974][60274] Avg episode reward: [(0, '152.277')]
[36m[2025-06-29 13:55:35,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 675840. Throughput: 0: 78.8. Samples: 679240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:55:35,947][60274] Avg episode reward: [(0, '160.730')]
[36m[2025-06-29 13:55:40,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 675840. Throughput: 0: 80.6. Samples: 679728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:55:40,984][60274] Avg episode reward: [(0, '165.688')]
[36m[2025-06-29 13:55:45,980][60274] Fps is (10 sec: 408.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 679936. Throughput: 0: 79.2. Samples: 680160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:55:45,981][60274] Avg episode reward: [(0, '156.379')]
[36m[2025-06-29 13:55:50,981][60274] Fps is (10 sec: 409.7, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 679936. Throughput: 0: 79.5. Samples: 680408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:55:50,981][60274] Avg episode reward: [(0, '175.331')]
[36m[2025-06-29 13:55:55,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 679936. Throughput: 0: 79.4. Samples: 680888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:55:55,990][60274] Avg episode reward: [(0, '182.549')]
[36m[2025-06-29 13:56:00,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 679936. Throughput: 0: 79.9. Samples: 681376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:00,988][60274] Avg episode reward: [(0, '167.783')]
[36m[2025-06-29 13:56:05,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 679936. Throughput: 0: 80.4. Samples: 681632. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:05,969][60274] Avg episode reward: [(0, '171.837')]
[36m[2025-06-29 13:56:10,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 679936. Throughput: 0: 79.8. Samples: 682096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:10,963][60274] Avg episode reward: [(0, '178.628')]
[36m[2025-06-29 13:56:15,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 679936. Throughput: 0: 79.7. Samples: 682572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:15,989][60274] Avg episode reward: [(0, '179.528')]
[36m[2025-06-29 13:56:20,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 679936. Throughput: 0: 79.4. Samples: 682816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:20,976][60274] Avg episode reward: [(0, '168.157')]
[36m[2025-06-29 13:56:25,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 679936. Throughput: 0: 79.6. Samples: 683312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:25,983][60274] Avg episode reward: [(0, '167.292')]
[36m[2025-06-29 13:56:30,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 679936. Throughput: 0: 80.5. Samples: 683780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:30,954][60274] Avg episode reward: [(0, '167.606')]
[36m[2025-06-29 13:56:35,990][60274] Fps is (10 sec: 409.3, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 684032. Throughput: 0: 80.2. Samples: 684016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:35,991][60274] Avg episode reward: [(0, '174.093')]
[36m[2025-06-29 13:56:40,968][60274] Fps is (10 sec: 409.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 684032. Throughput: 0: 79.2. Samples: 684452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:40,968][60274] Avg episode reward: [(0, '169.181')]
[36m[2025-06-29 13:56:45,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 684032. Throughput: 0: 79.5. Samples: 684952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:45,968][60274] Avg episode reward: [(0, '181.394')]
[36m[2025-06-29 13:56:50,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 684032. Throughput: 0: 79.2. Samples: 685196. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:50,947][60274] Avg episode reward: [(0, '179.415')]
[36m[2025-06-29 13:56:55,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 684032. Throughput: 0: 80.2. Samples: 685704. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:56:55,951][60274] Avg episode reward: [(0, '180.235')]
[36m[2025-06-29 13:57:00,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 684032. Throughput: 0: 80.4. Samples: 686192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:57:00,996][60274] Avg episode reward: [(0, '177.182')]
[37m[1m[2025-06-29 13:57:01,063][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002672_684032.pth...
[36m[2025-06-29 13:57:01,119][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002592_663552.pth
[36m[2025-06-29 13:57:05,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 684032. Throughput: 0: 79.8. Samples: 686408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:57:05,963][60274] Avg episode reward: [(0, '173.865')]
[36m[2025-06-29 13:57:10,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 684032. Throughput: 0: 80.0. Samples: 686908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:57:10,950][60274] Avg episode reward: [(0, '162.731')]
[36m[2025-06-29 13:57:15,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 684032. Throughput: 0: 80.7. Samples: 687412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:57:15,973][60274] Avg episode reward: [(0, '156.598')]
[36m[2025-06-29 13:57:21,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 684032. Throughput: 0: 80.9. Samples: 687660. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:57:21,007][60274] Avg episode reward: [(0, '158.236')]
[36m[2025-06-29 13:57:25,984][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 688128. Throughput: 0: 81.8. Samples: 688136. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:57:25,984][60274] Avg episode reward: [(0, '162.787')]
[36m[2025-06-29 13:57:30,979][60274] Fps is (10 sec: 410.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 688128. Throughput: 0: 80.8. Samples: 688588. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:57:30,979][60274] Avg episode reward: [(0, '158.628')]
[36m[2025-06-29 13:57:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 688128. Throughput: 0: 80.3. Samples: 688812. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:57:35,981][60274] Avg episode reward: [(0, '152.648')]
[36m[2025-06-29 13:57:40,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 688128. Throughput: 0: 79.5. Samples: 689284. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:57:40,955][60274] Avg episode reward: [(0, '154.655')]
[36m[2025-06-29 13:57:45,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 688128. Throughput: 0: 80.0. Samples: 689788. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:57:45,974][60274] Avg episode reward: [(0, '160.479')]
[36m[2025-06-29 13:57:50,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 688128. Throughput: 0: 80.8. Samples: 690048. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:57:50,991][60274] Avg episode reward: [(0, '157.022')]
[36m[2025-06-29 13:57:55,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 688128. Throughput: 0: 81.1. Samples: 690560. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:57:55,982][60274] Avg episode reward: [(0, '157.341')]
[36m[2025-06-29 13:58:01,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 688128. Throughput: 0: 80.5. Samples: 691036. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:58:01,007][60274] Avg episode reward: [(0, '161.400')]
[36m[2025-06-29 13:58:05,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 688128. Throughput: 0: 80.5. Samples: 691280. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:58:05,984][60274] Avg episode reward: [(0, '174.701')]
[36m[2025-06-29 13:58:10,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 688128. Throughput: 0: 80.4. Samples: 691752. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 13:58:10,962][60274] Avg episode reward: [(0, '169.087')]
[36m[2025-06-29 13:58:16,005][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 692224. Throughput: 0: 80.8. Samples: 692228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:58:16,005][60274] Avg episode reward: [(0, '175.623')]
[36m[2025-06-29 13:58:20,974][60274] Fps is (10 sec: 409.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 692224. Throughput: 0: 80.0. Samples: 692412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:58:20,974][60274] Avg episode reward: [(0, '165.141')]
[36m[2025-06-29 13:58:25,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 692224. Throughput: 0: 80.4. Samples: 692904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:58:25,960][60274] Avg episode reward: [(0, '174.302')]
[36m[2025-06-29 13:58:30,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 692224. Throughput: 0: 79.7. Samples: 693376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:58:30,985][60274] Avg episode reward: [(0, '175.481')]
[36m[2025-06-29 13:58:35,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 692224. Throughput: 0: 79.5. Samples: 693624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:58:35,990][60274] Avg episode reward: [(0, '185.528')]
[36m[2025-06-29 13:58:40,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 692224. Throughput: 0: 78.9. Samples: 694112. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:58:40,994][60274] Avg episode reward: [(0, '187.753')]
[36m[2025-06-29 13:58:45,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 692224. Throughput: 0: 79.4. Samples: 694604. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:58:45,949][60274] Avg episode reward: [(0, '172.602')]
[36m[2025-06-29 13:58:50,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 692224. Throughput: 0: 79.5. Samples: 694856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:58:50,966][60274] Avg episode reward: [(0, '176.071')]
[36m[2025-06-29 13:58:55,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 692224. Throughput: 0: 79.8. Samples: 695340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:58:55,950][60274] Avg episode reward: [(0, '181.203')]
[36m[2025-06-29 13:59:00,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 692224. Throughput: 0: 80.5. Samples: 695848. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:59:00,969][60274] Avg episode reward: [(0, '181.489')]
[37m[1m[2025-06-29 13:59:01,017][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002704_692224.pth...
[36m[2025-06-29 13:59:01,073][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002640_675840.pth
[36m[2025-06-29 13:59:05,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 692224. Throughput: 0: 81.4. Samples: 696076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 13:59:05,964][60274] Avg episode reward: [(0, '184.117')]
[36m[2025-06-29 13:59:10,966][60274] Fps is (10 sec: 409.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 696320. Throughput: 0: 80.1. Samples: 696508. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:59:10,966][60274] Avg episode reward: [(0, '189.460')]
[36m[2025-06-29 13:59:15,978][60274] Fps is (10 sec: 409.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 696320. Throughput: 0: 80.5. Samples: 697000. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:59:15,978][60274] Avg episode reward: [(0, '174.729')]
[36m[2025-06-29 13:59:20,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 696320. Throughput: 0: 80.1. Samples: 697228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:59:20,970][60274] Avg episode reward: [(0, '182.309')]
[36m[2025-06-29 13:59:25,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 696320. Throughput: 0: 80.2. Samples: 697720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:59:25,976][60274] Avg episode reward: [(0, '182.730')]
[36m[2025-06-29 13:59:30,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 696320. Throughput: 0: 79.8. Samples: 698196. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:59:30,963][60274] Avg episode reward: [(0, '183.515')]
[36m[2025-06-29 13:59:35,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 696320. Throughput: 0: 79.5. Samples: 698432. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:59:35,970][60274] Avg episode reward: [(0, '180.598')]
[36m[2025-06-29 13:59:40,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 696320. Throughput: 0: 79.7. Samples: 698928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:59:40,949][60274] Avg episode reward: [(0, '180.449')]
[36m[2025-06-29 13:59:46,009][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 696320. Throughput: 0: 79.0. Samples: 699404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:59:46,010][60274] Avg episode reward: [(0, '180.013')]
[36m[2025-06-29 13:59:50,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 696320. Throughput: 0: 79.3. Samples: 699644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:59:50,979][60274] Avg episode reward: [(0, '178.991')]
[36m[2025-06-29 13:59:55,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 696320. Throughput: 0: 80.0. Samples: 700112. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 13:59:55,993][60274] Avg episode reward: [(0, '181.533')]
[36m[2025-06-29 14:00:00,954][60274] Fps is (10 sec: 410.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 700416. Throughput: 0: 78.5. Samples: 700532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:00:00,954][60274] Avg episode reward: [(0, '181.649')]
[36m[2025-06-29 14:00:05,951][60274] Fps is (10 sec: 411.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 700416. Throughput: 0: 79.0. Samples: 700780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:00:05,951][60274] Avg episode reward: [(0, '179.427')]
[36m[2025-06-29 14:00:10,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 700416. Throughput: 0: 79.1. Samples: 701276. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:00:10,951][60274] Avg episode reward: [(0, '187.234')]
[36m[2025-06-29 14:00:15,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 700416. Throughput: 0: 79.4. Samples: 701772. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:00:15,987][60274] Avg episode reward: [(0, '185.131')]
[36m[2025-06-29 14:00:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 700416. Throughput: 0: 79.8. Samples: 702024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:00:20,985][60274] Avg episode reward: [(0, '190.817')]
[36m[2025-06-29 14:00:25,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 700416. Throughput: 0: 79.4. Samples: 702504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:00:25,981][60274] Avg episode reward: [(0, '190.813')]
[36m[2025-06-29 14:00:30,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 700416. Throughput: 0: 79.6. Samples: 702984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:00:30,975][60274] Avg episode reward: [(0, '195.325')]
[36m[2025-06-29 14:00:35,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 700416. Throughput: 0: 79.7. Samples: 703228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:00:35,949][60274] Avg episode reward: [(0, '198.638')]
[36m[2025-06-29 14:00:40,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 700416. Throughput: 0: 80.2. Samples: 703720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:00:40,984][60274] Avg episode reward: [(0, '202.528')]
[36m[2025-06-29 14:00:45,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 700416. Throughput: 0: 81.8. Samples: 704212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:00:45,947][60274] Avg episode reward: [(0, '191.451')]
[36m[2025-06-29 14:00:50,980][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 704512. Throughput: 0: 81.8. Samples: 704464. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:00:50,980][60274] Avg episode reward: [(0, '198.370')]
[36m[2025-06-29 14:00:56,006][60274] Fps is (10 sec: 407.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 704512. Throughput: 0: 80.2. Samples: 704888. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:00:56,006][60274] Avg episode reward: [(0, '199.574')]
[36m[2025-06-29 14:01:00,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 704512. Throughput: 0: 79.5. Samples: 705348. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:01:00,982][60274] Avg episode reward: [(0, '200.156')]
[37m[1m[2025-06-29 14:01:01,038][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002752_704512.pth...
[36m[2025-06-29 14:01:01,095][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002672_684032.pth
[36m[2025-06-29 14:01:05,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 704512. Throughput: 0: 79.0. Samples: 705576. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:01:05,973][60274] Avg episode reward: [(0, '190.396')]
[36m[2025-06-29 14:01:10,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 704512. Throughput: 0: 78.9. Samples: 706052. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:01:10,973][60274] Avg episode reward: [(0, '193.443')]
[36m[2025-06-29 14:01:15,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 704512. Throughput: 0: 78.7. Samples: 706528. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:01:15,987][60274] Avg episode reward: [(0, '186.672')]
[36m[2025-06-29 14:01:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 704512. Throughput: 0: 78.1. Samples: 706744. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:01:20,985][60274] Avg episode reward: [(0, '179.841')]
[36m[2025-06-29 14:01:25,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 704512. Throughput: 0: 78.0. Samples: 707228. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:01:25,959][60274] Avg episode reward: [(0, '186.728')]
[36m[2025-06-29 14:01:30,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 704512. Throughput: 0: 77.4. Samples: 707696. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:01:30,987][60274] Avg episode reward: [(0, '184.215')]
[36m[2025-06-29 14:01:35,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 704512. Throughput: 0: 77.3. Samples: 707944. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:01:35,989][60274] Avg episode reward: [(0, '186.101')]
[36m[2025-06-29 14:01:40,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 704512. Throughput: 0: 78.7. Samples: 708428. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 14:01:40,963][60274] Avg episode reward: [(0, '185.319')]
[36m[2025-06-29 14:01:45,978][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 708608. Throughput: 0: 78.1. Samples: 708864. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:01:45,979][60274] Avg episode reward: [(0, '175.749')]
[36m[2025-06-29 14:01:50,977][60274] Fps is (10 sec: 409.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 708608. Throughput: 0: 78.7. Samples: 709116. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:01:50,978][60274] Avg episode reward: [(0, '177.751')]
[36m[2025-06-29 14:01:55,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 708608. Throughput: 0: 78.7. Samples: 709596. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:01:55,978][60274] Avg episode reward: [(0, '183.916')]
[36m[2025-06-29 14:02:01,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 708608. Throughput: 0: 79.1. Samples: 710088. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:02:01,004][60274] Avg episode reward: [(0, '190.323')]
[36m[2025-06-29 14:02:05,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 708608. Throughput: 0: 79.6. Samples: 710324. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:02:05,961][60274] Avg episode reward: [(0, '186.922')]
[36m[2025-06-29 14:02:10,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 708608. Throughput: 0: 79.6. Samples: 710812. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:02:10,956][60274] Avg episode reward: [(0, '181.067')]
[36m[2025-06-29 14:02:15,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 708608. Throughput: 0: 79.7. Samples: 711284. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:02:15,986][60274] Avg episode reward: [(0, '178.765')]
[36m[2025-06-29 14:02:20,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 708608. Throughput: 0: 79.5. Samples: 711520. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:02:20,954][60274] Avg episode reward: [(0, '179.916')]
[36m[2025-06-29 14:02:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 708608. Throughput: 0: 79.5. Samples: 712008. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:02:25,980][60274] Avg episode reward: [(0, '178.386')]
[36m[2025-06-29 14:02:30,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 708608. Throughput: 0: 81.2. Samples: 712520. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:02:30,977][60274] Avg episode reward: [(0, '185.251')]
[36m[2025-06-29 14:02:35,949][60274] Fps is (10 sec: 410.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 712704. Throughput: 0: 80.1. Samples: 712720. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 14:02:35,950][60274] Avg episode reward: [(0, '187.544')]
[36m[2025-06-29 14:02:40,955][60274] Fps is (10 sec: 410.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 712704. Throughput: 0: 80.6. Samples: 713220. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 14:02:40,956][60274] Avg episode reward: [(0, '188.714')]
[36m[2025-06-29 14:02:45,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 712704. Throughput: 0: 79.9. Samples: 713680. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 14:02:45,977][60274] Avg episode reward: [(0, '184.700')]
[36m[2025-06-29 14:02:50,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 712704. Throughput: 0: 80.1. Samples: 713928. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 14:02:50,948][60274] Avg episode reward: [(0, '185.384')]
[36m[2025-06-29 14:02:55,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 712704. Throughput: 0: 79.8. Samples: 714404. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 14:02:55,987][60274] Avg episode reward: [(0, '192.521')]
[36m[2025-06-29 14:03:00,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 712704. Throughput: 0: 80.3. Samples: 714900. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 14:03:00,989][60274] Avg episode reward: [(0, '200.766')]
[37m[1m[2025-06-29 14:03:00,993][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002784_712704.pth...
[36m[2025-06-29 14:03:01,050][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002704_692224.pth
[36m[2025-06-29 14:03:05,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 712704. Throughput: 0: 80.5. Samples: 715144. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 14:03:05,976][60274] Avg episode reward: [(0, '200.593')]
[36m[2025-06-29 14:03:10,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 712704. Throughput: 0: 80.1. Samples: 715612. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 14:03:10,981][60274] Avg episode reward: [(0, '205.051')]
[36m[2025-06-29 14:03:15,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 712704. Throughput: 0: 79.3. Samples: 716084. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 14:03:15,947][60274] Avg episode reward: [(0, '205.643')]
[36m[2025-06-29 14:03:20,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 712704. Throughput: 0: 80.0. Samples: 716320. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 14:03:20,960][60274] Avg episode reward: [(0, '204.405')]
[36m[2025-06-29 14:03:25,957][60274] Fps is (10 sec: 409.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 716800. Throughput: 0: 79.5. Samples: 716796. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:03:25,957][60274] Avg episode reward: [(0, '208.349')]
[36m[2025-06-29 14:03:30,978][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 716800. Throughput: 0: 78.9. Samples: 717232. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:03:30,978][60274] Avg episode reward: [(0, '194.171')]
[36m[2025-06-29 14:03:35,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 716800. Throughput: 0: 78.8. Samples: 717476. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:03:35,951][60274] Avg episode reward: [(0, '178.039')]
[36m[2025-06-29 14:03:40,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 716800. Throughput: 0: 79.4. Samples: 717976. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:03:40,988][60274] Avg episode reward: [(0, '186.945')]
[36m[2025-06-29 14:03:45,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 716800. Throughput: 0: 79.1. Samples: 718460. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:03:45,980][60274] Avg episode reward: [(0, '174.254')]
[36m[2025-06-29 14:03:50,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 716800. Throughput: 0: 78.9. Samples: 718692. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:03:50,960][60274] Avg episode reward: [(0, '170.978')]
[36m[2025-06-29 14:03:55,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 716800. Throughput: 0: 79.6. Samples: 719192. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:03:55,956][60274] Avg episode reward: [(0, '175.298')]
[36m[2025-06-29 14:04:00,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 716800. Throughput: 0: 79.1. Samples: 719644. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:04:00,966][60274] Avg episode reward: [(0, '181.996')]
[36m[2025-06-29 14:04:05,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 716800. Throughput: 0: 79.3. Samples: 719892. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:04:05,990][60274] Avg episode reward: [(0, '187.226')]
[36m[2025-06-29 14:04:10,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 716800. Throughput: 0: 80.0. Samples: 720396. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:04:10,962][60274] Avg episode reward: [(0, '191.811')]
[36m[2025-06-29 14:04:16,108][60274] Fps is (10 sec: 404.8, 60 sec: 136.2, 300 sec: 83.3). Total num frames: 720896. Throughput: 0: 81.1. Samples: 720892. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:04:16,108][60274] Avg episode reward: [(0, '185.628')]
[36m[2025-06-29 14:04:20,978][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 720896. Throughput: 0: 79.8. Samples: 721068. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:04:20,979][60274] Avg episode reward: [(0, '184.421')]
[36m[2025-06-29 14:04:25,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 720896. Throughput: 0: 79.5. Samples: 721552. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:04:25,991][60274] Avg episode reward: [(0, '179.673')]
[36m[2025-06-29 14:04:30,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 720896. Throughput: 0: 79.6. Samples: 722040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:04:30,969][60274] Avg episode reward: [(0, '172.568')]
[36m[2025-06-29 14:04:35,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 720896. Throughput: 0: 80.1. Samples: 722296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:04:35,963][60274] Avg episode reward: [(0, '176.404')]
[36m[2025-06-29 14:04:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 720896. Throughput: 0: 79.4. Samples: 722764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:04:40,947][60274] Avg episode reward: [(0, '175.718')]
[36m[2025-06-29 14:04:45,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 720896. Throughput: 0: 80.5. Samples: 723268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:04:45,982][60274] Avg episode reward: [(0, '176.903')]
[36m[2025-06-29 14:04:50,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 720896. Throughput: 0: 80.6. Samples: 723520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:04:50,989][60274] Avg episode reward: [(0, '163.205')]
[36m[2025-06-29 14:04:55,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 720896. Throughput: 0: 80.2. Samples: 724004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:04:55,961][60274] Avg episode reward: [(0, '165.285')]
[36m[2025-06-29 14:05:00,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 720896. Throughput: 0: 80.1. Samples: 724488. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:00,991][60274] Avg episode reward: [(0, '166.014')]
[37m[1m[2025-06-29 14:05:01,039][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002816_720896.pth...
[36m[2025-06-29 14:05:01,094][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002752_704512.pth
[36m[2025-06-29 14:05:05,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 720896. Throughput: 0: 81.5. Samples: 724736. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:05,994][60274] Avg episode reward: [(0, '168.061')]
[36m[2025-06-29 14:05:10,947][60274] Fps is (10 sec: 411.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 724992. Throughput: 0: 80.1. Samples: 725152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:10,948][60274] Avg episode reward: [(0, '163.355')]
[36m[2025-06-29 14:05:15,956][60274] Fps is (10 sec: 411.1, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 724992. Throughput: 0: 80.2. Samples: 725648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:15,956][60274] Avg episode reward: [(0, '163.447')]
[36m[2025-06-29 14:05:20,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 724992. Throughput: 0: 80.2. Samples: 725904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:20,975][60274] Avg episode reward: [(0, '170.410')]
[36m[2025-06-29 14:05:25,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 724992. Throughput: 0: 80.9. Samples: 726408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:25,975][60274] Avg episode reward: [(0, '177.475')]
[36m[2025-06-29 14:05:30,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 724992. Throughput: 0: 81.1. Samples: 726916. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:30,956][60274] Avg episode reward: [(0, '170.620')]
[36m[2025-06-29 14:05:35,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 724992. Throughput: 0: 80.7. Samples: 727152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:35,968][60274] Avg episode reward: [(0, '174.211')]
[36m[2025-06-29 14:05:40,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 724992. Throughput: 0: 80.8. Samples: 727640. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:40,977][60274] Avg episode reward: [(0, '162.937')]
[36m[2025-06-29 14:05:45,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 724992. Throughput: 0: 80.3. Samples: 728100. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:45,955][60274] Avg episode reward: [(0, '154.225')]
[36m[2025-06-29 14:05:50,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 724992. Throughput: 0: 80.0. Samples: 728336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:50,991][60274] Avg episode reward: [(0, '156.127')]
[36m[2025-06-29 14:05:55,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 724992. Throughput: 0: 81.9. Samples: 728840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:05:55,959][60274] Avg episode reward: [(0, '143.564')]
[36m[2025-06-29 14:06:00,984][60274] Fps is (10 sec: 409.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 729088. Throughput: 0: 80.7. Samples: 729284. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:06:00,984][60274] Avg episode reward: [(0, '147.212')]
[36m[2025-06-29 14:06:05,959][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 729088. Throughput: 0: 80.3. Samples: 729516. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:06:05,959][60274] Avg episode reward: [(0, '141.857')]
[36m[2025-06-29 14:06:10,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 729088. Throughput: 0: 80.3. Samples: 730020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:06:10,957][60274] Avg episode reward: [(0, '138.760')]
[36m[2025-06-29 14:06:15,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 729088. Throughput: 0: 79.9. Samples: 730512. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:06:15,960][60274] Avg episode reward: [(0, '146.640')]
[36m[2025-06-29 14:06:20,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 729088. Throughput: 0: 80.0. Samples: 730752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:06:20,988][60274] Avg episode reward: [(0, '145.398')]
[36m[2025-06-29 14:06:25,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 729088. Throughput: 0: 79.5. Samples: 731216. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:06:25,980][60274] Avg episode reward: [(0, '149.034')]
[36m[2025-06-29 14:06:30,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 729088. Throughput: 0: 79.4. Samples: 731672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:06:30,956][60274] Avg episode reward: [(0, '149.467')]
[36m[2025-06-29 14:06:35,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 729088. Throughput: 0: 79.1. Samples: 731896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:06:35,976][60274] Avg episode reward: [(0, '141.619')]
[31m[9226060 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[9226060 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[9226060 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:06:40,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 729088. Throughput: 0: 78.6. Samples: 732380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:06:40,985][60274] Avg episode reward: [(0, '151.098')]
[36m[2025-06-29 14:06:45,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 729088. Throughput: 0: 79.1. Samples: 732844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:06:45,989][60274] Avg episode reward: [(0, '143.978')]
[36m[2025-06-29 14:06:50,957][60274] Fps is (10 sec: 410.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 733184. Throughput: 0: 79.5. Samples: 733092. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:06:50,957][60274] Avg episode reward: [(0, '139.838')]
[36m[2025-06-29 14:06:55,978][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 733184. Throughput: 0: 78.4. Samples: 733548. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:06:55,978][60274] Avg episode reward: [(0, '144.691')]
[36m[2025-06-29 14:07:00,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 733184. Throughput: 0: 78.5. Samples: 734048. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:07:00,986][60274] Avg episode reward: [(0, '140.391')]
[37m[1m[2025-06-29 14:07:01,040][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002864_733184.pth...
[36m[2025-06-29 14:07:01,094][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002784_712704.pth
[36m[2025-06-29 14:07:05,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 733184. Throughput: 0: 78.6. Samples: 734288. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:07:05,999][60274] Avg episode reward: [(0, '141.932')]
[36m[2025-06-29 14:07:10,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 733184. Throughput: 0: 78.9. Samples: 734764. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:07:10,976][60274] Avg episode reward: [(0, '147.672')]
[36m[2025-06-29 14:07:15,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 733184. Throughput: 0: 79.5. Samples: 735248. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:07:15,946][60274] Avg episode reward: [(0, '152.478')]
[36m[2025-06-29 14:07:20,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 733184. Throughput: 0: 79.9. Samples: 735492. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:07:20,991][60274] Avg episode reward: [(0, '167.754')]
[36m[2025-06-29 14:07:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 733184. Throughput: 0: 80.2. Samples: 735988. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:07:25,979][60274] Avg episode reward: [(0, '168.400')]
[36m[2025-06-29 14:07:30,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 733184. Throughput: 0: 81.0. Samples: 736488. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:07:30,959][60274] Avg episode reward: [(0, '164.288')]
[36m[2025-06-29 14:07:35,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 733184. Throughput: 0: 80.6. Samples: 736720. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:07:35,980][60274] Avg episode reward: [(0, '170.999')]
[36m[2025-06-29 14:07:40,947][60274] Fps is (10 sec: 410.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 737280. Throughput: 0: 81.5. Samples: 737212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:07:40,947][60274] Avg episode reward: [(0, '174.417')]
[36m[2025-06-29 14:07:45,955][60274] Fps is (10 sec: 410.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 737280. Throughput: 0: 80.1. Samples: 737652. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:07:45,955][60274] Avg episode reward: [(0, '176.630')]
[36m[2025-06-29 14:07:51,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 737280. Throughput: 0: 80.0. Samples: 737888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:07:51,000][60274] Avg episode reward: [(0, '176.847')]
[36m[2025-06-29 14:07:55,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 737280. Throughput: 0: 80.4. Samples: 738380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:07:55,962][60274] Avg episode reward: [(0, '189.718')]
[36m[2025-06-29 14:08:00,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 737280. Throughput: 0: 80.2. Samples: 738860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:08:00,971][60274] Avg episode reward: [(0, '187.282')]
[36m[2025-06-29 14:08:05,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 737280. Throughput: 0: 80.5. Samples: 739112. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:08:05,973][60274] Avg episode reward: [(0, '179.825')]
[36m[2025-06-29 14:08:10,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 737280. Throughput: 0: 79.6. Samples: 739568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:08:10,970][60274] Avg episode reward: [(0, '184.638')]
[36m[2025-06-29 14:08:15,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 737280. Throughput: 0: 79.9. Samples: 740084. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:08:15,971][60274] Avg episode reward: [(0, '183.942')]
[36m[2025-06-29 14:08:20,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 737280. Throughput: 0: 80.5. Samples: 740340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:08:20,971][60274] Avg episode reward: [(0, '190.681')]
[36m[2025-06-29 14:08:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 737280. Throughput: 0: 80.4. Samples: 740832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:08:25,980][60274] Avg episode reward: [(0, '202.448')]
[36m[2025-06-29 14:08:31,561][60274] Fps is (10 sec: 386.8, 60 sec: 135.2, 300 sec: 83.1). Total num frames: 741376. Throughput: 0: 80.7. Samples: 741332. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:08:31,562][60274] Avg episode reward: [(0, '202.326')]
[36m[2025-06-29 14:08:35,951][60274] Fps is (10 sec: 410.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 741376. Throughput: 0: 80.6. Samples: 741512. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:08:35,951][60274] Avg episode reward: [(0, '203.999')]
[36m[2025-06-29 14:08:40,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 741376. Throughput: 0: 79.8. Samples: 741972. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:08:40,986][60274] Avg episode reward: [(0, '204.316')]
[36m[2025-06-29 14:08:45,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 741376. Throughput: 0: 79.9. Samples: 742456. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:08:45,986][60274] Avg episode reward: [(0, '200.862')]
[36m[2025-06-29 14:08:50,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 741376. Throughput: 0: 79.4. Samples: 742688. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:08:50,982][60274] Avg episode reward: [(0, '204.633')]
[36m[2025-06-29 14:08:55,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 741376. Throughput: 0: 80.1. Samples: 743172. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:08:55,978][60274] Avg episode reward: [(0, '205.604')]
[36m[2025-06-29 14:09:00,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 741376. Throughput: 0: 79.5. Samples: 743660. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:09:00,971][60274] Avg episode reward: [(0, '209.988')]
[37m[1m[2025-06-29 14:09:01,018][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002896_741376.pth...
[36m[2025-06-29 14:09:01,073][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002816_720896.pth
[36m[2025-06-29 14:09:05,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 741376. Throughput: 0: 78.8. Samples: 743888. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:09:05,981][60274] Avg episode reward: [(0, '214.413')]
[36m[2025-06-29 14:09:10,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 741376. Throughput: 0: 78.7. Samples: 744372. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:09:10,984][60274] Avg episode reward: [(0, '205.041')]
[36m[2025-06-29 14:09:15,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 741376. Throughput: 0: 78.8. Samples: 744832. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:09:15,961][60274] Avg episode reward: [(0, '209.357')]
[36m[2025-06-29 14:09:20,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 741376. Throughput: 0: 79.2. Samples: 745076. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-06-29 14:09:20,951][60274] Avg episode reward: [(0, '199.397')]
[36m[2025-06-29 14:09:25,973][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 745472. Throughput: 0: 78.5. Samples: 745504. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 14:09:25,973][60274] Avg episode reward: [(0, '200.218')]
[36m[2025-06-29 14:09:30,957][60274] Fps is (10 sec: 409.3, 60 sec: 69.0, 300 sec: 83.3). Total num frames: 745472. Throughput: 0: 78.2. Samples: 745972. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 14:09:30,958][60274] Avg episode reward: [(0, '200.672')]
[36m[2025-06-29 14:09:35,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 745472. Throughput: 0: 78.1. Samples: 746200. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 14:09:35,953][60274] Avg episode reward: [(0, '198.415')]
[36m[2025-06-29 14:09:40,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 745472. Throughput: 0: 78.3. Samples: 746692. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 14:09:40,958][60274] Avg episode reward: [(0, '202.543')]
[36m[2025-06-29 14:09:45,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 745472. Throughput: 0: 77.7. Samples: 747156. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 14:09:45,980][60274] Avg episode reward: [(0, '195.800')]
[36m[2025-06-29 14:09:50,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 745472. Throughput: 0: 78.1. Samples: 747404. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 14:09:50,990][60274] Avg episode reward: [(0, '192.642')]
[36m[2025-06-29 14:09:55,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 745472. Throughput: 0: 78.0. Samples: 747880. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 14:09:55,964][60274] Avg episode reward: [(0, '197.347')]
[36m[2025-06-29 14:10:00,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 745472. Throughput: 0: 78.1. Samples: 748348. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 14:10:00,955][60274] Avg episode reward: [(0, '196.254')]
[36m[2025-06-29 14:10:05,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 745472. Throughput: 0: 78.2. Samples: 748596. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 14:10:05,979][60274] Avg episode reward: [(0, '197.254')]
[36m[2025-06-29 14:10:10,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 745472. Throughput: 0: 79.5. Samples: 749080. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 14:10:10,968][60274] Avg episode reward: [(0, '195.828')]
[36m[2025-06-29 14:10:16,014][60274] Fps is (10 sec: 408.2, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 749568. Throughput: 0: 74.4. Samples: 749324. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:10:16,014][60274] Avg episode reward: [(0, '187.713')]
[36m[2025-06-29 14:10:20,959][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 749568. Throughput: 0: 79.4. Samples: 749772. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:10:20,959][60274] Avg episode reward: [(0, '186.884')]
[36m[2025-06-29 14:10:25,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 749568. Throughput: 0: 78.5. Samples: 750228. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:10:25,986][60274] Avg episode reward: [(0, '187.505')]
[36m[2025-06-29 14:10:30,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 749568. Throughput: 0: 79.0. Samples: 750708. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:10:30,962][60274] Avg episode reward: [(0, '191.109')]
[36m[2025-06-29 14:10:35,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 749568. Throughput: 0: 78.9. Samples: 750952. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:10:35,963][60274] Avg episode reward: [(0, '184.602')]
[36m[2025-06-29 14:10:41,009][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 749568. Throughput: 0: 78.8. Samples: 751428. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:10:41,009][60274] Avg episode reward: [(0, '186.318')]
[36m[2025-06-29 14:10:45,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 749568. Throughput: 0: 79.1. Samples: 751912. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:10:45,987][60274] Avg episode reward: [(0, '177.002')]
[36m[2025-06-29 14:10:50,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 749568. Throughput: 0: 78.9. Samples: 752148. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:10:50,987][60274] Avg episode reward: [(0, '169.222')]
[36m[2025-06-29 14:10:55,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 749568. Throughput: 0: 78.8. Samples: 752624. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:10:55,957][60274] Avg episode reward: [(0, '170.218')]
[36m[2025-06-29 14:11:00,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 749568. Throughput: 0: 84.2. Samples: 753108. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:11:00,952][60274] Avg episode reward: [(0, '157.437')]
[37m[1m[2025-06-29 14:11:00,999][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002928_749568.pth...
[36m[2025-06-29 14:11:01,054][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002864_733184.pth
[36m[2025-06-29 14:11:05,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 749568. Throughput: 0: 79.6. Samples: 753356. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:11:05,981][60274] Avg episode reward: [(0, '166.195')]
[36m[2025-06-29 14:11:10,958][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 753664. Throughput: 0: 79.6. Samples: 753808. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:11:10,958][60274] Avg episode reward: [(0, '172.024')]
[36m[2025-06-29 14:11:15,969][60274] Fps is (10 sec: 410.1, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 753664. Throughput: 0: 79.8. Samples: 754300. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:11:15,970][60274] Avg episode reward: [(0, '168.216')]
[36m[2025-06-29 14:11:20,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 753664. Throughput: 0: 79.8. Samples: 754544. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:11:20,998][60274] Avg episode reward: [(0, '172.869')]
[36m[2025-06-29 14:11:25,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 753664. Throughput: 0: 80.1. Samples: 755028. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:11:25,967][60274] Avg episode reward: [(0, '174.780')]
[36m[2025-06-29 14:11:30,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 753664. Throughput: 0: 80.0. Samples: 755512. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:11:30,963][60274] Avg episode reward: [(0, '172.738')]
[36m[2025-06-29 14:11:35,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 753664. Throughput: 0: 80.4. Samples: 755764. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:11:35,985][60274] Avg episode reward: [(0, '170.629')]
[36m[2025-06-29 14:11:40,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 753664. Throughput: 0: 80.8. Samples: 756264. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:11:40,991][60274] Avg episode reward: [(0, '167.795')]
[36m[2025-06-29 14:11:45,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 753664. Throughput: 0: 80.9. Samples: 756748. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:11:45,971][60274] Avg episode reward: [(0, '159.848')]
[36m[2025-06-29 14:11:50,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 753664. Throughput: 0: 80.9. Samples: 756996. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:11:50,948][60274] Avg episode reward: [(0, '166.283')]
[36m[2025-06-29 14:11:55,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 753664. Throughput: 0: 81.4. Samples: 757472. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:11:55,977][60274] Avg episode reward: [(0, '168.887')]
[36m[2025-06-29 14:12:00,989][60274] Fps is (10 sec: 407.9, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 757760. Throughput: 0: 79.6. Samples: 757884. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:00,989][60274] Avg episode reward: [(0, '166.132')]
[36m[2025-06-29 14:12:05,953][60274] Fps is (10 sec: 410.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 757760. Throughput: 0: 79.9. Samples: 758136. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:05,953][60274] Avg episode reward: [(0, '158.533')]
[36m[2025-06-29 14:12:10,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 757760. Throughput: 0: 79.5. Samples: 758608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:10,987][60274] Avg episode reward: [(0, '156.377')]
[36m[2025-06-29 14:12:15,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 757760. Throughput: 0: 79.2. Samples: 759076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:15,976][60274] Avg episode reward: [(0, '153.073')]
[36m[2025-06-29 14:12:20,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 757760. Throughput: 0: 79.4. Samples: 759336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:20,960][60274] Avg episode reward: [(0, '165.294')]
[36m[2025-06-29 14:12:25,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 757760. Throughput: 0: 79.0. Samples: 759820. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:25,989][60274] Avg episode reward: [(0, '166.010')]
[36m[2025-06-29 14:12:30,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 757760. Throughput: 0: 79.3. Samples: 760316. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:30,992][60274] Avg episode reward: [(0, '166.025')]
[31m[9580521 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[9580521 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[9580521 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:12:35,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 757760. Throughput: 0: 78.9. Samples: 760548. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:35,973][60274] Avg episode reward: [(0, '176.473')]
[36m[2025-06-29 14:12:40,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 757760. Throughput: 0: 80.0. Samples: 761072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:40,963][60274] Avg episode reward: [(0, '170.904')]
[36m[2025-06-29 14:12:45,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 757760. Throughput: 0: 81.2. Samples: 761536. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:45,962][60274] Avg episode reward: [(0, '168.081')]
[36m[2025-06-29 14:12:50,967][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 761856. Throughput: 0: 81.0. Samples: 761784. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:50,968][60274] Avg episode reward: [(0, '173.055')]
[36m[2025-06-29 14:12:55,952][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 761856. Throughput: 0: 80.0. Samples: 762204. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:12:55,952][60274] Avg episode reward: [(0, '165.067')]
[36m[2025-06-29 14:13:00,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 761856. Throughput: 0: 80.6. Samples: 762704. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:00,985][60274] Avg episode reward: [(0, '171.685')]
[37m[1m[2025-06-29 14:13:01,033][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002976_761856.pth...
[36m[2025-06-29 14:13:01,089][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002896_741376.pth
[36m[2025-06-29 14:13:05,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 761856. Throughput: 0: 79.5. Samples: 762916. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:05,965][60274] Avg episode reward: [(0, '171.349')]
[36m[2025-06-29 14:13:10,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 761856. Throughput: 0: 79.7. Samples: 763404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:10,955][60274] Avg episode reward: [(0, '172.425')]
[36m[2025-06-29 14:13:15,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 761856. Throughput: 0: 79.8. Samples: 763908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:15,990][60274] Avg episode reward: [(0, '175.320')]
[36m[2025-06-29 14:13:20,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 761856. Throughput: 0: 79.8. Samples: 764140. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:20,972][60274] Avg episode reward: [(0, '170.661')]
[36m[2025-06-29 14:13:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 761856. Throughput: 0: 79.1. Samples: 764632. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:25,979][60274] Avg episode reward: [(0, '166.932')]
[36m[2025-06-29 14:13:30,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 761856. Throughput: 0: 78.9. Samples: 765088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:30,983][60274] Avg episode reward: [(0, '170.247')]
[36m[2025-06-29 14:13:35,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 761856. Throughput: 0: 78.6. Samples: 765320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:35,976][60274] Avg episode reward: [(0, '171.075')]
[36m[2025-06-29 14:13:40,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 761856. Throughput: 0: 80.3. Samples: 765816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:40,948][60274] Avg episode reward: [(0, '168.198')]
[36m[2025-06-29 14:13:45,964][60274] Fps is (10 sec: 410.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 765952. Throughput: 0: 79.2. Samples: 766268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:45,964][60274] Avg episode reward: [(0, '172.912')]
[36m[2025-06-29 14:13:50,969][60274] Fps is (10 sec: 408.8, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 765952. Throughput: 0: 79.6. Samples: 766500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:50,969][60274] Avg episode reward: [(0, '166.142')]
[36m[2025-06-29 14:13:55,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 765952. Throughput: 0: 78.9. Samples: 766956. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:13:55,979][60274] Avg episode reward: [(0, '168.572')]
[36m[2025-06-29 14:14:00,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 765952. Throughput: 0: 78.4. Samples: 767432. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:14:00,962][60274] Avg episode reward: [(0, '163.588')]
[36m[2025-06-29 14:14:05,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 765952. Throughput: 0: 78.4. Samples: 767668. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:14:05,995][60274] Avg episode reward: [(0, '163.761')]
[36m[2025-06-29 14:14:10,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 765952. Throughput: 0: 78.2. Samples: 768152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:14:10,978][60274] Avg episode reward: [(0, '154.441')]
[36m[2025-06-29 14:14:15,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 765952. Throughput: 0: 78.8. Samples: 768632. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:14:15,950][60274] Avg episode reward: [(0, '150.610')]
[36m[2025-06-29 14:14:20,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 765952. Throughput: 0: 78.6. Samples: 768856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:14:20,988][60274] Avg episode reward: [(0, '160.982')]
[36m[2025-06-29 14:14:25,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 765952. Throughput: 0: 78.3. Samples: 769340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:14:25,975][60274] Avg episode reward: [(0, '161.856')]
[36m[2025-06-29 14:14:30,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 765952. Throughput: 0: 78.6. Samples: 769804. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:14:30,949][60274] Avg episode reward: [(0, '159.627')]
[36m[2025-06-29 14:14:35,964][60274] Fps is (10 sec: 410.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 770048. Throughput: 0: 78.8. Samples: 770044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:14:35,964][60274] Avg episode reward: [(0, '169.831')]
[31m[9704850 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[9704851 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[9704851 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:14:40,980][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 770048. Throughput: 0: 77.7. Samples: 770452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:14:40,980][60274] Avg episode reward: [(0, '174.737')]
[36m[2025-06-29 14:14:45,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 770048. Throughput: 0: 77.4. Samples: 770916. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:14:45,957][60274] Avg episode reward: [(0, '178.024')]
[36m[2025-06-29 14:14:50,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 770048. Throughput: 0: 76.9. Samples: 771128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:14:50,987][60274] Avg episode reward: [(0, '184.908')]
[36m[2025-06-29 14:14:55,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 770048. Throughput: 0: 76.1. Samples: 771580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:14:55,995][60274] Avg episode reward: [(0, '182.532')]
[36m[2025-06-29 14:15:00,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 770048. Throughput: 0: 75.6. Samples: 772036. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:15:00,979][60274] Avg episode reward: [(0, '188.624')]
[37m[1m[2025-06-29 14:15:01,028][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003008_770048.pth...
[36m[2025-06-29 14:15:01,083][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002928_749568.pth
[36m[2025-06-29 14:15:05,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 770048. Throughput: 0: 76.1. Samples: 772280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:15:05,980][60274] Avg episode reward: [(0, '187.186')]
[36m[2025-06-29 14:15:10,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 770048. Throughput: 0: 75.7. Samples: 772748. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:15:10,975][60274] Avg episode reward: [(0, '186.558')]
[36m[2025-06-29 14:15:16,014][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 770048. Throughput: 0: 76.0. Samples: 773228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:15:16,014][60274] Avg episode reward: [(0, '185.151')]
[36m[2025-06-29 14:15:20,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 770048. Throughput: 0: 76.1. Samples: 773468. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:15:20,967][60274] Avg episode reward: [(0, '189.933')]
[36m[2025-06-29 14:15:25,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 770048. Throughput: 0: 77.1. Samples: 773920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:15:25,971][60274] Avg episode reward: [(0, '195.615')]
[36m[2025-06-29 14:15:30,985][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 774144. Throughput: 0: 76.1. Samples: 774344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:15:30,985][60274] Avg episode reward: [(0, '196.393')]
[36m[2025-06-29 14:15:35,979][60274] Fps is (10 sec: 409.3, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 774144. Throughput: 0: 76.9. Samples: 774588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:15:35,979][60274] Avg episode reward: [(0, '196.860')]
[36m[2025-06-29 14:15:40,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 774144. Throughput: 0: 77.8. Samples: 775076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:15:40,952][60274] Avg episode reward: [(0, '186.954')]
[36m[2025-06-29 14:15:45,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 774144. Throughput: 0: 78.2. Samples: 775556. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:15:45,991][60274] Avg episode reward: [(0, '198.540')]
[36m[2025-06-29 14:15:51,013][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 774144. Throughput: 0: 77.8. Samples: 775784. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:15:51,013][60274] Avg episode reward: [(0, '210.053')]
[36m[2025-06-29 14:15:55,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 774144. Throughput: 0: 77.9. Samples: 776252. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:15:55,950][60274] Avg episode reward: [(0, '214.769')]
[36m[2025-06-29 14:16:01,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 774144. Throughput: 0: 77.8. Samples: 776728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:16:01,001][60274] Avg episode reward: [(0, '222.226')]
[36m[2025-06-29 14:16:05,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 774144. Throughput: 0: 77.9. Samples: 776972. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:16:05,951][60274] Avg episode reward: [(0, '222.334')]
[36m[2025-06-29 14:16:10,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 774144. Throughput: 0: 77.9. Samples: 777428. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:16:10,989][60274] Avg episode reward: [(0, '225.293')]
[36m[2025-06-29 14:16:15,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 774144. Throughput: 0: 79.3. Samples: 777912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:16:15,976][60274] Avg episode reward: [(0, '230.006')]
[36m[2025-06-29 14:16:20,954][60274] Fps is (10 sec: 411.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 778240. Throughput: 0: 79.5. Samples: 778164. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:16:20,954][60274] Avg episode reward: [(0, '217.444')]
[36m[2025-06-29 14:16:25,992][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 778240. Throughput: 0: 78.2. Samples: 778600. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:16:25,992][60274] Avg episode reward: [(0, '218.942')]
[36m[2025-06-29 14:16:30,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 778240. Throughput: 0: 78.3. Samples: 779076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:16:30,968][60274] Avg episode reward: [(0, '214.648')]
[31m[9817812 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[9817813 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[9817813 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:16:35,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 778240. Throughput: 0: 78.4. Samples: 779308. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:16:35,959][60274] Avg episode reward: [(0, '203.143')]
[36m[2025-06-29 14:16:40,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 778240. Throughput: 0: 79.1. Samples: 779812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:16:40,957][60274] Avg episode reward: [(0, '200.115')]
[36m[2025-06-29 14:16:45,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 778240. Throughput: 0: 79.4. Samples: 780300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:16:45,988][60274] Avg episode reward: [(0, '192.607')]
[36m[2025-06-29 14:16:50,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 778240. Throughput: 0: 79.4. Samples: 780544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:16:50,967][60274] Avg episode reward: [(0, '178.431')]
[36m[2025-06-29 14:16:55,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 778240. Throughput: 0: 80.3. Samples: 781040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:16:55,973][60274] Avg episode reward: [(0, '178.531')]
[36m[2025-06-29 14:17:00,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 778240. Throughput: 0: 79.9. Samples: 781508. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:17:00,976][60274] Avg episode reward: [(0, '188.269')]
[37m[1m[2025-06-29 14:17:01,026][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003040_778240.pth...
[36m[2025-06-29 14:17:01,086][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000002976_761856.pth
[36m[2025-06-29 14:17:05,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 778240. Throughput: 0: 79.6. Samples: 781748. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:17:05,984][60274] Avg episode reward: [(0, '185.614')]
[36m[2025-06-29 14:17:11,481][60274] Fps is (10 sec: 389.9, 60 sec: 135.4, 300 sec: 83.2). Total num frames: 782336. Throughput: 0: 79.7. Samples: 782224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:17:11,482][60274] Avg episode reward: [(0, '194.782')]
[36m[2025-06-29 14:17:15,973][60274] Fps is (10 sec: 410.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 782336. Throughput: 0: 79.3. Samples: 782644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:17:15,973][60274] Avg episode reward: [(0, '184.535')]
[36m[2025-06-29 14:17:20,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 782336. Throughput: 0: 79.9. Samples: 782904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:17:20,959][60274] Avg episode reward: [(0, '191.442')]
[36m[2025-06-29 14:17:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 782336. Throughput: 0: 79.5. Samples: 783392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:17:25,967][60274] Avg episode reward: [(0, '183.897')]
[36m[2025-06-29 14:17:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 782336. Throughput: 0: 79.6. Samples: 783884. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:17:30,989][60274] Avg episode reward: [(0, '181.366')]
[36m[2025-06-29 14:17:35,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 782336. Throughput: 0: 80.0. Samples: 784144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:17:35,949][60274] Avg episode reward: [(0, '179.466')]
[36m[2025-06-29 14:17:40,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 782336. Throughput: 0: 79.5. Samples: 784616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:17:40,979][60274] Avg episode reward: [(0, '175.548')]
[36m[2025-06-29 14:17:45,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 782336. Throughput: 0: 79.9. Samples: 785104. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:17:45,990][60274] Avg episode reward: [(0, '171.998')]
[36m[2025-06-29 14:17:50,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 782336. Throughput: 0: 79.9. Samples: 785344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:17:50,997][60274] Avg episode reward: [(0, '174.774')]
[36m[2025-06-29 14:17:55,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 782336. Throughput: 0: 80.8. Samples: 785820. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:17:55,986][60274] Avg episode reward: [(0, '177.242')]
[36m[2025-06-29 14:18:00,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 782336. Throughput: 0: 81.3. Samples: 786304. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:18:00,970][60274] Avg episode reward: [(0, '172.205')]
[36m[2025-06-29 14:18:05,961][60274] Fps is (10 sec: 410.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 786432. Throughput: 0: 79.6. Samples: 786484. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:18:05,962][60274] Avg episode reward: [(0, '186.968')]
[36m[2025-06-29 14:18:10,978][60274] Fps is (10 sec: 409.2, 60 sec: 68.8, 300 sec: 83.3). Total num frames: 786432. Throughput: 0: 80.0. Samples: 786992. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:18:10,978][60274] Avg episode reward: [(0, '189.447')]
[36m[2025-06-29 14:18:15,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 786432. Throughput: 0: 80.0. Samples: 787480. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:18:15,955][60274] Avg episode reward: [(0, '185.551')]
[36m[2025-06-29 14:18:20,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 786432. Throughput: 0: 79.3. Samples: 787712. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:18:20,970][60274] Avg episode reward: [(0, '182.307')]
[36m[2025-06-29 14:18:25,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 786432. Throughput: 0: 79.0. Samples: 788172. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:18:25,980][60274] Avg episode reward: [(0, '185.932')]
[36m[2025-06-29 14:18:30,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 786432. Throughput: 0: 79.3. Samples: 788672. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:18:30,978][60274] Avg episode reward: [(0, '196.250')]
[36m[2025-06-29 14:18:35,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 786432. Throughput: 0: 79.2. Samples: 788908. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:18:35,992][60274] Avg episode reward: [(0, '199.725')]
[36m[2025-06-29 14:18:40,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 786432. Throughput: 0: 79.4. Samples: 789392. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:18:40,987][60274] Avg episode reward: [(0, '202.966')]
[36m[2025-06-29 14:18:45,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 786432. Throughput: 0: 79.5. Samples: 789880. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:18:45,956][60274] Avg episode reward: [(0, '216.071')]
[36m[2025-06-29 14:18:50,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 786432. Throughput: 0: 81.1. Samples: 790132. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:18:50,953][60274] Avg episode reward: [(0, '220.304')]
[36m[2025-06-29 14:18:55,956][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 790528. Throughput: 0: 79.1. Samples: 790552. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 14:18:55,957][60274] Avg episode reward: [(0, '217.240')]
[36m[2025-06-29 14:19:00,950][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 790528. Throughput: 0: 79.0. Samples: 791036. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 14:19:00,951][60274] Avg episode reward: [(0, '212.314')]
[37m[1m[2025-06-29 14:19:01,001][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003088_790528.pth...
[36m[2025-06-29 14:19:01,060][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003008_770048.pth
[36m[2025-06-29 14:19:05,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 790528. Throughput: 0: 79.0. Samples: 791268. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 14:19:05,955][60274] Avg episode reward: [(0, '218.502')]
[36m[2025-06-29 14:19:10,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 790528. Throughput: 0: 79.4. Samples: 791748. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 14:19:10,992][60274] Avg episode reward: [(0, '216.284')]
[36m[2025-06-29 14:19:15,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 790528. Throughput: 0: 78.9. Samples: 792220. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 14:19:15,973][60274] Avg episode reward: [(0, '211.726')]
[36m[2025-06-29 14:19:20,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 790528. Throughput: 0: 78.9. Samples: 792456. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 14:19:20,978][60274] Avg episode reward: [(0, '200.424')]
[36m[2025-06-29 14:19:25,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 790528. Throughput: 0: 79.3. Samples: 792960. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 14:19:25,978][60274] Avg episode reward: [(0, '210.967')]
[36m[2025-06-29 14:19:30,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 790528. Throughput: 0: 79.1. Samples: 793440. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 14:19:30,962][60274] Avg episode reward: [(0, '199.893')]
[36m[2025-06-29 14:19:35,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 790528. Throughput: 0: 78.9. Samples: 793684. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 14:19:35,949][60274] Avg episode reward: [(0, '204.760')]
[36m[2025-06-29 14:19:40,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 790528. Throughput: 0: 79.7. Samples: 794140. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-06-29 14:19:40,978][60274] Avg episode reward: [(0, '195.288')]
[36m[2025-06-29 14:19:46,015][60274] Fps is (10 sec: 406.9, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 794624. Throughput: 0: 79.7. Samples: 794628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:19:46,015][60274] Avg episode reward: [(0, '194.320')]
[36m[2025-06-29 14:19:50,955][60274] Fps is (10 sec: 410.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 794624. Throughput: 0: 78.8. Samples: 794816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:19:50,956][60274] Avg episode reward: [(0, '185.372')]
[36m[2025-06-29 14:19:55,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 794624. Throughput: 0: 79.3. Samples: 795312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:19:55,951][60274] Avg episode reward: [(0, '178.529')]
[36m[2025-06-29 14:20:00,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 794624. Throughput: 0: 79.5. Samples: 795796. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:20:00,966][60274] Avg episode reward: [(0, '177.349')]
[36m[2025-06-29 14:20:05,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 794624. Throughput: 0: 79.8. Samples: 796044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:20:05,960][60274] Avg episode reward: [(0, '177.237')]
[36m[2025-06-29 14:20:10,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 794624. Throughput: 0: 79.6. Samples: 796544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:20:10,982][60274] Avg episode reward: [(0, '179.103')]
[36m[2025-06-29 14:20:15,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 794624. Throughput: 0: 79.6. Samples: 797024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:20:15,967][60274] Avg episode reward: [(0, '188.424')]
[36m[2025-06-29 14:20:20,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 794624. Throughput: 0: 79.9. Samples: 797280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:20:20,953][60274] Avg episode reward: [(0, '178.569')]
[36m[2025-06-29 14:20:25,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 794624. Throughput: 0: 80.2. Samples: 797748. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:20:25,953][60274] Avg episode reward: [(0, '177.580')]
[36m[2025-06-29 14:20:30,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 794624. Throughput: 0: 80.1. Samples: 798228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:20:30,946][60274] Avg episode reward: [(0, '178.092')]
[36m[2025-06-29 14:20:35,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 794624. Throughput: 0: 81.5. Samples: 798484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:20:35,962][60274] Avg episode reward: [(0, '166.219')]
[36m[2025-06-29 14:20:40,969][60274] Fps is (10 sec: 408.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 798720. Throughput: 0: 79.7. Samples: 798900. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:20:40,969][60274] Avg episode reward: [(0, '167.483')]
[36m[2025-06-29 14:20:45,976][60274] Fps is (10 sec: 409.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 798720. Throughput: 0: 79.4. Samples: 799372. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:20:45,976][60274] Avg episode reward: [(0, '169.909')]
[36m[2025-06-29 14:20:50,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 798720. Throughput: 0: 79.1. Samples: 799608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:20:50,996][60274] Avg episode reward: [(0, '168.721')]
[36m[2025-06-29 14:20:55,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 798720. Throughput: 0: 79.0. Samples: 800096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:20:55,960][60274] Avg episode reward: [(0, '158.602')]
[36m[2025-06-29 14:21:00,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 798720. Throughput: 0: 79.1. Samples: 800584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:21:00,952][60274] Avg episode reward: [(0, '166.359')]
[37m[1m[2025-06-29 14:21:01,006][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003120_798720.pth...
[36m[2025-06-29 14:21:01,062][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003040_778240.pth
[36m[2025-06-29 14:21:05,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 798720. Throughput: 0: 78.7. Samples: 800820. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:21:05,961][60274] Avg episode reward: [(0, '167.865')]
[36m[2025-06-29 14:21:10,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 798720. Throughput: 0: 79.4. Samples: 801324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:21:10,983][60274] Avg episode reward: [(0, '186.390')]
[36m[2025-06-29 14:21:15,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 798720. Throughput: 0: 79.6. Samples: 801812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:21:15,968][60274] Avg episode reward: [(0, '182.701')]
[36m[2025-06-29 14:21:20,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 798720. Throughput: 0: 79.2. Samples: 802052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:21:20,987][60274] Avg episode reward: [(0, '190.929')]
[36m[2025-06-29 14:21:25,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 798720. Throughput: 0: 81.0. Samples: 802544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:21:25,969][60274] Avg episode reward: [(0, '197.688')]
[36m[2025-06-29 14:21:30,968][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 802816. Throughput: 0: 80.1. Samples: 802976. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:21:30,968][60274] Avg episode reward: [(0, '201.731')]
[36m[2025-06-29 14:21:35,978][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 802816. Throughput: 0: 80.5. Samples: 803228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:21:35,978][60274] Avg episode reward: [(0, '206.842')]
[36m[2025-06-29 14:21:40,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 802816. Throughput: 0: 79.8. Samples: 803684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:21:40,950][60274] Avg episode reward: [(0, '197.758')]
[36m[2025-06-29 14:21:45,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 802816. Throughput: 0: 79.7. Samples: 804172. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:21:45,989][60274] Avg episode reward: [(0, '208.865')]
[36m[2025-06-29 14:21:50,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 802816. Throughput: 0: 79.9. Samples: 804416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:21:50,967][60274] Avg episode reward: [(0, '203.646')]
[36m[2025-06-29 14:21:55,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 802816. Throughput: 0: 79.7. Samples: 804908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:21:55,960][60274] Avg episode reward: [(0, '201.192')]
[36m[2025-06-29 14:22:00,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 802816. Throughput: 0: 79.3. Samples: 805380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:00,951][60274] Avg episode reward: [(0, '200.077')]
[36m[2025-06-29 14:22:05,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.5). Total num frames: 802816. Throughput: 0: 79.8. Samples: 805644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:05,981][60274] Avg episode reward: [(0, '199.695')]
[36m[2025-06-29 14:22:10,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 802816. Throughput: 0: 79.5. Samples: 806120. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:10,978][60274] Avg episode reward: [(0, '198.787')]
[36m[2025-06-29 14:22:15,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 802816. Throughput: 0: 80.6. Samples: 806604. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:15,956][60274] Avg episode reward: [(0, '200.356')]
[31m[10162203 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[10162203 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[10162204 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:22:20,971][60274] Fps is (10 sec: 409.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 806912. Throughput: 0: 80.3. Samples: 806840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:20,971][60274] Avg episode reward: [(0, '192.567')]
[36m[2025-06-29 14:22:25,953][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 806912. Throughput: 0: 79.6. Samples: 807268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:25,953][60274] Avg episode reward: [(0, '199.719')]
[36m[2025-06-29 14:22:30,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 806912. Throughput: 0: 79.5. Samples: 807748. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:30,968][60274] Avg episode reward: [(0, '192.525')]
[36m[2025-06-29 14:22:35,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 806912. Throughput: 0: 79.0. Samples: 807972. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:35,980][60274] Avg episode reward: [(0, '205.720')]
[36m[2025-06-29 14:22:40,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 806912. Throughput: 0: 78.5. Samples: 808444. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:40,984][60274] Avg episode reward: [(0, '196.015')]
[36m[2025-06-29 14:22:45,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 806912. Throughput: 0: 78.7. Samples: 808920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:45,956][60274] Avg episode reward: [(0, '197.453')]
[36m[2025-06-29 14:22:50,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 806912. Throughput: 0: 78.5. Samples: 809176. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:50,990][60274] Avg episode reward: [(0, '202.673')]
[36m[2025-06-29 14:22:55,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 806912. Throughput: 0: 78.8. Samples: 809664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:22:55,948][60274] Avg episode reward: [(0, '208.320')]
[36m[2025-06-29 14:23:00,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 806912. Throughput: 0: 78.8. Samples: 810152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:23:00,975][60274] Avg episode reward: [(0, '202.134')]
[37m[1m[2025-06-29 14:23:01,034][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003152_806912.pth...
[36m[2025-06-29 14:23:01,093][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003088_790528.pth
[36m[2025-06-29 14:23:05,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 806912. Throughput: 0: 78.9. Samples: 810392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:23:05,962][60274] Avg episode reward: [(0, '194.288')]
[36m[2025-06-29 14:23:10,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 806912. Throughput: 0: 79.6. Samples: 810852. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:23:10,985][60274] Avg episode reward: [(0, '195.568')]
[31m[10219982 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[10219982 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[10219982 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:23:15,968][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 811008. Throughput: 0: 78.6. Samples: 811284. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:23:15,968][60274] Avg episode reward: [(0, '190.514')]
[36m[2025-06-29 14:23:20,950][60274] Fps is (10 sec: 411.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 811008. Throughput: 0: 78.8. Samples: 811516. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:23:20,950][60274] Avg episode reward: [(0, '181.846')]
[36m[2025-06-29 14:23:25,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 811008. Throughput: 0: 79.0. Samples: 811996. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:23:25,959][60274] Avg episode reward: [(0, '193.240')]
[36m[2025-06-29 14:23:30,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 811008. Throughput: 0: 79.4. Samples: 812492. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:23:30,951][60274] Avg episode reward: [(0, '207.322')]
[36m[2025-06-29 14:23:35,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 811008. Throughput: 0: 78.9. Samples: 812724. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:23:35,954][60274] Avg episode reward: [(0, '201.166')]
[36m[2025-06-29 14:23:40,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 811008. Throughput: 0: 78.9. Samples: 813220. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:23:40,998][60274] Avg episode reward: [(0, '198.351')]
[36m[2025-06-29 14:23:45,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 811008. Throughput: 0: 78.7. Samples: 813692. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:23:45,956][60274] Avg episode reward: [(0, '194.156')]
[36m[2025-06-29 14:23:50,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 811008. Throughput: 0: 78.9. Samples: 813940. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:23:50,948][60274] Avg episode reward: [(0, '183.270')]
[36m[2025-06-29 14:23:55,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 811008. Throughput: 0: 79.1. Samples: 814412. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:23:55,983][60274] Avg episode reward: [(0, '175.961')]
[36m[2025-06-29 14:24:00,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 811008. Throughput: 0: 80.3. Samples: 814896. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:24:00,963][60274] Avg episode reward: [(0, '186.713')]
[36m[2025-06-29 14:24:05,955][60274] Fps is (10 sec: 410.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 815104. Throughput: 0: 79.9. Samples: 815112. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:24:05,955][60274] Avg episode reward: [(0, '172.162')]
[36m[2025-06-29 14:24:10,970][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 815104. Throughput: 0: 79.8. Samples: 815588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:24:10,970][60274] Avg episode reward: [(0, '186.693')]
[36m[2025-06-29 14:24:15,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 815104. Throughput: 0: 79.5. Samples: 816072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:24:15,962][60274] Avg episode reward: [(0, '183.204')]
[36m[2025-06-29 14:24:21,006][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 815104. Throughput: 0: 79.3. Samples: 816296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:24:21,007][60274] Avg episode reward: [(0, '179.917')]
[36m[2025-06-29 14:24:25,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 815104. Throughput: 0: 79.7. Samples: 816804. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:24:25,960][60274] Avg episode reward: [(0, '177.231')]
[36m[2025-06-29 14:24:30,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 815104. Throughput: 0: 79.6. Samples: 817276. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:24:30,961][60274] Avg episode reward: [(0, '182.842')]
[36m[2025-06-29 14:24:35,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 815104. Throughput: 0: 79.7. Samples: 817528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:24:35,979][60274] Avg episode reward: [(0, '183.236')]
[36m[2025-06-29 14:24:41,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 815104. Throughput: 0: 80.1. Samples: 818020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:24:41,007][60274] Avg episode reward: [(0, '172.953')]
[36m[2025-06-29 14:24:45,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 815104. Throughput: 0: 80.1. Samples: 818500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:24:45,959][60274] Avg episode reward: [(0, '169.076')]
[36m[2025-06-29 14:24:50,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 815104. Throughput: 0: 81.1. Samples: 818764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:24:50,979][60274] Avg episode reward: [(0, '162.411')]
[36m[2025-06-29 14:24:55,966][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 819200. Throughput: 0: 80.6. Samples: 819216. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:24:55,966][60274] Avg episode reward: [(0, '172.150')]
[36m[2025-06-29 14:25:00,963][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 819200. Throughput: 0: 80.6. Samples: 819700. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:25:00,964][60274] Avg episode reward: [(0, '172.971')]
[37m[1m[2025-06-29 14:25:01,022][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003200_819200.pth...
[36m[2025-06-29 14:25:01,077][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003120_798720.pth
[36m[2025-06-29 14:25:05,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 819200. Throughput: 0: 81.1. Samples: 819940. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:25:05,947][60274] Avg episode reward: [(0, '177.849')]
[36m[2025-06-29 14:25:10,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 819200. Throughput: 0: 80.5. Samples: 820424. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:25:10,951][60274] Avg episode reward: [(0, '189.181')]
[36m[2025-06-29 14:25:15,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 819200. Throughput: 0: 80.9. Samples: 820920. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:25:15,989][60274] Avg episode reward: [(0, '180.568')]
[36m[2025-06-29 14:25:20,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 819200. Throughput: 0: 80.6. Samples: 821156. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:25:20,992][60274] Avg episode reward: [(0, '183.531')]
[36m[2025-06-29 14:25:25,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 819200. Throughput: 0: 80.9. Samples: 821656. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:25:25,977][60274] Avg episode reward: [(0, '173.888')]
[36m[2025-06-29 14:25:30,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 819200. Throughput: 0: 80.6. Samples: 822128. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:25:30,956][60274] Avg episode reward: [(0, '185.036')]
[36m[2025-06-29 14:25:35,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 819200. Throughput: 0: 80.0. Samples: 822364. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:25:35,980][60274] Avg episode reward: [(0, '188.577')]
[36m[2025-06-29 14:25:40,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 819200. Throughput: 0: 81.1. Samples: 822864. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:25:40,952][60274] Avg episode reward: [(0, '195.648')]
[36m[2025-06-29 14:25:45,974][60274] Fps is (10 sec: 409.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 823296. Throughput: 0: 80.1. Samples: 823304. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:25:45,974][60274] Avg episode reward: [(0, '200.759')]
[36m[2025-06-29 14:25:51,011][60274] Fps is (10 sec: 407.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 823296. Throughput: 0: 79.6. Samples: 823528. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:25:51,011][60274] Avg episode reward: [(0, '201.805')]
[36m[2025-06-29 14:25:55,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 823296. Throughput: 0: 78.9. Samples: 823976. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:25:55,948][60274] Avg episode reward: [(0, '204.483')]
[36m[2025-06-29 14:26:00,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 823296. Throughput: 0: 79.0. Samples: 824476. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:26:00,989][60274] Avg episode reward: [(0, '205.250')]
[36m[2025-06-29 14:26:05,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 823296. Throughput: 0: 79.4. Samples: 824728. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:26:05,963][60274] Avg episode reward: [(0, '197.584')]
[36m[2025-06-29 14:26:10,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 823296. Throughput: 0: 78.5. Samples: 825188. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:26:10,952][60274] Avg episode reward: [(0, '195.269')]
[36m[2025-06-29 14:26:15,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 823296. Throughput: 0: 79.0. Samples: 825684. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:26:15,957][60274] Avg episode reward: [(0, '192.271')]
[36m[2025-06-29 14:26:20,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 823296. Throughput: 0: 79.1. Samples: 825924. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:26:20,961][60274] Avg episode reward: [(0, '204.701')]
[36m[2025-06-29 14:26:25,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 823296. Throughput: 0: 78.8. Samples: 826412. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:26:25,975][60274] Avg episode reward: [(0, '204.492')]
[36m[2025-06-29 14:26:30,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 823296. Throughput: 0: 79.4. Samples: 826876. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:26:30,962][60274] Avg episode reward: [(0, '203.191')]
[36m[2025-06-29 14:26:35,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 823296. Throughput: 0: 80.0. Samples: 827124. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 14:26:35,975][60274] Avg episode reward: [(0, '191.131')]
[36m[2025-06-29 14:26:40,962][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 827392. Throughput: 0: 79.4. Samples: 827548. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:26:40,962][60274] Avg episode reward: [(0, '192.778')]
[36m[2025-06-29 14:26:45,980][60274] Fps is (10 sec: 409.4, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 827392. Throughput: 0: 79.2. Samples: 828040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:26:45,980][60274] Avg episode reward: [(0, '190.949')]
[36m[2025-06-29 14:26:50,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 827392. Throughput: 0: 78.9. Samples: 828280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:26:50,981][60274] Avg episode reward: [(0, '191.647')]
[33m[10436805 ms][navigation_task] - WARNING : Curriculum Level: 36, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[10436805 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.662109375
[33mCrash Rate: 0.25732421875
[33mTimeout Rate: 0.08056640625 (navigation_task.py:265)
[33m[10436805 ms][navigation_task] - WARNING : 
[33mSuccesses: 1356
[33mCrashes : 527
[33mTimeouts: 165 (navigation_task.py:268)
[36m[2025-06-29 14:26:55,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 827392. Throughput: 0: 80.1. Samples: 828792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:26:55,955][60274] Avg episode reward: [(0, '190.674')]
[36m[2025-06-29 14:27:00,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 827392. Throughput: 0: 79.5. Samples: 829260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:27:00,965][60274] Avg episode reward: [(0, '197.521')]
[37m[1m[2025-06-29 14:27:01,013][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003232_827392.pth...
[36m[2025-06-29 14:27:01,068][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003152_806912.pth
[36m[2025-06-29 14:27:05,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 827392. Throughput: 0: 79.3. Samples: 829496. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:27:05,981][60274] Avg episode reward: [(0, '195.865')]
[36m[2025-06-29 14:27:10,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 827392. Throughput: 0: 79.6. Samples: 829996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:27:10,987][60274] Avg episode reward: [(0, '173.571')]
[36m[2025-06-29 14:27:15,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 827392. Throughput: 0: 80.6. Samples: 830500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:27:15,949][60274] Avg episode reward: [(0, '177.723')]
[36m[2025-06-29 14:27:20,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 827392. Throughput: 0: 80.7. Samples: 830756. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:27:20,981][60274] Avg episode reward: [(0, '177.352')]
[36m[2025-06-29 14:27:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 827392. Throughput: 0: 81.7. Samples: 831224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:27:25,966][60274] Avg episode reward: [(0, '184.253')]
[36m[2025-06-29 14:27:30,967][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 831488. Throughput: 0: 80.1. Samples: 831644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:27:30,967][60274] Avg episode reward: [(0, '174.226')]
[36m[2025-06-29 14:27:35,987][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 831488. Throughput: 0: 80.3. Samples: 831892. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:27:35,987][60274] Avg episode reward: [(0, '182.211')]
[36m[2025-06-29 14:27:40,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 831488. Throughput: 0: 79.6. Samples: 832376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:27:40,953][60274] Avg episode reward: [(0, '174.298')]
[36m[2025-06-29 14:27:45,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 831488. Throughput: 0: 80.4. Samples: 832876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:27:45,955][60274] Avg episode reward: [(0, '177.505')]
[36m[2025-06-29 14:27:50,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 831488. Throughput: 0: 80.5. Samples: 833120. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:27:50,988][60274] Avg episode reward: [(0, '171.919')]
[36m[2025-06-29 14:27:55,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 831488. Throughput: 0: 80.3. Samples: 833608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:27:55,989][60274] Avg episode reward: [(0, '174.795')]
[36m[2025-06-29 14:28:00,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 831488. Throughput: 0: 79.9. Samples: 834100. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:00,987][60274] Avg episode reward: [(0, '178.988')]
[36m[2025-06-29 14:28:05,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 831488. Throughput: 0: 79.8. Samples: 834344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:05,968][60274] Avg episode reward: [(0, '175.778')]
[36m[2025-06-29 14:28:10,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 831488. Throughput: 0: 80.3. Samples: 834836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:10,951][60274] Avg episode reward: [(0, '169.449')]
[36m[2025-06-29 14:28:15,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 831488. Throughput: 0: 81.9. Samples: 835332. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:15,985][60274] Avg episode reward: [(0, '175.440')]
[36m[2025-06-29 14:28:20,971][60274] Fps is (10 sec: 408.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 835584. Throughput: 0: 81.8. Samples: 835572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:20,972][60274] Avg episode reward: [(0, '177.758')]
[36m[2025-06-29 14:28:25,947][60274] Fps is (10 sec: 411.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 835584. Throughput: 0: 80.2. Samples: 835984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:25,947][60274] Avg episode reward: [(0, '185.079')]
[36m[2025-06-29 14:28:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 835584. Throughput: 0: 79.7. Samples: 836464. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:30,989][60274] Avg episode reward: [(0, '188.449')]
[36m[2025-06-29 14:28:35,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 835584. Throughput: 0: 79.4. Samples: 836692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:35,962][60274] Avg episode reward: [(0, '183.291')]
[36m[2025-06-29 14:28:40,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 835584. Throughput: 0: 79.6. Samples: 837188. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:40,957][60274] Avg episode reward: [(0, '186.125')]
[36m[2025-06-29 14:28:45,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 835584. Throughput: 0: 79.6. Samples: 837680. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:45,978][60274] Avg episode reward: [(0, '183.943')]
[36m[2025-06-29 14:28:50,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 835584. Throughput: 0: 79.5. Samples: 837924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:50,992][60274] Avg episode reward: [(0, '172.762')]
[36m[2025-06-29 14:28:55,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 835584. Throughput: 0: 79.5. Samples: 838416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:28:55,977][60274] Avg episode reward: [(0, '174.375')]
[36m[2025-06-29 14:29:00,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 835584. Throughput: 0: 79.2. Samples: 838892. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:29:00,956][60274] Avg episode reward: [(0, '186.873')]
[37m[1m[2025-06-29 14:29:01,004][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003264_835584.pth...
[36m[2025-06-29 14:29:01,060][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003200_819200.pth
[36m[2025-06-29 14:29:05,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 835584. Throughput: 0: 79.2. Samples: 839136. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:29:05,959][60274] Avg episode reward: [(0, '196.295')]
[36m[2025-06-29 14:29:11,083][60274] Fps is (10 sec: 404.5, 60 sec: 136.2, 300 sec: 83.3). Total num frames: 839680. Throughput: 0: 80.1. Samples: 839600. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:29:11,083][60274] Avg episode reward: [(0, '201.555')]
[36m[2025-06-29 14:29:15,956][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 839680. Throughput: 0: 79.3. Samples: 840028. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:29:15,957][60274] Avg episode reward: [(0, '194.653')]
[36m[2025-06-29 14:29:20,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 839680. Throughput: 0: 79.6. Samples: 840276. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:29:20,977][60274] Avg episode reward: [(0, '185.826')]
[36m[2025-06-29 14:29:25,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 839680. Throughput: 0: 79.1. Samples: 840752. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:29:25,991][60274] Avg episode reward: [(0, '198.350')]
[36m[2025-06-29 14:29:30,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 839680. Throughput: 0: 78.9. Samples: 841228. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:29:30,968][60274] Avg episode reward: [(0, '193.228')]
[36m[2025-06-29 14:29:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 839680. Throughput: 0: 78.9. Samples: 841472. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:29:35,972][60274] Avg episode reward: [(0, '198.064')]
[36m[2025-06-29 14:29:40,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 839680. Throughput: 0: 79.0. Samples: 841968. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:29:40,962][60274] Avg episode reward: [(0, '199.922')]
[36m[2025-06-29 14:29:45,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 839680. Throughput: 0: 78.9. Samples: 842440. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:29:45,951][60274] Avg episode reward: [(0, '200.879')]
[36m[2025-06-29 14:29:50,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 839680. Throughput: 0: 78.6. Samples: 842676. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:29:50,969][60274] Avg episode reward: [(0, '200.639')]
[36m[2025-06-29 14:29:55,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 839680. Throughput: 0: 79.4. Samples: 843164. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:29:55,953][60274] Avg episode reward: [(0, '197.133')]
[36m[2025-06-29 14:30:00,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 839680. Throughput: 0: 80.4. Samples: 843648. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:30:00,984][60274] Avg episode reward: [(0, '197.496')]
[36m[2025-06-29 14:30:05,959][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 843776. Throughput: 0: 79.1. Samples: 843832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:05,960][60274] Avg episode reward: [(0, '204.578')]
[36m[2025-06-29 14:30:10,971][60274] Fps is (10 sec: 410.1, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 843776. Throughput: 0: 79.1. Samples: 844312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:10,971][60274] Avg episode reward: [(0, '201.463')]
[36m[2025-06-29 14:30:15,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 843776. Throughput: 0: 79.1. Samples: 844792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:15,997][60274] Avg episode reward: [(0, '208.444')]
[36m[2025-06-29 14:30:20,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 843776. Throughput: 0: 79.4. Samples: 845044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:20,972][60274] Avg episode reward: [(0, '213.402')]
[36m[2025-06-29 14:30:25,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 843776. Throughput: 0: 78.9. Samples: 845520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:25,957][60274] Avg episode reward: [(0, '210.305')]
[36m[2025-06-29 14:30:30,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 843776. Throughput: 0: 79.4. Samples: 846012. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:30,950][60274] Avg episode reward: [(0, '216.439')]
[36m[2025-06-29 14:30:35,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 843776. Throughput: 0: 79.7. Samples: 846260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:35,964][60274] Avg episode reward: [(0, '211.967')]
[36m[2025-06-29 14:30:40,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 843776. Throughput: 0: 80.0. Samples: 846764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:40,964][60274] Avg episode reward: [(0, '215.969')]
[36m[2025-06-29 14:30:45,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 843776. Throughput: 0: 79.6. Samples: 847228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:45,974][60274] Avg episode reward: [(0, '222.007')]
[36m[2025-06-29 14:30:50,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 843776. Throughput: 0: 80.6. Samples: 847460. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:50,973][60274] Avg episode reward: [(0, '206.216')]
[36m[2025-06-29 14:30:55,958][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 847872. Throughput: 0: 79.3. Samples: 847880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:30:55,958][60274] Avg episode reward: [(0, '201.565')]
[36m[2025-06-29 14:31:00,987][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 847872. Throughput: 0: 80.3. Samples: 848404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:31:00,987][60274] Avg episode reward: [(0, '202.827')]
[37m[1m[2025-06-29 14:31:01,036][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003312_847872.pth...
[36m[2025-06-29 14:31:01,093][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003232_827392.pth
[36m[2025-06-29 14:31:05,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 847872. Throughput: 0: 79.8. Samples: 848636. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:31:05,972][60274] Avg episode reward: [(0, '201.617')]
[36m[2025-06-29 14:31:10,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 847872. Throughput: 0: 80.2. Samples: 849132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:31:10,988][60274] Avg episode reward: [(0, '212.701')]
[36m[2025-06-29 14:31:15,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 847872. Throughput: 0: 80.0. Samples: 849616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:31:15,977][60274] Avg episode reward: [(0, '213.999')]
[36m[2025-06-29 14:31:20,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 847872. Throughput: 0: 80.1. Samples: 849864. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:31:20,948][60274] Avg episode reward: [(0, '222.791')]
[36m[2025-06-29 14:31:25,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 847872. Throughput: 0: 79.5. Samples: 850340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:31:25,952][60274] Avg episode reward: [(0, '215.758')]
[36m[2025-06-29 14:31:30,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 847872. Throughput: 0: 80.2. Samples: 850836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:31:30,966][60274] Avg episode reward: [(0, '214.520')]
[36m[2025-06-29 14:31:35,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 847872. Throughput: 0: 80.7. Samples: 851088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:31:35,949][60274] Avg episode reward: [(0, '217.934')]
[36m[2025-06-29 14:31:40,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 847872. Throughput: 0: 81.9. Samples: 851568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:31:40,994][60274] Avg episode reward: [(0, '215.478')]
[36m[2025-06-29 14:31:45,986][60274] Fps is (10 sec: 408.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 851968. Throughput: 0: 79.4. Samples: 851976. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:31:45,986][60274] Avg episode reward: [(0, '219.626')]
[36m[2025-06-29 14:31:50,965][60274] Fps is (10 sec: 410.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 851968. Throughput: 0: 79.2. Samples: 852200. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:31:50,965][60274] Avg episode reward: [(0, '220.940')]
[36m[2025-06-29 14:31:55,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 851968. Throughput: 0: 79.0. Samples: 852688. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:31:55,982][60274] Avg episode reward: [(0, '219.112')]
[36m[2025-06-29 14:32:00,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 851968. Throughput: 0: 79.0. Samples: 853168. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:32:00,961][60274] Avg episode reward: [(0, '217.254')]
[36m[2025-06-29 14:32:05,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 851968. Throughput: 0: 78.6. Samples: 853400. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:32:05,954][60274] Avg episode reward: [(0, '217.679')]
[36m[2025-06-29 14:32:10,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 851968. Throughput: 0: 78.9. Samples: 853892. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:32:10,963][60274] Avg episode reward: [(0, '207.302')]
[36m[2025-06-29 14:32:15,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 851968. Throughput: 0: 78.2. Samples: 854356. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:32:15,984][60274] Avg episode reward: [(0, '208.587')]
[36m[2025-06-29 14:32:20,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 851968. Throughput: 0: 77.9. Samples: 854592. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:32:20,956][60274] Avg episode reward: [(0, '210.156')]
[36m[2025-06-29 14:32:25,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 851968. Throughput: 0: 78.4. Samples: 855092. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:32:25,956][60274] Avg episode reward: [(0, '205.414')]
[36m[2025-06-29 14:32:30,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 851968. Throughput: 0: 80.4. Samples: 855592. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:32:30,950][60274] Avg episode reward: [(0, '206.312')]
[36m[2025-06-29 14:32:35,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 851968. Throughput: 0: 80.8. Samples: 855840. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 14:32:35,987][60274] Avg episode reward: [(0, '219.559')]
[36m[2025-06-29 14:32:40,960][60274] Fps is (10 sec: 409.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 856064. Throughput: 0: 79.9. Samples: 856280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:32:40,961][60274] Avg episode reward: [(0, '212.333')]
[36m[2025-06-29 14:32:45,947][60274] Fps is (10 sec: 411.2, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 856064. Throughput: 0: 80.5. Samples: 856788. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:32:45,947][60274] Avg episode reward: [(0, '219.959')]
[36m[2025-06-29 14:32:50,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 856064. Throughput: 0: 80.5. Samples: 857024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:32:50,962][60274] Avg episode reward: [(0, '233.461')]
[36m[2025-06-29 14:32:55,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 856064. Throughput: 0: 80.4. Samples: 857512. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:32:55,979][60274] Avg episode reward: [(0, '226.857')]
[36m[2025-06-29 14:33:00,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 856064. Throughput: 0: 81.7. Samples: 858032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:00,975][60274] Avg episode reward: [(0, '229.163')]
[37m[1m[2025-06-29 14:33:01,022][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003344_856064.pth...
[36m[2025-06-29 14:33:01,082][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003264_835584.pth
[36m[2025-06-29 14:33:05,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 856064. Throughput: 0: 81.8. Samples: 858272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:05,962][60274] Avg episode reward: [(0, '229.282')]
[36m[2025-06-29 14:33:10,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 856064. Throughput: 0: 82.0. Samples: 858780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:10,952][60274] Avg episode reward: [(0, '216.103')]
[36m[2025-06-29 14:33:15,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 856064. Throughput: 0: 81.9. Samples: 859280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:15,987][60274] Avg episode reward: [(0, '224.063')]
[36m[2025-06-29 14:33:20,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 856064. Throughput: 0: 82.0. Samples: 859528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:20,962][60274] Avg episode reward: [(0, '230.088')]
[36m[2025-06-29 14:33:26,015][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 856064. Throughput: 0: 82.7. Samples: 860004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:26,015][60274] Avg episode reward: [(0, '233.916')]
[36m[2025-06-29 14:33:30,958][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 860160. Throughput: 0: 81.1. Samples: 860440. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:30,958][60274] Avg episode reward: [(0, '229.817')]
[36m[2025-06-29 14:33:35,954][60274] Fps is (10 sec: 412.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 860160. Throughput: 0: 81.6. Samples: 860696. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:35,954][60274] Avg episode reward: [(0, '228.790')]
[36m[2025-06-29 14:33:40,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 860160. Throughput: 0: 81.9. Samples: 861196. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:40,982][60274] Avg episode reward: [(0, '225.269')]
[36m[2025-06-29 14:33:45,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 860160. Throughput: 0: 81.0. Samples: 861676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:45,985][60274] Avg episode reward: [(0, '224.271')]
[36m[2025-06-29 14:33:50,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 860160. Throughput: 0: 81.2. Samples: 861928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:50,994][60274] Avg episode reward: [(0, '220.153')]
[36m[2025-06-29 14:33:55,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 860160. Throughput: 0: 80.8. Samples: 862416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:33:55,969][60274] Avg episode reward: [(0, '212.937')]
[36m[2025-06-29 14:34:00,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 860160. Throughput: 0: 79.9. Samples: 862872. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:34:00,950][60274] Avg episode reward: [(0, '210.141')]
[36m[2025-06-29 14:34:05,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 860160. Throughput: 0: 79.7. Samples: 863116. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:34:05,958][60274] Avg episode reward: [(0, '208.358')]
[36m[2025-06-29 14:34:10,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 860160. Throughput: 0: 80.1. Samples: 863604. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:34:10,949][60274] Avg episode reward: [(0, '207.500')]
[36m[2025-06-29 14:34:15,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 860160. Throughput: 0: 81.0. Samples: 864088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:34:15,986][60274] Avg episode reward: [(0, '206.441')]
[36m[2025-06-29 14:34:20,948][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 864256. Throughput: 0: 79.8. Samples: 864288. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 14:34:20,949][60274] Avg episode reward: [(0, '200.870')]
[36m[2025-06-29 14:34:25,987][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 864256. Throughput: 0: 80.1. Samples: 864800. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 14:34:25,987][60274] Avg episode reward: [(0, '199.569')]
[36m[2025-06-29 14:34:30,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 864256. Throughput: 0: 80.3. Samples: 865288. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 14:34:30,974][60274] Avg episode reward: [(0, '204.146')]
[36m[2025-06-29 14:34:35,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 864256. Throughput: 0: 79.7. Samples: 865512. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 14:34:35,954][60274] Avg episode reward: [(0, '203.560')]
[36m[2025-06-29 14:34:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 864256. Throughput: 0: 79.7. Samples: 866000. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 14:34:40,948][60274] Avg episode reward: [(0, '208.967')]
[36m[2025-06-29 14:34:45,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 864256. Throughput: 0: 80.4. Samples: 866492. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 14:34:45,964][60274] Avg episode reward: [(0, '210.708')]
[36m[2025-06-29 14:34:50,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 864256. Throughput: 0: 80.8. Samples: 866752. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 14:34:50,984][60274] Avg episode reward: [(0, '215.632')]
[36m[2025-06-29 14:34:56,002][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 864256. Throughput: 0: 80.6. Samples: 867236. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 14:34:56,002][60274] Avg episode reward: [(0, '216.208')]
[36m[2025-06-29 14:35:00,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 864256. Throughput: 0: 80.8. Samples: 867724. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 14:35:00,970][60274] Avg episode reward: [(0, '221.724')]
[37m[1m[2025-06-29 14:35:01,016][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003376_864256.pth...
[36m[2025-06-29 14:35:01,071][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003312_847872.pth
[36m[2025-06-29 14:35:05,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 864256. Throughput: 0: 81.8. Samples: 867972. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 14:35:05,970][60274] Avg episode reward: [(0, '215.436')]
[36m[2025-06-29 14:35:10,956][60274] Fps is (10 sec: 410.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 868352. Throughput: 0: 80.4. Samples: 868416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:35:10,956][60274] Avg episode reward: [(0, '201.474')]
[36m[2025-06-29 14:35:15,980][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 868352. Throughput: 0: 80.4. Samples: 868908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:35:15,980][60274] Avg episode reward: [(0, '205.766')]
[36m[2025-06-29 14:35:20,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 868352. Throughput: 0: 80.7. Samples: 869144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:35:20,952][60274] Avg episode reward: [(0, '220.125')]
[36m[2025-06-29 14:35:25,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 868352. Throughput: 0: 80.9. Samples: 869640. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:35:25,958][60274] Avg episode reward: [(0, '222.449')]
[36m[2025-06-29 14:35:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 868352. Throughput: 0: 80.8. Samples: 870128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:35:30,973][60274] Avg episode reward: [(0, '205.870')]
[36m[2025-06-29 14:35:35,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 868352. Throughput: 0: 80.2. Samples: 870360. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:35:35,990][60274] Avg episode reward: [(0, '223.720')]
[36m[2025-06-29 14:35:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 868352. Throughput: 0: 80.1. Samples: 870840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:35:40,982][60274] Avg episode reward: [(0, '223.060')]
[36m[2025-06-29 14:35:45,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 868352. Throughput: 0: 79.9. Samples: 871320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:35:45,978][60274] Avg episode reward: [(0, '227.534')]
[36m[2025-06-29 14:35:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 868352. Throughput: 0: 79.7. Samples: 871560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:35:50,962][60274] Avg episode reward: [(0, '229.388')]
[36m[2025-06-29 14:35:55,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 868352. Throughput: 0: 81.0. Samples: 872064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:35:55,986][60274] Avg episode reward: [(0, '237.514')]
[36m[2025-06-29 14:36:00,975][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 872448. Throughput: 0: 79.8. Samples: 872500. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:00,975][60274] Avg episode reward: [(0, '234.334')]
[36m[2025-06-29 14:36:05,969][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 872448. Throughput: 0: 80.0. Samples: 872744. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:05,969][60274] Avg episode reward: [(0, '234.227')]
[36m[2025-06-29 14:36:10,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 872448. Throughput: 0: 79.6. Samples: 873224. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:10,961][60274] Avg episode reward: [(0, '230.739')]
[36m[2025-06-29 14:36:15,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 872448. Throughput: 0: 79.7. Samples: 873716. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:15,975][60274] Avg episode reward: [(0, '239.310')]
[36m[2025-06-29 14:36:20,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 872448. Throughput: 0: 80.3. Samples: 873972. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:20,959][60274] Avg episode reward: [(0, '241.642')]
[36m[2025-06-29 14:36:25,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 872448. Throughput: 0: 80.9. Samples: 874480. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:25,977][60274] Avg episode reward: [(0, '239.834')]
[36m[2025-06-29 14:36:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 872448. Throughput: 0: 81.1. Samples: 874968. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:30,973][60274] Avg episode reward: [(0, '239.692')]
[36m[2025-06-29 14:36:35,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 872448. Throughput: 0: 81.3. Samples: 875220. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:35,981][60274] Avg episode reward: [(0, '237.627')]
[36m[2025-06-29 14:36:40,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 872448. Throughput: 0: 81.2. Samples: 875716. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:40,951][60274] Avg episode reward: [(0, '238.949')]
[36m[2025-06-29 14:36:45,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 872448. Throughput: 0: 82.6. Samples: 876216. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:45,973][60274] Avg episode reward: [(0, '227.097')]
[36m[2025-06-29 14:36:50,979][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 876544. Throughput: 0: 82.5. Samples: 876456. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:50,980][60274] Avg episode reward: [(0, '223.629')]
[36m[2025-06-29 14:36:55,965][60274] Fps is (10 sec: 409.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 876544. Throughput: 0: 81.1. Samples: 876872. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:36:55,965][60274] Avg episode reward: [(0, '226.817')]
[36m[2025-06-29 14:37:00,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 876544. Throughput: 0: 80.9. Samples: 877356. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:37:00,974][60274] Avg episode reward: [(0, '233.746')]
[37m[1m[2025-06-29 14:37:01,021][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003424_876544.pth...
[36m[2025-06-29 14:37:01,081][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003344_856064.pth
[36m[2025-06-29 14:37:05,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 876544. Throughput: 0: 80.4. Samples: 877592. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:37:05,988][60274] Avg episode reward: [(0, '238.467')]
[36m[2025-06-29 14:37:10,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 876544. Throughput: 0: 79.3. Samples: 878048. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:37:10,993][60274] Avg episode reward: [(0, '237.454')]
[36m[2025-06-29 14:37:15,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 876544. Throughput: 0: 79.1. Samples: 878528. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:37:15,951][60274] Avg episode reward: [(0, '235.218')]
[36m[2025-06-29 14:37:20,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 876544. Throughput: 0: 78.9. Samples: 878768. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:37:20,975][60274] Avg episode reward: [(0, '231.650')]
[36m[2025-06-29 14:37:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 876544. Throughput: 0: 78.4. Samples: 879244. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:37:25,966][60274] Avg episode reward: [(0, '241.795')]
[36m[2025-06-29 14:37:30,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 876544. Throughput: 0: 78.2. Samples: 879736. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:37:30,978][60274] Avg episode reward: [(0, '232.855')]
[36m[2025-06-29 14:37:35,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 876544. Throughput: 0: 78.4. Samples: 879984. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:37:35,961][60274] Avg episode reward: [(0, '231.549')]
[36m[2025-06-29 14:37:40,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 876544. Throughput: 0: 80.3. Samples: 880488. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:37:40,975][60274] Avg episode reward: [(0, '229.318')]
[36m[2025-06-29 14:37:45,961][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 880640. Throughput: 0: 79.3. Samples: 880924. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:37:45,962][60274] Avg episode reward: [(0, '223.047')]
[36m[2025-06-29 14:37:50,982][60274] Fps is (10 sec: 409.3, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 880640. Throughput: 0: 79.3. Samples: 881160. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:37:50,982][60274] Avg episode reward: [(0, '209.146')]
[36m[2025-06-29 14:37:55,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 880640. Throughput: 0: 79.9. Samples: 881640. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:37:55,955][60274] Avg episode reward: [(0, '210.991')]
[36m[2025-06-29 14:38:00,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 880640. Throughput: 0: 80.4. Samples: 882148. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:38:00,968][60274] Avg episode reward: [(0, '212.492')]
[36m[2025-06-29 14:38:05,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 880640. Throughput: 0: 80.4. Samples: 882388. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:38:05,975][60274] Avg episode reward: [(0, '217.061')]
[36m[2025-06-29 14:38:10,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 880640. Throughput: 0: 80.4. Samples: 882864. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:38:10,967][60274] Avg episode reward: [(0, '213.101')]
[36m[2025-06-29 14:38:15,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 880640. Throughput: 0: 80.5. Samples: 883360. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:38:15,988][60274] Avg episode reward: [(0, '200.533')]
[31m[11121585 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[11121586 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[11121586 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:38:20,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 880640. Throughput: 0: 80.4. Samples: 883604. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:38:20,961][60274] Avg episode reward: [(0, '186.422')]
[36m[2025-06-29 14:38:25,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 880640. Throughput: 0: 80.5. Samples: 884108. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:38:25,969][60274] Avg episode reward: [(0, '178.472')]
[36m[2025-06-29 14:38:30,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 880640. Throughput: 0: 81.2. Samples: 884580. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:38:30,968][60274] Avg episode reward: [(0, '178.065')]
[36m[2025-06-29 14:38:35,949][60274] Fps is (10 sec: 410.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 884736. Throughput: 0: 80.5. Samples: 884780. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-06-29 14:38:35,949][60274] Avg episode reward: [(0, '180.123')]
[36m[2025-06-29 14:38:40,965][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 884736. Throughput: 0: 80.6. Samples: 885268. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-06-29 14:38:40,965][60274] Avg episode reward: [(0, '182.302')]
[36m[2025-06-29 14:38:45,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 884736. Throughput: 0: 79.7. Samples: 885736. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-06-29 14:38:45,960][60274] Avg episode reward: [(0, '179.642')]
[36m[2025-06-29 14:38:50,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 884736. Throughput: 0: 79.8. Samples: 885980. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-06-29 14:38:50,990][60274] Avg episode reward: [(0, '183.551')]
[36m[2025-06-29 14:38:55,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 884736. Throughput: 0: 79.6. Samples: 886444. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-06-29 14:38:55,949][60274] Avg episode reward: [(0, '178.355')]
[36m[2025-06-29 14:39:00,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 884736. Throughput: 0: 78.5. Samples: 886892. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-06-29 14:39:00,974][60274] Avg episode reward: [(0, '182.254')]
[37m[1m[2025-06-29 14:39:01,021][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003456_884736.pth...
[36m[2025-06-29 14:39:01,075][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003376_864256.pth
[36m[2025-06-29 14:39:05,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 884736. Throughput: 0: 78.3. Samples: 887132. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-06-29 14:39:05,999][60274] Avg episode reward: [(0, '176.823')]
[36m[2025-06-29 14:39:10,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 884736. Throughput: 0: 78.0. Samples: 887616. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-06-29 14:39:10,956][60274] Avg episode reward: [(0, '177.116')]
[36m[2025-06-29 14:39:15,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 884736. Throughput: 0: 78.2. Samples: 888100. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-06-29 14:39:15,965][60274] Avg episode reward: [(0, '188.395')]
[36m[2025-06-29 14:39:20,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 884736. Throughput: 0: 79.6. Samples: 888364. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-06-29 14:39:20,980][60274] Avg episode reward: [(0, '185.198')]
[36m[2025-06-29 14:39:25,958][60274] Fps is (10 sec: 409.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 888832. Throughput: 0: 79.4. Samples: 888840. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:39:25,958][60274] Avg episode reward: [(0, '189.983')]
[36m[2025-06-29 14:39:30,984][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 888832. Throughput: 0: 78.8. Samples: 889284. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:39:30,984][60274] Avg episode reward: [(0, '182.371')]
[36m[2025-06-29 14:39:35,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 888832. Throughput: 0: 79.1. Samples: 889536. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:39:35,975][60274] Avg episode reward: [(0, '184.947')]
[36m[2025-06-29 14:39:40,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 888832. Throughput: 0: 78.8. Samples: 889992. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:39:40,986][60274] Avg episode reward: [(0, '203.353')]
[36m[2025-06-29 14:39:45,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 888832. Throughput: 0: 79.9. Samples: 890484. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:39:45,958][60274] Avg episode reward: [(0, '200.840')]
[36m[2025-06-29 14:39:50,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 888832. Throughput: 0: 79.9. Samples: 890728. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:39:50,980][60274] Avg episode reward: [(0, '197.914')]
[36m[2025-06-29 14:39:55,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 888832. Throughput: 0: 80.1. Samples: 891224. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:39:55,973][60274] Avg episode reward: [(0, '205.066')]
[36m[2025-06-29 14:40:00,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 888832. Throughput: 0: 80.2. Samples: 891712. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:40:00,976][60274] Avg episode reward: [(0, '203.562')]
[36m[2025-06-29 14:40:05,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 888832. Throughput: 0: 79.8. Samples: 891956. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:40:05,975][60274] Avg episode reward: [(0, '202.021')]
[36m[2025-06-29 14:40:10,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 888832. Throughput: 0: 80.1. Samples: 892448. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:40:10,987][60274] Avg episode reward: [(0, '207.424')]
[36m[2025-06-29 14:40:15,956][60274] Fps is (10 sec: 410.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 892928. Throughput: 0: 81.2. Samples: 892936. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:40:15,956][60274] Avg episode reward: [(0, '218.263')]
[36m[2025-06-29 14:40:20,954][60274] Fps is (10 sec: 411.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 892928. Throughput: 0: 80.0. Samples: 893136. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:40:20,954][60274] Avg episode reward: [(0, '225.270')]
[36m[2025-06-29 14:40:25,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 892928. Throughput: 0: 81.0. Samples: 893636. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:40:25,963][60274] Avg episode reward: [(0, '221.047')]
[36m[2025-06-29 14:40:30,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 892928. Throughput: 0: 81.4. Samples: 894148. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:40:30,979][60274] Avg episode reward: [(0, '228.450')]
[36m[2025-06-29 14:40:35,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 892928. Throughput: 0: 81.4. Samples: 894388. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:40:35,966][60274] Avg episode reward: [(0, '229.223')]
[36m[2025-06-29 14:40:40,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 892928. Throughput: 0: 81.7. Samples: 894900. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:40:40,985][60274] Avg episode reward: [(0, '224.186')]
[36m[2025-06-29 14:40:46,013][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 892928. Throughput: 0: 81.3. Samples: 895372. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:40:46,013][60274] Avg episode reward: [(0, '218.578')]
[36m[2025-06-29 14:40:50,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 892928. Throughput: 0: 81.1. Samples: 895604. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:40:50,983][60274] Avg episode reward: [(0, '225.876')]
[36m[2025-06-29 14:40:55,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 892928. Throughput: 0: 80.9. Samples: 896088. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:40:55,977][60274] Avg episode reward: [(0, '228.386')]
[36m[2025-06-29 14:41:00,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 892928. Throughput: 0: 81.2. Samples: 896592. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 14:41:00,958][60274] Avg episode reward: [(0, '222.453')]
[37m[1m[2025-06-29 14:41:01,007][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003488_892928.pth...
[36m[2025-06-29 14:41:01,062][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003424_876544.pth
[31m[11288958 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[11288958 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[11288959 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:41:06,441][60274] Fps is (10 sec: 391.4, 60 sec: 135.5, 300 sec: 83.2). Total num frames: 897024. Throughput: 0: 81.3. Samples: 896836. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:06,442][60274] Avg episode reward: [(0, '218.270')]
[36m[2025-06-29 14:41:10,948][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 897024. Throughput: 0: 80.6. Samples: 897260. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:10,948][60274] Avg episode reward: [(0, '218.979')]
[36m[2025-06-29 14:41:15,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 897024. Throughput: 0: 80.2. Samples: 897756. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:15,982][60274] Avg episode reward: [(0, '224.214')]
[36m[2025-06-29 14:41:20,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 897024. Throughput: 0: 80.1. Samples: 897992. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:20,969][60274] Avg episode reward: [(0, '218.904')]
[36m[2025-06-29 14:41:25,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 897024. Throughput: 0: 79.3. Samples: 898464. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:25,950][60274] Avg episode reward: [(0, '233.149')]
[36m[2025-06-29 14:41:30,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 897024. Throughput: 0: 79.1. Samples: 898928. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:30,968][60274] Avg episode reward: [(0, '233.394')]
[36m[2025-06-29 14:41:35,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 897024. Throughput: 0: 79.2. Samples: 899168. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:35,987][60274] Avg episode reward: [(0, '217.996')]
[36m[2025-06-29 14:41:40,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 897024. Throughput: 0: 79.2. Samples: 899652. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:40,979][60274] Avg episode reward: [(0, '228.999')]
[36m[2025-06-29 14:41:46,006][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 897024. Throughput: 0: 78.8. Samples: 900144. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:46,006][60274] Avg episode reward: [(0, '214.134')]
[31m[11334144 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[11334145 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[11334145 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:41:50,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 897024. Throughput: 0: 79.6. Samples: 900380. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:50,949][60274] Avg episode reward: [(0, '202.826')]
[36m[2025-06-29 14:41:55,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 897024. Throughput: 0: 79.8. Samples: 900852. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:41:55,963][60274] Avg episode reward: [(0, '213.922')]
[36m[2025-06-29 14:42:00,981][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 901120. Throughput: 0: 78.6. Samples: 901292. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 14:42:00,981][60274] Avg episode reward: [(0, '227.177')]
[36m[2025-06-29 14:42:05,946][60274] Fps is (10 sec: 410.3, 60 sec: 68.8, 300 sec: 83.3). Total num frames: 901120. Throughput: 0: 78.8. Samples: 901536. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 14:42:05,947][60274] Avg episode reward: [(0, '221.164')]
[36m[2025-06-29 14:42:10,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 901120. Throughput: 0: 78.2. Samples: 901984. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 14:42:10,951][60274] Avg episode reward: [(0, '220.612')]
[36m[2025-06-29 14:42:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 901120. Throughput: 0: 78.6. Samples: 902464. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 14:42:15,952][60274] Avg episode reward: [(0, '205.743')]
[36m[2025-06-29 14:42:20,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 901120. Throughput: 0: 78.5. Samples: 902700. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 14:42:20,973][60274] Avg episode reward: [(0, '207.174')]
[36m[2025-06-29 14:42:25,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 901120. Throughput: 0: 78.0. Samples: 903164. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 14:42:25,980][60274] Avg episode reward: [(0, '210.507')]
[36m[2025-06-29 14:42:30,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 901120. Throughput: 0: 77.6. Samples: 903632. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 14:42:30,961][60274] Avg episode reward: [(0, '212.077')]
[36m[2025-06-29 14:42:35,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 901120. Throughput: 0: 77.6. Samples: 903872. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 14:42:35,978][60274] Avg episode reward: [(0, '204.215')]
[36m[2025-06-29 14:42:40,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 901120. Throughput: 0: 77.4. Samples: 904336. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 14:42:40,968][60274] Avg episode reward: [(0, '193.428')]
[36m[2025-06-29 14:42:45,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 901120. Throughput: 0: 78.3. Samples: 904812. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 14:42:45,952][60274] Avg episode reward: [(0, '194.771')]
[36m[2025-06-29 14:42:51,034][60274] Fps is (10 sec: 406.9, 60 sec: 136.3, 300 sec: 83.3). Total num frames: 905216. Throughput: 0: 78.2. Samples: 905064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:42:51,034][60274] Avg episode reward: [(0, '193.252')]
[36m[2025-06-29 14:42:55,957][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 905216. Throughput: 0: 77.9. Samples: 905488. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:42:55,957][60274] Avg episode reward: [(0, '192.270')]
[36m[2025-06-29 14:43:00,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 905216. Throughput: 0: 78.1. Samples: 905980. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:43:00,985][60274] Avg episode reward: [(0, '195.418')]
[37m[1m[2025-06-29 14:43:01,055][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003536_905216.pth...
[36m[2025-06-29 14:43:01,118][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003456_884736.pth
[36m[2025-06-29 14:43:05,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 905216. Throughput: 0: 78.3. Samples: 906224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:43:05,969][60274] Avg episode reward: [(0, '186.332')]
[36m[2025-06-29 14:43:10,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 905216. Throughput: 0: 78.8. Samples: 906708. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:43:10,949][60274] Avg episode reward: [(0, '176.533')]
[36m[2025-06-29 14:43:16,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 905216. Throughput: 0: 78.7. Samples: 907176. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:43:16,000][60274] Avg episode reward: [(0, '166.894')]
[36m[2025-06-29 14:43:20,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 905216. Throughput: 0: 78.5. Samples: 907408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:43:20,995][60274] Avg episode reward: [(0, '171.056')]
[36m[2025-06-29 14:43:25,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 905216. Throughput: 0: 79.1. Samples: 907896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:43:25,961][60274] Avg episode reward: [(0, '166.168')]
[36m[2025-06-29 14:43:30,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 905216. Throughput: 0: 78.9. Samples: 908364. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:43:30,949][60274] Avg episode reward: [(0, '168.369')]
[36m[2025-06-29 14:43:35,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 905216. Throughput: 0: 78.9. Samples: 908608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:43:35,970][60274] Avg episode reward: [(0, '179.531')]
[36m[2025-06-29 14:43:40,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 905216. Throughput: 0: 80.8. Samples: 909124. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:43:40,956][60274] Avg episode reward: [(0, '183.899')]
[36m[2025-06-29 14:43:45,967][60274] Fps is (10 sec: 409.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 909312. Throughput: 0: 79.6. Samples: 909560. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 14:43:45,968][60274] Avg episode reward: [(0, '187.407')]
[36m[2025-06-29 14:43:50,955][60274] Fps is (10 sec: 409.6, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 909312. Throughput: 0: 79.3. Samples: 909792. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 14:43:50,956][60274] Avg episode reward: [(0, '181.743')]
[36m[2025-06-29 14:43:56,006][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 909312. Throughput: 0: 78.9. Samples: 910264. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 14:43:56,006][60274] Avg episode reward: [(0, '191.230')]
[36m[2025-06-29 14:44:00,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 909312. Throughput: 0: 79.0. Samples: 910728. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 14:44:00,969][60274] Avg episode reward: [(0, '192.462')]
[36m[2025-06-29 14:44:05,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 909312. Throughput: 0: 79.1. Samples: 910968. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 14:44:05,973][60274] Avg episode reward: [(0, '193.814')]
[36m[2025-06-29 14:44:10,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 909312. Throughput: 0: 78.6. Samples: 911432. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 14:44:10,949][60274] Avg episode reward: [(0, '197.590')]
[36m[2025-06-29 14:44:15,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 909312. Throughput: 0: 79.2. Samples: 911928. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 14:44:15,975][60274] Avg episode reward: [(0, '198.396')]
[36m[2025-06-29 14:44:20,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 909312. Throughput: 0: 79.1. Samples: 912168. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 14:44:20,952][60274] Avg episode reward: [(0, '183.338')]
[36m[2025-06-29 14:44:25,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 909312. Throughput: 0: 78.4. Samples: 912652. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 14:44:25,975][60274] Avg episode reward: [(0, '192.085')]
[36m[2025-06-29 14:44:30,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 909312. Throughput: 0: 80.1. Samples: 913164. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 14:44:30,981][60274] Avg episode reward: [(0, '203.418')]
[36m[2025-06-29 14:44:35,989][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 913408. Throughput: 0: 80.5. Samples: 913416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:44:35,989][60274] Avg episode reward: [(0, '199.765')]
[36m[2025-06-29 14:44:40,993][60274] Fps is (10 sec: 409.1, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 913408. Throughput: 0: 79.9. Samples: 913860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:44:40,994][60274] Avg episode reward: [(0, '205.727')]
[36m[2025-06-29 14:44:45,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 913408. Throughput: 0: 80.1. Samples: 914336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:44:45,986][60274] Avg episode reward: [(0, '209.166')]
[36m[2025-06-29 14:44:50,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 913408. Throughput: 0: 80.6. Samples: 914592. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:44:50,962][60274] Avg episode reward: [(0, '198.602')]
[36m[2025-06-29 14:44:55,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 913408. Throughput: 0: 80.6. Samples: 915064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:44:55,997][60274] Avg episode reward: [(0, '201.948')]
[36m[2025-06-29 14:45:00,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 913408. Throughput: 0: 80.5. Samples: 915552. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:45:00,975][60274] Avg episode reward: [(0, '199.759')]
[37m[1m[2025-06-29 14:45:01,031][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003568_913408.pth...
[36m[2025-06-29 14:45:01,087][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003488_892928.pth
[36m[2025-06-29 14:45:05,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 913408. Throughput: 0: 80.5. Samples: 915792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:45:05,952][60274] Avg episode reward: [(0, '202.056')]
[36m[2025-06-29 14:45:10,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 913408. Throughput: 0: 80.6. Samples: 916280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:45:10,959][60274] Avg episode reward: [(0, '203.455')]
[36m[2025-06-29 14:45:15,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 913408. Throughput: 0: 80.9. Samples: 916804. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:45:15,961][60274] Avg episode reward: [(0, '198.970')]
[36m[2025-06-29 14:45:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 913408. Throughput: 0: 80.9. Samples: 917056. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:45:20,986][60274] Avg episode reward: [(0, '201.276')]
[36m[2025-06-29 14:45:25,971][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 917504. Throughput: 0: 81.2. Samples: 917512. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 14:45:25,971][60274] Avg episode reward: [(0, '192.366')]
[36m[2025-06-29 14:45:30,965][60274] Fps is (10 sec: 410.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 917504. Throughput: 0: 81.5. Samples: 918000. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 14:45:30,965][60274] Avg episode reward: [(0, '196.163')]
[36m[2025-06-29 14:45:35,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 917504. Throughput: 0: 81.4. Samples: 918256. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 14:45:35,987][60274] Avg episode reward: [(0, '195.764')]
[36m[2025-06-29 14:45:40,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 917504. Throughput: 0: 82.0. Samples: 918752. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 14:45:40,983][60274] Avg episode reward: [(0, '190.460')]
[36m[2025-06-29 14:45:45,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 917504. Throughput: 0: 82.2. Samples: 919252. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 14:45:45,978][60274] Avg episode reward: [(0, '185.328')]
[36m[2025-06-29 14:45:50,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 917504. Throughput: 0: 82.2. Samples: 919496. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 14:45:50,991][60274] Avg episode reward: [(0, '203.961')]
[36m[2025-06-29 14:45:55,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 917504. Throughput: 0: 82.0. Samples: 919972. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 14:45:55,997][60274] Avg episode reward: [(0, '197.848')]
[36m[2025-06-29 14:46:00,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 917504. Throughput: 0: 81.1. Samples: 920452. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 14:46:00,948][60274] Avg episode reward: [(0, '206.136')]
[36m[2025-06-29 14:46:05,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 917504. Throughput: 0: 80.8. Samples: 920692. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 14:46:05,974][60274] Avg episode reward: [(0, '215.619')]
[36m[2025-06-29 14:46:10,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 917504. Throughput: 0: 81.8. Samples: 921192. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 14:46:10,984][60274] Avg episode reward: [(0, '204.964')]
[36m[2025-06-29 14:46:15,974][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 921600. Throughput: 0: 80.6. Samples: 921628. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:46:15,974][60274] Avg episode reward: [(0, '217.414')]
[36m[2025-06-29 14:46:20,968][60274] Fps is (10 sec: 410.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 921600. Throughput: 0: 80.7. Samples: 921884. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:46:20,968][60274] Avg episode reward: [(0, '201.927')]
[36m[2025-06-29 14:46:25,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 921600. Throughput: 0: 81.1. Samples: 922400. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:46:25,980][60274] Avg episode reward: [(0, '203.062')]
[36m[2025-06-29 14:46:30,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 921600. Throughput: 0: 80.7. Samples: 922880. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:46:30,958][60274] Avg episode reward: [(0, '203.006')]
[36m[2025-06-29 14:46:35,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 921600. Throughput: 0: 80.0. Samples: 923092. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:46:35,952][60274] Avg episode reward: [(0, '212.595')]
[36m[2025-06-29 14:46:40,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 921600. Throughput: 0: 80.2. Samples: 923580. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:46:40,987][60274] Avg episode reward: [(0, '221.273')]
[36m[2025-06-29 14:46:45,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 921600. Throughput: 0: 80.7. Samples: 924084. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:46:45,978][60274] Avg episode reward: [(0, '233.161')]
[36m[2025-06-29 14:46:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 921600. Throughput: 0: 80.8. Samples: 924328. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:46:50,961][60274] Avg episode reward: [(0, '227.681')]
[36m[2025-06-29 14:46:55,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 921600. Throughput: 0: 80.6. Samples: 924820. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:46:55,988][60274] Avg episode reward: [(0, '241.283')]
[36m[2025-06-29 14:47:00,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 921600. Throughput: 0: 81.7. Samples: 925304. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 14:47:00,987][60274] Avg episode reward: [(0, '232.728')]
[37m[1m[2025-06-29 14:47:01,036][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003600_921600.pth...
[36m[2025-06-29 14:47:01,093][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003536_905216.pth
[36m[2025-06-29 14:47:06,133][60274] Fps is (10 sec: 403.7, 60 sec: 136.2, 300 sec: 83.3). Total num frames: 925696. Throughput: 0: 80.7. Samples: 925528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:06,133][60274] Avg episode reward: [(0, '252.188')]
[36m[2025-06-29 14:47:10,947][60274] Fps is (10 sec: 411.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 925696. Throughput: 0: 79.3. Samples: 925968. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:10,947][60274] Avg episode reward: [(0, '244.606')]
[36m[2025-06-29 14:47:15,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 925696. Throughput: 0: 79.4. Samples: 926456. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:15,974][60274] Avg episode reward: [(0, '245.242')]
[36m[2025-06-29 14:47:20,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 925696. Throughput: 0: 80.4. Samples: 926712. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:20,991][60274] Avg episode reward: [(0, '225.589')]
[36m[2025-06-29 14:47:25,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 925696. Throughput: 0: 80.1. Samples: 927184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:25,960][60274] Avg episode reward: [(0, '229.848')]
[36m[2025-06-29 14:47:30,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 925696. Throughput: 0: 79.7. Samples: 927672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:30,988][60274] Avg episode reward: [(0, '229.384')]
[36m[2025-06-29 14:47:35,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 925696. Throughput: 0: 79.7. Samples: 927916. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:35,965][60274] Avg episode reward: [(0, '224.463')]
[36m[2025-06-29 14:47:40,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 925696. Throughput: 0: 79.8. Samples: 928408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:40,955][60274] Avg episode reward: [(0, '224.621')]
[36m[2025-06-29 14:47:45,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 925696. Throughput: 0: 80.0. Samples: 928904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:45,983][60274] Avg episode reward: [(0, '216.478')]
[36m[2025-06-29 14:47:50,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 925696. Throughput: 0: 80.8. Samples: 929152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:50,985][60274] Avg episode reward: [(0, '217.305')]
[36m[2025-06-29 14:47:55,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 925696. Throughput: 0: 81.6. Samples: 929644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:47:55,979][60274] Avg episode reward: [(0, '211.101')]
[36m[2025-06-29 14:48:00,978][60274] Fps is (10 sec: 409.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 929792. Throughput: 0: 80.5. Samples: 930080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:48:00,978][60274] Avg episode reward: [(0, '210.609')]
[36m[2025-06-29 14:48:05,960][60274] Fps is (10 sec: 410.4, 60 sec: 68.5, 300 sec: 83.3). Total num frames: 929792. Throughput: 0: 80.0. Samples: 930308. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:48:05,960][60274] Avg episode reward: [(0, '215.619')]
[36m[2025-06-29 14:48:10,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 929792. Throughput: 0: 80.3. Samples: 930800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:48:10,966][60274] Avg episode reward: [(0, '219.750')]
[36m[2025-06-29 14:48:15,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 929792. Throughput: 0: 80.8. Samples: 931308. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:48:15,974][60274] Avg episode reward: [(0, '211.353')]
[36m[2025-06-29 14:48:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 929792. Throughput: 0: 80.9. Samples: 931560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:48:20,985][60274] Avg episode reward: [(0, '198.241')]
[36m[2025-06-29 14:48:25,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 929792. Throughput: 0: 80.3. Samples: 932024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:48:25,986][60274] Avg episode reward: [(0, '197.727')]
[36m[2025-06-29 14:48:30,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 929792. Throughput: 0: 80.5. Samples: 932524. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:48:30,972][60274] Avg episode reward: [(0, '189.187')]
[36m[2025-06-29 14:48:35,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 929792. Throughput: 0: 80.0. Samples: 932752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:48:35,986][60274] Avg episode reward: [(0, '183.012')]
[36m[2025-06-29 14:48:40,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 929792. Throughput: 0: 79.9. Samples: 933236. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:48:40,963][60274] Avg episode reward: [(0, '173.846')]
[36m[2025-06-29 14:48:45,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 929792. Throughput: 0: 81.0. Samples: 933724. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:48:45,949][60274] Avg episode reward: [(0, '174.920')]
[36m[2025-06-29 14:48:50,957][60274] Fps is (10 sec: 409.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 933888. Throughput: 0: 79.9. Samples: 933904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:48:50,957][60274] Avg episode reward: [(0, '181.433')]
[36m[2025-06-29 14:48:55,982][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 933888. Throughput: 0: 79.4. Samples: 934376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:48:55,982][60274] Avg episode reward: [(0, '188.244')]
[36m[2025-06-29 14:49:00,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 933888. Throughput: 0: 79.3. Samples: 934876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:00,983][60274] Avg episode reward: [(0, '192.463')]
[37m[1m[2025-06-29 14:49:01,031][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003648_933888.pth...
[36m[2025-06-29 14:49:01,087][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003568_913408.pth
[36m[2025-06-29 14:49:05,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 933888. Throughput: 0: 78.7. Samples: 935100. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:05,988][60274] Avg episode reward: [(0, '189.372')]
[36m[2025-06-29 14:49:10,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 933888. Throughput: 0: 78.8. Samples: 935568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:10,978][60274] Avg episode reward: [(0, '206.475')]
[36m[2025-06-29 14:49:15,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 933888. Throughput: 0: 78.3. Samples: 936048. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:15,987][60274] Avg episode reward: [(0, '209.734')]
[36m[2025-06-29 14:49:20,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 933888. Throughput: 0: 78.9. Samples: 936300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:20,948][60274] Avg episode reward: [(0, '209.751')]
[36m[2025-06-29 14:49:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 933888. Throughput: 0: 78.1. Samples: 936752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:25,980][60274] Avg episode reward: [(0, '206.807')]
[36m[2025-06-29 14:49:30,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 933888. Throughput: 0: 77.5. Samples: 937216. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:30,984][60274] Avg episode reward: [(0, '200.263')]
[36m[2025-06-29 14:49:35,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 933888. Throughput: 0: 78.6. Samples: 937444. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:35,974][60274] Avg episode reward: [(0, '204.074')]
[36m[2025-06-29 14:49:40,996][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 937984. Throughput: 0: 79.2. Samples: 937940. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:40,996][60274] Avg episode reward: [(0, '200.951')]
[31m[11809699 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[11809699 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[11809700 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:49:45,952][60274] Fps is (10 sec: 410.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 937984. Throughput: 0: 77.8. Samples: 938376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:45,952][60274] Avg episode reward: [(0, '187.544')]
[36m[2025-06-29 14:49:50,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 937984. Throughput: 0: 78.1. Samples: 938612. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:50,981][60274] Avg episode reward: [(0, '200.925')]
[36m[2025-06-29 14:49:55,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 937984. Throughput: 0: 78.5. Samples: 939096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:49:55,949][60274] Avg episode reward: [(0, '201.472')]
[36m[2025-06-29 14:50:00,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 937984. Throughput: 0: 78.4. Samples: 939572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:50:00,948][60274] Avg episode reward: [(0, '194.045')]
[36m[2025-06-29 14:50:05,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 937984. Throughput: 0: 78.0. Samples: 939812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:50:05,955][60274] Avg episode reward: [(0, '198.822')]
[36m[2025-06-29 14:50:10,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 937984. Throughput: 0: 78.9. Samples: 940300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:50:10,974][60274] Avg episode reward: [(0, '206.297')]
[36m[2025-06-29 14:50:15,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 937984. Throughput: 0: 79.4. Samples: 940788. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:50:15,963][60274] Avg episode reward: [(0, '207.372')]
[36m[2025-06-29 14:50:20,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 937984. Throughput: 0: 79.7. Samples: 941028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:50:20,949][60274] Avg episode reward: [(0, '210.697')]
[36m[2025-06-29 14:50:25,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 937984. Throughput: 0: 80.1. Samples: 941540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:50:25,968][60274] Avg episode reward: [(0, '221.066')]
[36m[2025-06-29 14:50:30,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 937984. Throughput: 0: 80.8. Samples: 942016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:50:30,979][60274] Avg episode reward: [(0, '228.887')]
[36m[2025-06-29 14:50:35,957][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 942080. Throughput: 0: 79.9. Samples: 942204. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:50:35,957][60274] Avg episode reward: [(0, '236.463')]
[36m[2025-06-29 14:50:40,955][60274] Fps is (10 sec: 410.5, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 942080. Throughput: 0: 80.2. Samples: 942704. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:50:40,956][60274] Avg episode reward: [(0, '232.361')]
[36m[2025-06-29 14:50:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 942080. Throughput: 0: 80.0. Samples: 943176. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:50:45,970][60274] Avg episode reward: [(0, '236.606')]
[36m[2025-06-29 14:50:50,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 942080. Throughput: 0: 80.1. Samples: 943416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:50:50,957][60274] Avg episode reward: [(0, '226.677')]
[36m[2025-06-29 14:50:55,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 942080. Throughput: 0: 79.4. Samples: 943876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:50:55,988][60274] Avg episode reward: [(0, '220.576')]
[36m[2025-06-29 14:51:00,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 942080. Throughput: 0: 80.0. Samples: 944388. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:51:00,982][60274] Avg episode reward: [(0, '212.019')]
[37m[1m[2025-06-29 14:51:01,033][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003680_942080.pth...
[36m[2025-06-29 14:51:01,090][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003600_921600.pth
[36m[2025-06-29 14:51:05,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 942080. Throughput: 0: 80.0. Samples: 944628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:51:05,973][60274] Avg episode reward: [(0, '204.232')]
[36m[2025-06-29 14:51:10,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 942080. Throughput: 0: 78.7. Samples: 945080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:51:10,955][60274] Avg episode reward: [(0, '207.977')]
[36m[2025-06-29 14:51:15,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 942080. Throughput: 0: 79.0. Samples: 945572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:51:15,972][60274] Avg episode reward: [(0, '212.301')]
[31m[11905751 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[11905752 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[11905752 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:51:20,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 942080. Throughput: 0: 79.8. Samples: 945796. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 14:51:20,969][60274] Avg episode reward: [(0, '206.881')]
[36m[2025-06-29 14:51:25,964][60274] Fps is (10 sec: 409.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 946176. Throughput: 0: 77.9. Samples: 946212. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:51:25,965][60274] Avg episode reward: [(0, '207.634')]
[36m[2025-06-29 14:51:30,959][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 946176. Throughput: 0: 78.5. Samples: 946708. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:51:30,959][60274] Avg episode reward: [(0, '212.613')]
[36m[2025-06-29 14:51:35,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 946176. Throughput: 0: 78.0. Samples: 946928. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:51:35,984][60274] Avg episode reward: [(0, '221.594')]
[36m[2025-06-29 14:51:40,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 946176. Throughput: 0: 78.5. Samples: 947408. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:51:40,981][60274] Avg episode reward: [(0, '230.439')]
[36m[2025-06-29 14:51:45,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 946176. Throughput: 0: 77.3. Samples: 947868. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:51:45,976][60274] Avg episode reward: [(0, '225.025')]
[36m[2025-06-29 14:51:50,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 946176. Throughput: 0: 77.2. Samples: 948104. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:51:50,974][60274] Avg episode reward: [(0, '229.887')]
[36m[2025-06-29 14:51:55,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 946176. Throughput: 0: 77.9. Samples: 948588. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:51:55,991][60274] Avg episode reward: [(0, '233.222')]
[36m[2025-06-29 14:52:00,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 946176. Throughput: 0: 77.5. Samples: 949060. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:52:00,986][60274] Avg episode reward: [(0, '229.579')]
[36m[2025-06-29 14:52:05,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 946176. Throughput: 0: 77.8. Samples: 949296. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:52:05,952][60274] Avg episode reward: [(0, '224.884')]
[36m[2025-06-29 14:52:10,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 946176. Throughput: 0: 79.5. Samples: 949788. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:52:10,973][60274] Avg episode reward: [(0, '225.118')]
[36m[2025-06-29 14:52:15,994][60274] Fps is (10 sec: 407.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 950272. Throughput: 0: 79.2. Samples: 950276. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:52:15,995][60274] Avg episode reward: [(0, '232.751')]
[36m[2025-06-29 14:52:20,970][60274] Fps is (10 sec: 409.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 950272. Throughput: 0: 79.0. Samples: 950480. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:52:20,970][60274] Avg episode reward: [(0, '227.664')]
[36m[2025-06-29 14:52:25,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 950272. Throughput: 0: 79.2. Samples: 950968. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:52:25,952][60274] Avg episode reward: [(0, '212.615')]
[36m[2025-06-29 14:52:30,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 950272. Throughput: 0: 79.7. Samples: 951456. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:52:30,976][60274] Avg episode reward: [(0, '209.193')]
[36m[2025-06-29 14:52:35,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 950272. Throughput: 0: 80.0. Samples: 951704. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:52:35,988][60274] Avg episode reward: [(0, '207.650')]
[36m[2025-06-29 14:52:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 950272. Throughput: 0: 80.1. Samples: 952192. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:52:40,981][60274] Avg episode reward: [(0, '207.687')]
[36m[2025-06-29 14:52:45,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 950272. Throughput: 0: 80.6. Samples: 952688. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:52:45,975][60274] Avg episode reward: [(0, '213.689')]
[36m[2025-06-29 14:52:50,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 950272. Throughput: 0: 80.5. Samples: 952920. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:52:50,991][60274] Avg episode reward: [(0, '211.173')]
[36m[2025-06-29 14:52:55,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 950272. Throughput: 0: 80.2. Samples: 953396. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:52:55,982][60274] Avg episode reward: [(0, '215.918')]
[36m[2025-06-29 14:53:00,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 950272. Throughput: 0: 80.2. Samples: 953884. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:53:00,974][60274] Avg episode reward: [(0, '220.631')]
[37m[1m[2025-06-29 14:53:01,023][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003712_950272.pth...
[36m[2025-06-29 14:53:01,080][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003648_933888.pth
[36m[2025-06-29 14:53:05,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 950272. Throughput: 0: 81.1. Samples: 954132. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 14:53:05,977][60274] Avg episode reward: [(0, '220.811')]
[36m[2025-06-29 14:53:10,958][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 954368. Throughput: 0: 80.0. Samples: 954568. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 14:53:10,959][60274] Avg episode reward: [(0, '218.806')]
[36m[2025-06-29 14:53:15,954][60274] Fps is (10 sec: 410.6, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 954368. Throughput: 0: 80.5. Samples: 955076. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 14:53:15,954][60274] Avg episode reward: [(0, '231.417')]
[36m[2025-06-29 14:53:20,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 954368. Throughput: 0: 80.2. Samples: 955312. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 14:53:20,990][60274] Avg episode reward: [(0, '221.594')]
[36m[2025-06-29 14:53:25,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 954368. Throughput: 0: 80.1. Samples: 955796. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 14:53:25,962][60274] Avg episode reward: [(0, '221.950')]
[36m[2025-06-29 14:53:30,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 954368. Throughput: 0: 79.8. Samples: 956280. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 14:53:30,974][60274] Avg episode reward: [(0, '214.709')]
[36m[2025-06-29 14:53:35,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 954368. Throughput: 0: 80.3. Samples: 956532. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 14:53:35,992][60274] Avg episode reward: [(0, '207.047')]
[36m[2025-06-29 14:53:40,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 954368. Throughput: 0: 80.9. Samples: 957036. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 14:53:40,963][60274] Avg episode reward: [(0, '205.927')]
[36m[2025-06-29 14:53:45,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 954368. Throughput: 0: 81.1. Samples: 957532. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 14:53:45,960][60274] Avg episode reward: [(0, '212.617')]
[36m[2025-06-29 14:53:50,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 954368. Throughput: 0: 80.9. Samples: 957772. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 14:53:50,989][60274] Avg episode reward: [(0, '204.904')]
[36m[2025-06-29 14:53:55,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 954368. Throughput: 0: 81.9. Samples: 958252. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 14:53:55,955][60274] Avg episode reward: [(0, '199.766')]
[36m[2025-06-29 14:54:00,954][60274] Fps is (10 sec: 411.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 958464. Throughput: 0: 80.6. Samples: 958704. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:54:00,955][60274] Avg episode reward: [(0, '198.260')]
[36m[2025-06-29 14:54:05,988][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 958464. Throughput: 0: 81.1. Samples: 958960. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:54:05,988][60274] Avg episode reward: [(0, '193.300')]
[36m[2025-06-29 14:54:10,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 958464. Throughput: 0: 81.4. Samples: 959460. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:54:10,986][60274] Avg episode reward: [(0, '186.849')]
[36m[2025-06-29 14:54:15,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 958464. Throughput: 0: 81.7. Samples: 959956. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:54:15,980][60274] Avg episode reward: [(0, '188.370')]
[36m[2025-06-29 14:54:20,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 958464. Throughput: 0: 81.5. Samples: 960196. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:54:20,947][60274] Avg episode reward: [(0, '189.659')]
[36m[2025-06-29 14:54:25,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 958464. Throughput: 0: 81.0. Samples: 960680. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:54:25,948][60274] Avg episode reward: [(0, '190.672')]
[36m[2025-06-29 14:54:30,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 958464. Throughput: 0: 80.2. Samples: 961144. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:54:30,978][60274] Avg episode reward: [(0, '194.544')]
[36m[2025-06-29 14:54:35,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 958464. Throughput: 0: 80.7. Samples: 961400. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:54:35,959][60274] Avg episode reward: [(0, '194.970')]
[36m[2025-06-29 14:54:40,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 958464. Throughput: 0: 81.3. Samples: 961912. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:54:40,978][60274] Avg episode reward: [(0, '196.180')]
[36m[2025-06-29 14:54:45,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 958464. Throughput: 0: 82.0. Samples: 962396. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 14:54:45,977][60274] Avg episode reward: [(0, '190.596')]
[36m[2025-06-29 14:54:50,969][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 962560. Throughput: 0: 80.6. Samples: 962584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:54:50,969][60274] Avg episode reward: [(0, '196.729')]
[31m[12120535 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[12120535 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[12120535 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:54:55,949][60274] Fps is (10 sec: 410.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 962560. Throughput: 0: 80.1. Samples: 963060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:54:55,949][60274] Avg episode reward: [(0, '190.559')]
[36m[2025-06-29 14:55:00,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 962560. Throughput: 0: 79.5. Samples: 963532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:55:00,959][60274] Avg episode reward: [(0, '204.946')]
[37m[1m[2025-06-29 14:55:01,017][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003760_962560.pth...
[36m[2025-06-29 14:55:01,075][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003680_942080.pth
[36m[2025-06-29 14:55:05,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 962560. Throughput: 0: 79.6. Samples: 963780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:55:05,964][60274] Avg episode reward: [(0, '202.892')]
[36m[2025-06-29 14:55:10,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 962560. Throughput: 0: 79.7. Samples: 964268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:55:10,977][60274] Avg episode reward: [(0, '194.759')]
[36m[2025-06-29 14:55:15,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 962560. Throughput: 0: 79.9. Samples: 964736. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:55:15,949][60274] Avg episode reward: [(0, '206.943')]
[36m[2025-06-29 14:55:20,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 962560. Throughput: 0: 79.6. Samples: 964984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:55:20,961][60274] Avg episode reward: [(0, '204.660')]
[36m[2025-06-29 14:55:25,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 962560. Throughput: 0: 78.6. Samples: 965448. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:55:25,963][60274] Avg episode reward: [(0, '217.803')]
[36m[2025-06-29 14:55:30,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 962560. Throughput: 0: 78.3. Samples: 965920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:55:30,988][60274] Avg episode reward: [(0, '220.232')]
[36m[2025-06-29 14:55:35,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 962560. Throughput: 0: 79.6. Samples: 966164. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:55:35,955][60274] Avg episode reward: [(0, '232.114')]
[36m[2025-06-29 14:55:40,976][60274] Fps is (10 sec: 410.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 966656. Throughput: 0: 79.6. Samples: 966644. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:55:40,976][60274] Avg episode reward: [(0, '241.939')]
[36m[2025-06-29 14:55:45,994][60274] Fps is (10 sec: 408.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 966656. Throughput: 0: 78.8. Samples: 967080. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:55:45,994][60274] Avg episode reward: [(0, '258.235')]
[36m[2025-06-29 14:55:50,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 966656. Throughput: 0: 78.3. Samples: 967304. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:55:50,953][60274] Avg episode reward: [(0, '259.567')]
[36m[2025-06-29 14:55:55,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 966656. Throughput: 0: 77.8. Samples: 967768. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:55:55,987][60274] Avg episode reward: [(0, '252.789')]
[36m[2025-06-29 14:56:00,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 966656. Throughput: 0: 78.2. Samples: 968256. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:56:00,948][60274] Avg episode reward: [(0, '254.689')]
[36m[2025-06-29 14:56:05,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 966656. Throughput: 0: 78.2. Samples: 968504. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:56:05,982][60274] Avg episode reward: [(0, '265.097')]
[36m[2025-06-29 14:56:10,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 966656. Throughput: 0: 78.9. Samples: 969000. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:56:10,989][60274] Avg episode reward: [(0, '267.465')]
[36m[2025-06-29 14:56:15,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 966656. Throughput: 0: 79.2. Samples: 969484. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:56:15,968][60274] Avg episode reward: [(0, '268.411')]
[36m[2025-06-29 14:56:20,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 966656. Throughput: 0: 79.5. Samples: 969740. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:56:20,950][60274] Avg episode reward: [(0, '266.863')]
[36m[2025-06-29 14:56:25,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 966656. Throughput: 0: 79.7. Samples: 970228. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:56:25,960][60274] Avg episode reward: [(0, '272.676')]
[36m[2025-06-29 14:56:30,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 966656. Throughput: 0: 80.4. Samples: 970696. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 14:56:30,948][60274] Avg episode reward: [(0, '266.401')]
[36m[2025-06-29 14:56:35,954][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 970752. Throughput: 0: 79.5. Samples: 970880. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:56:35,954][60274] Avg episode reward: [(0, '268.578')]
[36m[2025-06-29 14:56:40,966][60274] Fps is (10 sec: 408.8, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 970752. Throughput: 0: 79.9. Samples: 971364. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:56:40,966][60274] Avg episode reward: [(0, '271.244')]
[36m[2025-06-29 14:56:45,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 970752. Throughput: 0: 80.0. Samples: 971856. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:56:45,959][60274] Avg episode reward: [(0, '261.590')]
[36m[2025-06-29 14:56:50,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 970752. Throughput: 0: 79.4. Samples: 972076. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:56:50,950][60274] Avg episode reward: [(0, '261.769')]
[36m[2025-06-29 14:56:55,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 970752. Throughput: 0: 78.8. Samples: 972548. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:56:55,987][60274] Avg episode reward: [(0, '248.157')]
[36m[2025-06-29 14:57:00,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 970752. Throughput: 0: 78.9. Samples: 973032. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:57:00,962][60274] Avg episode reward: [(0, '261.300')]
[37m[1m[2025-06-29 14:57:01,010][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003792_970752.pth...
[36m[2025-06-29 14:57:01,064][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003712_950272.pth
[36m[2025-06-29 14:57:05,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 970752. Throughput: 0: 78.0. Samples: 973252. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:57:05,953][60274] Avg episode reward: [(0, '271.578')]
[36m[2025-06-29 14:57:10,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 970752. Throughput: 0: 78.2. Samples: 973748. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:57:10,964][60274] Avg episode reward: [(0, '267.600')]
[36m[2025-06-29 14:57:15,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 970752. Throughput: 0: 78.2. Samples: 974216. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:57:15,958][60274] Avg episode reward: [(0, '272.608')]
[36m[2025-06-29 14:57:20,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 970752. Throughput: 0: 79.4. Samples: 974456. Policy #0 lag: (min: 10.0, avg: 10.0, max: 26.0)
[36m[2025-06-29 14:57:20,976][60274] Avg episode reward: [(0, '260.333')]
[36m[2025-06-29 14:57:25,962][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 974848. Throughput: 0: 78.0. Samples: 974872. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:57:25,962][60274] Avg episode reward: [(0, '253.274')]
[36m[2025-06-29 14:57:30,965][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 974848. Throughput: 0: 78.3. Samples: 975380. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:57:30,965][60274] Avg episode reward: [(0, '248.987')]
[36m[2025-06-29 14:57:35,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 974848. Throughput: 0: 78.7. Samples: 975620. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:57:35,967][60274] Avg episode reward: [(0, '251.973')]
[36m[2025-06-29 14:57:40,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 974848. Throughput: 0: 79.2. Samples: 976112. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:57:40,976][60274] Avg episode reward: [(0, '243.456')]
[36m[2025-06-29 14:57:45,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 974848. Throughput: 0: 79.6. Samples: 976612. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:57:45,955][60274] Avg episode reward: [(0, '240.454')]
[36m[2025-06-29 14:57:50,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 974848. Throughput: 0: 79.8. Samples: 976844. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:57:50,983][60274] Avg episode reward: [(0, '242.215')]
[36m[2025-06-29 14:57:55,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 974848. Throughput: 0: 79.0. Samples: 977304. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:57:55,962][60274] Avg episode reward: [(0, '253.968')]
[36m[2025-06-29 14:58:00,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 974848. Throughput: 0: 79.7. Samples: 977800. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:58:00,952][60274] Avg episode reward: [(0, '245.930')]
[36m[2025-06-29 14:58:05,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 974848. Throughput: 0: 79.7. Samples: 978040. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:58:05,961][60274] Avg episode reward: [(0, '239.655')]
[36m[2025-06-29 14:58:10,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 974848. Throughput: 0: 80.9. Samples: 978516. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 14:58:10,990][60274] Avg episode reward: [(0, '239.132')]
[36m[2025-06-29 14:58:15,979][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 978944. Throughput: 0: 79.4. Samples: 978956. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:58:15,979][60274] Avg episode reward: [(0, '238.966')]
[36m[2025-06-29 14:58:20,992][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 978944. Throughput: 0: 79.8. Samples: 979212. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:58:20,992][60274] Avg episode reward: [(0, '235.977')]
[36m[2025-06-29 14:58:25,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 978944. Throughput: 0: 79.7. Samples: 979696. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:58:25,969][60274] Avg episode reward: [(0, '236.145')]
[36m[2025-06-29 14:58:30,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 978944. Throughput: 0: 78.9. Samples: 980164. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:58:30,975][60274] Avg episode reward: [(0, '248.524')]
[36m[2025-06-29 14:58:35,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 978944. Throughput: 0: 79.5. Samples: 980420. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:58:35,971][60274] Avg episode reward: [(0, '246.029')]
[36m[2025-06-29 14:58:40,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 978944. Throughput: 0: 79.8. Samples: 980896. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:58:40,985][60274] Avg episode reward: [(0, '258.310')]
[36m[2025-06-29 14:58:45,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 978944. Throughput: 0: 78.9. Samples: 981352. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:58:45,978][60274] Avg episode reward: [(0, '247.578')]
[36m[2025-06-29 14:58:50,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 978944. Throughput: 0: 79.0. Samples: 981596. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:58:50,997][60274] Avg episode reward: [(0, '260.435')]
[36m[2025-06-29 14:58:55,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 978944. Throughput: 0: 78.8. Samples: 982064. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:58:56,000][60274] Avg episode reward: [(0, '254.858')]
[36m[2025-06-29 14:59:00,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 978944. Throughput: 0: 79.5. Samples: 982532. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:59:00,969][60274] Avg episode reward: [(0, '254.522')]
[37m[1m[2025-06-29 14:59:01,017][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003824_978944.pth...
[36m[2025-06-29 14:59:01,073][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003760_962560.pth
[36m[2025-06-29 14:59:05,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 978944. Throughput: 0: 79.2. Samples: 982776. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 14:59:05,971][60274] Avg episode reward: [(0, '249.045')]
[36m[2025-06-29 14:59:10,954][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 983040. Throughput: 0: 78.7. Samples: 983236. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:59:10,954][60274] Avg episode reward: [(0, '249.692')]
[31m[12377396 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[12377396 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[12377396 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 14:59:15,958][60274] Fps is (10 sec: 410.1, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 983040. Throughput: 0: 78.9. Samples: 983712. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:59:15,959][60274] Avg episode reward: [(0, '252.918')]
[36m[2025-06-29 14:59:20,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 983040. Throughput: 0: 78.7. Samples: 983960. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:59:20,980][60274] Avg episode reward: [(0, '245.772')]
[36m[2025-06-29 14:59:26,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 983040. Throughput: 0: 79.0. Samples: 984452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:59:26,004][60274] Avg episode reward: [(0, '263.473')]
[36m[2025-06-29 14:59:30,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 983040. Throughput: 0: 79.8. Samples: 984944. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:59:30,987][60274] Avg episode reward: [(0, '259.398')]
[36m[2025-06-29 14:59:35,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 983040. Throughput: 0: 79.7. Samples: 985180. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:59:35,990][60274] Avg episode reward: [(0, '262.777')]
[36m[2025-06-29 14:59:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 983040. Throughput: 0: 79.9. Samples: 985656. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:59:40,981][60274] Avg episode reward: [(0, '257.983')]
[36m[2025-06-29 14:59:45,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 983040. Throughput: 0: 80.2. Samples: 986144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:59:45,984][60274] Avg episode reward: [(0, '266.923')]
[36m[2025-06-29 14:59:50,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 983040. Throughput: 0: 80.1. Samples: 986380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:59:50,978][60274] Avg episode reward: [(0, '263.801')]
[36m[2025-06-29 14:59:55,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 983040. Throughput: 0: 81.0. Samples: 986884. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 14:59:55,971][60274] Avg episode reward: [(0, '261.060')]
[36m[2025-06-29 15:00:00,970][60274] Fps is (10 sec: 409.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 987136. Throughput: 0: 79.6. Samples: 987296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:00:00,970][60274] Avg episode reward: [(0, '263.268')]
[36m[2025-06-29 15:00:05,993][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 987136. Throughput: 0: 79.4. Samples: 987532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:00:05,994][60274] Avg episode reward: [(0, '255.174')]
[36m[2025-06-29 15:00:10,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 987136. Throughput: 0: 78.8. Samples: 987996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:00:10,984][60274] Avg episode reward: [(0, '260.318')]
[36m[2025-06-29 15:00:15,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 987136. Throughput: 0: 78.7. Samples: 988484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:00:15,992][60274] Avg episode reward: [(0, '257.770')]
[36m[2025-06-29 15:00:20,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 987136. Throughput: 0: 78.7. Samples: 988720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:00:20,951][60274] Avg episode reward: [(0, '258.162')]
[36m[2025-06-29 15:00:25,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 987136. Throughput: 0: 79.1. Samples: 989216. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:00:25,975][60274] Avg episode reward: [(0, '254.248')]
[36m[2025-06-29 15:00:30,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 987136. Throughput: 0: 79.2. Samples: 989704. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:00:30,960][60274] Avg episode reward: [(0, '243.885')]
[36m[2025-06-29 15:00:35,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 987136. Throughput: 0: 79.3. Samples: 989944. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:00:35,948][60274] Avg episode reward: [(0, '253.051')]
[36m[2025-06-29 15:00:40,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 987136. Throughput: 0: 79.1. Samples: 990440. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:00:40,954][60274] Avg episode reward: [(0, '251.640')]
[36m[2025-06-29 15:00:45,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 987136. Throughput: 0: 80.0. Samples: 990896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:00:45,964][60274] Avg episode reward: [(0, '249.769')]
[36m[2025-06-29 15:00:50,948][60274] Fps is (10 sec: 409.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 991232. Throughput: 0: 79.7. Samples: 991116. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:00:50,949][60274] Avg episode reward: [(0, '245.503')]
[36m[2025-06-29 15:00:55,974][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 991232. Throughput: 0: 79.6. Samples: 991576. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:00:55,974][60274] Avg episode reward: [(0, '232.608')]
[36m[2025-06-29 15:01:00,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 991232. Throughput: 0: 79.6. Samples: 992064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:01:00,982][60274] Avg episode reward: [(0, '236.789')]
[37m[1m[2025-06-29 15:01:01,031][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003872_991232.pth...
[36m[2025-06-29 15:01:01,085][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003792_970752.pth
[36m[2025-06-29 15:01:05,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 991232. Throughput: 0: 79.7. Samples: 992308. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:01:05,978][60274] Avg episode reward: [(0, '240.961')]
[36m[2025-06-29 15:01:10,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 991232. Throughput: 0: 78.7. Samples: 992760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:01:10,986][60274] Avg episode reward: [(0, '234.075')]
[36m[2025-06-29 15:01:15,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 991232. Throughput: 0: 78.3. Samples: 993228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:01:15,964][60274] Avg episode reward: [(0, '232.693')]
[36m[2025-06-29 15:01:20,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 991232. Throughput: 0: 77.8. Samples: 993444. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:01:20,963][60274] Avg episode reward: [(0, '231.839')]
[36m[2025-06-29 15:01:25,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 991232. Throughput: 0: 77.3. Samples: 993920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:01:25,975][60274] Avg episode reward: [(0, '227.301')]
[36m[2025-06-29 15:01:30,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 991232. Throughput: 0: 77.9. Samples: 994400. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:01:30,951][60274] Avg episode reward: [(0, '242.231')]
[36m[2025-06-29 15:01:35,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 991232. Throughput: 0: 78.4. Samples: 994644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:01:35,977][60274] Avg episode reward: [(0, '246.072')]
[36m[2025-06-29 15:01:40,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 991232. Throughput: 0: 78.9. Samples: 995124. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:01:40,968][60274] Avg episode reward: [(0, '250.724')]
[36m[2025-06-29 15:01:45,998][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 995328. Throughput: 0: 77.7. Samples: 995564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:01:45,998][60274] Avg episode reward: [(0, '251.442')]
[36m[2025-06-29 15:01:50,956][60274] Fps is (10 sec: 410.1, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 995328. Throughput: 0: 77.4. Samples: 995788. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:01:50,956][60274] Avg episode reward: [(0, '253.764')]
[36m[2025-06-29 15:01:55,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 995328. Throughput: 0: 78.3. Samples: 996280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:01:55,963][60274] Avg episode reward: [(0, '258.623')]
[36m[2025-06-29 15:02:00,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 995328. Throughput: 0: 78.9. Samples: 996780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:02:00,973][60274] Avg episode reward: [(0, '253.506')]
[36m[2025-06-29 15:02:05,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 995328. Throughput: 0: 78.9. Samples: 996996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:02:05,983][60274] Avg episode reward: [(0, '259.034')]
[36m[2025-06-29 15:02:10,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 995328. Throughput: 0: 79.5. Samples: 997496. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:02:10,963][60274] Avg episode reward: [(0, '246.022')]
[36m[2025-06-29 15:02:15,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 995328. Throughput: 0: 79.9. Samples: 997996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:02:15,979][60274] Avg episode reward: [(0, '236.806')]
[36m[2025-06-29 15:02:20,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 995328. Throughput: 0: 80.2. Samples: 998252. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:02:20,964][60274] Avg episode reward: [(0, '252.833')]
[36m[2025-06-29 15:02:25,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 995328. Throughput: 0: 80.4. Samples: 998740. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:02:25,968][60274] Avg episode reward: [(0, '238.579')]
[36m[2025-06-29 15:02:30,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 995328. Throughput: 0: 81.5. Samples: 999228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:02:30,982][60274] Avg episode reward: [(0, '236.633')]
[36m[2025-06-29 15:02:35,972][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 999424. Throughput: 0: 81.0. Samples: 999432. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:02:35,972][60274] Avg episode reward: [(0, '245.022')]
[36m[2025-06-29 15:02:40,978][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 999424. Throughput: 0: 80.1. Samples: 999884. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:02:40,978][60274] Avg episode reward: [(0, '249.407')]
[36m[2025-06-29 15:02:45,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 999424. Throughput: 0: 79.8. Samples: 1000372. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:02:45,989][60274] Avg episode reward: [(0, '251.636')]
[36m[2025-06-29 15:02:50,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 999424. Throughput: 0: 80.5. Samples: 1000616. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:02:50,955][60274] Avg episode reward: [(0, '250.051')]
[36m[2025-06-29 15:02:55,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 999424. Throughput: 0: 80.7. Samples: 1001128. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:02:55,969][60274] Avg episode reward: [(0, '242.498')]
[36m[2025-06-29 15:03:00,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 999424. Throughput: 0: 80.3. Samples: 1001608. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:03:00,956][60274] Avg episode reward: [(0, '250.097')]
[37m[1m[2025-06-29 15:03:01,009][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003904_999424.pth...
[36m[2025-06-29 15:03:01,064][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003824_978944.pth
[36m[2025-06-29 15:03:05,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 999424. Throughput: 0: 80.0. Samples: 1001852. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:03:05,981][60274] Avg episode reward: [(0, '240.247')]
[36m[2025-06-29 15:03:10,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 999424. Throughput: 0: 80.2. Samples: 1002352. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:03:10,990][60274] Avg episode reward: [(0, '235.161')]
[36m[2025-06-29 15:03:15,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 999424. Throughput: 0: 80.4. Samples: 1002844. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:03:15,978][60274] Avg episode reward: [(0, '224.004')]
[36m[2025-06-29 15:03:20,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 999424. Throughput: 0: 81.3. Samples: 1003092. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:03:20,968][60274] Avg episode reward: [(0, '221.163')]
[36m[2025-06-29 15:03:25,964][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1003520. Throughput: 0: 81.0. Samples: 1003528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:03:25,964][60274] Avg episode reward: [(0, '216.238')]
[37m[1m[2025-06-29 15:03:26,010][60274] Saving new best policy, reward=216.238!
[36m[2025-06-29 15:03:30,969][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1003520. Throughput: 0: 80.6. Samples: 1003996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:03:30,969][60274] Avg episode reward: [(0, '229.696')]
[37m[1m[2025-06-29 15:03:31,017][60274] Saving new best policy, reward=229.696!
[36m[2025-06-29 15:03:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1003520. Throughput: 0: 80.3. Samples: 1004232. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:03:35,972][60274] Avg episode reward: [(0, '223.556')]
[36m[2025-06-29 15:03:40,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1003520. Throughput: 0: 80.3. Samples: 1004740. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:03:40,960][60274] Avg episode reward: [(0, '219.485')]
[36m[2025-06-29 15:03:45,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1003520. Throughput: 0: 80.1. Samples: 1005216. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:03:45,982][60274] Avg episode reward: [(0, '222.886')]
[36m[2025-06-29 15:03:50,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1003520. Throughput: 0: 79.9. Samples: 1005448. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:03:50,967][60274] Avg episode reward: [(0, '232.797')]
[37m[1m[2025-06-29 15:03:51,014][60274] Saving new best policy, reward=232.797!
[36m[2025-06-29 15:03:55,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1003520. Throughput: 0: 79.9. Samples: 1005948. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:03:55,978][60274] Avg episode reward: [(0, '245.492')]
[37m[1m[2025-06-29 15:03:56,024][60274] Saving new best policy, reward=245.492!
[31m[12665525 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[12665526 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[12665526 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:04:00,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1003520. Throughput: 0: 80.0. Samples: 1006444. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:00,979][60274] Avg episode reward: [(0, '246.362')]
[37m[1m[2025-06-29 15:04:01,026][60274] Saving new best policy, reward=246.362!
[36m[2025-06-29 15:04:05,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1003520. Throughput: 0: 79.4. Samples: 1006664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:05,958][60274] Avg episode reward: [(0, '238.364')]
[36m[2025-06-29 15:04:10,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1003520. Throughput: 0: 80.8. Samples: 1007164. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:10,952][60274] Avg episode reward: [(0, '247.674')]
[37m[1m[2025-06-29 15:04:11,000][60274] Saving new best policy, reward=247.674!
[36m[2025-06-29 15:04:15,984][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1007616. Throughput: 0: 80.6. Samples: 1007624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:15,984][60274] Avg episode reward: [(0, '250.517')]
[37m[1m[2025-06-29 15:04:16,028][60274] Saving new best policy, reward=250.517!
[36m[2025-06-29 15:04:20,974][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1007616. Throughput: 0: 79.9. Samples: 1007828. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:20,974][60274] Avg episode reward: [(0, '237.773')]
[36m[2025-06-29 15:04:25,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1007616. Throughput: 0: 79.7. Samples: 1008328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:25,989][60274] Avg episode reward: [(0, '235.896')]
[36m[2025-06-29 15:04:31,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1007616. Throughput: 0: 79.9. Samples: 1008812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:31,007][60274] Avg episode reward: [(0, '240.149')]
[36m[2025-06-29 15:04:35,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1007616. Throughput: 0: 79.9. Samples: 1009044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:35,970][60274] Avg episode reward: [(0, '251.557')]
[37m[1m[2025-06-29 15:04:36,027][60274] Saving new best policy, reward=251.557!
[36m[2025-06-29 15:04:40,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1007616. Throughput: 0: 79.4. Samples: 1009520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:40,957][60274] Avg episode reward: [(0, '253.901')]
[37m[1m[2025-06-29 15:04:41,006][60274] Saving new best policy, reward=253.901!
[33m[12707429 ms][navigation_task] - WARNING : Curriculum Level: 36, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[12707429 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.69775390625
[33mCrash Rate: 0.240234375
[33mTimeout Rate: 0.06201171875 (navigation_task.py:265)
[33m[12707429 ms][navigation_task] - WARNING : 
[33mSuccesses: 1429
[33mCrashes : 492
[33mTimeouts: 127 (navigation_task.py:268)
[36m[2025-06-29 15:04:45,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1007616. Throughput: 0: 78.9. Samples: 1009992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:45,952][60274] Avg episode reward: [(0, '252.567')]
[36m[2025-06-29 15:04:50,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1007616. Throughput: 0: 79.1. Samples: 1010224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:50,989][60274] Avg episode reward: [(0, '248.430')]
[36m[2025-06-29 15:04:55,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1007616. Throughput: 0: 78.8. Samples: 1010712. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:04:55,971][60274] Avg episode reward: [(0, '256.662')]
[37m[1m[2025-06-29 15:04:56,016][60274] Saving new best policy, reward=256.662!
[36m[2025-06-29 15:05:00,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1007616. Throughput: 0: 79.5. Samples: 1011200. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:05:00,949][60274] Avg episode reward: [(0, '262.541')]
[37m[1m[2025-06-29 15:05:00,998][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003936_1007616.pth...
[36m[2025-06-29 15:05:01,053][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003872_991232.pth
[37m[1m[2025-06-29 15:05:01,059][60274] Saving new best policy, reward=262.541!
[36m[2025-06-29 15:05:05,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1007616. Throughput: 0: 80.0. Samples: 1011428. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:05:05,964][60274] Avg episode reward: [(0, '249.260')]
[36m[2025-06-29 15:05:10,967][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1011712. Throughput: 0: 79.0. Samples: 1011880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:05:10,967][60274] Avg episode reward: [(0, '251.646')]
[36m[2025-06-29 15:05:15,966][60274] Fps is (10 sec: 409.5, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1011712. Throughput: 0: 79.4. Samples: 1012384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:05:15,966][60274] Avg episode reward: [(0, '244.329')]
[36m[2025-06-29 15:05:20,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1011712. Throughput: 0: 79.6. Samples: 1012628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:05:20,974][60274] Avg episode reward: [(0, '237.230')]
[36m[2025-06-29 15:05:25,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1011712. Throughput: 0: 79.6. Samples: 1013104. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:05:25,960][60274] Avg episode reward: [(0, '246.531')]
[36m[2025-06-29 15:05:30,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1011712. Throughput: 0: 79.1. Samples: 1013552. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:05:30,968][60274] Avg episode reward: [(0, '242.238')]
[36m[2025-06-29 15:05:35,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1011712. Throughput: 0: 79.3. Samples: 1013792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:05:35,961][60274] Avg episode reward: [(0, '238.092')]
[36m[2025-06-29 15:05:40,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1011712. Throughput: 0: 78.8. Samples: 1014260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:05:40,972][60274] Avg episode reward: [(0, '231.494')]
[36m[2025-06-29 15:05:45,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1011712. Throughput: 0: 78.9. Samples: 1014752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:05:45,987][60274] Avg episode reward: [(0, '231.537')]
[36m[2025-06-29 15:05:50,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1011712. Throughput: 0: 78.8. Samples: 1014976. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:05:50,977][60274] Avg episode reward: [(0, '230.156')]
[36m[2025-06-29 15:05:55,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1011712. Throughput: 0: 79.3. Samples: 1015448. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:05:55,967][60274] Avg episode reward: [(0, '217.140')]
[36m[2025-06-29 15:06:00,954][60274] Fps is (10 sec: 410.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1015808. Throughput: 0: 78.1. Samples: 1015896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:00,955][60274] Avg episode reward: [(0, '204.293')]
[36m[2025-06-29 15:06:05,990][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1015808. Throughput: 0: 78.1. Samples: 1016144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:05,990][60274] Avg episode reward: [(0, '199.878')]
[36m[2025-06-29 15:06:10,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1015808. Throughput: 0: 78.2. Samples: 1016620. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:10,950][60274] Avg episode reward: [(0, '201.780')]
[36m[2025-06-29 15:06:15,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1015808. Throughput: 0: 78.7. Samples: 1017096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:15,976][60274] Avg episode reward: [(0, '199.000')]
[36m[2025-06-29 15:06:20,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1015808. Throughput: 0: 78.9. Samples: 1017344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:20,954][60274] Avg episode reward: [(0, '186.863')]
[36m[2025-06-29 15:06:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1015808. Throughput: 0: 79.2. Samples: 1017824. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:25,966][60274] Avg episode reward: [(0, '191.449')]
[36m[2025-06-29 15:06:30,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1015808. Throughput: 0: 79.2. Samples: 1018312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:30,956][60274] Avg episode reward: [(0, '189.980')]
[36m[2025-06-29 15:06:35,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1015808. Throughput: 0: 79.3. Samples: 1018544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:35,966][60274] Avg episode reward: [(0, '182.074')]
[36m[2025-06-29 15:06:40,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1015808. Throughput: 0: 79.3. Samples: 1019016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:40,955][60274] Avg episode reward: [(0, '200.262')]
[36m[2025-06-29 15:06:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1015808. Throughput: 0: 80.3. Samples: 1019512. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:45,970][60274] Avg episode reward: [(0, '200.993')]
[36m[2025-06-29 15:06:50,952][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1019904. Throughput: 0: 80.1. Samples: 1019744. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:50,953][60274] Avg episode reward: [(0, '201.190')]
[36m[2025-06-29 15:06:55,970][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1019904. Throughput: 0: 79.5. Samples: 1020200. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:06:55,970][60274] Avg episode reward: [(0, '204.795')]
[36m[2025-06-29 15:07:00,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1019904. Throughput: 0: 79.6. Samples: 1020676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:00,957][60274] Avg episode reward: [(0, '211.041')]
[37m[1m[2025-06-29 15:07:01,010][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003984_1019904.pth...
[36m[2025-06-29 15:07:01,067][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003904_999424.pth
[36m[2025-06-29 15:07:05,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1019904. Throughput: 0: 79.1. Samples: 1020908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:05,991][60274] Avg episode reward: [(0, '203.846')]
[36m[2025-06-29 15:07:10,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1019904. Throughput: 0: 79.4. Samples: 1021400. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:10,990][60274] Avg episode reward: [(0, '211.730')]
[36m[2025-06-29 15:07:15,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1019904. Throughput: 0: 79.2. Samples: 1021876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:15,969][60274] Avg episode reward: [(0, '211.224')]
[36m[2025-06-29 15:07:20,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1019904. Throughput: 0: 79.7. Samples: 1022132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:20,967][60274] Avg episode reward: [(0, '225.315')]
[36m[2025-06-29 15:07:25,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1019904. Throughput: 0: 79.8. Samples: 1022608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:25,958][60274] Avg episode reward: [(0, '219.200')]
[36m[2025-06-29 15:07:30,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1019904. Throughput: 0: 79.8. Samples: 1023104. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:30,977][60274] Avg episode reward: [(0, '222.894')]
[36m[2025-06-29 15:07:35,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1019904. Throughput: 0: 79.8. Samples: 1023336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:35,985][60274] Avg episode reward: [(0, '213.716')]
[36m[2025-06-29 15:07:40,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1019904. Throughput: 0: 80.7. Samples: 1023832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:40,972][60274] Avg episode reward: [(0, '218.957')]
[36m[2025-06-29 15:07:45,984][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1024000. Throughput: 0: 79.7. Samples: 1024264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:45,985][60274] Avg episode reward: [(0, '234.159')]
[36m[2025-06-29 15:07:50,995][60274] Fps is (10 sec: 408.6, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1024000. Throughput: 0: 79.6. Samples: 1024492. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:50,996][60274] Avg episode reward: [(0, '245.414')]
[36m[2025-06-29 15:07:55,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1024000. Throughput: 0: 78.9. Samples: 1024948. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:07:55,947][60274] Avg episode reward: [(0, '256.248')]
[36m[2025-06-29 15:08:00,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1024000. Throughput: 0: 78.6. Samples: 1025412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:00,952][60274] Avg episode reward: [(0, '260.598')]
[36m[2025-06-29 15:08:06,012][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1024000. Throughput: 0: 78.0. Samples: 1025644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:06,013][60274] Avg episode reward: [(0, '261.930')]
[36m[2025-06-29 15:08:10,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1024000. Throughput: 0: 78.7. Samples: 1026152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:10,989][60274] Avg episode reward: [(0, '268.397')]
[37m[1m[2025-06-29 15:08:11,050][60274] Saving new best policy, reward=268.397!
[36m[2025-06-29 15:08:15,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1024000. Throughput: 0: 78.3. Samples: 1026628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:15,974][60274] Avg episode reward: [(0, '261.291')]
[36m[2025-06-29 15:08:20,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1024000. Throughput: 0: 78.4. Samples: 1026864. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:20,956][60274] Avg episode reward: [(0, '254.319')]
[36m[2025-06-29 15:08:25,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1024000. Throughput: 0: 77.9. Samples: 1027336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:25,948][60274] Avg episode reward: [(0, '261.962')]
[36m[2025-06-29 15:08:30,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1024000. Throughput: 0: 79.1. Samples: 1027820. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:30,966][60274] Avg episode reward: [(0, '254.369')]
[36m[2025-06-29 15:08:35,983][60274] Fps is (10 sec: 408.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1028096. Throughput: 0: 79.6. Samples: 1028072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:35,984][60274] Avg episode reward: [(0, '253.955')]
[36m[2025-06-29 15:08:40,977][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1028096. Throughput: 0: 79.6. Samples: 1028532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:40,977][60274] Avg episode reward: [(0, '249.032')]
[36m[2025-06-29 15:08:45,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1028096. Throughput: 0: 79.9. Samples: 1029008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:45,952][60274] Avg episode reward: [(0, '249.336')]
[36m[2025-06-29 15:08:50,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1028096. Throughput: 0: 80.2. Samples: 1029248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:50,962][60274] Avg episode reward: [(0, '248.332')]
[36m[2025-06-29 15:08:55,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1028096. Throughput: 0: 80.0. Samples: 1029752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:08:55,982][60274] Avg episode reward: [(0, '250.330')]
[36m[2025-06-29 15:09:00,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1028096. Throughput: 0: 80.0. Samples: 1030228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:09:00,962][60274] Avg episode reward: [(0, '241.724')]
[37m[1m[2025-06-29 15:09:01,011][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004016_1028096.pth...
[36m[2025-06-29 15:09:01,067][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003936_1007616.pth
[36m[2025-06-29 15:09:05,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1028096. Throughput: 0: 80.1. Samples: 1030472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:09:05,990][60274] Avg episode reward: [(0, '250.522')]
[36m[2025-06-29 15:09:10,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1028096. Throughput: 0: 80.3. Samples: 1030952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:09:10,990][60274] Avg episode reward: [(0, '239.408')]
[36m[2025-06-29 15:09:15,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1028096. Throughput: 0: 79.8. Samples: 1031412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:09:15,965][60274] Avg episode reward: [(0, '246.176')]
[36m[2025-06-29 15:09:20,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1028096. Throughput: 0: 79.5. Samples: 1031648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:09:20,964][60274] Avg episode reward: [(0, '242.898')]
[36m[2025-06-29 15:09:25,951][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1032192. Throughput: 0: 80.0. Samples: 1032132. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:09:25,951][60274] Avg episode reward: [(0, '247.578')]
[36m[2025-06-29 15:09:30,958][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1032192. Throughput: 0: 79.0. Samples: 1032564. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:09:30,959][60274] Avg episode reward: [(0, '235.892')]
[36m[2025-06-29 15:09:35,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1032192. Throughput: 0: 79.5. Samples: 1032824. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:09:35,952][60274] Avg episode reward: [(0, '247.512')]
[36m[2025-06-29 15:09:40,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1032192. Throughput: 0: 79.3. Samples: 1033320. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:09:40,984][60274] Avg episode reward: [(0, '247.251')]
[36m[2025-06-29 15:09:45,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1032192. Throughput: 0: 79.9. Samples: 1033824. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:09:45,979][60274] Avg episode reward: [(0, '238.697')]
[36m[2025-06-29 15:09:51,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1032192. Throughput: 0: 79.9. Samples: 1034068. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:09:51,005][60274] Avg episode reward: [(0, '243.982')]
[36m[2025-06-29 15:09:55,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1032192. Throughput: 0: 80.0. Samples: 1034548. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:09:55,959][60274] Avg episode reward: [(0, '241.603')]
[36m[2025-06-29 15:10:00,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1032192. Throughput: 0: 80.2. Samples: 1035024. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:10:00,989][60274] Avg episode reward: [(0, '246.273')]
[36m[2025-06-29 15:10:05,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1032192. Throughput: 0: 80.0. Samples: 1035248. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:10:05,983][60274] Avg episode reward: [(0, '249.991')]
[36m[2025-06-29 15:10:10,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1032192. Throughput: 0: 80.0. Samples: 1035736. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:10:10,989][60274] Avg episode reward: [(0, '258.439')]
[36m[2025-06-29 15:10:15,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1032192. Throughput: 0: 81.5. Samples: 1036232. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:10:15,956][60274] Avg episode reward: [(0, '265.137')]
[36m[2025-06-29 15:10:20,969][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1036288. Throughput: 0: 80.0. Samples: 1036424. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:10:20,970][60274] Avg episode reward: [(0, '259.463')]
[36m[2025-06-29 15:10:25,957][60274] Fps is (10 sec: 409.5, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1036288. Throughput: 0: 79.2. Samples: 1036884. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:10:25,958][60274] Avg episode reward: [(0, '255.794')]
[36m[2025-06-29 15:10:30,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1036288. Throughput: 0: 78.8. Samples: 1037372. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:10:30,980][60274] Avg episode reward: [(0, '260.237')]
[36m[2025-06-29 15:10:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1036288. Throughput: 0: 78.7. Samples: 1037608. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:10:35,981][60274] Avg episode reward: [(0, '252.161')]
[36m[2025-06-29 15:10:40,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1036288. Throughput: 0: 78.8. Samples: 1038096. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:10:40,980][60274] Avg episode reward: [(0, '262.032')]
[36m[2025-06-29 15:10:45,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1036288. Throughput: 0: 78.2. Samples: 1038544. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:10:45,997][60274] Avg episode reward: [(0, '257.455')]
[36m[2025-06-29 15:10:50,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1036288. Throughput: 0: 78.1. Samples: 1038764. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:10:50,989][60274] Avg episode reward: [(0, '270.464')]
[37m[1m[2025-06-29 15:10:51,036][60274] Saving new best policy, reward=270.464!
[36m[2025-06-29 15:10:55,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1036288. Throughput: 0: 78.1. Samples: 1039248. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:10:55,983][60274] Avg episode reward: [(0, '274.280')]
[37m[1m[2025-06-29 15:10:56,028][60274] Saving new best policy, reward=274.280!
[36m[2025-06-29 15:11:00,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1036288. Throughput: 0: 77.6. Samples: 1039728. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:11:00,989][60274] Avg episode reward: [(0, '271.249')]
[37m[1m[2025-06-29 15:11:01,039][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004048_1036288.pth...
[36m[2025-06-29 15:11:01,094][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000003984_1019904.pth
[36m[2025-06-29 15:11:05,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1036288. Throughput: 0: 78.5. Samples: 1039956. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:11:05,978][60274] Avg episode reward: [(0, '263.002')]
[36m[2025-06-29 15:11:10,950][60274] Fps is (10 sec: 411.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1040384. Throughput: 0: 78.0. Samples: 1040392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:11:10,950][60274] Avg episode reward: [(0, '270.858')]
[36m[2025-06-29 15:11:15,950][60274] Fps is (10 sec: 410.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1040384. Throughput: 0: 78.4. Samples: 1040896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:11:15,950][60274] Avg episode reward: [(0, '259.636')]
[36m[2025-06-29 15:11:20,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1040384. Throughput: 0: 78.7. Samples: 1041148. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:11:20,981][60274] Avg episode reward: [(0, '261.162')]
[36m[2025-06-29 15:11:25,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1040384. Throughput: 0: 78.2. Samples: 1041616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:11:25,990][60274] Avg episode reward: [(0, '264.652')]
[36m[2025-06-29 15:11:30,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1040384. Throughput: 0: 79.0. Samples: 1042100. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:11:30,988][60274] Avg episode reward: [(0, '260.350')]
[36m[2025-06-29 15:11:35,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1040384. Throughput: 0: 79.7. Samples: 1042352. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:11:35,984][60274] Avg episode reward: [(0, '254.831')]
[36m[2025-06-29 15:11:40,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1040384. Throughput: 0: 79.8. Samples: 1042840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:11:40,985][60274] Avg episode reward: [(0, '264.632')]
[36m[2025-06-29 15:11:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1040384. Throughput: 0: 80.0. Samples: 1043328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:11:45,969][60274] Avg episode reward: [(0, '257.373')]
[36m[2025-06-29 15:11:50,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1040384. Throughput: 0: 80.2. Samples: 1043564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:11:50,952][60274] Avg episode reward: [(0, '255.965')]
[31m[13139243 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[13139244 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[13139244 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:11:55,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1040384. Throughput: 0: 81.6. Samples: 1044064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:11:55,954][60274] Avg episode reward: [(0, '239.256')]
[36m[2025-06-29 15:12:00,951][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1044480. Throughput: 0: 80.3. Samples: 1044508. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:12:00,952][60274] Avg episode reward: [(0, '236.424')]
[36m[2025-06-29 15:12:05,985][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1044480. Throughput: 0: 80.3. Samples: 1044760. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:12:05,985][60274] Avg episode reward: [(0, '232.481')]
[36m[2025-06-29 15:12:10,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1044480. Throughput: 0: 80.9. Samples: 1045252. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:12:10,958][60274] Avg episode reward: [(0, '237.513')]
[36m[2025-06-29 15:12:15,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1044480. Throughput: 0: 80.9. Samples: 1045736. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:12:15,957][60274] Avg episode reward: [(0, '255.548')]
[36m[2025-06-29 15:12:20,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1044480. Throughput: 0: 80.6. Samples: 1045976. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:12:20,974][60274] Avg episode reward: [(0, '257.539')]
[36m[2025-06-29 15:12:26,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1044480. Throughput: 0: 80.5. Samples: 1046464. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:12:26,007][60274] Avg episode reward: [(0, '252.668')]
[36m[2025-06-29 15:12:30,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1044480. Throughput: 0: 80.7. Samples: 1046956. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:12:30,951][60274] Avg episode reward: [(0, '248.015')]
[36m[2025-06-29 15:12:35,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1044480. Throughput: 0: 80.6. Samples: 1047192. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:12:35,988][60274] Avg episode reward: [(0, '242.385')]
[36m[2025-06-29 15:12:40,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1044480. Throughput: 0: 79.9. Samples: 1047660. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:12:40,948][60274] Avg episode reward: [(0, '242.452')]
[36m[2025-06-29 15:12:46,008][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1044480. Throughput: 0: 80.3. Samples: 1048128. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:12:46,008][60274] Avg episode reward: [(0, '239.714')]
[36m[2025-06-29 15:12:51,652][60274] Fps is (10 sec: 382.7, 60 sec: 135.0, 300 sec: 83.1). Total num frames: 1048576. Throughput: 0: 79.0. Samples: 1048368. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:12:51,653][60274] Avg episode reward: [(0, '232.429')]
[36m[2025-06-29 15:12:55,951][60274] Fps is (10 sec: 411.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1048576. Throughput: 0: 78.8. Samples: 1048796. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:12:55,952][60274] Avg episode reward: [(0, '240.242')]
[36m[2025-06-29 15:13:00,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1048576. Throughput: 0: 78.6. Samples: 1049272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:00,961][60274] Avg episode reward: [(0, '240.496')]
[37m[1m[2025-06-29 15:13:01,024][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004096_1048576.pth...
[36m[2025-06-29 15:13:01,081][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004016_1028096.pth
[36m[2025-06-29 15:13:05,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1048576. Throughput: 0: 78.5. Samples: 1049508. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:05,956][60274] Avg episode reward: [(0, '250.780')]
[36m[2025-06-29 15:13:10,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1048576. Throughput: 0: 78.2. Samples: 1049984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:10,998][60274] Avg episode reward: [(0, '254.761')]
[36m[2025-06-29 15:13:15,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1048576. Throughput: 0: 77.9. Samples: 1050464. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:15,955][60274] Avg episode reward: [(0, '255.601')]
[36m[2025-06-29 15:13:20,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1048576. Throughput: 0: 78.3. Samples: 1050712. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:20,954][60274] Avg episode reward: [(0, '260.856')]
[31m[13230018 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[13230018 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[13230019 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:13:25,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1048576. Throughput: 0: 78.7. Samples: 1051200. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:25,948][60274] Avg episode reward: [(0, '260.471')]
[36m[2025-06-29 15:13:30,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1048576. Throughput: 0: 79.2. Samples: 1051688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:30,982][60274] Avg episode reward: [(0, '252.921')]
[36m[2025-06-29 15:13:35,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1048576. Throughput: 0: 80.4. Samples: 1051932. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:35,970][60274] Avg episode reward: [(0, '255.724')]
[36m[2025-06-29 15:13:40,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1048576. Throughput: 0: 80.5. Samples: 1052420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:40,975][60274] Avg episode reward: [(0, '253.884')]
[36m[2025-06-29 15:13:45,983][60274] Fps is (10 sec: 409.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1052672. Throughput: 0: 80.0. Samples: 1052872. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:45,983][60274] Avg episode reward: [(0, '266.608')]
[36m[2025-06-29 15:13:50,975][60274] Fps is (10 sec: 409.6, 60 sec: 69.0, 300 sec: 83.3). Total num frames: 1052672. Throughput: 0: 80.0. Samples: 1053108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:50,975][60274] Avg episode reward: [(0, '262.767')]
[36m[2025-06-29 15:13:55,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1052672. Throughput: 0: 79.7. Samples: 1053568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:13:55,986][60274] Avg episode reward: [(0, '262.991')]
[36m[2025-06-29 15:14:01,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1052672. Throughput: 0: 79.8. Samples: 1054060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:14:01,004][60274] Avg episode reward: [(0, '265.181')]
[36m[2025-06-29 15:14:05,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1052672. Throughput: 0: 79.5. Samples: 1054292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:14:05,982][60274] Avg episode reward: [(0, '252.692')]
[36m[2025-06-29 15:14:10,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1052672. Throughput: 0: 79.4. Samples: 1054772. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:14:10,960][60274] Avg episode reward: [(0, '248.078')]
[36m[2025-06-29 15:14:15,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1052672. Throughput: 0: 78.7. Samples: 1055228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:14:15,988][60274] Avg episode reward: [(0, '250.468')]
[36m[2025-06-29 15:14:20,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1052672. Throughput: 0: 78.4. Samples: 1055460. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:14:20,954][60274] Avg episode reward: [(0, '249.851')]
[36m[2025-06-29 15:14:25,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1052672. Throughput: 0: 78.3. Samples: 1055940. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:14:25,950][60274] Avg episode reward: [(0, '249.216')]
[36m[2025-06-29 15:14:30,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1052672. Throughput: 0: 78.8. Samples: 1056416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:14:30,959][60274] Avg episode reward: [(0, '250.389')]
[36m[2025-06-29 15:14:35,958][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1056768. Throughput: 0: 79.2. Samples: 1056672. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:14:35,958][60274] Avg episode reward: [(0, '254.031')]
[36m[2025-06-29 15:14:40,968][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1056768. Throughput: 0: 78.5. Samples: 1057100. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:14:40,968][60274] Avg episode reward: [(0, '256.043')]
[36m[2025-06-29 15:14:45,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1056768. Throughput: 0: 78.0. Samples: 1057568. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:14:45,977][60274] Avg episode reward: [(0, '253.700')]
[36m[2025-06-29 15:14:50,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1056768. Throughput: 0: 78.1. Samples: 1057804. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:14:50,958][60274] Avg episode reward: [(0, '251.980')]
[36m[2025-06-29 15:14:55,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1056768. Throughput: 0: 77.5. Samples: 1058260. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:14:55,986][60274] Avg episode reward: [(0, '244.544')]
[36m[2025-06-29 15:15:00,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1056768. Throughput: 0: 78.0. Samples: 1058736. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:15:00,990][60274] Avg episode reward: [(0, '240.261')]
[37m[1m[2025-06-29 15:15:01,037][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004128_1056768.pth...
[36m[2025-06-29 15:15:01,092][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004048_1036288.pth
[31m[13329719 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[13329720 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[13329720 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:15:05,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1056768. Throughput: 0: 78.0. Samples: 1058972. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:15:05,963][60274] Avg episode reward: [(0, '235.264')]
[36m[2025-06-29 15:15:10,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1056768. Throughput: 0: 78.2. Samples: 1059460. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:15:10,947][60274] Avg episode reward: [(0, '221.158')]
[36m[2025-06-29 15:15:15,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1056768. Throughput: 0: 77.8. Samples: 1059916. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:15:15,971][60274] Avg episode reward: [(0, '227.210')]
[36m[2025-06-29 15:15:20,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1056768. Throughput: 0: 77.5. Samples: 1060160. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:15:20,968][60274] Avg episode reward: [(0, '241.337')]
[36m[2025-06-29 15:15:26,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1056768. Throughput: 0: 78.8. Samples: 1060648. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 15:15:26,006][60274] Avg episode reward: [(0, '218.802')]
[36m[2025-06-29 15:15:30,968][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1060864. Throughput: 0: 77.9. Samples: 1061072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:15:30,968][60274] Avg episode reward: [(0, '197.497')]
[36m[2025-06-29 15:15:35,970][60274] Fps is (10 sec: 411.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1060864. Throughput: 0: 78.3. Samples: 1061328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:15:35,970][60274] Avg episode reward: [(0, '208.370')]
[36m[2025-06-29 15:15:40,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1060864. Throughput: 0: 78.8. Samples: 1061804. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:15:40,959][60274] Avg episode reward: [(0, '197.301')]
[36m[2025-06-29 15:15:45,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1060864. Throughput: 0: 79.3. Samples: 1062304. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:15:45,991][60274] Avg episode reward: [(0, '201.075')]
[36m[2025-06-29 15:15:50,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1060864. Throughput: 0: 79.3. Samples: 1062540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:15:50,962][60274] Avg episode reward: [(0, '201.799')]
[36m[2025-06-29 15:15:55,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1060864. Throughput: 0: 79.2. Samples: 1063024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:15:55,966][60274] Avg episode reward: [(0, '195.651')]
[36m[2025-06-29 15:16:00,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1060864. Throughput: 0: 79.5. Samples: 1063496. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:16:00,988][60274] Avg episode reward: [(0, '197.425')]
[36m[2025-06-29 15:16:05,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1060864. Throughput: 0: 79.3. Samples: 1063728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:16:05,975][60274] Avg episode reward: [(0, '199.986')]
[36m[2025-06-29 15:16:10,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1060864. Throughput: 0: 78.8. Samples: 1064192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:16:10,962][60274] Avg episode reward: [(0, '212.495')]
[36m[2025-06-29 15:16:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1060864. Throughput: 0: 80.4. Samples: 1064688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:16:15,952][60274] Avg episode reward: [(0, '205.360')]
[36m[2025-06-29 15:16:20,959][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1064960. Throughput: 0: 80.0. Samples: 1064928. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 15:16:20,960][60274] Avg episode reward: [(0, '208.219')]
[36m[2025-06-29 15:16:25,981][60274] Fps is (10 sec: 408.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1064960. Throughput: 0: 79.2. Samples: 1065372. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 15:16:25,981][60274] Avg episode reward: [(0, '187.232')]
[36m[2025-06-29 15:16:30,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1064960. Throughput: 0: 79.4. Samples: 1065876. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 15:16:30,960][60274] Avg episode reward: [(0, '187.729')]
[36m[2025-06-29 15:16:35,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1064960. Throughput: 0: 79.6. Samples: 1066120. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 15:16:35,957][60274] Avg episode reward: [(0, '189.259')]
[36m[2025-06-29 15:16:40,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1064960. Throughput: 0: 79.5. Samples: 1066604. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 15:16:40,982][60274] Avg episode reward: [(0, '180.766')]
[36m[2025-06-29 15:16:45,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1064960. Throughput: 0: 79.9. Samples: 1067092. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 15:16:45,994][60274] Avg episode reward: [(0, '177.464')]
[36m[2025-06-29 15:16:50,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1064960. Throughput: 0: 79.8. Samples: 1067316. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 15:16:50,954][60274] Avg episode reward: [(0, '188.519')]
[36m[2025-06-29 15:16:55,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1064960. Throughput: 0: 79.2. Samples: 1067756. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 15:16:55,950][60274] Avg episode reward: [(0, '177.562')]
[36m[2025-06-29 15:17:00,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1064960. Throughput: 0: 79.0. Samples: 1068244. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 15:17:00,961][60274] Avg episode reward: [(0, '181.660')]
[37m[1m[2025-06-29 15:17:01,009][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004160_1064960.pth...
[36m[2025-06-29 15:17:01,066][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004096_1048576.pth
[36m[2025-06-29 15:17:05,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1064960. Throughput: 0: 78.5. Samples: 1068464. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 15:17:05,978][60274] Avg episode reward: [(0, '188.195')]
[36m[2025-06-29 15:17:11,449][60274] Fps is (10 sec: 390.6, 60 sec: 135.4, 300 sec: 83.2). Total num frames: 1069056. Throughput: 0: 78.7. Samples: 1068952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:17:11,449][60274] Avg episode reward: [(0, '199.344')]
[36m[2025-06-29 15:17:15,958][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1069056. Throughput: 0: 77.7. Samples: 1069372. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:17:15,958][60274] Avg episode reward: [(0, '208.860')]
[36m[2025-06-29 15:17:20,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1069056. Throughput: 0: 77.8. Samples: 1069620. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:17:20,948][60274] Avg episode reward: [(0, '207.058')]
[36m[2025-06-29 15:17:26,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1069056. Throughput: 0: 77.9. Samples: 1070112. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:17:26,007][60274] Avg episode reward: [(0, '216.458')]
[36m[2025-06-29 15:17:30,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1069056. Throughput: 0: 77.2. Samples: 1070564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:17:30,980][60274] Avg episode reward: [(0, '220.121')]
[36m[2025-06-29 15:17:35,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1069056. Throughput: 0: 77.8. Samples: 1070820. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:17:35,976][60274] Avg episode reward: [(0, '218.481')]
[36m[2025-06-29 15:17:40,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1069056. Throughput: 0: 79.2. Samples: 1071320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:17:40,951][60274] Avg episode reward: [(0, '223.836')]
[36m[2025-06-29 15:17:45,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 1069056. Throughput: 0: 79.3. Samples: 1071812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:17:45,973][60274] Avg episode reward: [(0, '230.860')]
[36m[2025-06-29 15:17:50,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1069056. Throughput: 0: 79.9. Samples: 1072060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:17:50,980][60274] Avg episode reward: [(0, '222.946')]
[36m[2025-06-29 15:17:55,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1069056. Throughput: 0: 80.9. Samples: 1072556. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:17:55,973][60274] Avg episode reward: [(0, '211.854')]
[36m[2025-06-29 15:18:00,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1069056. Throughput: 0: 81.3. Samples: 1073032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:00,980][60274] Avg episode reward: [(0, '215.295')]
[36m[2025-06-29 15:18:05,980][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1073152. Throughput: 0: 79.8. Samples: 1073212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:05,980][60274] Avg episode reward: [(0, '207.479')]
[36m[2025-06-29 15:18:10,966][60274] Fps is (10 sec: 410.1, 60 sec: 68.8, 300 sec: 83.3). Total num frames: 1073152. Throughput: 0: 79.5. Samples: 1073688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:10,967][60274] Avg episode reward: [(0, '212.174')]
[36m[2025-06-29 15:18:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1073152. Throughput: 0: 80.1. Samples: 1074168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:15,953][60274] Avg episode reward: [(0, '219.949')]
[36m[2025-06-29 15:18:20,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1073152. Throughput: 0: 79.5. Samples: 1074396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:20,965][60274] Avg episode reward: [(0, '217.459')]
[36m[2025-06-29 15:18:25,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1073152. Throughput: 0: 79.2. Samples: 1074888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:25,977][60274] Avg episode reward: [(0, '218.256')]
[36m[2025-06-29 15:18:30,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1073152. Throughput: 0: 78.8. Samples: 1075356. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:30,966][60274] Avg episode reward: [(0, '228.072')]
[36m[2025-06-29 15:18:35,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1073152. Throughput: 0: 78.1. Samples: 1075572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:35,954][60274] Avg episode reward: [(0, '228.163')]
[36m[2025-06-29 15:18:40,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1073152. Throughput: 0: 77.5. Samples: 1076044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:40,977][60274] Avg episode reward: [(0, '229.474')]
[36m[2025-06-29 15:18:45,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1073152. Throughput: 0: 77.9. Samples: 1076536. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:45,976][60274] Avg episode reward: [(0, '235.038')]
[36m[2025-06-29 15:18:50,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1073152. Throughput: 0: 79.2. Samples: 1076776. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:18:50,953][60274] Avg episode reward: [(0, '229.882')]
[36m[2025-06-29 15:18:55,998][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1077248. Throughput: 0: 78.9. Samples: 1077240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:18:55,999][60274] Avg episode reward: [(0, '235.961')]
[36m[2025-06-29 15:19:00,974][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1077248. Throughput: 0: 77.7. Samples: 1077664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:19:00,975][60274] Avg episode reward: [(0, '236.855')]
[37m[1m[2025-06-29 15:19:01,027][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004208_1077248.pth...
[36m[2025-06-29 15:19:01,085][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004128_1056768.pth
[36m[2025-06-29 15:19:05,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1077248. Throughput: 0: 77.5. Samples: 1077884. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:19:05,958][60274] Avg episode reward: [(0, '239.688')]
[36m[2025-06-29 15:19:10,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1077248. Throughput: 0: 77.9. Samples: 1078392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:19:10,948][60274] Avg episode reward: [(0, '235.233')]
[36m[2025-06-29 15:19:15,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1077248. Throughput: 0: 78.6. Samples: 1078892. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:19:15,947][60274] Avg episode reward: [(0, '231.972')]
[36m[2025-06-29 15:19:20,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1077248. Throughput: 0: 78.9. Samples: 1079124. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:19:20,982][60274] Avg episode reward: [(0, '229.238')]
[36m[2025-06-29 15:19:25,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1077248. Throughput: 0: 78.9. Samples: 1079592. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:19:25,964][60274] Avg episode reward: [(0, '236.519')]
[36m[2025-06-29 15:19:30,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1077248. Throughput: 0: 78.8. Samples: 1080084. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:19:30,982][60274] Avg episode reward: [(0, '229.501')]
[36m[2025-06-29 15:19:35,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1077248. Throughput: 0: 78.9. Samples: 1080328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:19:35,979][60274] Avg episode reward: [(0, '228.127')]
[36m[2025-06-29 15:19:40,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1077248. Throughput: 0: 79.5. Samples: 1080816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:19:40,953][60274] Avg episode reward: [(0, '227.757')]
[36m[2025-06-29 15:19:46,713][60274] Fps is (10 sec: 381.6, 60 sec: 134.9, 300 sec: 83.1). Total num frames: 1081344. Throughput: 0: 79.2. Samples: 1081288. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:19:46,713][60274] Avg episode reward: [(0, '231.124')]
[36m[2025-06-29 15:19:50,989][60274] Fps is (10 sec: 408.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1081344. Throughput: 0: 79.7. Samples: 1081472. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:19:50,989][60274] Avg episode reward: [(0, '226.309')]
[36m[2025-06-29 15:19:55,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1081344. Throughput: 0: 79.3. Samples: 1081960. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:19:55,947][60274] Avg episode reward: [(0, '238.231')]
[36m[2025-06-29 15:20:00,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1081344. Throughput: 0: 78.9. Samples: 1082444. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:20:00,961][60274] Avg episode reward: [(0, '236.444')]
[36m[2025-06-29 15:20:05,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1081344. Throughput: 0: 79.4. Samples: 1082692. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:20:05,947][60274] Avg episode reward: [(0, '253.035')]
[36m[2025-06-29 15:20:11,002][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1081344. Throughput: 0: 79.9. Samples: 1083192. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:20:11,002][60274] Avg episode reward: [(0, '259.836')]
[36m[2025-06-29 15:20:15,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1081344. Throughput: 0: 80.0. Samples: 1083680. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:20:15,949][60274] Avg episode reward: [(0, '252.257')]
[36m[2025-06-29 15:20:20,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1081344. Throughput: 0: 79.9. Samples: 1083920. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:20:20,954][60274] Avg episode reward: [(0, '255.934')]
[36m[2025-06-29 15:20:25,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1081344. Throughput: 0: 79.0. Samples: 1084372. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:20:25,948][60274] Avg episode reward: [(0, '268.066')]
[36m[2025-06-29 15:20:30,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1081344. Throughput: 0: 80.9. Samples: 1084868. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:20:30,947][60274] Avg episode reward: [(0, '261.332')]
[36m[2025-06-29 15:20:35,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1081344. Throughput: 0: 80.9. Samples: 1085112. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 15:20:35,956][60274] Avg episode reward: [(0, '267.870')]
[36m[2025-06-29 15:20:40,987][60274] Fps is (10 sec: 407.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1085440. Throughput: 0: 79.6. Samples: 1085544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:20:40,988][60274] Avg episode reward: [(0, '266.263')]
[36m[2025-06-29 15:20:45,980][60274] Fps is (10 sec: 408.6, 60 sec: 69.1, 300 sec: 83.3). Total num frames: 1085440. Throughput: 0: 80.0. Samples: 1086044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:20:45,980][60274] Avg episode reward: [(0, '273.303')]
[36m[2025-06-29 15:20:50,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1085440. Throughput: 0: 79.7. Samples: 1086284. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:20:50,996][60274] Avg episode reward: [(0, '255.346')]
[36m[2025-06-29 15:20:55,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1085440. Throughput: 0: 79.3. Samples: 1086760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:20:55,981][60274] Avg episode reward: [(0, '255.280')]
[36m[2025-06-29 15:21:00,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1085440. Throughput: 0: 79.5. Samples: 1087260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:21:00,986][60274] Avg episode reward: [(0, '250.542')]
[37m[1m[2025-06-29 15:21:01,035][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004240_1085440.pth...
[36m[2025-06-29 15:21:01,094][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004160_1064960.pth
[36m[2025-06-29 15:21:05,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1085440. Throughput: 0: 79.8. Samples: 1087516. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:21:05,991][60274] Avg episode reward: [(0, '253.042')]
[36m[2025-06-29 15:21:10,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1085440. Throughput: 0: 80.7. Samples: 1088004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:21:10,952][60274] Avg episode reward: [(0, '250.691')]
[36m[2025-06-29 15:21:15,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1085440. Throughput: 0: 80.1. Samples: 1088476. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:21:15,983][60274] Avg episode reward: [(0, '252.121')]
[36m[2025-06-29 15:21:20,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1085440. Throughput: 0: 79.9. Samples: 1088708. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:21:20,951][60274] Avg episode reward: [(0, '250.526')]
[36m[2025-06-29 15:21:25,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1085440. Throughput: 0: 81.0. Samples: 1089184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:21:25,953][60274] Avg episode reward: [(0, '255.482')]
[36m[2025-06-29 15:21:30,954][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1089536. Throughput: 0: 79.3. Samples: 1089612. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:21:30,954][60274] Avg episode reward: [(0, '255.641')]
[36m[2025-06-29 15:21:35,971][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1089536. Throughput: 0: 79.6. Samples: 1089864. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:21:35,971][60274] Avg episode reward: [(0, '259.611')]
[36m[2025-06-29 15:21:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1089536. Throughput: 0: 79.7. Samples: 1090348. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:21:40,982][60274] Avg episode reward: [(0, '253.593')]
[36m[2025-06-29 15:21:45,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1089536. Throughput: 0: 79.5. Samples: 1090836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:21:45,979][60274] Avg episode reward: [(0, '255.284')]
[36m[2025-06-29 15:21:50,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1089536. Throughput: 0: 79.3. Samples: 1091080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:21:50,952][60274] Avg episode reward: [(0, '244.793')]
[36m[2025-06-29 15:21:55,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1089536. Throughput: 0: 79.4. Samples: 1091580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:21:55,980][60274] Avg episode reward: [(0, '243.245')]
[36m[2025-06-29 15:22:00,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1089536. Throughput: 0: 80.0. Samples: 1092076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:22:00,987][60274] Avg episode reward: [(0, '242.224')]
[36m[2025-06-29 15:22:05,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 1089536. Throughput: 0: 80.2. Samples: 1092320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:22:05,989][60274] Avg episode reward: [(0, '240.889')]
[36m[2025-06-29 15:22:10,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1089536. Throughput: 0: 80.4. Samples: 1092800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:22:10,948][60274] Avg episode reward: [(0, '223.161')]
[36m[2025-06-29 15:22:15,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1089536. Throughput: 0: 81.6. Samples: 1093288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:22:15,994][60274] Avg episode reward: [(0, '217.462')]
[36m[2025-06-29 15:22:20,959][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1093632. Throughput: 0: 81.6. Samples: 1093536. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:22:20,959][60274] Avg episode reward: [(0, '215.935')]
[36m[2025-06-29 15:22:25,976][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1093632. Throughput: 0: 81.0. Samples: 1093992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:22:25,976][60274] Avg episode reward: [(0, '221.174')]
[36m[2025-06-29 15:22:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1093632. Throughput: 0: 80.1. Samples: 1094440. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:22:30,990][60274] Avg episode reward: [(0, '221.562')]
[36m[2025-06-29 15:22:35,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1093632. Throughput: 0: 80.2. Samples: 1094692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:22:35,990][60274] Avg episode reward: [(0, '221.480')]
[36m[2025-06-29 15:22:40,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1093632. Throughput: 0: 80.1. Samples: 1095184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:22:40,993][60274] Avg episode reward: [(0, '219.733')]
[36m[2025-06-29 15:22:45,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1093632. Throughput: 0: 79.6. Samples: 1095656. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:22:45,947][60274] Avg episode reward: [(0, '223.558')]
[36m[2025-06-29 15:22:50,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1093632. Throughput: 0: 79.1. Samples: 1095880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:22:50,969][60274] Avg episode reward: [(0, '215.765')]
[36m[2025-06-29 15:22:55,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1093632. Throughput: 0: 79.1. Samples: 1096364. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:22:55,996][60274] Avg episode reward: [(0, '216.548')]
[36m[2025-06-29 15:23:00,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1093632. Throughput: 0: 79.5. Samples: 1096860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:23:00,947][60274] Avg episode reward: [(0, '219.659')]
[37m[1m[2025-06-29 15:23:00,996][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004272_1093632.pth...
[36m[2025-06-29 15:23:01,052][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004208_1077248.pth
[36m[2025-06-29 15:23:05,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1093632. Throughput: 0: 78.9. Samples: 1097088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:23:05,963][60274] Avg episode reward: [(0, '210.885')]
[36m[2025-06-29 15:23:10,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1093632. Throughput: 0: 79.6. Samples: 1097576. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:23:10,984][60274] Avg episode reward: [(0, '208.841')]
[36m[2025-06-29 15:23:15,988][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1097728. Throughput: 0: 79.0. Samples: 1097996. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:23:15,989][60274] Avg episode reward: [(0, '215.561')]
[36m[2025-06-29 15:23:20,961][60274] Fps is (10 sec: 410.5, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1097728. Throughput: 0: 79.0. Samples: 1098244. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:23:20,961][60274] Avg episode reward: [(0, '200.319')]
[36m[2025-06-29 15:23:25,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1097728. Throughput: 0: 79.1. Samples: 1098744. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:23:25,988][60274] Avg episode reward: [(0, '214.927')]
[36m[2025-06-29 15:23:31,010][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1097728. Throughput: 0: 79.6. Samples: 1099244. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:23:31,010][60274] Avg episode reward: [(0, '214.860')]
[36m[2025-06-29 15:23:35,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1097728. Throughput: 0: 79.8. Samples: 1099472. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:23:35,974][60274] Avg episode reward: [(0, '219.842')]
[36m[2025-06-29 15:23:40,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1097728. Throughput: 0: 79.7. Samples: 1099948. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:23:40,950][60274] Avg episode reward: [(0, '223.901')]
[36m[2025-06-29 15:23:45,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1097728. Throughput: 0: 79.4. Samples: 1100436. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:23:45,979][60274] Avg episode reward: [(0, '217.607')]
[36m[2025-06-29 15:23:50,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1097728. Throughput: 0: 79.4. Samples: 1100664. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:23:50,992][60274] Avg episode reward: [(0, '222.753')]
[36m[2025-06-29 15:23:55,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1097728. Throughput: 0: 79.9. Samples: 1101168. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:23:55,964][60274] Avg episode reward: [(0, '234.518')]
[36m[2025-06-29 15:24:00,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1097728. Throughput: 0: 81.1. Samples: 1101644. Policy #0 lag: (min: 11.0, avg: 11.0, max: 27.0)
[36m[2025-06-29 15:24:00,948][60274] Avg episode reward: [(0, '242.060')]
[36m[2025-06-29 15:24:05,947][60274] Fps is (10 sec: 410.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1101824. Throughput: 0: 79.8. Samples: 1101832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:24:05,948][60274] Avg episode reward: [(0, '233.225')]
[36m[2025-06-29 15:24:10,986][60274] Fps is (10 sec: 408.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1101824. Throughput: 0: 79.4. Samples: 1102316. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:24:10,986][60274] Avg episode reward: [(0, '238.296')]
[36m[2025-06-29 15:24:15,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1101824. Throughput: 0: 79.0. Samples: 1102796. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:24:15,947][60274] Avg episode reward: [(0, '230.134')]
[36m[2025-06-29 15:24:20,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1101824. Throughput: 0: 79.3. Samples: 1103040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:24:20,978][60274] Avg episode reward: [(0, '238.745')]
[36m[2025-06-29 15:24:25,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1101824. Throughput: 0: 79.5. Samples: 1103528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:24:25,971][60274] Avg episode reward: [(0, '245.897')]
[36m[2025-06-29 15:24:30,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1101824. Throughput: 0: 80.1. Samples: 1104040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:24:30,986][60274] Avg episode reward: [(0, '242.250')]
[36m[2025-06-29 15:24:35,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1101824. Throughput: 0: 80.1. Samples: 1104268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:24:35,963][60274] Avg episode reward: [(0, '230.536')]
[36m[2025-06-29 15:24:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 1101824. Throughput: 0: 79.9. Samples: 1104760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:24:40,947][60274] Avg episode reward: [(0, '240.695')]
[36m[2025-06-29 15:24:45,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1101824. Throughput: 0: 80.1. Samples: 1105252. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:24:45,968][60274] Avg episode reward: [(0, '240.971')]
[36m[2025-06-29 15:24:50,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1101824. Throughput: 0: 81.6. Samples: 1105504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:24:50,947][60274] Avg episode reward: [(0, '242.711')]
[36m[2025-06-29 15:24:55,982][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1105920. Throughput: 0: 80.5. Samples: 1105936. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:24:55,982][60274] Avg episode reward: [(0, '238.005')]
[36m[2025-06-29 15:25:00,991][60274] Fps is (10 sec: 407.8, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1105920. Throughput: 0: 80.8. Samples: 1106436. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:00,991][60274] Avg episode reward: [(0, '238.317')]
[37m[1m[2025-06-29 15:25:00,995][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004320_1105920.pth...
[36m[2025-06-29 15:25:01,048][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004240_1085440.pth
[36m[2025-06-29 15:25:05,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1105920. Throughput: 0: 80.5. Samples: 1106660. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:05,954][60274] Avg episode reward: [(0, '244.001')]
[36m[2025-06-29 15:25:10,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1105920. Throughput: 0: 80.2. Samples: 1107136. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:10,974][60274] Avg episode reward: [(0, '239.009')]
[36m[2025-06-29 15:25:15,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1105920. Throughput: 0: 79.1. Samples: 1107600. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:15,970][60274] Avg episode reward: [(0, '250.755')]
[36m[2025-06-29 15:25:20,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1105920. Throughput: 0: 79.4. Samples: 1107844. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:20,973][60274] Avg episode reward: [(0, '243.492')]
[36m[2025-06-29 15:25:25,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1105920. Throughput: 0: 79.5. Samples: 1108336. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:25,950][60274] Avg episode reward: [(0, '243.688')]
[36m[2025-06-29 15:25:30,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1105920. Throughput: 0: 79.3. Samples: 1108820. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:30,972][60274] Avg episode reward: [(0, '250.136')]
[36m[2025-06-29 15:25:35,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1105920. Throughput: 0: 79.4. Samples: 1109076. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:35,959][60274] Avg episode reward: [(0, '251.659')]
[36m[2025-06-29 15:25:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1105920. Throughput: 0: 80.3. Samples: 1109548. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:40,981][60274] Avg episode reward: [(0, '253.953')]
[36m[2025-06-29 15:25:45,961][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1110016. Throughput: 0: 79.8. Samples: 1110024. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:45,961][60274] Avg episode reward: [(0, '243.908')]
[36m[2025-06-29 15:25:50,974][60274] Fps is (10 sec: 409.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1110016. Throughput: 0: 79.3. Samples: 1110228. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:50,974][60274] Avg episode reward: [(0, '246.439')]
[36m[2025-06-29 15:25:55,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1110016. Throughput: 0: 79.6. Samples: 1110720. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:25:55,986][60274] Avg episode reward: [(0, '233.215')]
[36m[2025-06-29 15:26:00,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1110016. Throughput: 0: 80.5. Samples: 1111220. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:26:00,962][60274] Avg episode reward: [(0, '236.276')]
[36m[2025-06-29 15:26:05,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1110016. Throughput: 0: 80.3. Samples: 1111456. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:26:05,958][60274] Avg episode reward: [(0, '233.960')]
[36m[2025-06-29 15:26:10,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1110016. Throughput: 0: 79.8. Samples: 1111928. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:26:10,976][60274] Avg episode reward: [(0, '232.711')]
[36m[2025-06-29 15:26:15,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1110016. Throughput: 0: 80.0. Samples: 1112420. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:26:15,987][60274] Avg episode reward: [(0, '230.848')]
[36m[2025-06-29 15:26:20,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1110016. Throughput: 0: 79.6. Samples: 1112656. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:26:20,949][60274] Avg episode reward: [(0, '234.687')]
[36m[2025-06-29 15:26:25,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1110016. Throughput: 0: 80.2. Samples: 1113156. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:26:25,976][60274] Avg episode reward: [(0, '235.185')]
[36m[2025-06-29 15:26:30,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1110016. Throughput: 0: 80.8. Samples: 1113660. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:26:30,976][60274] Avg episode reward: [(0, '240.869')]
[36m[2025-06-29 15:26:36,625][60274] Fps is (10 sec: 384.6, 60 sec: 135.0, 300 sec: 83.1). Total num frames: 1114112. Throughput: 0: 80.5. Samples: 1113904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:26:36,626][60274] Avg episode reward: [(0, '244.947')]
[36m[2025-06-29 15:26:40,957][60274] Fps is (10 sec: 410.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1114112. Throughput: 0: 80.7. Samples: 1114348. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:26:40,958][60274] Avg episode reward: [(0, '234.984')]
[36m[2025-06-29 15:26:45,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1114112. Throughput: 0: 79.6. Samples: 1114804. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:26:45,986][60274] Avg episode reward: [(0, '228.918')]
[36m[2025-06-29 15:26:50,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1114112. Throughput: 0: 79.7. Samples: 1115040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:26:50,950][60274] Avg episode reward: [(0, '224.378')]
[36m[2025-06-29 15:26:55,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1114112. Throughput: 0: 80.2. Samples: 1115536. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:26:55,953][60274] Avg episode reward: [(0, '230.265')]
[36m[2025-06-29 15:27:00,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1114112. Throughput: 0: 80.2. Samples: 1116024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:27:00,952][60274] Avg episode reward: [(0, '229.974')]
[37m[1m[2025-06-29 15:27:00,999][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004352_1114112.pth...
[36m[2025-06-29 15:27:01,054][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004272_1093632.pth
[36m[2025-06-29 15:27:05,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1114112. Throughput: 0: 80.3. Samples: 1116272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:27:05,973][60274] Avg episode reward: [(0, '225.971')]
[36m[2025-06-29 15:27:10,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1114112. Throughput: 0: 80.7. Samples: 1116784. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:27:10,957][60274] Avg episode reward: [(0, '235.111')]
[36m[2025-06-29 15:27:15,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1114112. Throughput: 0: 80.6. Samples: 1117288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:27:15,970][60274] Avg episode reward: [(0, '214.221')]
[36m[2025-06-29 15:27:20,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1114112. Throughput: 0: 81.8. Samples: 1117532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:27:20,965][60274] Avg episode reward: [(0, '216.064')]
[36m[2025-06-29 15:27:26,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1114112. Throughput: 0: 82.1. Samples: 1118044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:27:26,002][60274] Avg episode reward: [(0, '205.245')]
[36m[2025-06-29 15:27:30,971][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1118208. Throughput: 0: 81.1. Samples: 1118452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:27:30,971][60274] Avg episode reward: [(0, '213.295')]
[36m[2025-06-29 15:27:35,955][60274] Fps is (10 sec: 411.5, 60 sec: 69.0, 300 sec: 83.3). Total num frames: 1118208. Throughput: 0: 81.3. Samples: 1118700. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:27:35,956][60274] Avg episode reward: [(0, '211.557')]
[36m[2025-06-29 15:27:40,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1118208. Throughput: 0: 81.6. Samples: 1119208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:27:40,965][60274] Avg episode reward: [(0, '216.886')]
[36m[2025-06-29 15:27:45,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1118208. Throughput: 0: 81.5. Samples: 1119692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:27:45,974][60274] Avg episode reward: [(0, '224.331')]
[36m[2025-06-29 15:27:50,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1118208. Throughput: 0: 81.3. Samples: 1119928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:27:50,966][60274] Avg episode reward: [(0, '222.854')]
[36m[2025-06-29 15:27:55,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1118208. Throughput: 0: 80.8. Samples: 1120420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:27:55,964][60274] Avg episode reward: [(0, '225.391')]
[36m[2025-06-29 15:28:00,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1118208. Throughput: 0: 80.1. Samples: 1120892. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:28:00,948][60274] Avg episode reward: [(0, '228.181')]
[36m[2025-06-29 15:28:05,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1118208. Throughput: 0: 80.3. Samples: 1121148. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:28:05,983][60274] Avg episode reward: [(0, '216.089')]
[36m[2025-06-29 15:28:10,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1118208. Throughput: 0: 80.2. Samples: 1121652. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:28:10,982][60274] Avg episode reward: [(0, '218.427')]
[36m[2025-06-29 15:28:15,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1118208. Throughput: 0: 82.4. Samples: 1122160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:28:15,948][60274] Avg episode reward: [(0, '211.517')]
[36m[2025-06-29 15:28:20,964][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1122304. Throughput: 0: 81.0. Samples: 1122344. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-06-29 15:28:20,965][60274] Avg episode reward: [(0, '217.561')]
[36m[2025-06-29 15:28:25,981][60274] Fps is (10 sec: 408.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1122304. Throughput: 0: 79.9. Samples: 1122804. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-06-29 15:28:25,981][60274] Avg episode reward: [(0, '225.418')]
[31m[14135744 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[14135744 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[14135744 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:28:30,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1122304. Throughput: 0: 79.5. Samples: 1123272. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-06-29 15:28:30,977][60274] Avg episode reward: [(0, '239.591')]
[36m[2025-06-29 15:28:35,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1122304. Throughput: 0: 79.6. Samples: 1123508. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-06-29 15:28:35,947][60274] Avg episode reward: [(0, '251.875')]
[36m[2025-06-29 15:28:40,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1122304. Throughput: 0: 79.6. Samples: 1124004. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-06-29 15:28:40,994][60274] Avg episode reward: [(0, '243.201')]
[36m[2025-06-29 15:28:45,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1122304. Throughput: 0: 80.0. Samples: 1124492. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-06-29 15:28:45,961][60274] Avg episode reward: [(0, '243.002')]
[36m[2025-06-29 15:28:51,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1122304. Throughput: 0: 79.3. Samples: 1124720. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-06-29 15:28:51,000][60274] Avg episode reward: [(0, '240.411')]
[36m[2025-06-29 15:28:55,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1122304. Throughput: 0: 78.8. Samples: 1125196. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-06-29 15:28:55,964][60274] Avg episode reward: [(0, '251.847')]
[31m[14162249 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[14162249 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[14162249 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:29:00,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1122304. Throughput: 0: 78.6. Samples: 1125700. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-06-29 15:29:00,962][60274] Avg episode reward: [(0, '244.719')]
[37m[1m[2025-06-29 15:29:01,017][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004384_1122304.pth...
[36m[2025-06-29 15:29:01,077][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004320_1105920.pth
[36m[2025-06-29 15:29:05,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1122304. Throughput: 0: 79.8. Samples: 1125932. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-06-29 15:29:05,951][60274] Avg episode reward: [(0, '249.786')]
[36m[2025-06-29 15:29:10,963][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1126400. Throughput: 0: 80.0. Samples: 1126404. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:29:10,963][60274] Avg episode reward: [(0, '260.287')]
[36m[2025-06-29 15:29:15,950][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1126400. Throughput: 0: 79.6. Samples: 1126852. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:29:15,951][60274] Avg episode reward: [(0, '263.014')]
[36m[2025-06-29 15:29:20,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1126400. Throughput: 0: 79.5. Samples: 1127088. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:29:20,957][60274] Avg episode reward: [(0, '261.850')]
[36m[2025-06-29 15:29:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1126400. Throughput: 0: 78.8. Samples: 1127548. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:29:25,979][60274] Avg episode reward: [(0, '258.943')]
[36m[2025-06-29 15:29:31,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1126400. Throughput: 0: 78.8. Samples: 1128040. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:29:31,001][60274] Avg episode reward: [(0, '252.325')]
[36m[2025-06-29 15:29:35,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1126400. Throughput: 0: 79.2. Samples: 1128284. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:29:35,984][60274] Avg episode reward: [(0, '244.047')]
[36m[2025-06-29 15:29:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1126400. Throughput: 0: 79.5. Samples: 1128772. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:29:40,948][60274] Avg episode reward: [(0, '244.737')]
[36m[2025-06-29 15:29:45,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1126400. Throughput: 0: 79.4. Samples: 1129272. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:29:45,949][60274] Avg episode reward: [(0, '239.841')]
[36m[2025-06-29 15:29:50,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1126400. Throughput: 0: 79.7. Samples: 1129524. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:29:50,994][60274] Avg episode reward: [(0, '238.913')]
[36m[2025-06-29 15:29:55,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1126400. Throughput: 0: 79.0. Samples: 1129960. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:29:55,966][60274] Avg episode reward: [(0, '247.589')]
[36m[2025-06-29 15:30:01,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1126400. Throughput: 0: 78.9. Samples: 1130408. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 15:30:01,001][60274] Avg episode reward: [(0, '247.153')]
[36m[2025-06-29 15:30:05,966][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1130496. Throughput: 0: 77.9. Samples: 1130592. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:30:05,966][60274] Avg episode reward: [(0, '245.081')]
[36m[2025-06-29 15:30:10,954][60274] Fps is (10 sec: 411.5, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1130496. Throughput: 0: 78.4. Samples: 1131072. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:30:10,954][60274] Avg episode reward: [(0, '241.812')]
[36m[2025-06-29 15:30:15,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1130496. Throughput: 0: 79.0. Samples: 1131592. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:30:15,982][60274] Avg episode reward: [(0, '234.578')]
[36m[2025-06-29 15:30:20,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1130496. Throughput: 0: 78.5. Samples: 1131816. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:30:20,956][60274] Avg episode reward: [(0, '239.283')]
[36m[2025-06-29 15:30:25,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1130496. Throughput: 0: 78.3. Samples: 1132300. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:30:25,997][60274] Avg episode reward: [(0, '231.180')]
[36m[2025-06-29 15:30:30,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1130496. Throughput: 0: 77.9. Samples: 1132776. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:30:30,948][60274] Avg episode reward: [(0, '227.789')]
[36m[2025-06-29 15:30:36,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1130496. Throughput: 0: 77.6. Samples: 1133016. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:30:36,003][60274] Avg episode reward: [(0, '217.121')]
[36m[2025-06-29 15:30:40,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1130496. Throughput: 0: 78.1. Samples: 1133476. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:30:40,957][60274] Avg episode reward: [(0, '225.423')]
[36m[2025-06-29 15:30:45,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1130496. Throughput: 0: 79.0. Samples: 1133960. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:30:45,949][60274] Avg episode reward: [(0, '216.973')]
[36m[2025-06-29 15:30:50,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1130496. Throughput: 0: 80.2. Samples: 1134200. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:30:50,968][60274] Avg episode reward: [(0, '216.525')]
[36m[2025-06-29 15:30:55,952][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1134592. Throughput: 0: 79.0. Samples: 1134628. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:30:55,952][60274] Avg episode reward: [(0, '218.118')]
[36m[2025-06-29 15:31:00,991][60274] Fps is (10 sec: 408.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1134592. Throughput: 0: 78.3. Samples: 1135116. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:31:00,991][60274] Avg episode reward: [(0, '200.290')]
[37m[1m[2025-06-29 15:31:00,995][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004432_1134592.pth...
[36m[2025-06-29 15:31:01,051][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004352_1114112.pth
[36m[2025-06-29 15:31:05,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1134592. Throughput: 0: 78.5. Samples: 1135348. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:31:05,956][60274] Avg episode reward: [(0, '202.121')]
[36m[2025-06-29 15:31:10,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1134592. Throughput: 0: 78.0. Samples: 1135812. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:31:10,994][60274] Avg episode reward: [(0, '213.117')]
[36m[2025-06-29 15:31:15,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1134592. Throughput: 0: 77.9. Samples: 1136284. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:31:15,972][60274] Avg episode reward: [(0, '213.467')]
[36m[2025-06-29 15:31:20,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1134592. Throughput: 0: 78.2. Samples: 1136532. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:31:20,969][60274] Avg episode reward: [(0, '221.707')]
[36m[2025-06-29 15:31:25,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1134592. Throughput: 0: 78.6. Samples: 1137016. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:31:25,971][60274] Avg episode reward: [(0, '224.187')]
[36m[2025-06-29 15:31:30,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 1134592. Throughput: 0: 78.9. Samples: 1137512. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:31:30,947][60274] Avg episode reward: [(0, '231.448')]
[31m[14319082 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[14319083 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[14319083 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:31:35,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1134592. Throughput: 0: 79.0. Samples: 1137756. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:31:35,985][60274] Avg episode reward: [(0, '221.134')]
[36m[2025-06-29 15:31:40,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1134592. Throughput: 0: 80.3. Samples: 1138244. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:31:40,968][60274] Avg episode reward: [(0, '230.287')]
[36m[2025-06-29 15:31:45,969][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1138688. Throughput: 0: 79.6. Samples: 1138696. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 15:31:45,969][60274] Avg episode reward: [(0, '220.760')]
[36m[2025-06-29 15:31:50,981][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1138688. Throughput: 0: 79.8. Samples: 1138940. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 15:31:50,982][60274] Avg episode reward: [(0, '221.139')]
[36m[2025-06-29 15:31:55,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1138688. Throughput: 0: 80.6. Samples: 1139436. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 15:31:55,955][60274] Avg episode reward: [(0, '236.535')]
[36m[2025-06-29 15:32:00,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1138688. Throughput: 0: 81.1. Samples: 1139932. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 15:32:00,960][60274] Avg episode reward: [(0, '232.160')]
[36m[2025-06-29 15:32:05,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1138688. Throughput: 0: 81.2. Samples: 1140184. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 15:32:05,972][60274] Avg episode reward: [(0, '234.085')]
[36m[2025-06-29 15:32:10,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1138688. Throughput: 0: 80.4. Samples: 1140636. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 15:32:10,983][60274] Avg episode reward: [(0, '233.234')]
[36m[2025-06-29 15:32:15,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1138688. Throughput: 0: 80.2. Samples: 1141120. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 15:32:15,952][60274] Avg episode reward: [(0, '245.563')]
[36m[2025-06-29 15:32:20,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1138688. Throughput: 0: 80.3. Samples: 1141368. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 15:32:20,963][60274] Avg episode reward: [(0, '245.035')]
[36m[2025-06-29 15:32:26,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1138688. Throughput: 0: 80.3. Samples: 1141860. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 15:32:26,003][60274] Avg episode reward: [(0, '250.632')]
[36m[2025-06-29 15:32:30,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1138688. Throughput: 0: 81.2. Samples: 1142348. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 15:32:30,949][60274] Avg episode reward: [(0, '265.048')]
[36m[2025-06-29 15:32:36,468][60274] Fps is (10 sec: 391.4, 60 sec: 135.4, 300 sec: 83.2). Total num frames: 1142784. Throughput: 0: 80.1. Samples: 1142584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:32:36,468][60274] Avg episode reward: [(0, '262.079')]
[36m[2025-06-29 15:32:40,949][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1142784. Throughput: 0: 79.7. Samples: 1143020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:32:40,949][60274] Avg episode reward: [(0, '255.456')]
[31m[14387352 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[14387353 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[14387353 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:32:45,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1142784. Throughput: 0: 78.9. Samples: 1143484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:32:45,951][60274] Avg episode reward: [(0, '261.284')]
[36m[2025-06-29 15:32:50,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1142784. Throughput: 0: 78.8. Samples: 1143728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:32:50,973][60274] Avg episode reward: [(0, '262.834')]
[36m[2025-06-29 15:32:55,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1142784. Throughput: 0: 79.1. Samples: 1144192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:32:55,965][60274] Avg episode reward: [(0, '274.801')]
[37m[1m[2025-06-29 15:32:56,015][60274] Saving new best policy, reward=274.801!
[36m[2025-06-29 15:33:00,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1142784. Throughput: 0: 78.5. Samples: 1144652. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:33:00,974][60274] Avg episode reward: [(0, '275.208')]
[37m[1m[2025-06-29 15:33:01,021][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004464_1142784.pth...
[36m[2025-06-29 15:33:01,076][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004384_1122304.pth
[37m[1m[2025-06-29 15:33:01,083][60274] Saving new best policy, reward=275.208!
[36m[2025-06-29 15:33:05,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1142784. Throughput: 0: 78.2. Samples: 1144888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:33:05,975][60274] Avg episode reward: [(0, '278.557')]
[37m[1m[2025-06-29 15:33:06,021][60274] Saving new best policy, reward=278.557!
[36m[2025-06-29 15:33:10,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1142784. Throughput: 0: 77.8. Samples: 1145360. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:33:10,987][60274] Avg episode reward: [(0, '274.103')]
[36m[2025-06-29 15:33:15,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1142784. Throughput: 0: 77.6. Samples: 1145840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:33:15,963][60274] Avg episode reward: [(0, '279.943')]
[37m[1m[2025-06-29 15:33:16,008][60274] Saving new best policy, reward=279.943!
[31m[14426082 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[14426082 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[14426082 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:33:20,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1142784. Throughput: 0: 78.4. Samples: 1146072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:33:20,976][60274] Avg episode reward: [(0, '276.068')]
[36m[2025-06-29 15:33:25,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1142784. Throughput: 0: 78.3. Samples: 1146548. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:33:25,985][60274] Avg episode reward: [(0, '284.069')]
[37m[1m[2025-06-29 15:33:26,031][60274] Saving new best policy, reward=284.069!
[36m[2025-06-29 15:33:30,988][60274] Fps is (10 sec: 409.1, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1146880. Throughput: 0: 78.0. Samples: 1146996. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:33:30,988][60274] Avg episode reward: [(0, '287.189')]
[37m[1m[2025-06-29 15:33:31,040][60274] Saving new best policy, reward=287.189!
[36m[2025-06-29 15:33:35,952][60274] Fps is (10 sec: 410.9, 60 sec: 68.9, 300 sec: 83.3). Total num frames: 1146880. Throughput: 0: 77.9. Samples: 1147232. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:33:35,952][60274] Avg episode reward: [(0, '284.911')]
[36m[2025-06-29 15:33:40,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1146880. Throughput: 0: 78.7. Samples: 1147736. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:33:40,989][60274] Avg episode reward: [(0, '290.991')]
[37m[1m[2025-06-29 15:33:40,992][60274] Saving new best policy, reward=290.991!
[36m[2025-06-29 15:33:45,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1146880. Throughput: 0: 78.8. Samples: 1148200. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:33:45,984][60274] Avg episode reward: [(0, '279.448')]
[36m[2025-06-29 15:33:50,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1146880. Throughput: 0: 79.3. Samples: 1148456. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:33:50,950][60274] Avg episode reward: [(0, '276.184')]
[36m[2025-06-29 15:33:55,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1146880. Throughput: 0: 79.2. Samples: 1148924. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:33:55,968][60274] Avg episode reward: [(0, '271.232')]
[36m[2025-06-29 15:34:00,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1146880. Throughput: 0: 79.1. Samples: 1149400. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:34:00,949][60274] Avg episode reward: [(0, '272.659')]
[36m[2025-06-29 15:34:05,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1146880. Throughput: 0: 79.7. Samples: 1149656. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:34:05,948][60274] Avg episode reward: [(0, '270.030')]
[36m[2025-06-29 15:34:10,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1146880. Throughput: 0: 80.5. Samples: 1150172. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:34:10,979][60274] Avg episode reward: [(0, '271.448')]
[36m[2025-06-29 15:34:15,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1146880. Throughput: 0: 81.1. Samples: 1150644. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:34:15,961][60274] Avg episode reward: [(0, '263.541')]
[36m[2025-06-29 15:34:20,947][60274] Fps is (10 sec: 410.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1150976. Throughput: 0: 80.9. Samples: 1150872. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:34:20,947][60274] Avg episode reward: [(0, '268.141')]
[36m[2025-06-29 15:34:25,954][60274] Fps is (10 sec: 409.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1150976. Throughput: 0: 79.0. Samples: 1151288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:34:25,954][60274] Avg episode reward: [(0, '260.123')]
[36m[2025-06-29 15:34:30,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1150976. Throughput: 0: 79.5. Samples: 1151776. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:34:30,985][60274] Avg episode reward: [(0, '261.103')]
[36m[2025-06-29 15:34:35,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1150976. Throughput: 0: 79.1. Samples: 1152016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:34:35,963][60274] Avg episode reward: [(0, '268.967')]
[36m[2025-06-29 15:34:40,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1150976. Throughput: 0: 79.3. Samples: 1152492. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:34:40,957][60274] Avg episode reward: [(0, '251.952')]
[36m[2025-06-29 15:34:45,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1150976. Throughput: 0: 79.4. Samples: 1152972. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:34:45,963][60274] Avg episode reward: [(0, '245.452')]
[36m[2025-06-29 15:34:50,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1150976. Throughput: 0: 78.9. Samples: 1153212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:34:50,991][60274] Avg episode reward: [(0, '234.137')]
[36m[2025-06-29 15:34:55,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1150976. Throughput: 0: 78.3. Samples: 1153696. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:34:55,992][60274] Avg episode reward: [(0, '227.914')]
[36m[2025-06-29 15:35:00,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1150976. Throughput: 0: 78.2. Samples: 1154164. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:35:00,987][60274] Avg episode reward: [(0, '229.869')]
[37m[1m[2025-06-29 15:35:01,033][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004496_1150976.pth...
[36m[2025-06-29 15:35:01,089][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004432_1134592.pth
[36m[2025-06-29 15:35:05,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1150976. Throughput: 0: 78.3. Samples: 1154400. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:35:05,979][60274] Avg episode reward: [(0, '228.826')]
[36m[2025-06-29 15:35:10,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1150976. Throughput: 0: 80.3. Samples: 1154904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:35:10,967][60274] Avg episode reward: [(0, '221.215')]
[36m[2025-06-29 15:35:15,959][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1155072. Throughput: 0: 79.5. Samples: 1155352. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:35:15,960][60274] Avg episode reward: [(0, '221.926')]
[36m[2025-06-29 15:35:20,958][60274] Fps is (10 sec: 410.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1155072. Throughput: 0: 79.4. Samples: 1155588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:35:20,958][60274] Avg episode reward: [(0, '213.842')]
[36m[2025-06-29 15:35:25,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1155072. Throughput: 0: 79.4. Samples: 1156068. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:35:25,985][60274] Avg episode reward: [(0, '209.748')]
[36m[2025-06-29 15:35:30,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1155072. Throughput: 0: 79.4. Samples: 1156548. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:35:30,998][60274] Avg episode reward: [(0, '217.497')]
[36m[2025-06-29 15:35:35,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1155072. Throughput: 0: 79.4. Samples: 1156780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:35:35,949][60274] Avg episode reward: [(0, '215.400')]
[36m[2025-06-29 15:35:40,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1155072. Throughput: 0: 79.0. Samples: 1157248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:35:40,948][60274] Avg episode reward: [(0, '225.918')]
[36m[2025-06-29 15:35:45,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1155072. Throughput: 0: 78.8. Samples: 1157708. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:35:45,964][60274] Avg episode reward: [(0, '217.640')]
[36m[2025-06-29 15:35:50,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1155072. Throughput: 0: 78.7. Samples: 1157944. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:35:50,983][60274] Avg episode reward: [(0, '229.938')]
[36m[2025-06-29 15:35:55,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1155072. Throughput: 0: 77.4. Samples: 1158388. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:35:55,975][60274] Avg episode reward: [(0, '223.760')]
[36m[2025-06-29 15:36:00,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1155072. Throughput: 0: 78.7. Samples: 1158892. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:00,950][60274] Avg episode reward: [(0, '213.718')]
[36m[2025-06-29 15:36:05,972][60274] Fps is (10 sec: 409.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1159168. Throughput: 0: 78.6. Samples: 1159124. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:05,972][60274] Avg episode reward: [(0, '214.695')]
[36m[2025-06-29 15:36:10,971][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1159168. Throughput: 0: 77.9. Samples: 1159572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:10,972][60274] Avg episode reward: [(0, '218.651')]
[36m[2025-06-29 15:36:15,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1159168. Throughput: 0: 78.1. Samples: 1160060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:15,973][60274] Avg episode reward: [(0, '224.324')]
[36m[2025-06-29 15:36:20,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1159168. Throughput: 0: 78.1. Samples: 1160296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:20,949][60274] Avg episode reward: [(0, '216.268')]
[36m[2025-06-29 15:36:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1159168. Throughput: 0: 77.9. Samples: 1160752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:25,956][60274] Avg episode reward: [(0, '210.195')]
[36m[2025-06-29 15:36:30,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1159168. Throughput: 0: 79.1. Samples: 1161264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:30,947][60274] Avg episode reward: [(0, '224.665')]
[36m[2025-06-29 15:36:36,011][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1159168. Throughput: 0: 79.1. Samples: 1161504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:36,011][60274] Avg episode reward: [(0, '232.353')]
[36m[2025-06-29 15:36:40,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1159168. Throughput: 0: 80.1. Samples: 1161992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:40,964][60274] Avg episode reward: [(0, '223.919')]
[36m[2025-06-29 15:36:45,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1159168. Throughput: 0: 79.7. Samples: 1162480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:45,963][60274] Avg episode reward: [(0, '226.937')]
[31m[14632475 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[14632476 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[14632476 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:36:50,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1159168. Throughput: 0: 80.2. Samples: 1162732. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:36:50,962][60274] Avg episode reward: [(0, '215.330')]
[36m[2025-06-29 15:36:55,977][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1163264. Throughput: 0: 81.0. Samples: 1163216. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:36:55,977][60274] Avg episode reward: [(0, '214.676')]
[36m[2025-06-29 15:37:00,963][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1163264. Throughput: 0: 79.4. Samples: 1163632. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:37:00,963][60274] Avg episode reward: [(0, '221.786')]
[37m[1m[2025-06-29 15:37:01,024][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004544_1163264.pth...
[36m[2025-06-29 15:37:01,079][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004464_1142784.pth
[36m[2025-06-29 15:37:05,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1163264. Throughput: 0: 79.1. Samples: 1163856. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:37:05,972][60274] Avg episode reward: [(0, '234.995')]
[36m[2025-06-29 15:37:10,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1163264. Throughput: 0: 79.3. Samples: 1164324. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:37:10,989][60274] Avg episode reward: [(0, '237.679')]
[36m[2025-06-29 15:37:15,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1163264. Throughput: 0: 78.3. Samples: 1164788. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:37:15,971][60274] Avg episode reward: [(0, '251.189')]
[36m[2025-06-29 15:37:20,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1163264. Throughput: 0: 78.5. Samples: 1165032. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:37:20,965][60274] Avg episode reward: [(0, '238.635')]
[36m[2025-06-29 15:37:25,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1163264. Throughput: 0: 77.9. Samples: 1165500. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:37:25,988][60274] Avg episode reward: [(0, '238.288')]
[36m[2025-06-29 15:37:30,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.5). Total num frames: 1163264. Throughput: 0: 77.7. Samples: 1165976. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:37:30,975][60274] Avg episode reward: [(0, '239.937')]
[36m[2025-06-29 15:37:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1163264. Throughput: 0: 77.3. Samples: 1166212. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:37:35,973][60274] Avg episode reward: [(0, '238.976')]
[36m[2025-06-29 15:37:40,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1163264. Throughput: 0: 77.6. Samples: 1166704. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:37:40,947][60274] Avg episode reward: [(0, '252.033')]
[36m[2025-06-29 15:37:45,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1163264. Throughput: 0: 78.7. Samples: 1167176. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-06-29 15:37:45,987][60274] Avg episode reward: [(0, '240.339')]
[36m[2025-06-29 15:37:50,983][60274] Fps is (10 sec: 408.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1167360. Throughput: 0: 78.0. Samples: 1167368. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 15:37:50,983][60274] Avg episode reward: [(0, '245.936')]
[36m[2025-06-29 15:37:55,955][60274] Fps is (10 sec: 410.9, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1167360. Throughput: 0: 78.6. Samples: 1167860. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 15:37:55,955][60274] Avg episode reward: [(0, '233.484')]
[36m[2025-06-29 15:38:00,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1167360. Throughput: 0: 79.3. Samples: 1168356. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 15:38:00,971][60274] Avg episode reward: [(0, '231.251')]
[36m[2025-06-29 15:38:05,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1167360. Throughput: 0: 78.8. Samples: 1168580. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 15:38:05,975][60274] Avg episode reward: [(0, '232.913')]
[36m[2025-06-29 15:38:10,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1167360. Throughput: 0: 78.9. Samples: 1169052. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 15:38:10,986][60274] Avg episode reward: [(0, '240.856')]
[36m[2025-06-29 15:38:15,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1167360. Throughput: 0: 78.8. Samples: 1169520. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 15:38:15,963][60274] Avg episode reward: [(0, '246.197')]
[36m[2025-06-29 15:38:20,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1167360. Throughput: 0: 79.0. Samples: 1169768. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 15:38:20,983][60274] Avg episode reward: [(0, '244.753')]
[36m[2025-06-29 15:38:25,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1167360. Throughput: 0: 79.5. Samples: 1170284. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 15:38:25,974][60274] Avg episode reward: [(0, '247.812')]
[36m[2025-06-29 15:38:30,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1167360. Throughput: 0: 79.5. Samples: 1170752. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 15:38:30,959][60274] Avg episode reward: [(0, '262.319')]
[36m[2025-06-29 15:38:35,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1167360. Throughput: 0: 80.7. Samples: 1171000. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 15:38:35,973][60274] Avg episode reward: [(0, '265.611')]
[36m[2025-06-29 15:38:40,988][60274] Fps is (10 sec: 408.4, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1171456. Throughput: 0: 80.0. Samples: 1171464. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:38:40,989][60274] Avg episode reward: [(0, '263.102')]
[36m[2025-06-29 15:38:46,010][60274] Fps is (10 sec: 408.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1171456. Throughput: 0: 79.6. Samples: 1171940. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:38:46,010][60274] Avg episode reward: [(0, '265.146')]
[36m[2025-06-29 15:38:51,010][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1171456. Throughput: 0: 79.7. Samples: 1172168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:38:51,010][60274] Avg episode reward: [(0, '254.497')]
[36m[2025-06-29 15:38:55,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1171456. Throughput: 0: 80.1. Samples: 1172656. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:38:55,980][60274] Avg episode reward: [(0, '257.168')]
[36m[2025-06-29 15:39:00,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1171456. Throughput: 0: 80.4. Samples: 1173136. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:39:00,952][60274] Avg episode reward: [(0, '236.394')]
[37m[1m[2025-06-29 15:39:01,001][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004576_1171456.pth...
[36m[2025-06-29 15:39:01,057][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004496_1150976.pth
[36m[2025-06-29 15:39:05,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1171456. Throughput: 0: 80.2. Samples: 1173376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:39:05,967][60274] Avg episode reward: [(0, '233.208')]
[36m[2025-06-29 15:39:10,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1171456. Throughput: 0: 79.4. Samples: 1173856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:39:10,967][60274] Avg episode reward: [(0, '227.176')]
[36m[2025-06-29 15:39:16,011][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1171456. Throughput: 0: 79.7. Samples: 1174344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:39:16,012][60274] Avg episode reward: [(0, '224.065')]
[36m[2025-06-29 15:39:20,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1171456. Throughput: 0: 79.6. Samples: 1174580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:39:20,973][60274] Avg episode reward: [(0, '226.205')]
[36m[2025-06-29 15:39:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1171456. Throughput: 0: 80.0. Samples: 1175060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:39:25,966][60274] Avg episode reward: [(0, '224.137')]
[36m[2025-06-29 15:39:30,985][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1175552. Throughput: 0: 80.5. Samples: 1175560. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:39:30,985][60274] Avg episode reward: [(0, '216.083')]
[36m[2025-06-29 15:39:35,956][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1175552. Throughput: 0: 79.5. Samples: 1175740. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:39:35,956][60274] Avg episode reward: [(0, '226.859')]
[31m[14804732 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[14804732 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[14804732 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:39:40,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1175552. Throughput: 0: 78.9. Samples: 1176204. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:39:40,974][60274] Avg episode reward: [(0, '210.673')]
[36m[2025-06-29 15:39:45,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1175552. Throughput: 0: 78.8. Samples: 1176684. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:39:45,971][60274] Avg episode reward: [(0, '223.612')]
[36m[2025-06-29 15:39:50,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1175552. Throughput: 0: 78.7. Samples: 1176920. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:39:50,975][60274] Avg episode reward: [(0, '237.183')]
[36m[2025-06-29 15:39:55,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1175552. Throughput: 0: 78.4. Samples: 1177388. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:39:55,989][60274] Avg episode reward: [(0, '240.855')]
[36m[2025-06-29 15:40:00,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1175552. Throughput: 0: 78.9. Samples: 1177888. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:40:00,953][60274] Avg episode reward: [(0, '236.666')]
[36m[2025-06-29 15:40:05,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1175552. Throughput: 0: 79.2. Samples: 1178144. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:40:05,998][60274] Avg episode reward: [(0, '237.380')]
[36m[2025-06-29 15:40:10,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1175552. Throughput: 0: 79.3. Samples: 1178628. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:40:10,966][60274] Avg episode reward: [(0, '233.202')]
[36m[2025-06-29 15:40:15,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1175552. Throughput: 0: 79.0. Samples: 1179116. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:40:15,977][60274] Avg episode reward: [(0, '232.689')]
[36m[2025-06-29 15:40:20,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1175552. Throughput: 0: 80.4. Samples: 1179360. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:40:20,958][60274] Avg episode reward: [(0, '228.535')]
[36m[2025-06-29 15:40:25,986][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1179648. Throughput: 0: 79.9. Samples: 1179800. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:40:25,986][60274] Avg episode reward: [(0, '222.221')]
[36m[2025-06-29 15:40:30,963][60274] Fps is (10 sec: 409.4, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1179648. Throughput: 0: 79.8. Samples: 1180276. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:40:30,964][60274] Avg episode reward: [(0, '229.504')]
[36m[2025-06-29 15:40:35,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1179648. Throughput: 0: 79.9. Samples: 1180516. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:40:35,973][60274] Avg episode reward: [(0, '230.020')]
[36m[2025-06-29 15:40:40,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1179648. Throughput: 0: 80.5. Samples: 1181008. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:40:40,968][60274] Avg episode reward: [(0, '235.723')]
[36m[2025-06-29 15:40:45,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1179648. Throughput: 0: 79.7. Samples: 1181480. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:40:45,998][60274] Avg episode reward: [(0, '237.483')]
[36m[2025-06-29 15:40:50,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1179648. Throughput: 0: 79.6. Samples: 1181724. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:40:50,957][60274] Avg episode reward: [(0, '245.449')]
[36m[2025-06-29 15:40:55,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1179648. Throughput: 0: 79.0. Samples: 1182180. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:40:55,956][60274] Avg episode reward: [(0, '264.731')]
[36m[2025-06-29 15:41:00,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1179648. Throughput: 0: 78.9. Samples: 1182664. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:41:00,965][60274] Avg episode reward: [(0, '259.411')]
[37m[1m[2025-06-29 15:41:01,014][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004608_1179648.pth...
[36m[2025-06-29 15:41:01,069][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004544_1163264.pth
[36m[2025-06-29 15:41:05,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1179648. Throughput: 0: 78.6. Samples: 1182900. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:41:05,989][60274] Avg episode reward: [(0, '260.647')]
[36m[2025-06-29 15:41:10,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1179648. Throughput: 0: 79.6. Samples: 1183384. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:41:10,992][60274] Avg episode reward: [(0, '258.359')]
[36m[2025-06-29 15:41:15,983][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1183744. Throughput: 0: 78.3. Samples: 1183800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:41:15,984][60274] Avg episode reward: [(0, '261.760')]
[36m[2025-06-29 15:41:20,972][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1183744. Throughput: 0: 78.6. Samples: 1184052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:41:20,972][60274] Avg episode reward: [(0, '262.552')]
[36m[2025-06-29 15:41:25,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1183744. Throughput: 0: 78.5. Samples: 1184540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:41:25,981][60274] Avg episode reward: [(0, '270.954')]
[36m[2025-06-29 15:41:30,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1183744. Throughput: 0: 78.9. Samples: 1185028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:41:30,962][60274] Avg episode reward: [(0, '266.906')]
[36m[2025-06-29 15:41:36,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1183744. Throughput: 0: 78.9. Samples: 1185276. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:41:36,001][60274] Avg episode reward: [(0, '265.895')]
[36m[2025-06-29 15:41:40,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1183744. Throughput: 0: 79.5. Samples: 1185760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:41:40,986][60274] Avg episode reward: [(0, '267.199')]
[36m[2025-06-29 15:41:45,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1183744. Throughput: 0: 79.9. Samples: 1186260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:41:45,982][60274] Avg episode reward: [(0, '264.084')]
[36m[2025-06-29 15:41:50,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1183744. Throughput: 0: 80.1. Samples: 1186500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:41:50,956][60274] Avg episode reward: [(0, '264.075')]
[36m[2025-06-29 15:41:55,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1183744. Throughput: 0: 79.6. Samples: 1186968. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:41:55,994][60274] Avg episode reward: [(0, '262.217')]
[36m[2025-06-29 15:42:00,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1183744. Throughput: 0: 80.3. Samples: 1187416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:42:00,995][60274] Avg episode reward: [(0, '249.512')]
[36m[2025-06-29 15:42:06,415][60274] Fps is (10 sec: 393.1, 60 sec: 135.6, 300 sec: 83.2). Total num frames: 1187840. Throughput: 0: 79.3. Samples: 1187656. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:06,415][60274] Avg episode reward: [(0, '258.709')]
[36m[2025-06-29 15:42:10,989][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1187840. Throughput: 0: 78.8. Samples: 1188088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:10,989][60274] Avg episode reward: [(0, '242.924')]
[36m[2025-06-29 15:42:15,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1187840. Throughput: 0: 78.9. Samples: 1188580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:15,954][60274] Avg episode reward: [(0, '245.488')]
[36m[2025-06-29 15:42:20,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1187840. Throughput: 0: 79.0. Samples: 1188828. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:20,987][60274] Avg episode reward: [(0, '242.388')]
[33m[14968203 ms][navigation_task] - WARNING : Curriculum Level: 36, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[14968203 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.69189453125
[33mCrash Rate: 0.2529296875
[33mTimeout Rate: 0.05517578125 (navigation_task.py:265)
[33m[14968203 ms][navigation_task] - WARNING : 
[33mSuccesses: 1417
[33mCrashes : 518
[33mTimeouts: 113 (navigation_task.py:268)
[36m[2025-06-29 15:42:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1187840. Throughput: 0: 79.7. Samples: 1189344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:25,966][60274] Avg episode reward: [(0, '245.057')]
[36m[2025-06-29 15:42:30,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1187840. Throughput: 0: 79.6. Samples: 1189840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:30,980][60274] Avg episode reward: [(0, '259.304')]
[36m[2025-06-29 15:42:35,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1187840. Throughput: 0: 79.7. Samples: 1190088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:35,992][60274] Avg episode reward: [(0, '240.823')]
[31m[14984726 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[14984726 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[14984726 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:42:40,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1187840. Throughput: 0: 80.0. Samples: 1190564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:40,970][60274] Avg episode reward: [(0, '234.169')]
[36m[2025-06-29 15:42:45,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1187840. Throughput: 0: 80.8. Samples: 1191052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:45,978][60274] Avg episode reward: [(0, '242.311')]
[36m[2025-06-29 15:42:50,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1187840. Throughput: 0: 81.7. Samples: 1191296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:50,987][60274] Avg episode reward: [(0, '251.008')]
[36m[2025-06-29 15:42:55,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1187840. Throughput: 0: 81.6. Samples: 1191760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:42:55,990][60274] Avg episode reward: [(0, '249.346')]
[36m[2025-06-29 15:43:00,958][60274] Fps is (10 sec: 410.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1191936. Throughput: 0: 80.2. Samples: 1192188. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:43:00,958][60274] Avg episode reward: [(0, '242.765')]
[37m[1m[2025-06-29 15:43:01,006][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004656_1191936.pth...
[36m[2025-06-29 15:43:01,061][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004576_1171456.pth
[36m[2025-06-29 15:43:05,984][60274] Fps is (10 sec: 409.8, 60 sec: 68.8, 300 sec: 83.3). Total num frames: 1191936. Throughput: 0: 79.8. Samples: 1192420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:43:05,985][60274] Avg episode reward: [(0, '242.594')]
[36m[2025-06-29 15:43:10,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1191936. Throughput: 0: 79.2. Samples: 1192908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:43:10,975][60274] Avg episode reward: [(0, '235.474')]
[36m[2025-06-29 15:43:15,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1191936. Throughput: 0: 78.8. Samples: 1193384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:43:15,951][60274] Avg episode reward: [(0, '237.548')]
[36m[2025-06-29 15:43:20,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1191936. Throughput: 0: 78.6. Samples: 1193624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:43:20,975][60274] Avg episode reward: [(0, '243.857')]
[36m[2025-06-29 15:43:25,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1191936. Throughput: 0: 78.5. Samples: 1194096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:43:25,954][60274] Avg episode reward: [(0, '236.228')]
[36m[2025-06-29 15:43:30,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1191936. Throughput: 0: 78.6. Samples: 1194588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:43:30,957][60274] Avg episode reward: [(0, '237.699')]
[36m[2025-06-29 15:43:35,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1191936. Throughput: 0: 78.4. Samples: 1194824. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:43:35,978][60274] Avg episode reward: [(0, '237.973')]
[36m[2025-06-29 15:43:40,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1191936. Throughput: 0: 79.0. Samples: 1195316. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:43:40,980][60274] Avg episode reward: [(0, '236.681')]
[36m[2025-06-29 15:43:45,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1191936. Throughput: 0: 80.1. Samples: 1195796. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:43:45,974][60274] Avg episode reward: [(0, '246.116')]
[36m[2025-06-29 15:43:50,947][60274] Fps is (10 sec: 411.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1196032. Throughput: 0: 80.0. Samples: 1196016. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:43:50,947][60274] Avg episode reward: [(0, '250.225')]
[36m[2025-06-29 15:43:55,980][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1196032. Throughput: 0: 79.1. Samples: 1196468. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:43:55,980][60274] Avg episode reward: [(0, '248.363')]
[36m[2025-06-29 15:44:00,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1196032. Throughput: 0: 79.2. Samples: 1196948. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:44:00,953][60274] Avg episode reward: [(0, '261.719')]
[36m[2025-06-29 15:44:05,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1196032. Throughput: 0: 79.6. Samples: 1197208. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:44:05,987][60274] Avg episode reward: [(0, '248.764')]
[36m[2025-06-29 15:44:10,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1196032. Throughput: 0: 80.5. Samples: 1197720. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:44:10,989][60274] Avg episode reward: [(0, '249.334')]
[36m[2025-06-29 15:44:15,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1196032. Throughput: 0: 80.5. Samples: 1198212. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:44:15,980][60274] Avg episode reward: [(0, '247.830')]
[36m[2025-06-29 15:44:20,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1196032. Throughput: 0: 81.3. Samples: 1198480. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:44:20,963][60274] Avg episode reward: [(0, '243.065')]
[36m[2025-06-29 15:44:25,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1196032. Throughput: 0: 81.4. Samples: 1198976. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:44:25,965][60274] Avg episode reward: [(0, '247.693')]
[36m[2025-06-29 15:44:30,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1196032. Throughput: 0: 81.5. Samples: 1199464. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:44:30,971][60274] Avg episode reward: [(0, '248.517')]
[36m[2025-06-29 15:44:35,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1196032. Throughput: 0: 82.2. Samples: 1199716. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 15:44:35,961][60274] Avg episode reward: [(0, '240.154')]
[36m[2025-06-29 15:44:40,957][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1200128. Throughput: 0: 81.7. Samples: 1200144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:44:40,957][60274] Avg episode reward: [(0, '241.789')]
[36m[2025-06-29 15:44:45,949][60274] Fps is (10 sec: 410.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1200128. Throughput: 0: 82.1. Samples: 1200640. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:44:45,950][60274] Avg episode reward: [(0, '240.398')]
[36m[2025-06-29 15:44:50,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1200128. Throughput: 0: 81.6. Samples: 1200876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:44:50,947][60274] Avg episode reward: [(0, '243.283')]
[36m[2025-06-29 15:44:55,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1200128. Throughput: 0: 81.2. Samples: 1201372. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:44:55,980][60274] Avg episode reward: [(0, '238.308')]
[36m[2025-06-29 15:45:01,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1200128. Throughput: 0: 80.9. Samples: 1201856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:45:01,002][60274] Avg episode reward: [(0, '234.303')]
[37m[1m[2025-06-29 15:45:01,076][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004688_1200128.pth...
[36m[2025-06-29 15:45:01,132][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004608_1179648.pth
[36m[2025-06-29 15:45:05,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1200128. Throughput: 0: 80.0. Samples: 1202080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:45:05,989][60274] Avg episode reward: [(0, '227.706')]
[36m[2025-06-29 15:45:10,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1200128. Throughput: 0: 79.5. Samples: 1202556. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:45:10,972][60274] Avg episode reward: [(0, '225.029')]
[36m[2025-06-29 15:45:15,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1200128. Throughput: 0: 79.6. Samples: 1203044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:45:15,961][60274] Avg episode reward: [(0, '226.394')]
[36m[2025-06-29 15:45:20,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1200128. Throughput: 0: 79.7. Samples: 1203300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:45:20,956][60274] Avg episode reward: [(0, '230.667')]
[36m[2025-06-29 15:45:25,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1200128. Throughput: 0: 80.6. Samples: 1203772. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:45:25,948][60274] Avg episode reward: [(0, '245.273')]
[36m[2025-06-29 15:45:30,972][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1204224. Throughput: 0: 79.8. Samples: 1204232. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:45:30,973][60274] Avg episode reward: [(0, '230.220')]
[36m[2025-06-29 15:45:35,962][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1204224. Throughput: 0: 79.4. Samples: 1204452. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:45:35,962][60274] Avg episode reward: [(0, '235.491')]
[36m[2025-06-29 15:45:41,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1204224. Throughput: 0: 79.8. Samples: 1204964. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:45:41,004][60274] Avg episode reward: [(0, '219.170')]
[36m[2025-06-29 15:45:45,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1204224. Throughput: 0: 79.8. Samples: 1205448. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:45:45,991][60274] Avg episode reward: [(0, '216.220')]
[36m[2025-06-29 15:45:50,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1204224. Throughput: 0: 80.2. Samples: 1205688. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:45:50,985][60274] Avg episode reward: [(0, '215.451')]
[36m[2025-06-29 15:45:55,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1204224. Throughput: 0: 80.4. Samples: 1206176. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:45:55,971][60274] Avg episode reward: [(0, '220.923')]
[36m[2025-06-29 15:46:00,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1204224. Throughput: 0: 80.4. Samples: 1206660. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:46:00,954][60274] Avg episode reward: [(0, '213.329')]
[36m[2025-06-29 15:46:05,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1204224. Throughput: 0: 80.2. Samples: 1206912. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:46:05,993][60274] Avg episode reward: [(0, '215.861')]
[36m[2025-06-29 15:46:10,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1204224. Throughput: 0: 80.6. Samples: 1207400. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:46:10,979][60274] Avg episode reward: [(0, '227.208')]
[36m[2025-06-29 15:46:15,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1204224. Throughput: 0: 81.1. Samples: 1207880. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:46:15,972][60274] Avg episode reward: [(0, '224.548')]
[36m[2025-06-29 15:46:21,645][60274] Fps is (10 sec: 384.0, 60 sec: 135.0, 300 sec: 83.1). Total num frames: 1208320. Throughput: 0: 80.2. Samples: 1208116. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:46:21,645][60274] Avg episode reward: [(0, '215.735')]
[36m[2025-06-29 15:46:25,957][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1208320. Throughput: 0: 79.5. Samples: 1208536. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:46:25,957][60274] Avg episode reward: [(0, '217.455')]
[36m[2025-06-29 15:46:30,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1208320. Throughput: 0: 79.3. Samples: 1209016. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:46:30,981][60274] Avg episode reward: [(0, '223.661')]
[36m[2025-06-29 15:46:35,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1208320. Throughput: 0: 79.3. Samples: 1209256. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:46:35,952][60274] Avg episode reward: [(0, '223.150')]
[36m[2025-06-29 15:46:40,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1208320. Throughput: 0: 79.2. Samples: 1209740. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:46:40,998][60274] Avg episode reward: [(0, '238.288')]
[36m[2025-06-29 15:46:45,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1208320. Throughput: 0: 79.3. Samples: 1210228. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:46:45,961][60274] Avg episode reward: [(0, '235.671')]
[36m[2025-06-29 15:46:50,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1208320. Throughput: 0: 79.0. Samples: 1210464. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:46:50,954][60274] Avg episode reward: [(0, '236.595')]
[36m[2025-06-29 15:46:55,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1208320. Throughput: 0: 78.4. Samples: 1210928. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:46:55,972][60274] Avg episode reward: [(0, '249.074')]
[36m[2025-06-29 15:47:00,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.5). Total num frames: 1208320. Throughput: 0: 78.4. Samples: 1211408. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:47:00,988][60274] Avg episode reward: [(0, '254.189')]
[37m[1m[2025-06-29 15:47:01,045][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004720_1208320.pth...
[36m[2025-06-29 15:47:01,101][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004656_1191936.pth
[36m[2025-06-29 15:47:05,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1208320. Throughput: 0: 79.5. Samples: 1211636. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:47:05,948][60274] Avg episode reward: [(0, '241.854')]
[36m[2025-06-29 15:47:10,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1208320. Throughput: 0: 79.6. Samples: 1212116. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 15:47:10,949][60274] Avg episode reward: [(0, '236.339')]
[36m[2025-06-29 15:47:15,983][60274] Fps is (10 sec: 408.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1212416. Throughput: 0: 78.4. Samples: 1212544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:47:15,984][60274] Avg episode reward: [(0, '231.049')]
[36m[2025-06-29 15:47:20,955][60274] Fps is (10 sec: 409.4, 60 sec: 69.1, 300 sec: 83.3). Total num frames: 1212416. Throughput: 0: 78.3. Samples: 1212780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:47:20,955][60274] Avg episode reward: [(0, '237.328')]
[36m[2025-06-29 15:47:25,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1212416. Throughput: 0: 78.9. Samples: 1213288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:47:25,954][60274] Avg episode reward: [(0, '237.858')]
[36m[2025-06-29 15:47:30,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1212416. Throughput: 0: 78.8. Samples: 1213776. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:47:30,985][60274] Avg episode reward: [(0, '236.218')]
[36m[2025-06-29 15:47:35,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1212416. Throughput: 0: 79.0. Samples: 1214020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:47:35,959][60274] Avg episode reward: [(0, '237.522')]
[36m[2025-06-29 15:47:40,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1212416. Throughput: 0: 79.6. Samples: 1214512. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:47:40,979][60274] Avg episode reward: [(0, '238.390')]
[36m[2025-06-29 15:47:45,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1212416. Throughput: 0: 79.7. Samples: 1214996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:47:45,987][60274] Avg episode reward: [(0, '234.998')]
[36m[2025-06-29 15:47:51,009][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1212416. Throughput: 0: 79.8. Samples: 1215232. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:47:51,009][60274] Avg episode reward: [(0, '258.235')]
[36m[2025-06-29 15:47:55,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1212416. Throughput: 0: 79.5. Samples: 1215696. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:47:55,957][60274] Avg episode reward: [(0, '247.408')]
[36m[2025-06-29 15:48:00,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1212416. Throughput: 0: 80.6. Samples: 1216168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:48:00,960][60274] Avg episode reward: [(0, '247.390')]
[36m[2025-06-29 15:48:05,963][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1216512. Throughput: 0: 80.7. Samples: 1216412. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:48:05,963][60274] Avg episode reward: [(0, '250.165')]
[36m[2025-06-29 15:48:10,973][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1216512. Throughput: 0: 79.6. Samples: 1216872. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:48:10,973][60274] Avg episode reward: [(0, '250.269')]
[36m[2025-06-29 15:48:15,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1216512. Throughput: 0: 79.6. Samples: 1217360. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:48:15,997][60274] Avg episode reward: [(0, '261.410')]
[31m[15324115 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[15324115 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[15324115 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:48:20,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1216512. Throughput: 0: 79.6. Samples: 1217600. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:48:20,952][60274] Avg episode reward: [(0, '236.683')]
[36m[2025-06-29 15:48:25,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1216512. Throughput: 0: 79.2. Samples: 1218072. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:48:25,950][60274] Avg episode reward: [(0, '245.861')]
[31m[15331769 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[15331769 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[15331769 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:48:30,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1216512. Throughput: 0: 79.3. Samples: 1218564. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:48:30,990][60274] Avg episode reward: [(0, '228.996')]
[36m[2025-06-29 15:48:35,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1216512. Throughput: 0: 79.0. Samples: 1218784. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:48:35,983][60274] Avg episode reward: [(0, '241.109')]
[36m[2025-06-29 15:48:40,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1216512. Throughput: 0: 79.5. Samples: 1219276. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:48:40,980][60274] Avg episode reward: [(0, '244.500')]
[36m[2025-06-29 15:48:45,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1216512. Throughput: 0: 80.5. Samples: 1219792. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:48:45,962][60274] Avg episode reward: [(0, '239.536')]
[36m[2025-06-29 15:48:50,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1216512. Throughput: 0: 80.6. Samples: 1220036. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 15:48:50,951][60274] Avg episode reward: [(0, '251.553')]
[36m[2025-06-29 15:48:56,366][60274] Fps is (10 sec: 393.7, 60 sec: 135.6, 300 sec: 83.2). Total num frames: 1220608. Throughput: 0: 79.8. Samples: 1220496. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:48:56,366][60274] Avg episode reward: [(0, '256.921')]
[36m[2025-06-29 15:49:00,965][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1220608. Throughput: 0: 79.6. Samples: 1220940. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:00,965][60274] Avg episode reward: [(0, '267.330')]
[37m[1m[2025-06-29 15:49:01,013][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004768_1220608.pth...
[36m[2025-06-29 15:49:01,068][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004688_1200128.pth
[36m[2025-06-29 15:49:05,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1220608. Throughput: 0: 79.6. Samples: 1221184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:05,956][60274] Avg episode reward: [(0, '262.611')]
[36m[2025-06-29 15:49:10,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1220608. Throughput: 0: 79.6. Samples: 1221656. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:10,971][60274] Avg episode reward: [(0, '254.947')]
[36m[2025-06-29 15:49:15,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1220608. Throughput: 0: 80.1. Samples: 1222164. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:15,958][60274] Avg episode reward: [(0, '255.185')]
[36m[2025-06-29 15:49:20,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1220608. Throughput: 0: 80.2. Samples: 1222392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:20,962][60274] Avg episode reward: [(0, '258.813')]
[36m[2025-06-29 15:49:25,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1220608. Throughput: 0: 80.3. Samples: 1222888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:25,960][60274] Avg episode reward: [(0, '269.544')]
[36m[2025-06-29 15:49:30,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1220608. Throughput: 0: 79.3. Samples: 1223364. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:30,986][60274] Avg episode reward: [(0, '270.910')]
[36m[2025-06-29 15:49:35,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1220608. Throughput: 0: 79.3. Samples: 1223604. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:35,951][60274] Avg episode reward: [(0, '263.596')]
[33m[15401534 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[36m[2025-06-29 15:49:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1220608. Throughput: 0: 79.6. Samples: 1224048. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:40,981][60274] Avg episode reward: [(0, '259.872')]
[36m[2025-06-29 15:49:45,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1220608. Throughput: 0: 80.0. Samples: 1224540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:45,952][60274] Avg episode reward: [(0, '269.738')]
[36m[2025-06-29 15:49:50,966][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1224704. Throughput: 0: 78.9. Samples: 1224736. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:50,966][60274] Avg episode reward: [(0, '281.593')]
[36m[2025-06-29 15:49:56,007][60274] Fps is (10 sec: 407.3, 60 sec: 68.7, 300 sec: 83.3). Total num frames: 1224704. Throughput: 0: 79.2. Samples: 1225224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:49:56,008][60274] Avg episode reward: [(0, '274.123')]
[36m[2025-06-29 15:50:00,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1224704. Throughput: 0: 78.0. Samples: 1225676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:50:00,971][60274] Avg episode reward: [(0, '271.554')]
[36m[2025-06-29 15:50:05,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1224704. Throughput: 0: 78.1. Samples: 1225904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:50:05,953][60274] Avg episode reward: [(0, '274.431')]
[36m[2025-06-29 15:50:10,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1224704. Throughput: 0: 77.4. Samples: 1226372. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:50:10,984][60274] Avg episode reward: [(0, '280.847')]
[36m[2025-06-29 15:50:15,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1224704. Throughput: 0: 76.8. Samples: 1226816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:50:15,951][60274] Avg episode reward: [(0, '278.873')]
[36m[2025-06-29 15:50:21,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1224704. Throughput: 0: 77.0. Samples: 1227072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:50:21,004][60274] Avg episode reward: [(0, '280.447')]
[36m[2025-06-29 15:50:26,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1224704. Throughput: 0: 78.0. Samples: 1227560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:50:26,005][60274] Avg episode reward: [(0, '292.125')]
[37m[1m[2025-06-29 15:50:26,066][60274] Saving new best policy, reward=292.125!
[36m[2025-06-29 15:50:30,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1224704. Throughput: 0: 77.2. Samples: 1228016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:50:30,973][60274] Avg episode reward: [(0, '277.921')]
[36m[2025-06-29 15:50:35,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1224704. Throughput: 0: 78.4. Samples: 1228264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:50:35,992][60274] Avg episode reward: [(0, '270.864')]
[36m[2025-06-29 15:50:41,020][60274] Fps is (10 sec: 407.6, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1228800. Throughput: 0: 77.9. Samples: 1228732. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:50:41,021][60274] Avg episode reward: [(0, '274.122')]
[36m[2025-06-29 15:50:45,957][60274] Fps is (10 sec: 411.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1228800. Throughput: 0: 77.0. Samples: 1229140. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:50:45,958][60274] Avg episode reward: [(0, '276.662')]
[36m[2025-06-29 15:50:50,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1228800. Throughput: 0: 77.6. Samples: 1229396. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:50:50,953][60274] Avg episode reward: [(0, '274.554')]
[31m[15479144 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[15479145 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[15479145 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:50:55,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1228800. Throughput: 0: 77.5. Samples: 1229860. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:50:55,990][60274] Avg episode reward: [(0, '262.504')]
[36m[2025-06-29 15:51:00,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1228800. Throughput: 0: 78.0. Samples: 1230332. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:51:01,000][60274] Avg episode reward: [(0, '277.338')]
[37m[1m[2025-06-29 15:51:01,053][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004800_1228800.pth...
[36m[2025-06-29 15:51:01,113][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004720_1208320.pth
[36m[2025-06-29 15:51:05,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1228800. Throughput: 0: 77.6. Samples: 1230564. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:51:05,988][60274] Avg episode reward: [(0, '281.732')]
[36m[2025-06-29 15:51:10,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1228800. Throughput: 0: 77.2. Samples: 1231032. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:51:10,959][60274] Avg episode reward: [(0, '273.872')]
[36m[2025-06-29 15:51:15,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.6). Total num frames: 1228800. Throughput: 0: 78.1. Samples: 1231532. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:51:15,966][60274] Avg episode reward: [(0, '273.615')]
[36m[2025-06-29 15:51:20,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1228800. Throughput: 0: 77.9. Samples: 1231768. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:51:20,965][60274] Avg episode reward: [(0, '262.620')]
[36m[2025-06-29 15:51:25,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1228800. Throughput: 0: 79.2. Samples: 1232288. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:51:25,947][60274] Avg episode reward: [(0, '265.406')]
[36m[2025-06-29 15:51:30,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1228800. Throughput: 0: 80.7. Samples: 1232772. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 15:51:30,972][60274] Avg episode reward: [(0, '273.702')]
[36m[2025-06-29 15:51:35,978][60274] Fps is (10 sec: 408.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1232896. Throughput: 0: 79.2. Samples: 1232964. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:51:35,979][60274] Avg episode reward: [(0, '269.517')]
[36m[2025-06-29 15:51:40,956][60274] Fps is (10 sec: 410.3, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1232896. Throughput: 0: 80.2. Samples: 1233468. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:51:40,956][60274] Avg episode reward: [(0, '265.388')]
[36m[2025-06-29 15:51:45,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1232896. Throughput: 0: 81.3. Samples: 1233988. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:51:45,975][60274] Avg episode reward: [(0, '267.285')]
[36m[2025-06-29 15:51:50,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1232896. Throughput: 0: 81.3. Samples: 1234220. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:51:50,956][60274] Avg episode reward: [(0, '269.146')]
[36m[2025-06-29 15:51:55,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1232896. Throughput: 0: 81.9. Samples: 1234716. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:51:55,952][60274] Avg episode reward: [(0, '272.687')]
[36m[2025-06-29 15:52:00,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1232896. Throughput: 0: 81.7. Samples: 1235208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:00,980][60274] Avg episode reward: [(0, '278.031')]
[36m[2025-06-29 15:52:05,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1232896. Throughput: 0: 81.1. Samples: 1235420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:05,985][60274] Avg episode reward: [(0, '282.286')]
[36m[2025-06-29 15:52:11,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1232896. Throughput: 0: 80.2. Samples: 1235900. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:11,004][60274] Avg episode reward: [(0, '290.431')]
[36m[2025-06-29 15:52:15,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1232896. Throughput: 0: 80.2. Samples: 1236384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:15,983][60274] Avg episode reward: [(0, '290.887')]
[36m[2025-06-29 15:52:20,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1232896. Throughput: 0: 81.6. Samples: 1236632. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:20,953][60274] Avg episode reward: [(0, '286.643')]
[36m[2025-06-29 15:52:25,958][60274] Fps is (10 sec: 410.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1236992. Throughput: 0: 80.2. Samples: 1237076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:25,959][60274] Avg episode reward: [(0, '294.730')]
[37m[1m[2025-06-29 15:52:26,013][60274] Saving new best policy, reward=294.730!
[36m[2025-06-29 15:52:30,959][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1236992. Throughput: 0: 79.0. Samples: 1237544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:30,960][60274] Avg episode reward: [(0, '295.380')]
[37m[1m[2025-06-29 15:52:31,038][60274] Saving new best policy, reward=295.380!
[36m[2025-06-29 15:52:35,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1236992. Throughput: 0: 79.0. Samples: 1237776. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:35,986][60274] Avg episode reward: [(0, '286.309')]
[36m[2025-06-29 15:52:40,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1236992. Throughput: 0: 79.1. Samples: 1238276. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:40,951][60274] Avg episode reward: [(0, '282.459')]
[36m[2025-06-29 15:52:45,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1236992. Throughput: 0: 79.1. Samples: 1238768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:45,989][60274] Avg episode reward: [(0, '289.501')]
[36m[2025-06-29 15:52:50,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1236992. Throughput: 0: 79.8. Samples: 1239008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:50,958][60274] Avg episode reward: [(0, '293.244')]
[36m[2025-06-29 15:52:55,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1236992. Throughput: 0: 80.0. Samples: 1239500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:52:55,989][60274] Avg episode reward: [(0, '281.887')]
[36m[2025-06-29 15:53:00,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1236992. Throughput: 0: 79.9. Samples: 1239976. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:00,957][60274] Avg episode reward: [(0, '292.075')]
[37m[1m[2025-06-29 15:53:01,030][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004832_1236992.pth...
[36m[2025-06-29 15:53:01,087][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004768_1220608.pth
[36m[2025-06-29 15:53:05,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1236992. Throughput: 0: 79.0. Samples: 1240188. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:05,951][60274] Avg episode reward: [(0, '302.310')]
[37m[1m[2025-06-29 15:53:05,998][60274] Saving new best policy, reward=302.310!
[36m[2025-06-29 15:53:10,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1236992. Throughput: 0: 79.8. Samples: 1240668. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:10,986][60274] Avg episode reward: [(0, '306.755')]
[37m[1m[2025-06-29 15:53:11,034][60274] Saving new best policy, reward=306.755!
[36m[2025-06-29 15:53:15,989][60274] Fps is (10 sec: 408.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1241088. Throughput: 0: 78.9. Samples: 1241096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:15,990][60274] Avg episode reward: [(0, '312.889')]
[37m[1m[2025-06-29 15:53:15,992][60274] Saving new best policy, reward=312.889!
[36m[2025-06-29 15:53:20,997][60274] Fps is (10 sec: 409.2, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1241088. Throughput: 0: 79.2. Samples: 1241340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:20,997][60274] Avg episode reward: [(0, '318.422')]
[37m[1m[2025-06-29 15:53:21,063][60274] Saving new best policy, reward=318.422!
[36m[2025-06-29 15:53:25,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1241088. Throughput: 0: 79.1. Samples: 1241836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:25,964][60274] Avg episode reward: [(0, '310.685')]
[36m[2025-06-29 15:53:30,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1241088. Throughput: 0: 79.4. Samples: 1242340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:30,988][60274] Avg episode reward: [(0, '313.013')]
[36m[2025-06-29 15:53:36,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1241088. Throughput: 0: 79.7. Samples: 1242600. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:36,005][60274] Avg episode reward: [(0, '304.673')]
[36m[2025-06-29 15:53:40,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1241088. Throughput: 0: 79.4. Samples: 1243072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:40,956][60274] Avg episode reward: [(0, '305.874')]
[36m[2025-06-29 15:53:45,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1241088. Throughput: 0: 79.9. Samples: 1243572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:45,975][60274] Avg episode reward: [(0, '303.320')]
[36m[2025-06-29 15:53:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 1241088. Throughput: 0: 80.7. Samples: 1243820. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:50,961][60274] Avg episode reward: [(0, '299.082')]
[36m[2025-06-29 15:53:55,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1241088. Throughput: 0: 80.7. Samples: 1244300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:53:55,965][60274] Avg episode reward: [(0, '287.519')]
[31m[15662234 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[15662235 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[15662235 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 15:54:00,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1241088. Throughput: 0: 82.0. Samples: 1244784. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:54:00,954][60274] Avg episode reward: [(0, '281.111')]
[36m[2025-06-29 15:54:05,976][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1245184. Throughput: 0: 82.3. Samples: 1245044. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 15:54:05,976][60274] Avg episode reward: [(0, '281.830')]
[36m[2025-06-29 15:54:10,978][60274] Fps is (10 sec: 408.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1245184. Throughput: 0: 80.9. Samples: 1245476. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 15:54:10,978][60274] Avg episode reward: [(0, '274.968')]
[36m[2025-06-29 15:54:15,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1245184. Throughput: 0: 80.5. Samples: 1245960. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 15:54:15,950][60274] Avg episode reward: [(0, '268.554')]
[36m[2025-06-29 15:54:21,011][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1245184. Throughput: 0: 80.1. Samples: 1246204. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 15:54:21,011][60274] Avg episode reward: [(0, '273.499')]
[36m[2025-06-29 15:54:25,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1245184. Throughput: 0: 80.5. Samples: 1246696. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 15:54:25,970][60274] Avg episode reward: [(0, '274.961')]
[36m[2025-06-29 15:54:30,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1245184. Throughput: 0: 80.5. Samples: 1247196. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 15:54:30,974][60274] Avg episode reward: [(0, '278.762')]
[36m[2025-06-29 15:54:35,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1245184. Throughput: 0: 80.9. Samples: 1247460. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 15:54:35,982][60274] Avg episode reward: [(0, '280.366')]
[36m[2025-06-29 15:54:40,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1245184. Throughput: 0: 81.1. Samples: 1247948. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 15:54:40,954][60274] Avg episode reward: [(0, '282.050')]
[36m[2025-06-29 15:54:45,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1245184. Throughput: 0: 81.1. Samples: 1248432. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 15:54:45,953][60274] Avg episode reward: [(0, '270.809')]
[36m[2025-06-29 15:54:50,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1245184. Throughput: 0: 81.2. Samples: 1248696. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-06-29 15:54:50,967][60274] Avg episode reward: [(0, '283.288')]
[36m[2025-06-29 15:54:56,423][60274] Fps is (10 sec: 391.2, 60 sec: 135.5, 300 sec: 83.2). Total num frames: 1249280. Throughput: 0: 81.2. Samples: 1249168. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:54:56,424][60274] Avg episode reward: [(0, '276.698')]
[36m[2025-06-29 15:55:00,961][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1249280. Throughput: 0: 80.9. Samples: 1249600. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:55:00,961][60274] Avg episode reward: [(0, '263.135')]
[37m[1m[2025-06-29 15:55:01,008][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004880_1249280.pth...
[36m[2025-06-29 15:55:01,064][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004800_1228800.pth
[36m[2025-06-29 15:55:05,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1249280. Throughput: 0: 81.0. Samples: 1249844. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:55:05,950][60274] Avg episode reward: [(0, '258.127')]
[36m[2025-06-29 15:55:10,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1249280. Throughput: 0: 80.4. Samples: 1250316. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:55:10,998][60274] Avg episode reward: [(0, '249.250')]
[36m[2025-06-29 15:55:15,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1249280. Throughput: 0: 80.7. Samples: 1250828. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:55:15,969][60274] Avg episode reward: [(0, '249.462')]
[36m[2025-06-29 15:55:20,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1249280. Throughput: 0: 80.4. Samples: 1251076. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:55:20,952][60274] Avg episode reward: [(0, '250.942')]
[36m[2025-06-29 15:55:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1249280. Throughput: 0: 80.7. Samples: 1251580. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:55:25,967][60274] Avg episode reward: [(0, '269.428')]
[36m[2025-06-29 15:55:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1249280. Throughput: 0: 81.0. Samples: 1252080. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:55:30,989][60274] Avg episode reward: [(0, '260.877')]
[36m[2025-06-29 15:55:35,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1249280. Throughput: 0: 80.5. Samples: 1252320. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:55:35,966][60274] Avg episode reward: [(0, '258.891')]
[36m[2025-06-29 15:55:40,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1249280. Throughput: 0: 82.1. Samples: 1252824. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:55:40,973][60274] Avg episode reward: [(0, '258.094')]
[36m[2025-06-29 15:55:45,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1249280. Throughput: 0: 82.8. Samples: 1253324. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-06-29 15:55:45,963][60274] Avg episode reward: [(0, '262.685')]
[36m[2025-06-29 15:55:50,999][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1253376. Throughput: 0: 81.3. Samples: 1253508. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:55:51,000][60274] Avg episode reward: [(0, '261.321')]
[36m[2025-06-29 15:55:55,950][60274] Fps is (10 sec: 410.1, 60 sec: 68.8, 300 sec: 83.3). Total num frames: 1253376. Throughput: 0: 81.8. Samples: 1253992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:55:55,950][60274] Avg episode reward: [(0, '255.893')]
[36m[2025-06-29 15:56:00,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1253376. Throughput: 0: 81.1. Samples: 1254476. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:56:00,977][60274] Avg episode reward: [(0, '258.444')]
[36m[2025-06-29 15:56:05,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1253376. Throughput: 0: 81.2. Samples: 1254728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:56:05,954][60274] Avg episode reward: [(0, '261.386')]
[36m[2025-06-29 15:56:10,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1253376. Throughput: 0: 81.0. Samples: 1255224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:56:10,950][60274] Avg episode reward: [(0, '274.098')]
[36m[2025-06-29 15:56:15,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1253376. Throughput: 0: 80.5. Samples: 1255700. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:56:15,965][60274] Avg episode reward: [(0, '262.364')]
[36m[2025-06-29 15:56:20,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1253376. Throughput: 0: 80.3. Samples: 1255932. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:56:20,972][60274] Avg episode reward: [(0, '260.124')]
[36m[2025-06-29 15:56:25,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1253376. Throughput: 0: 79.9. Samples: 1256416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:56:25,956][60274] Avg episode reward: [(0, '266.185')]
[36m[2025-06-29 15:56:30,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1253376. Throughput: 0: 79.6. Samples: 1256904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:56:30,952][60274] Avg episode reward: [(0, '263.377')]
[36m[2025-06-29 15:56:35,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1253376. Throughput: 0: 81.4. Samples: 1257168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 15:56:35,988][60274] Avg episode reward: [(0, '266.606')]
[36m[2025-06-29 15:56:40,949][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1257472. Throughput: 0: 80.4. Samples: 1257608. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:56:40,949][60274] Avg episode reward: [(0, '268.673')]
[36m[2025-06-29 15:56:45,979][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1257472. Throughput: 0: 80.3. Samples: 1258088. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:56:45,979][60274] Avg episode reward: [(0, '259.129')]
[36m[2025-06-29 15:56:50,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1257472. Throughput: 0: 80.2. Samples: 1258340. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:56:50,993][60274] Avg episode reward: [(0, '257.020')]
[36m[2025-06-29 15:56:55,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1257472. Throughput: 0: 80.1. Samples: 1258832. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:56:55,983][60274] Avg episode reward: [(0, '268.186')]
[36m[2025-06-29 15:57:00,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1257472. Throughput: 0: 80.8. Samples: 1259336. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:57:00,960][60274] Avg episode reward: [(0, '270.328')]
[37m[1m[2025-06-29 15:57:01,006][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004912_1257472.pth...
[36m[2025-06-29 15:57:01,069][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004832_1236992.pth
[36m[2025-06-29 15:57:05,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1257472. Throughput: 0: 80.7. Samples: 1259564. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:57:05,996][60274] Avg episode reward: [(0, '274.555')]
[36m[2025-06-29 15:57:10,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1257472. Throughput: 0: 80.7. Samples: 1260052. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:57:10,986][60274] Avg episode reward: [(0, '269.345')]
[36m[2025-06-29 15:57:15,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1257472. Throughput: 0: 80.8. Samples: 1260540. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:57:15,948][60274] Avg episode reward: [(0, '264.014')]
[36m[2025-06-29 15:57:21,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1257472. Throughput: 0: 80.5. Samples: 1260792. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:57:21,004][60274] Avg episode reward: [(0, '251.353')]
[36m[2025-06-29 15:57:25,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1257472. Throughput: 0: 81.6. Samples: 1261284. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 15:57:25,992][60274] Avg episode reward: [(0, '258.310')]
[36m[2025-06-29 15:57:30,987][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1261568. Throughput: 0: 80.3. Samples: 1261704. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:57:30,987][60274] Avg episode reward: [(0, '260.120')]
[36m[2025-06-29 15:57:35,981][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1261568. Throughput: 0: 80.5. Samples: 1261960. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:57:35,982][60274] Avg episode reward: [(0, '266.912')]
[36m[2025-06-29 15:57:40,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1261568. Throughput: 0: 80.0. Samples: 1262428. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:57:40,949][60274] Avg episode reward: [(0, '258.307')]
[36m[2025-06-29 15:57:45,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1261568. Throughput: 0: 80.3. Samples: 1262952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:57:45,981][60274] Avg episode reward: [(0, '254.646')]
[36m[2025-06-29 15:57:50,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1261568. Throughput: 0: 80.9. Samples: 1263200. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:57:50,968][60274] Avg episode reward: [(0, '245.732')]
[36m[2025-06-29 15:57:55,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1261568. Throughput: 0: 80.5. Samples: 1263676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:57:55,998][60274] Avg episode reward: [(0, '240.485')]
[36m[2025-06-29 15:58:00,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1261568. Throughput: 0: 80.3. Samples: 1264152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:58:00,956][60274] Avg episode reward: [(0, '244.662')]
[36m[2025-06-29 15:58:05,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1261568. Throughput: 0: 80.5. Samples: 1264412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:58:05,978][60274] Avg episode reward: [(0, '260.609')]
[36m[2025-06-29 15:58:10,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1261568. Throughput: 0: 80.7. Samples: 1264912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:58:10,969][60274] Avg episode reward: [(0, '254.706')]
[36m[2025-06-29 15:58:15,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1261568. Throughput: 0: 82.3. Samples: 1265404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 15:58:15,966][60274] Avg episode reward: [(0, '254.489')]
[36m[2025-06-29 15:58:20,981][60274] Fps is (10 sec: 409.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1265664. Throughput: 0: 81.9. Samples: 1265644. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 15:58:20,981][60274] Avg episode reward: [(0, '258.592')]
[36m[2025-06-29 15:58:25,987][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1265664. Throughput: 0: 81.2. Samples: 1266084. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 15:58:25,997][60274] Avg episode reward: [(0, '255.275')]
[36m[2025-06-29 15:58:30,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1265664. Throughput: 0: 80.3. Samples: 1266564. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 15:58:30,979][60274] Avg episode reward: [(0, '254.369')]
[36m[2025-06-29 15:58:35,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1265664. Throughput: 0: 80.2. Samples: 1266812. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 15:58:35,987][60274] Avg episode reward: [(0, '262.272')]
[36m[2025-06-29 15:58:40,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1265664. Throughput: 0: 81.2. Samples: 1267328. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 15:58:40,952][60274] Avg episode reward: [(0, '259.489')]
[36m[2025-06-29 15:58:45,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1265664. Throughput: 0: 81.3. Samples: 1267812. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 15:58:45,952][60274] Avg episode reward: [(0, '256.805')]
[36m[2025-06-29 15:58:50,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1265664. Throughput: 0: 81.2. Samples: 1268068. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 15:58:50,981][60274] Avg episode reward: [(0, '247.949')]
[36m[2025-06-29 15:58:55,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1265664. Throughput: 0: 80.4. Samples: 1268532. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 15:58:55,982][60274] Avg episode reward: [(0, '244.599')]
[36m[2025-06-29 15:59:00,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1265664. Throughput: 0: 80.3. Samples: 1269020. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 15:59:00,976][60274] Avg episode reward: [(0, '243.198')]
[37m[1m[2025-06-29 15:59:01,023][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004944_1265664.pth...
[36m[2025-06-29 15:59:01,081][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004880_1249280.pth
[36m[2025-06-29 15:59:05,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1265664. Throughput: 0: 80.3. Samples: 1269260. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 15:59:05,999][60274] Avg episode reward: [(0, '248.526')]
[36m[2025-06-29 15:59:10,959][60274] Fps is (10 sec: 410.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1269760. Throughput: 0: 81.6. Samples: 1269752. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:59:10,959][60274] Avg episode reward: [(0, '248.782')]
[36m[2025-06-29 15:59:15,953][60274] Fps is (10 sec: 411.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1269760. Throughput: 0: 80.7. Samples: 1270192. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:59:15,954][60274] Avg episode reward: [(0, '238.545')]
[36m[2025-06-29 15:59:20,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1269760. Throughput: 0: 80.7. Samples: 1270440. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:59:20,954][60274] Avg episode reward: [(0, '232.195')]
[36m[2025-06-29 15:59:25,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1269760. Throughput: 0: 79.7. Samples: 1270916. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:59:25,988][60274] Avg episode reward: [(0, '240.333')]
[36m[2025-06-29 15:59:30,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1269760. Throughput: 0: 79.7. Samples: 1271400. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:59:30,970][60274] Avg episode reward: [(0, '241.538')]
[36m[2025-06-29 15:59:35,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1269760. Throughput: 0: 79.9. Samples: 1271660. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:59:35,955][60274] Avg episode reward: [(0, '248.226')]
[36m[2025-06-29 15:59:40,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1269760. Throughput: 0: 80.3. Samples: 1272148. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:59:40,992][60274] Avg episode reward: [(0, '250.724')]
[36m[2025-06-29 15:59:45,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1269760. Throughput: 0: 80.3. Samples: 1272632. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:59:45,963][60274] Avg episode reward: [(0, '249.496')]
[36m[2025-06-29 15:59:50,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 1269760. Throughput: 0: 80.2. Samples: 1272868. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:59:50,984][60274] Avg episode reward: [(0, '249.526')]
[36m[2025-06-29 15:59:55,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1269760. Throughput: 0: 80.0. Samples: 1273356. Policy #0 lag: (min: 4.0, avg: 4.0, max: 20.0)
[36m[2025-06-29 15:59:55,987][60274] Avg episode reward: [(0, '248.052')]
[36m[2025-06-29 16:00:01,010][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1273856. Throughput: 0: 81.4. Samples: 1273860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:01,011][60274] Avg episode reward: [(0, '244.923')]
[36m[2025-06-29 16:00:05,986][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1273856. Throughput: 0: 80.2. Samples: 1274052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:05,987][60274] Avg episode reward: [(0, '250.845')]
[36m[2025-06-29 16:00:10,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1273856. Throughput: 0: 79.9. Samples: 1274512. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:10,976][60274] Avg episode reward: [(0, '236.744')]
[36m[2025-06-29 16:00:15,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1273856. Throughput: 0: 80.2. Samples: 1275012. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:15,983][60274] Avg episode reward: [(0, '237.027')]
[36m[2025-06-29 16:00:20,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1273856. Throughput: 0: 79.8. Samples: 1275252. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:20,948][60274] Avg episode reward: [(0, '237.332')]
[36m[2025-06-29 16:00:25,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1273856. Throughput: 0: 79.7. Samples: 1275732. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:25,954][60274] Avg episode reward: [(0, '234.375')]
[36m[2025-06-29 16:00:30,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1273856. Throughput: 0: 79.6. Samples: 1276216. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:30,975][60274] Avg episode reward: [(0, '226.534')]
[36m[2025-06-29 16:00:36,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1273856. Throughput: 0: 79.9. Samples: 1276464. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:36,001][60274] Avg episode reward: [(0, '240.730')]
[36m[2025-06-29 16:00:40,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1273856. Throughput: 0: 78.3. Samples: 1276876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:40,947][60274] Avg episode reward: [(0, '241.419')]
[36m[2025-06-29 16:00:46,002][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1273856. Throughput: 0: 76.7. Samples: 1277312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:46,002][60274] Avg episode reward: [(0, '246.806')]
[36m[2025-06-29 16:00:50,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1273856. Throughput: 0: 77.4. Samples: 1277532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:00:50,949][60274] Avg episode reward: [(0, '252.750')]
[36m[2025-06-29 16:00:55,959][60274] Fps is (10 sec: 411.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1277952. Throughput: 0: 76.6. Samples: 1277956. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:00:55,960][60274] Avg episode reward: [(0, '252.727')]
[36m[2025-06-29 16:01:00,988][60274] Fps is (10 sec: 408.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1277952. Throughput: 0: 73.7. Samples: 1278328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:00,988][60274] Avg episode reward: [(0, '265.419')]
[37m[1m[2025-06-29 16:01:01,071][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004992_1277952.pth...
[36m[2025-06-29 16:01:01,160][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004912_1257472.pth
[36m[2025-06-29 16:01:05,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1277952. Throughput: 0: 72.8. Samples: 1278528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:05,951][60274] Avg episode reward: [(0, '268.047')]
[36m[2025-06-29 16:01:10,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1277952. Throughput: 0: 71.2. Samples: 1278936. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:10,968][60274] Avg episode reward: [(0, '273.695')]
[36m[2025-06-29 16:01:15,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1277952. Throughput: 0: 70.8. Samples: 1279404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:15,988][60274] Avg episode reward: [(0, '274.105')]
[36m[2025-06-29 16:01:20,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1277952. Throughput: 0: 70.7. Samples: 1279644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:20,960][60274] Avg episode reward: [(0, '265.408')]
[36m[2025-06-29 16:01:25,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1277952. Throughput: 0: 72.3. Samples: 1280132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:25,966][60274] Avg episode reward: [(0, '265.800')]
[36m[2025-06-29 16:01:30,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1277952. Throughput: 0: 72.8. Samples: 1280584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:30,964][60274] Avg episode reward: [(0, '260.570')]
[36m[2025-06-29 16:01:35,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1277952. Throughput: 0: 71.8. Samples: 1280764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:35,983][60274] Avg episode reward: [(0, '257.234')]
[36m[2025-06-29 16:01:40,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1277952. Throughput: 0: 71.2. Samples: 1281160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:40,957][60274] Avg episode reward: [(0, '268.945')]
[36m[2025-06-29 16:01:46,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1277952. Throughput: 0: 72.2. Samples: 1281580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:46,007][60274] Avg episode reward: [(0, '260.175')]
[36m[2025-06-29 16:01:50,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1277952. Throughput: 0: 71.9. Samples: 1281768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:01:51,000][60274] Avg episode reward: [(0, '261.394')]
[36m[2025-06-29 16:01:55,965][60274] Fps is (10 sec: 411.3, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1282048. Throughput: 0: 70.8. Samples: 1282120. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:01:55,966][60274] Avg episode reward: [(0, '264.489')]
[36m[2025-06-29 16:02:00,973][60274] Fps is (10 sec: 410.7, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1282048. Throughput: 0: 69.6. Samples: 1282536. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:02:00,973][60274] Avg episode reward: [(0, '258.924')]
[36m[2025-06-29 16:02:05,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1282048. Throughput: 0: 69.1. Samples: 1282756. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:02:05,977][60274] Avg episode reward: [(0, '237.273')]
[36m[2025-06-29 16:02:10,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1282048. Throughput: 0: 67.6. Samples: 1283172. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:02:10,957][60274] Avg episode reward: [(0, '246.704')]
[36m[2025-06-29 16:02:16,002][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1282048. Throughput: 0: 66.4. Samples: 1283576. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:02:16,002][60274] Avg episode reward: [(0, '250.029')]
[36m[2025-06-29 16:02:20,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1282048. Throughput: 0: 67.2. Samples: 1283788. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:02:21,000][60274] Avg episode reward: [(0, '262.803')]
[36m[2025-06-29 16:02:26,006][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1282048. Throughput: 0: 67.8. Samples: 1284216. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:02:26,006][60274] Avg episode reward: [(0, '262.413')]
[36m[2025-06-29 16:02:30,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1282048. Throughput: 0: 68.8. Samples: 1284672. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:02:30,957][60274] Avg episode reward: [(0, '260.130')]
[36m[2025-06-29 16:02:35,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1282048. Throughput: 0: 70.1. Samples: 1284920. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:02:35,958][60274] Avg episode reward: [(0, '264.766')]
[36m[2025-06-29 16:02:40,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1282048. Throughput: 0: 73.0. Samples: 1285404. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:02:40,978][60274] Avg episode reward: [(0, '258.370')]
[36m[2025-06-29 16:02:45,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1282048. Throughput: 0: 73.6. Samples: 1285848. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 16:02:45,972][60274] Avg episode reward: [(0, '258.826')]
[36m[2025-06-29 16:02:50,976][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1286144. Throughput: 0: 73.9. Samples: 1286080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:02:50,977][60274] Avg episode reward: [(0, '257.308')]
[36m[2025-06-29 16:02:55,965][60274] Fps is (10 sec: 409.9, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1286144. Throughput: 0: 74.2. Samples: 1286512. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:02:55,965][60274] Avg episode reward: [(0, '252.754')]
[36m[2025-06-29 16:03:00,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1286144. Throughput: 0: 76.2. Samples: 1287004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:00,979][60274] Avg episode reward: [(0, '247.203')]
[37m[1m[2025-06-29 16:03:01,027][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005024_1286144.pth...
[36m[2025-06-29 16:03:01,083][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004944_1265664.pth
[36m[2025-06-29 16:03:05,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1286144. Throughput: 0: 76.6. Samples: 1287232. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:05,968][60274] Avg episode reward: [(0, '230.109')]
[36m[2025-06-29 16:03:10,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1286144. Throughput: 0: 77.3. Samples: 1287692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:10,972][60274] Avg episode reward: [(0, '237.181')]
[36m[2025-06-29 16:03:15,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1286144. Throughput: 0: 78.1. Samples: 1288188. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:15,958][60274] Avg episode reward: [(0, '242.657')]
[36m[2025-06-29 16:03:20,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1286144. Throughput: 0: 77.9. Samples: 1288428. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:20,976][60274] Avg episode reward: [(0, '254.762')]
[36m[2025-06-29 16:03:25,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1286144. Throughput: 0: 77.9. Samples: 1288912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:25,982][60274] Avg episode reward: [(0, '266.424')]
[36m[2025-06-29 16:03:30,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1286144. Throughput: 0: 78.1. Samples: 1289364. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:30,991][60274] Avg episode reward: [(0, '262.457')]
[36m[2025-06-29 16:03:35,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1286144. Throughput: 0: 77.6. Samples: 1289568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:35,949][60274] Avg episode reward: [(0, '259.043')]
[36m[2025-06-29 16:03:40,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1286144. Throughput: 0: 78.1. Samples: 1290028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:40,967][60274] Avg episode reward: [(0, '256.944')]
[36m[2025-06-29 16:03:45,955][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1290240. Throughput: 0: 76.4. Samples: 1290440. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:45,955][60274] Avg episode reward: [(0, '252.606')]
[31m[16253721 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[16253721 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[16253722 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 16:03:51,033][60274] Fps is (10 sec: 406.9, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1290240. Throughput: 0: 76.6. Samples: 1290684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:51,034][60274] Avg episode reward: [(0, '249.032')]
[36m[2025-06-29 16:03:55,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1290240. Throughput: 0: 76.9. Samples: 1291152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:03:55,975][60274] Avg episode reward: [(0, '257.438')]
[36m[2025-06-29 16:04:00,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1290240. Throughput: 0: 76.8. Samples: 1291644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:04:00,951][60274] Avg episode reward: [(0, '260.249')]
[36m[2025-06-29 16:04:05,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1290240. Throughput: 0: 76.7. Samples: 1291880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:04:05,965][60274] Avg episode reward: [(0, '276.012')]
[36m[2025-06-29 16:04:10,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1290240. Throughput: 0: 76.6. Samples: 1292360. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:04:10,997][60274] Avg episode reward: [(0, '263.260')]
[36m[2025-06-29 16:04:15,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1290240. Throughput: 0: 76.8. Samples: 1292820. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:04:15,985][60274] Avg episode reward: [(0, '250.709')]
[36m[2025-06-29 16:04:20,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1290240. Throughput: 0: 77.0. Samples: 1293036. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:04:20,966][60274] Avg episode reward: [(0, '252.013')]
[36m[2025-06-29 16:04:25,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1290240. Throughput: 0: 77.5. Samples: 1293516. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:04:25,953][60274] Avg episode reward: [(0, '250.566')]
[36m[2025-06-29 16:04:30,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1290240. Throughput: 0: 79.6. Samples: 1294024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:04:30,965][60274] Avg episode reward: [(0, '263.191')]
[36m[2025-06-29 16:04:35,960][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1294336. Throughput: 0: 80.0. Samples: 1294280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:04:35,960][60274] Avg episode reward: [(0, '267.417')]
[36m[2025-06-29 16:04:40,957][60274] Fps is (10 sec: 409.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1294336. Throughput: 0: 79.1. Samples: 1294712. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:04:40,958][60274] Avg episode reward: [(0, '257.442')]
[36m[2025-06-29 16:04:45,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1294336. Throughput: 0: 78.6. Samples: 1295184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:04:45,973][60274] Avg episode reward: [(0, '262.878')]
[36m[2025-06-29 16:04:50,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 1294336. Throughput: 0: 78.7. Samples: 1295420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:04:50,955][60274] Avg episode reward: [(0, '263.925')]
[36m[2025-06-29 16:04:55,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1294336. Throughput: 0: 78.0. Samples: 1295868. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:04:55,947][60274] Avg episode reward: [(0, '269.300')]
[36m[2025-06-29 16:05:00,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1294336. Throughput: 0: 77.9. Samples: 1296328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:05:00,991][60274] Avg episode reward: [(0, '276.064')]
[37m[1m[2025-06-29 16:05:01,059][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005056_1294336.pth...
[36m[2025-06-29 16:05:01,134][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000004992_1277952.pth
[36m[2025-06-29 16:05:05,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1294336. Throughput: 0: 76.9. Samples: 1296500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:05:05,989][60274] Avg episode reward: [(0, '277.736')]
[36m[2025-06-29 16:05:10,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1294336. Throughput: 0: 75.4. Samples: 1296912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:05:10,988][60274] Avg episode reward: [(0, '269.955')]
[36m[2025-06-29 16:05:15,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1294336. Throughput: 0: 74.9. Samples: 1297392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:05:15,958][60274] Avg episode reward: [(0, '265.446')]
[36m[2025-06-29 16:05:20,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1294336. Throughput: 0: 74.4. Samples: 1297628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:05:20,988][60274] Avg episode reward: [(0, '265.656')]
[36m[2025-06-29 16:05:25,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1294336. Throughput: 0: 73.9. Samples: 1298040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:05:25,978][60274] Avg episode reward: [(0, '272.022')]
[36m[2025-06-29 16:05:31,365][60274] Fps is (10 sec: 394.7, 60 sec: 135.6, 300 sec: 83.2). Total num frames: 1298432. Throughput: 0: 71.3. Samples: 1298420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:05:31,366][60274] Avg episode reward: [(0, '277.024')]
[36m[2025-06-29 16:05:35,989][60274] Fps is (10 sec: 409.1, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1298432. Throughput: 0: 70.3. Samples: 1298588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:05:35,990][60274] Avg episode reward: [(0, '277.115')]
[36m[2025-06-29 16:05:40,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1298432. Throughput: 0: 70.0. Samples: 1299020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:05:40,951][60274] Avg episode reward: [(0, '274.824')]
[36m[2025-06-29 16:05:45,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1298432. Throughput: 0: 70.2. Samples: 1299484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:05:45,959][60274] Avg episode reward: [(0, '284.310')]
[36m[2025-06-29 16:05:50,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1298432. Throughput: 0: 71.2. Samples: 1299700. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:05:50,953][60274] Avg episode reward: [(0, '281.279')]
[36m[2025-06-29 16:05:55,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1298432. Throughput: 0: 72.3. Samples: 1300164. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:05:55,977][60274] Avg episode reward: [(0, '282.308')]
[36m[2025-06-29 16:06:00,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1298432. Throughput: 0: 71.9. Samples: 1300628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:06:00,956][60274] Avg episode reward: [(0, '279.919')]
[36m[2025-06-29 16:06:05,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1298432. Throughput: 0: 71.6. Samples: 1300852. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:06:05,986][60274] Avg episode reward: [(0, '277.352')]
[36m[2025-06-29 16:06:10,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1298432. Throughput: 0: 72.8. Samples: 1301312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:06:10,953][60274] Avg episode reward: [(0, '289.893')]
[36m[2025-06-29 16:06:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1298432. Throughput: 0: 75.4. Samples: 1301784. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:06:15,952][60274] Avg episode reward: [(0, '303.751')]
[36m[2025-06-29 16:06:20,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1298432. Throughput: 0: 75.8. Samples: 1301996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:06:20,955][60274] Avg episode reward: [(0, '300.738')]
[36m[2025-06-29 16:06:25,985][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1302528. Throughput: 0: 76.9. Samples: 1302484. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:06:25,985][60274] Avg episode reward: [(0, '304.325')]
[36m[2025-06-29 16:06:30,953][60274] Fps is (10 sec: 409.7, 60 sec: 68.7, 300 sec: 83.3). Total num frames: 1302528. Throughput: 0: 76.1. Samples: 1302908. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:06:30,953][60274] Avg episode reward: [(0, '292.267')]
[36m[2025-06-29 16:06:35,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1302528. Throughput: 0: 76.6. Samples: 1303148. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:06:35,970][60274] Avg episode reward: [(0, '279.913')]
[36m[2025-06-29 16:06:40,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1302528. Throughput: 0: 76.8. Samples: 1303620. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:06:40,967][60274] Avg episode reward: [(0, '271.815')]
[36m[2025-06-29 16:06:46,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1302528. Throughput: 0: 76.5. Samples: 1304076. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:06:46,006][60274] Avg episode reward: [(0, '269.811')]
[36m[2025-06-29 16:06:50,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1302528. Throughput: 0: 75.8. Samples: 1304260. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:06:50,962][60274] Avg episode reward: [(0, '269.959')]
[36m[2025-06-29 16:06:55,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1302528. Throughput: 0: 75.4. Samples: 1304708. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:06:55,970][60274] Avg episode reward: [(0, '262.413')]
[36m[2025-06-29 16:07:00,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1302528. Throughput: 0: 74.2. Samples: 1305124. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:07:00,972][60274] Avg episode reward: [(0, '269.300')]
[37m[1m[2025-06-29 16:07:01,020][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005088_1302528.pth...
[36m[2025-06-29 16:07:01,079][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005024_1286144.pth
[36m[2025-06-29 16:07:05,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1302528. Throughput: 0: 74.2. Samples: 1305336. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:07:05,959][60274] Avg episode reward: [(0, '254.552')]
[36m[2025-06-29 16:07:11,021][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1302528. Throughput: 0: 73.5. Samples: 1305796. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:07:11,022][60274] Avg episode reward: [(0, '266.228')]
[36m[2025-06-29 16:07:15,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1302528. Throughput: 0: 73.7. Samples: 1306224. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 16:07:15,969][60274] Avg episode reward: [(0, '262.890')]
[36m[2025-06-29 16:07:21,176][60274] Fps is (10 sec: 403.4, 60 sec: 136.0, 300 sec: 83.3). Total num frames: 1306624. Throughput: 0: 73.2. Samples: 1306456. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:07:21,176][60274] Avg episode reward: [(0, '249.536')]
[36m[2025-06-29 16:07:25,952][60274] Fps is (10 sec: 410.3, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1306624. Throughput: 0: 72.3. Samples: 1306872. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:07:25,952][60274] Avg episode reward: [(0, '248.416')]
[36m[2025-06-29 16:07:30,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1306624. Throughput: 0: 71.3. Samples: 1307284. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:07:30,996][60274] Avg episode reward: [(0, '240.958')]
[36m[2025-06-29 16:07:35,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1306624. Throughput: 0: 72.5. Samples: 1307520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:07:35,956][60274] Avg episode reward: [(0, '254.104')]
[36m[2025-06-29 16:07:40,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1306624. Throughput: 0: 73.3. Samples: 1308004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:07:40,963][60274] Avg episode reward: [(0, '252.950')]
[36m[2025-06-29 16:07:45,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1306624. Throughput: 0: 73.6. Samples: 1308436. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:07:45,987][60274] Avg episode reward: [(0, '249.345')]
[36m[2025-06-29 16:07:51,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1306624. Throughput: 0: 73.5. Samples: 1308648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:07:51,005][60274] Avg episode reward: [(0, '226.780')]
[36m[2025-06-29 16:07:55,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1306624. Throughput: 0: 73.7. Samples: 1309108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:07:55,960][60274] Avg episode reward: [(0, '220.192')]
[36m[2025-06-29 16:08:00,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1306624. Throughput: 0: 73.9. Samples: 1309552. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:08:00,979][60274] Avg episode reward: [(0, '226.825')]
[36m[2025-06-29 16:08:05,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1306624. Throughput: 0: 74.3. Samples: 1309784. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:08:05,967][60274] Avg episode reward: [(0, '229.399')]
[36m[2025-06-29 16:08:10,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1306624. Throughput: 0: 75.4. Samples: 1310264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:08:10,961][60274] Avg episode reward: [(0, '214.567')]
[36m[2025-06-29 16:08:15,975][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1310720. Throughput: 0: 76.6. Samples: 1310728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:08:15,975][60274] Avg episode reward: [(0, '209.041')]
[36m[2025-06-29 16:08:20,956][60274] Fps is (10 sec: 409.8, 60 sec: 68.5, 300 sec: 83.3). Total num frames: 1310720. Throughput: 0: 75.6. Samples: 1310924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:08:20,956][60274] Avg episode reward: [(0, '211.726')]
[36m[2025-06-29 16:08:25,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1310720. Throughput: 0: 74.8. Samples: 1311372. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:08:25,965][60274] Avg episode reward: [(0, '212.359')]
[36m[2025-06-29 16:08:30,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1310720. Throughput: 0: 75.1. Samples: 1311816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:08:30,979][60274] Avg episode reward: [(0, '219.045')]
[36m[2025-06-29 16:08:35,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1310720. Throughput: 0: 75.2. Samples: 1312028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:08:35,979][60274] Avg episode reward: [(0, '223.703')]
[36m[2025-06-29 16:08:40,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1310720. Throughput: 0: 75.0. Samples: 1312484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:08:40,961][60274] Avg episode reward: [(0, '228.887')]
[36m[2025-06-29 16:08:45,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1310720. Throughput: 0: 76.5. Samples: 1312992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:08:45,965][60274] Avg episode reward: [(0, '224.573')]
[36m[2025-06-29 16:08:51,036][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1310720. Throughput: 0: 76.6. Samples: 1313236. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:08:51,037][60274] Avg episode reward: [(0, '220.580')]
[36m[2025-06-29 16:08:55,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1310720. Throughput: 0: 76.8. Samples: 1313720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:08:55,967][60274] Avg episode reward: [(0, '232.675')]
[36m[2025-06-29 16:09:00,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1310720. Throughput: 0: 77.0. Samples: 1314192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:09:00,952][60274] Avg episode reward: [(0, '229.765')]
[37m[1m[2025-06-29 16:09:00,998][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005120_1310720.pth...
[36m[2025-06-29 16:09:01,053][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005056_1294336.pth
[36m[2025-06-29 16:09:05,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1310720. Throughput: 0: 78.0. Samples: 1314436. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:09:05,982][60274] Avg episode reward: [(0, '236.331')]
[36m[2025-06-29 16:09:10,983][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1314816. Throughput: 0: 77.2. Samples: 1314848. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:09:10,984][60274] Avg episode reward: [(0, '231.354')]
[36m[2025-06-29 16:09:15,950][60274] Fps is (10 sec: 410.9, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1314816. Throughput: 0: 76.7. Samples: 1315264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:09:15,950][60274] Avg episode reward: [(0, '237.748')]
[36m[2025-06-29 16:09:20,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1314816. Throughput: 0: 77.7. Samples: 1315524. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:09:20,951][60274] Avg episode reward: [(0, '225.815')]
[36m[2025-06-29 16:09:25,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1314816. Throughput: 0: 77.4. Samples: 1315968. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:09:25,989][60274] Avg episode reward: [(0, '230.640')]
[36m[2025-06-29 16:09:30,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1314816. Throughput: 0: 76.0. Samples: 1316412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:09:30,982][60274] Avg episode reward: [(0, '227.623')]
[36m[2025-06-29 16:09:35,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1314816. Throughput: 0: 75.7. Samples: 1316636. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:09:35,977][60274] Avg episode reward: [(0, '230.471')]
[36m[2025-06-29 16:09:40,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1314816. Throughput: 0: 75.2. Samples: 1317104. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:09:40,950][60274] Avg episode reward: [(0, '236.198')]
[36m[2025-06-29 16:09:45,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1314816. Throughput: 0: 75.3. Samples: 1317580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:09:45,961][60274] Avg episode reward: [(0, '240.087')]
[36m[2025-06-29 16:09:50,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1314816. Throughput: 0: 74.8. Samples: 1317804. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:09:50,984][60274] Avg episode reward: [(0, '245.729')]
[36m[2025-06-29 16:09:56,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1314816. Throughput: 0: 75.8. Samples: 1318260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:09:56,005][60274] Avg episode reward: [(0, '238.759')]
[36m[2025-06-29 16:10:00,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1314816. Throughput: 0: 75.9. Samples: 1318680. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:10:00,970][60274] Avg episode reward: [(0, '242.013')]
[36m[2025-06-29 16:10:05,970][60274] Fps is (10 sec: 411.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1318912. Throughput: 0: 74.9. Samples: 1318896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:05,970][60274] Avg episode reward: [(0, '242.520')]
[36m[2025-06-29 16:10:10,989][60274] Fps is (10 sec: 408.8, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1318912. Throughput: 0: 73.2. Samples: 1319264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:10,989][60274] Avg episode reward: [(0, '257.535')]
[36m[2025-06-29 16:10:16,010][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1318912. Throughput: 0: 72.6. Samples: 1319680. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:16,010][60274] Avg episode reward: [(0, '259.298')]
[36m[2025-06-29 16:10:20,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1318912. Throughput: 0: 72.5. Samples: 1319900. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:20,978][60274] Avg episode reward: [(0, '259.545')]
[36m[2025-06-29 16:10:25,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 1318912. Throughput: 0: 70.2. Samples: 1320264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:25,993][60274] Avg episode reward: [(0, '247.371')]
[36m[2025-06-29 16:10:31,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1318912. Throughput: 0: 68.7. Samples: 1320676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:31,000][60274] Avg episode reward: [(0, '252.074')]
[36m[2025-06-29 16:10:35,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1318912. Throughput: 0: 67.6. Samples: 1320848. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:35,988][60274] Avg episode reward: [(0, '253.189')]
[36m[2025-06-29 16:10:40,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1318912. Throughput: 0: 66.7. Samples: 1321260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:40,997][60274] Avg episode reward: [(0, '244.656')]
[36m[2025-06-29 16:10:45,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1318912. Throughput: 0: 66.6. Samples: 1321680. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:45,981][60274] Avg episode reward: [(0, '236.798')]
[36m[2025-06-29 16:10:50,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1318912. Throughput: 0: 67.0. Samples: 1321912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:50,969][60274] Avg episode reward: [(0, '248.879')]
[36m[2025-06-29 16:10:55,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1318912. Throughput: 0: 69.2. Samples: 1322376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:10:55,960][60274] Avg episode reward: [(0, '239.535')]
[36m[2025-06-29 16:11:00,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1318912. Throughput: 0: 69.7. Samples: 1322812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:11:00,961][60274] Avg episode reward: [(0, '237.628')]
[37m[1m[2025-06-29 16:11:01,013][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005152_1318912.pth...
[36m[2025-06-29 16:11:01,069][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005088_1302528.pth
[36m[2025-06-29 16:11:05,963][60274] Fps is (10 sec: 409.4, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1323008. Throughput: 0: 69.3. Samples: 1323016. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:05,964][60274] Avg episode reward: [(0, '229.627')]
[36m[2025-06-29 16:11:10,962][60274] Fps is (10 sec: 409.5, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1323008. Throughput: 0: 71.4. Samples: 1323476. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:10,962][60274] Avg episode reward: [(0, '235.658')]
[36m[2025-06-29 16:11:15,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1323008. Throughput: 0: 71.8. Samples: 1323904. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:15,985][60274] Avg episode reward: [(0, '236.195')]
[36m[2025-06-29 16:11:21,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1323008. Throughput: 0: 73.1. Samples: 1324140. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:21,000][60274] Avg episode reward: [(0, '247.473')]
[36m[2025-06-29 16:11:25,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1323008. Throughput: 0: 74.3. Samples: 1324604. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:25,975][60274] Avg episode reward: [(0, '249.787')]
[36m[2025-06-29 16:11:30,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1323008. Throughput: 0: 73.8. Samples: 1325000. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:30,983][60274] Avg episode reward: [(0, '249.364')]
[36m[2025-06-29 16:11:36,034][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1323008. Throughput: 0: 73.2. Samples: 1325212. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:36,034][60274] Avg episode reward: [(0, '252.339')]
[36m[2025-06-29 16:11:41,012][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1323008. Throughput: 0: 69.9. Samples: 1325524. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:41,012][60274] Avg episode reward: [(0, '251.030')]
[36m[2025-06-29 16:11:45,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1323008. Throughput: 0: 68.6. Samples: 1325900. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:45,967][60274] Avg episode reward: [(0, '251.415')]
[36m[2025-06-29 16:11:51,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1323008. Throughput: 0: 68.5. Samples: 1326100. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:51,003][60274] Avg episode reward: [(0, '260.573')]
[36m[2025-06-29 16:11:55,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1323008. Throughput: 0: 65.6. Samples: 1326432. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:11:55,999][60274] Avg episode reward: [(0, '253.822')]
[36m[2025-06-29 16:12:00,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1323008. Throughput: 0: 63.6. Samples: 1326764. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:12:00,949][60274] Avg episode reward: [(0, '254.104')]
[36m[2025-06-29 16:12:06,004][60274] Fps is (10 sec: 409.4, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1327104. Throughput: 0: 63.4. Samples: 1326992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:06,004][60274] Avg episode reward: [(0, '263.356')]
[36m[2025-06-29 16:12:10,965][60274] Fps is (10 sec: 408.9, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1327104. Throughput: 0: 60.8. Samples: 1327340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:10,966][60274] Avg episode reward: [(0, '259.931')]
[36m[2025-06-29 16:12:15,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 1327104. Throughput: 0: 61.1. Samples: 1327748. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:15,956][60274] Avg episode reward: [(0, '251.490')]
[36m[2025-06-29 16:12:20,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1327104. Throughput: 0: 61.1. Samples: 1327956. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:20,956][60274] Avg episode reward: [(0, '251.007')]
[36m[2025-06-29 16:12:25,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1327104. Throughput: 0: 62.9. Samples: 1328352. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:25,991][60274] Avg episode reward: [(0, '245.563')]
[36m[2025-06-29 16:12:30,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1327104. Throughput: 0: 64.2. Samples: 1328792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:30,987][60274] Avg episode reward: [(0, '248.826')]
[36m[2025-06-29 16:12:35,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1327104. Throughput: 0: 63.8. Samples: 1328972. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:35,986][60274] Avg episode reward: [(0, '258.144')]
[36m[2025-06-29 16:12:40,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1327104. Throughput: 0: 65.7. Samples: 1329388. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:40,996][60274] Avg episode reward: [(0, '252.110')]
[36m[2025-06-29 16:12:45,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1327104. Throughput: 0: 68.1. Samples: 1329832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:45,975][60274] Avg episode reward: [(0, '258.080')]
[31m[16793274 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[16793274 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[16793275 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 16:12:50,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1327104. Throughput: 0: 67.6. Samples: 1330032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:50,971][60274] Avg episode reward: [(0, '267.299')]
[36m[2025-06-29 16:12:55,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1327104. Throughput: 0: 69.3. Samples: 1330460. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:12:55,964][60274] Avg episode reward: [(0, '271.142')]
[36m[2025-06-29 16:13:00,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1327104. Throughput: 0: 70.0. Samples: 1330900. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:00,953][60274] Avg episode reward: [(0, '261.090')]
[37m[1m[2025-06-29 16:13:01,002][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005184_1327104.pth...
[36m[2025-06-29 16:13:01,057][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005120_1310720.pth
[36m[2025-06-29 16:13:05,989][60274] Fps is (10 sec: 408.6, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1331200. Throughput: 0: 70.0. Samples: 1331108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:05,989][60274] Avg episode reward: [(0, '267.470')]
[36m[2025-06-29 16:13:10,992][60274] Fps is (10 sec: 408.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 69.6. Samples: 1331484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:10,992][60274] Avg episode reward: [(0, '266.818')]
[36m[2025-06-29 16:13:15,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 69.0. Samples: 1331896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:15,962][60274] Avg episode reward: [(0, '268.539')]
[36m[2025-06-29 16:13:20,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 70.1. Samples: 1332128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:20,992][60274] Avg episode reward: [(0, '276.860')]
[36m[2025-06-29 16:13:25,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 70.4. Samples: 1332556. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:25,994][60274] Avg episode reward: [(0, '267.616')]
[36m[2025-06-29 16:13:31,009][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 69.5. Samples: 1332960. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:31,009][60274] Avg episode reward: [(0, '270.137')]
[36m[2025-06-29 16:13:35,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 69.8. Samples: 1333172. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:35,958][60274] Avg episode reward: [(0, '270.979')]
[36m[2025-06-29 16:13:40,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 69.3. Samples: 1333580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:40,967][60274] Avg episode reward: [(0, '264.764')]
[36m[2025-06-29 16:13:45,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 69.1. Samples: 1334012. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:45,969][60274] Avg episode reward: [(0, '265.359')]
[36m[2025-06-29 16:13:50,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 69.8. Samples: 1334248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:50,953][60274] Avg episode reward: [(0, '260.525')]
[36m[2025-06-29 16:13:55,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 71.6. Samples: 1334704. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:13:55,963][60274] Avg episode reward: [(0, '247.414')]
[36m[2025-06-29 16:14:00,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1331200. Throughput: 0: 72.7. Samples: 1335168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:14:00,967][60274] Avg episode reward: [(0, '265.916')]
[36m[2025-06-29 16:14:05,963][60274] Fps is (10 sec: 409.6, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 71.6. Samples: 1335348. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:05,963][60274] Avg episode reward: [(0, '265.285')]
[36m[2025-06-29 16:14:10,972][60274] Fps is (10 sec: 409.4, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 72.7. Samples: 1335824. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:10,973][60274] Avg episode reward: [(0, '255.698')]
[36m[2025-06-29 16:14:15,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 73.7. Samples: 1336272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:15,954][60274] Avg episode reward: [(0, '259.154')]
[36m[2025-06-29 16:14:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 74.0. Samples: 1336504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:20,985][60274] Avg episode reward: [(0, '254.806')]
[36m[2025-06-29 16:14:25,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 75.1. Samples: 1336960. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:25,984][60274] Avg episode reward: [(0, '256.489')]
[36m[2025-06-29 16:14:31,010][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 75.3. Samples: 1337404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:31,011][60274] Avg episode reward: [(0, '251.676')]
[36m[2025-06-29 16:14:35,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 75.0. Samples: 1337624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:35,969][60274] Avg episode reward: [(0, '255.219')]
[36m[2025-06-29 16:14:41,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 75.2. Samples: 1338092. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:41,000][60274] Avg episode reward: [(0, '254.176')]
[36m[2025-06-29 16:14:45,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 75.0. Samples: 1338544. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:45,967][60274] Avg episode reward: [(0, '248.844')]
[36m[2025-06-29 16:14:50,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 76.5. Samples: 1338788. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:50,947][60274] Avg episode reward: [(0, '253.535')]
[36m[2025-06-29 16:14:55,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1335296. Throughput: 0: 75.3. Samples: 1339212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:14:55,995][60274] Avg episode reward: [(0, '249.076')]
[36m[2025-06-29 16:15:00,959][60274] Fps is (10 sec: 409.1, 60 sec: 136.6, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 74.1. Samples: 1339608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:00,959][60274] Avg episode reward: [(0, '260.109')]
[37m[1m[2025-06-29 16:15:01,007][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005232_1339392.pth...
[36m[2025-06-29 16:15:01,064][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005152_1318912.pth
[36m[2025-06-29 16:15:05,952][60274] Fps is (10 sec: 411.3, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 73.5. Samples: 1339808. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:05,952][60274] Avg episode reward: [(0, '257.813')]
[36m[2025-06-29 16:15:11,011][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 72.6. Samples: 1340228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:11,012][60274] Avg episode reward: [(0, '253.898')]
[36m[2025-06-29 16:15:16,017][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 70.2. Samples: 1340564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:16,017][60274] Avg episode reward: [(0, '244.378')]
[36m[2025-06-29 16:15:20,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 68.8. Samples: 1340720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:20,988][60274] Avg episode reward: [(0, '245.290')]
[36m[2025-06-29 16:15:25,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 67.9. Samples: 1341148. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:25,986][60274] Avg episode reward: [(0, '251.305')]
[36m[2025-06-29 16:15:31,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 66.9. Samples: 1341556. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:31,004][60274] Avg episode reward: [(0, '252.363')]
[36m[2025-06-29 16:15:36,008][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 65.5. Samples: 1341740. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:36,008][60274] Avg episode reward: [(0, '257.145')]
[36m[2025-06-29 16:15:40,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 64.0. Samples: 1342092. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:40,979][60274] Avg episode reward: [(0, '258.845')]
[36m[2025-06-29 16:15:46,008][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 62.5. Samples: 1342424. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:46,009][60274] Avg episode reward: [(0, '254.202')]
[36m[2025-06-29 16:15:51,010][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 61.6. Samples: 1342584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:51,010][60274] Avg episode reward: [(0, '248.182')]
[36m[2025-06-29 16:15:55,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1339392. Throughput: 0: 60.0. Samples: 1342928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:15:55,982][60274] Avg episode reward: [(0, '261.546')]
[36m[2025-06-29 16:16:00,966][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1339392. Throughput: 0: 61.3. Samples: 1343320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:16:00,966][60274] Avg episode reward: [(0, '268.578')]
[36m[2025-06-29 16:16:05,997][60274] Fps is (10 sec: 409.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 61.7. Samples: 1343496. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:05,997][60274] Avg episode reward: [(0, '260.379')]
[36m[2025-06-29 16:16:10,956][60274] Fps is (10 sec: 410.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 61.8. Samples: 1343928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:10,957][60274] Avg episode reward: [(0, '262.195')]
[36m[2025-06-29 16:16:15,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 62.9. Samples: 1344384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:15,976][60274] Avg episode reward: [(0, '257.654')]
[36m[2025-06-29 16:16:20,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 63.4. Samples: 1344588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:20,961][60274] Avg episode reward: [(0, '264.752')]
[36m[2025-06-29 16:16:25,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 65.1. Samples: 1345020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:25,959][60274] Avg episode reward: [(0, '253.641')]
[36m[2025-06-29 16:16:30,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 67.6. Samples: 1345464. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:30,960][60274] Avg episode reward: [(0, '265.209')]
[36m[2025-06-29 16:16:35,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 68.9. Samples: 1345684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:35,991][60274] Avg episode reward: [(0, '267.032')]
[36m[2025-06-29 16:16:40,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 71.0. Samples: 1346124. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:40,971][60274] Avg episode reward: [(0, '260.244')]
[36m[2025-06-29 16:16:45,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 70.4. Samples: 1346488. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:45,973][60274] Avg episode reward: [(0, '272.209')]
[36m[2025-06-29 16:16:50,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 70.4. Samples: 1346664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:50,994][60274] Avg episode reward: [(0, '263.263')]
[36m[2025-06-29 16:16:55,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1343488. Throughput: 0: 68.4. Samples: 1347008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:16:55,962][60274] Avg episode reward: [(0, '270.384')]
[36m[2025-06-29 16:17:01,012][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1343488. Throughput: 0: 65.4. Samples: 1347328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:17:01,012][60274] Avg episode reward: [(0, '268.569')]
[37m[1m[2025-06-29 16:17:01,091][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005248_1343488.pth...
[36m[2025-06-29 16:17:01,164][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005184_1327104.pth
[36m[2025-06-29 16:17:05,994][60274] Fps is (10 sec: 408.3, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 64.4. Samples: 1347488. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:05,994][60274] Avg episode reward: [(0, '275.204')]
[36m[2025-06-29 16:17:10,982][60274] Fps is (10 sec: 410.8, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 61.3. Samples: 1347780. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:10,983][60274] Avg episode reward: [(0, '272.472')]
[36m[2025-06-29 16:17:16,012][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 58.7. Samples: 1348108. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:16,012][60274] Avg episode reward: [(0, '262.744')]
[36m[2025-06-29 16:17:21,054][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 56.2. Samples: 1348216. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:21,055][60274] Avg episode reward: [(0, '264.912')]
[36m[2025-06-29 16:17:25,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 51.9. Samples: 1348460. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:25,954][60274] Avg episode reward: [(0, '265.417')]
[36m[2025-06-29 16:17:31,033][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 48.7. Samples: 1348684. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:31,033][60274] Avg episode reward: [(0, '261.218')]
[36m[2025-06-29 16:17:36,034][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 47.6. Samples: 1348808. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:36,034][60274] Avg episode reward: [(0, '259.962')]
[36m[2025-06-29 16:17:41,048][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 45.7. Samples: 1349068. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:41,048][60274] Avg episode reward: [(0, '266.446')]
[36m[2025-06-29 16:17:45,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 45.6. Samples: 1349380. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:45,993][60274] Avg episode reward: [(0, '263.920')]
[36m[2025-06-29 16:17:50,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 45.8. Samples: 1349548. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:50,950][60274] Avg episode reward: [(0, '263.574')]
[36m[2025-06-29 16:17:55,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1347584. Throughput: 0: 46.2. Samples: 1349860. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:17:55,962][60274] Avg episode reward: [(0, '277.515')]
[36m[2025-06-29 16:18:00,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1347584. Throughput: 0: 45.7. Samples: 1350164. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:18:00,959][60274] Avg episode reward: [(0, '272.377')]
[36m[2025-06-29 16:18:06,011][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1347584. Throughput: 0: 47.2. Samples: 1350336. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:18:06,011][60274] Avg episode reward: [(0, '267.953')]
[36m[2025-06-29 16:18:11,054][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1347584. Throughput: 0: 48.2. Samples: 1350632. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:18:11,054][60274] Avg episode reward: [(0, '268.365')]
[36m[2025-06-29 16:18:16,032][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1347584. Throughput: 0: 48.6. Samples: 1350872. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:18:16,033][60274] Avg episode reward: [(0, '275.398')]
[36m[2025-06-29 16:18:20,978][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1347584. Throughput: 0: 48.1. Samples: 1350972. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:18:20,979][60274] Avg episode reward: [(0, '269.959')]
[36m[2025-06-29 16:18:25,976][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1347584. Throughput: 0: 49.2. Samples: 1351280. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:18:25,977][60274] Avg episode reward: [(0, '263.989')]
[36m[2025-06-29 16:18:30,953][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1347584. Throughput: 0: 49.3. Samples: 1351596. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:18:30,954][60274] Avg episode reward: [(0, '256.934')]
[36m[2025-06-29 16:18:35,954][60274] Fps is (10 sec: 410.5, 60 sec: 68.4, 300 sec: 69.4). Total num frames: 1351680. Throughput: 0: 48.3. Samples: 1351720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:18:35,954][60274] Avg episode reward: [(0, '256.106')]
[36m[2025-06-29 16:18:41,013][60274] Fps is (10 sec: 407.2, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1351680. Throughput: 0: 47.9. Samples: 1352020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:18:41,014][60274] Avg episode reward: [(0, '247.759')]
[36m[2025-06-29 16:18:45,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1351680. Throughput: 0: 48.0. Samples: 1352324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:18:45,954][60274] Avg episode reward: [(0, '246.368')]
[36m[2025-06-29 16:18:51,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1351680. Throughput: 0: 47.9. Samples: 1352492. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:18:51,001][60274] Avg episode reward: [(0, '252.517')]
[36m[2025-06-29 16:18:55,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1351680. Throughput: 0: 48.6. Samples: 1352816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:18:55,958][60274] Avg episode reward: [(0, '243.687')]
[36m[2025-06-29 16:19:01,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 50.2. Samples: 1353128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:01,004][60274] Avg episode reward: [(0, '242.247')]
[37m[1m[2025-06-29 16:19:01,092][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005280_1351680.pth...
[36m[2025-06-29 16:19:01,170][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005232_1339392.pth
[36m[2025-06-29 16:19:06,010][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 51.1. Samples: 1353272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:06,010][60274] Avg episode reward: [(0, '246.255')]
[36m[2025-06-29 16:19:10,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.4, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 51.1. Samples: 1353580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:10,960][60274] Avg episode reward: [(0, '246.611')]
[36m[2025-06-29 16:19:16,061][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 51.3. Samples: 1353908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:16,062][60274] Avg episode reward: [(0, '249.731')]
[36m[2025-06-29 16:19:20,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 51.9. Samples: 1354056. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:20,993][60274] Avg episode reward: [(0, '253.831')]
[36m[2025-06-29 16:19:26,008][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 52.5. Samples: 1354380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:26,008][60274] Avg episode reward: [(0, '253.759')]
[36m[2025-06-29 16:19:30,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 52.4. Samples: 1354684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:30,998][60274] Avg episode reward: [(0, '251.913')]
[36m[2025-06-29 16:19:35,973][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 52.3. Samples: 1354844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:35,974][60274] Avg episode reward: [(0, '255.040')]
[36m[2025-06-29 16:19:41,009][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 51.6. Samples: 1355140. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:41,010][60274] Avg episode reward: [(0, '252.440')]
[36m[2025-06-29 16:19:45,974][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 50.3. Samples: 1355392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:45,974][60274] Avg episode reward: [(0, '257.576')]
[36m[2025-06-29 16:19:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 55.5). Total num frames: 1351680. Throughput: 0: 49.7. Samples: 1355508. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:50,976][60274] Avg episode reward: [(0, '261.570')]
[36m[2025-06-29 16:19:55,994][60274] Fps is (10 sec: 408.8, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 50.5. Samples: 1355852. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:19:55,994][60274] Avg episode reward: [(0, '257.514')]
[36m[2025-06-29 16:20:00,989][60274] Fps is (10 sec: 409.1, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 51.6. Samples: 1356228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:00,989][60274] Avg episode reward: [(0, '252.071')]
[36m[2025-06-29 16:20:05,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 51.6. Samples: 1356376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:05,958][60274] Avg episode reward: [(0, '247.648')]
[36m[2025-06-29 16:20:10,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 54.1. Samples: 1356812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:10,991][60274] Avg episode reward: [(0, '246.154')]
[36m[2025-06-29 16:20:15,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.4, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 57.9. Samples: 1357288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:15,956][60274] Avg episode reward: [(0, '253.797')]
[36m[2025-06-29 16:20:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 59.5. Samples: 1357520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:20,985][60274] Avg episode reward: [(0, '254.815')]
[36m[2025-06-29 16:20:25,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 63.8. Samples: 1358008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:25,985][60274] Avg episode reward: [(0, '254.697')]
[36m[2025-06-29 16:20:30,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 68.7. Samples: 1358484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:30,993][60274] Avg episode reward: [(0, '257.976')]
[36m[2025-06-29 16:20:35,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 71.1. Samples: 1358708. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:35,960][60274] Avg episode reward: [(0, '254.393')]
[36m[2025-06-29 16:20:40,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 74.9. Samples: 1359220. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:40,951][60274] Avg episode reward: [(0, '254.861')]
[36m[2025-06-29 16:20:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1355776. Throughput: 0: 77.5. Samples: 1359712. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:45,970][60274] Avg episode reward: [(0, '254.126')]
[36m[2025-06-29 16:20:50,982][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 69.4). Total num frames: 1359872. Throughput: 0: 78.2. Samples: 1359896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:50,983][60274] Avg episode reward: [(0, '251.929')]
[36m[2025-06-29 16:20:55,947][60274] Fps is (10 sec: 410.5, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1359872. Throughput: 0: 79.6. Samples: 1360392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:20:55,947][60274] Avg episode reward: [(0, '264.963')]
[36m[2025-06-29 16:21:00,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1359872. Throughput: 0: 79.2. Samples: 1360852. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:21:00,956][60274] Avg episode reward: [(0, '265.653')]
[37m[1m[2025-06-29 16:21:01,003][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005312_1359872.pth...
[36m[2025-06-29 16:21:01,060][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005248_1343488.pth
[36m[2025-06-29 16:21:05,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1359872. Throughput: 0: 79.0. Samples: 1361076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:21:05,992][60274] Avg episode reward: [(0, '273.465')]
[36m[2025-06-29 16:21:10,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1359872. Throughput: 0: 78.2. Samples: 1361528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:21:10,987][60274] Avg episode reward: [(0, '280.327')]
[36m[2025-06-29 16:21:15,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1359872. Throughput: 0: 76.4. Samples: 1361924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:21:15,997][60274] Avg episode reward: [(0, '273.384')]
[36m[2025-06-29 16:21:20,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1359872. Throughput: 0: 76.4. Samples: 1362144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:21:20,955][60274] Avg episode reward: [(0, '275.824')]
[36m[2025-06-29 16:21:26,043][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 55.5). Total num frames: 1359872. Throughput: 0: 74.2. Samples: 1362564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:21:26,043][60274] Avg episode reward: [(0, '276.339')]
[36m[2025-06-29 16:21:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1359872. Throughput: 0: 70.9. Samples: 1362904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:21:30,973][60274] Avg episode reward: [(0, '265.824')]
[36m[2025-06-29 16:21:35,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1359872. Throughput: 0: 70.3. Samples: 1363056. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:21:35,965][60274] Avg episode reward: [(0, '272.108')]
[36m[2025-06-29 16:21:40,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1359872. Throughput: 0: 68.4. Samples: 1363472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:21:40,946][60274] Avg episode reward: [(0, '278.643')]
[36m[2025-06-29 16:21:45,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1359872. Throughput: 0: 67.8. Samples: 1363904. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:21:45,983][60274] Avg episode reward: [(0, '286.954')]
[36m[2025-06-29 16:21:50,957][60274] Fps is (10 sec: 409.1, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1363968. Throughput: 0: 66.7. Samples: 1364076. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 16:21:50,958][60274] Avg episode reward: [(0, '275.796')]
[36m[2025-06-29 16:21:55,968][60274] Fps is (10 sec: 410.2, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1363968. Throughput: 0: 67.3. Samples: 1364556. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 16:21:55,969][60274] Avg episode reward: [(0, '282.619')]
[36m[2025-06-29 16:22:00,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1363968. Throughput: 0: 69.2. Samples: 1365036. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 16:22:00,967][60274] Avg episode reward: [(0, '286.612')]
[36m[2025-06-29 16:22:05,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1363968. Throughput: 0: 69.6. Samples: 1365280. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 16:22:05,987][60274] Avg episode reward: [(0, '285.907')]
[36m[2025-06-29 16:22:10,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.6). Total num frames: 1363968. Throughput: 0: 71.9. Samples: 1365792. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 16:22:10,948][60274] Avg episode reward: [(0, '287.531')]
[36m[2025-06-29 16:22:15,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.6). Total num frames: 1363968. Throughput: 0: 75.5. Samples: 1366300. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 16:22:15,983][60274] Avg episode reward: [(0, '267.663')]
[36m[2025-06-29 16:22:20,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1363968. Throughput: 0: 77.2. Samples: 1366528. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 16:22:20,957][60274] Avg episode reward: [(0, '282.259')]
[36m[2025-06-29 16:22:25,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.4, 300 sec: 55.6). Total num frames: 1363968. Throughput: 0: 77.9. Samples: 1366980. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 16:22:25,955][60274] Avg episode reward: [(0, '273.432')]
[36m[2025-06-29 16:22:30,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.6). Total num frames: 1363968. Throughput: 0: 79.0. Samples: 1367456. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 16:22:30,967][60274] Avg episode reward: [(0, '274.012')]
[36m[2025-06-29 16:22:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.6). Total num frames: 1363968. Throughput: 0: 81.0. Samples: 1367720. Policy #0 lag: (min: 7.0, avg: 7.0, max: 23.0)
[36m[2025-06-29 16:22:35,972][60274] Avg episode reward: [(0, '259.532')]
[36m[2025-06-29 16:22:40,956][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 69.4). Total num frames: 1368064. Throughput: 0: 80.1. Samples: 1368160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:22:40,956][60274] Avg episode reward: [(0, '254.677')]
[36m[2025-06-29 16:22:45,956][60274] Fps is (10 sec: 410.2, 60 sec: 136.6, 300 sec: 69.4). Total num frames: 1368064. Throughput: 0: 80.0. Samples: 1368636. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:22:45,957][60274] Avg episode reward: [(0, '253.250')]
[36m[2025-06-29 16:22:50,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1368064. Throughput: 0: 80.0. Samples: 1368880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:22:50,988][60274] Avg episode reward: [(0, '261.319')]
[36m[2025-06-29 16:22:55,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1368064. Throughput: 0: 79.6. Samples: 1369376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:22:55,978][60274] Avg episode reward: [(0, '261.246')]
[36m[2025-06-29 16:23:00,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1368064. Throughput: 0: 78.8. Samples: 1369844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:00,977][60274] Avg episode reward: [(0, '267.793')]
[37m[1m[2025-06-29 16:23:01,026][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005344_1368064.pth...
[36m[2025-06-29 16:23:01,084][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005280_1351680.pth
[36m[2025-06-29 16:23:05,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1368064. Throughput: 0: 79.2. Samples: 1370092. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:05,959][60274] Avg episode reward: [(0, '251.737')]
[36m[2025-06-29 16:23:10,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1368064. Throughput: 0: 80.5. Samples: 1370600. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:10,951][60274] Avg episode reward: [(0, '256.657')]
[33m[17420890 ms][navigation_task] - WARNING : Curriculum Level: 38, Curriculum progress fraction: 0.14285714285714285 (navigation_task.py:262)
[33m[17420890 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.71142578125
[33mCrash Rate: 0.23193359375
[33mTimeout Rate: 0.056640625 (navigation_task.py:265)
[33m[17420890 ms][navigation_task] - WARNING : 
[33mSuccesses: 1457
[33mCrashes : 475
[33mTimeouts: 116 (navigation_task.py:268)
[36m[2025-06-29 16:23:15,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1368064. Throughput: 0: 81.2. Samples: 1371112. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:15,969][60274] Avg episode reward: [(0, '251.743')]
[36m[2025-06-29 16:23:20,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1368064. Throughput: 0: 80.8. Samples: 1371356. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:20,964][60274] Avg episode reward: [(0, '252.396')]
[36m[2025-06-29 16:23:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1368064. Throughput: 0: 81.8. Samples: 1371840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:25,957][60274] Avg episode reward: [(0, '269.424')]
[36m[2025-06-29 16:23:30,947][60274] Fps is (10 sec: 410.3, 60 sec: 136.6, 300 sec: 69.4). Total num frames: 1372160. Throughput: 0: 80.5. Samples: 1372256. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:30,947][60274] Avg episode reward: [(0, '266.200')]
[36m[2025-06-29 16:23:35,969][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 69.4). Total num frames: 1372160. Throughput: 0: 80.5. Samples: 1372500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:35,969][60274] Avg episode reward: [(0, '269.386')]
[36m[2025-06-29 16:23:40,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1372160. Throughput: 0: 80.6. Samples: 1373004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:40,994][60274] Avg episode reward: [(0, '268.005')]
[36m[2025-06-29 16:23:45,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1372160. Throughput: 0: 81.3. Samples: 1373504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:45,972][60274] Avg episode reward: [(0, '275.602')]
[36m[2025-06-29 16:23:50,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1372160. Throughput: 0: 81.1. Samples: 1373744. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:50,989][60274] Avg episode reward: [(0, '274.899')]
[36m[2025-06-29 16:23:55,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1372160. Throughput: 0: 80.8. Samples: 1374236. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:23:55,948][60274] Avg episode reward: [(0, '285.945')]
[36m[2025-06-29 16:24:00,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1372160. Throughput: 0: 80.1. Samples: 1374720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:24:00,984][60274] Avg episode reward: [(0, '292.615')]
[36m[2025-06-29 16:24:05,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1372160. Throughput: 0: 80.5. Samples: 1374980. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:24:05,989][60274] Avg episode reward: [(0, '308.464')]
[36m[2025-06-29 16:24:10,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1372160. Throughput: 0: 80.7. Samples: 1375472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:24:10,957][60274] Avg episode reward: [(0, '310.003')]
[36m[2025-06-29 16:24:15,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1372160. Throughput: 0: 82.3. Samples: 1375964. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:24:15,993][60274] Avg episode reward: [(0, '311.993')]
[36m[2025-06-29 16:24:20,985][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1376256. Throughput: 0: 82.3. Samples: 1376204. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:24:20,985][60274] Avg episode reward: [(0, '340.611')]
[37m[1m[2025-06-29 16:24:21,031][60274] Saving new best policy, reward=340.611!
[36m[2025-06-29 16:24:25,950][60274] Fps is (10 sec: 411.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1376256. Throughput: 0: 80.6. Samples: 1376628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:24:25,950][60274] Avg episode reward: [(0, '350.067')]
[37m[1m[2025-06-29 16:24:25,994][60274] Saving new best policy, reward=350.067!
[36m[2025-06-29 16:24:30,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1376256. Throughput: 0: 80.4. Samples: 1377124. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:24:30,988][60274] Avg episode reward: [(0, '364.299')]
[37m[1m[2025-06-29 16:24:31,035][60274] Saving new best policy, reward=364.299!
[36m[2025-06-29 16:24:35,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1376256. Throughput: 0: 80.6. Samples: 1377368. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:24:35,974][60274] Avg episode reward: [(0, '360.153')]
[36m[2025-06-29 16:24:40,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1376256. Throughput: 0: 80.6. Samples: 1377864. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:24:40,965][60274] Avg episode reward: [(0, '362.962')]
[36m[2025-06-29 16:24:45,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1376256. Throughput: 0: 80.6. Samples: 1378344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:24:45,948][60274] Avg episode reward: [(0, '353.936')]
[36m[2025-06-29 16:24:50,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1376256. Throughput: 0: 80.2. Samples: 1378588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:24:50,982][60274] Avg episode reward: [(0, '351.972')]
[36m[2025-06-29 16:24:55,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1376256. Throughput: 0: 80.5. Samples: 1379096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:24:55,979][60274] Avg episode reward: [(0, '352.746')]
[36m[2025-06-29 16:25:00,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1376256. Throughput: 0: 80.8. Samples: 1379596. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:25:00,951][60274] Avg episode reward: [(0, '370.558')]
[37m[1m[2025-06-29 16:25:00,998][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005376_1376256.pth...
[36m[2025-06-29 16:25:01,054][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005312_1359872.pth
[37m[1m[2025-06-29 16:25:01,061][60274] Saving new best policy, reward=370.558!
[36m[2025-06-29 16:25:05,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1376256. Throughput: 0: 80.9. Samples: 1379840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:25:05,951][60274] Avg episode reward: [(0, '356.789')]
[36m[2025-06-29 16:25:10,958][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1380352. Throughput: 0: 82.6. Samples: 1380344. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:25:10,958][60274] Avg episode reward: [(0, '361.363')]
[36m[2025-06-29 16:25:15,955][60274] Fps is (10 sec: 409.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1380352. Throughput: 0: 81.4. Samples: 1380784. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:25:15,956][60274] Avg episode reward: [(0, '348.458')]
[36m[2025-06-29 16:25:20,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1380352. Throughput: 0: 81.2. Samples: 1381020. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:25:20,974][60274] Avg episode reward: [(0, '347.390')]
[36m[2025-06-29 16:25:25,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1380352. Throughput: 0: 81.1. Samples: 1381516. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:25:25,969][60274] Avg episode reward: [(0, '350.519')]
[36m[2025-06-29 16:25:30,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1380352. Throughput: 0: 81.0. Samples: 1381992. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:25:30,988][60274] Avg episode reward: [(0, '349.270')]
[36m[2025-06-29 16:25:35,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1380352. Throughput: 0: 81.3. Samples: 1382244. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:25:35,962][60274] Avg episode reward: [(0, '353.165')]
[36m[2025-06-29 16:25:40,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1380352. Throughput: 0: 80.2. Samples: 1382704. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:25:40,976][60274] Avg episode reward: [(0, '346.240')]
[36m[2025-06-29 16:25:45,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1380352. Throughput: 0: 80.0. Samples: 1383196. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:25:45,950][60274] Avg episode reward: [(0, '343.097')]
[36m[2025-06-29 16:25:50,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1380352. Throughput: 0: 79.7. Samples: 1383428. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:25:50,990][60274] Avg episode reward: [(0, '344.048')]
[36m[2025-06-29 16:25:55,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1380352. Throughput: 0: 78.6. Samples: 1383884. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:25:55,994][60274] Avg episode reward: [(0, '327.840')]
[36m[2025-06-29 16:26:00,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1380352. Throughput: 0: 79.2. Samples: 1384348. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-06-29 16:26:00,957][60274] Avg episode reward: [(0, '337.342')]
[36m[2025-06-29 16:26:05,978][60274] Fps is (10 sec: 410.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1384448. Throughput: 0: 77.9. Samples: 1384528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:26:05,978][60274] Avg episode reward: [(0, '334.560')]
[36m[2025-06-29 16:26:10,996][60274] Fps is (10 sec: 408.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1384448. Throughput: 0: 77.3. Samples: 1384996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:26:10,997][60274] Avg episode reward: [(0, '335.434')]
[36m[2025-06-29 16:26:15,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1384448. Throughput: 0: 76.6. Samples: 1385436. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:26:15,973][60274] Avg episode reward: [(0, '332.918')]
[36m[2025-06-29 16:26:20,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1384448. Throughput: 0: 76.5. Samples: 1385684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:26:20,958][60274] Avg episode reward: [(0, '323.613')]
[36m[2025-06-29 16:26:25,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1384448. Throughput: 0: 76.8. Samples: 1386160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:26:25,981][60274] Avg episode reward: [(0, '322.692')]
[36m[2025-06-29 16:26:30,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1384448. Throughput: 0: 76.2. Samples: 1386628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:26:30,980][60274] Avg episode reward: [(0, '334.745')]
[36m[2025-06-29 16:26:35,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1384448. Throughput: 0: 76.2. Samples: 1386852. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:26:35,946][60274] Avg episode reward: [(0, '341.735')]
[36m[2025-06-29 16:26:40,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1384448. Throughput: 0: 76.5. Samples: 1387324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:26:40,984][60274] Avg episode reward: [(0, '343.049')]
[36m[2025-06-29 16:26:45,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1384448. Throughput: 0: 77.1. Samples: 1387816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:26:45,954][60274] Avg episode reward: [(0, '355.497')]
[36m[2025-06-29 16:26:50,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1384448. Throughput: 0: 78.5. Samples: 1388060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:26:50,966][60274] Avg episode reward: [(0, '346.131')]
[36m[2025-06-29 16:26:55,982][60274] Fps is (10 sec: 408.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1388544. Throughput: 0: 78.3. Samples: 1388520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:26:55,982][60274] Avg episode reward: [(0, '347.138')]
[36m[2025-06-29 16:27:00,975][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1388544. Throughput: 0: 78.0. Samples: 1388944. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:00,975][60274] Avg episode reward: [(0, '345.819')]
[37m[1m[2025-06-29 16:27:01,023][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005424_1388544.pth...
[36m[2025-06-29 16:27:01,079][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005344_1368064.pth
[36m[2025-06-29 16:27:05,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1388544. Throughput: 0: 77.4. Samples: 1389168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:05,955][60274] Avg episode reward: [(0, '343.839')]
[36m[2025-06-29 16:27:10,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1388544. Throughput: 0: 77.4. Samples: 1389644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:10,988][60274] Avg episode reward: [(0, '357.442')]
[36m[2025-06-29 16:27:15,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1388544. Throughput: 0: 76.6. Samples: 1390076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:15,986][60274] Avg episode reward: [(0, '362.715')]
[36m[2025-06-29 16:27:20,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1388544. Throughput: 0: 75.9. Samples: 1390268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:20,958][60274] Avg episode reward: [(0, '372.867')]
[37m[1m[2025-06-29 16:27:21,005][60274] Saving new best policy, reward=372.867!
[36m[2025-06-29 16:27:25,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1388544. Throughput: 0: 73.8. Samples: 1390644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:25,977][60274] Avg episode reward: [(0, '369.002')]
[36m[2025-06-29 16:27:30,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1388544. Throughput: 0: 71.3. Samples: 1391028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:30,988][60274] Avg episode reward: [(0, '346.834')]
[36m[2025-06-29 16:27:35,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1388544. Throughput: 0: 70.6. Samples: 1391236. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:35,969][60274] Avg episode reward: [(0, '348.951')]
[36m[2025-06-29 16:27:40,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1388544. Throughput: 0: 69.7. Samples: 1391652. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:40,950][60274] Avg episode reward: [(0, '340.017')]
[36m[2025-06-29 16:27:45,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1388544. Throughput: 0: 70.5. Samples: 1392116. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:45,981][60274] Avg episode reward: [(0, '331.492')]
[36m[2025-06-29 16:27:50,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1388544. Throughput: 0: 70.3. Samples: 1392332. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:50,948][60274] Avg episode reward: [(0, '329.673')]
[36m[2025-06-29 16:27:55,962][60274] Fps is (10 sec: 410.4, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1392640. Throughput: 0: 68.4. Samples: 1392720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:27:55,963][60274] Avg episode reward: [(0, '321.587')]
[36m[2025-06-29 16:28:00,985][60274] Fps is (10 sec: 408.1, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1392640. Throughput: 0: 68.7. Samples: 1393168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:00,985][60274] Avg episode reward: [(0, '329.788')]
[36m[2025-06-29 16:28:05,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1392640. Throughput: 0: 69.6. Samples: 1393400. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:05,973][60274] Avg episode reward: [(0, '334.207')]
[36m[2025-06-29 16:28:10,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1392640. Throughput: 0: 68.5. Samples: 1393728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:10,981][60274] Avg episode reward: [(0, '333.730')]
[36m[2025-06-29 16:28:15,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1392640. Throughput: 0: 69.0. Samples: 1394132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:15,961][60274] Avg episode reward: [(0, '319.343')]
[36m[2025-06-29 16:28:20,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1392640. Throughput: 0: 68.2. Samples: 1394308. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:20,991][60274] Avg episode reward: [(0, '309.809')]
[36m[2025-06-29 16:28:25,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1392640. Throughput: 0: 67.4. Samples: 1394688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:25,976][60274] Avg episode reward: [(0, '311.917')]
[36m[2025-06-29 16:28:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1392640. Throughput: 0: 64.9. Samples: 1395036. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:30,989][60274] Avg episode reward: [(0, '317.511')]
[36m[2025-06-29 16:28:35,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1392640. Throughput: 0: 64.4. Samples: 1395232. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:35,950][60274] Avg episode reward: [(0, '317.128')]
[36m[2025-06-29 16:28:40,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1392640. Throughput: 0: 64.4. Samples: 1395620. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:40,976][60274] Avg episode reward: [(0, '311.635')]
[36m[2025-06-29 16:28:45,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1392640. Throughput: 0: 64.1. Samples: 1396052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:45,994][60274] Avg episode reward: [(0, '315.745')]
[36m[2025-06-29 16:28:50,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1392640. Throughput: 0: 63.4. Samples: 1396252. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:28:50,987][60274] Avg episode reward: [(0, '308.659')]
[36m[2025-06-29 16:28:55,995][60274] Fps is (10 sec: 409.5, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1396736. Throughput: 0: 66.0. Samples: 1396700. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:28:55,996][60274] Avg episode reward: [(0, '304.285')]
[36m[2025-06-29 16:29:01,004][60274] Fps is (10 sec: 408.9, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1396736. Throughput: 0: 65.4. Samples: 1397076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:29:01,004][60274] Avg episode reward: [(0, '313.354')]
[37m[1m[2025-06-29 16:29:01,060][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005456_1396736.pth...
[36m[2025-06-29 16:29:01,120][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005376_1376256.pth
[36m[2025-06-29 16:29:05,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1396736. Throughput: 0: 66.6. Samples: 1397304. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:29:05,970][60274] Avg episode reward: [(0, '306.336')]
[36m[2025-06-29 16:29:10,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1396736. Throughput: 0: 69.3. Samples: 1397808. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:29:10,969][60274] Avg episode reward: [(0, '313.888')]
[36m[2025-06-29 16:29:15,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1396736. Throughput: 0: 73.0. Samples: 1398320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:29:15,976][60274] Avg episode reward: [(0, '321.467')]
[36m[2025-06-29 16:29:20,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1396736. Throughput: 0: 74.2. Samples: 1398572. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:29:20,958][60274] Avg episode reward: [(0, '305.109')]
[36m[2025-06-29 16:29:25,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1396736. Throughput: 0: 76.4. Samples: 1399056. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:29:25,959][60274] Avg episode reward: [(0, '298.113')]
[36m[2025-06-29 16:29:30,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1396736. Throughput: 0: 77.9. Samples: 1399556. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:29:30,991][60274] Avg episode reward: [(0, '310.008')]
[36m[2025-06-29 16:29:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1396736. Throughput: 0: 79.0. Samples: 1399808. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:29:35,981][60274] Avg episode reward: [(0, '322.635')]
[36m[2025-06-29 16:29:40,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1396736. Throughput: 0: 80.6. Samples: 1400328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:29:40,986][60274] Avg episode reward: [(0, '321.283')]
[36m[2025-06-29 16:29:45,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1396736. Throughput: 0: 81.7. Samples: 1400752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:29:45,996][60274] Avg episode reward: [(0, '319.064')]
[36m[2025-06-29 16:29:50,988][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1400832. Throughput: 0: 80.1. Samples: 1400912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:29:50,988][60274] Avg episode reward: [(0, '335.590')]
[36m[2025-06-29 16:29:55,946][60274] Fps is (10 sec: 411.6, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1400832. Throughput: 0: 80.3. Samples: 1401420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:29:55,947][60274] Avg episode reward: [(0, '333.672')]
[36m[2025-06-29 16:30:00,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1400832. Throughput: 0: 79.8. Samples: 1401912. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:30:00,976][60274] Avg episode reward: [(0, '327.277')]
[36m[2025-06-29 16:30:05,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1400832. Throughput: 0: 79.7. Samples: 1402160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:30:05,954][60274] Avg episode reward: [(0, '324.265')]
[36m[2025-06-29 16:30:10,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1400832. Throughput: 0: 79.8. Samples: 1402648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:30:10,975][60274] Avg episode reward: [(0, '314.155')]
[36m[2025-06-29 16:30:15,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1400832. Throughput: 0: 79.6. Samples: 1403136. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:30:15,958][60274] Avg episode reward: [(0, '334.609')]
[36m[2025-06-29 16:30:20,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1400832. Throughput: 0: 79.4. Samples: 1403380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:30:20,963][60274] Avg episode reward: [(0, '339.411')]
[36m[2025-06-29 16:30:25,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1400832. Throughput: 0: 78.0. Samples: 1403836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:30:25,984][60274] Avg episode reward: [(0, '322.891')]
[36m[2025-06-29 16:30:30,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1400832. Throughput: 0: 79.7. Samples: 1404336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:30:30,955][60274] Avg episode reward: [(0, '330.598')]
[36m[2025-06-29 16:30:35,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1400832. Throughput: 0: 81.2. Samples: 1404564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:30:35,966][60274] Avg episode reward: [(0, '326.508')]
[36m[2025-06-29 16:30:40,960][60274] Fps is (10 sec: 409.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1404928. Throughput: 0: 78.1. Samples: 1404936. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:30:40,961][60274] Avg episode reward: [(0, '333.837')]
[36m[2025-06-29 16:30:45,946][60274] Fps is (10 sec: 410.4, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1404928. Throughput: 0: 76.1. Samples: 1405336. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:30:45,947][60274] Avg episode reward: [(0, '335.314')]
[36m[2025-06-29 16:30:50,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1404928. Throughput: 0: 75.7. Samples: 1405568. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:30:50,951][60274] Avg episode reward: [(0, '343.428')]
[36m[2025-06-29 16:30:55,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1404928. Throughput: 0: 75.1. Samples: 1406028. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:30:55,989][60274] Avg episode reward: [(0, '350.374')]
[36m[2025-06-29 16:31:00,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1404928. Throughput: 0: 73.9. Samples: 1406464. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:31:00,979][60274] Avg episode reward: [(0, '348.009')]
[37m[1m[2025-06-29 16:31:01,033][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005488_1404928.pth...
[36m[2025-06-29 16:31:01,095][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005424_1388544.pth
[36m[2025-06-29 16:31:05,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1404928. Throughput: 0: 72.9. Samples: 1406664. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:31:05,993][60274] Avg episode reward: [(0, '338.607')]
[36m[2025-06-29 16:31:10,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1404928. Throughput: 0: 72.7. Samples: 1407108. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:31:10,977][60274] Avg episode reward: [(0, '332.179')]
[36m[2025-06-29 16:31:15,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1404928. Throughput: 0: 71.9. Samples: 1407572. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:31:15,960][60274] Avg episode reward: [(0, '330.811')]
[36m[2025-06-29 16:31:20,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1404928. Throughput: 0: 72.0. Samples: 1407804. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:31:20,968][60274] Avg episode reward: [(0, '344.522')]
[36m[2025-06-29 16:31:25,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1404928. Throughput: 0: 73.2. Samples: 1408232. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:31:25,959][60274] Avg episode reward: [(0, '342.703')]
[36m[2025-06-29 16:31:30,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1404928. Throughput: 0: 74.0. Samples: 1408668. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:31:30,999][60274] Avg episode reward: [(0, '344.247')]
[36m[2025-06-29 16:31:35,959][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1409024. Throughput: 0: 73.9. Samples: 1408896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:31:35,960][60274] Avg episode reward: [(0, '335.908')]
[36m[2025-06-29 16:31:40,962][60274] Fps is (10 sec: 411.1, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1409024. Throughput: 0: 72.3. Samples: 1409280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:31:40,963][60274] Avg episode reward: [(0, '340.370')]
[36m[2025-06-29 16:31:46,012][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1409024. Throughput: 0: 73.0. Samples: 1409752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:31:46,013][60274] Avg episode reward: [(0, '347.604')]
[36m[2025-06-29 16:31:50,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1409024. Throughput: 0: 73.3. Samples: 1409960. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:31:50,949][60274] Avg episode reward: [(0, '345.798')]
[36m[2025-06-29 16:31:55,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1409024. Throughput: 0: 72.9. Samples: 1410388. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:31:55,984][60274] Avg episode reward: [(0, '345.571')]
[36m[2025-06-29 16:32:00,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1409024. Throughput: 0: 73.0. Samples: 1410856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:00,948][60274] Avg episode reward: [(0, '353.751')]
[36m[2025-06-29 16:32:05,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1409024. Throughput: 0: 72.9. Samples: 1411088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:05,994][60274] Avg episode reward: [(0, '357.386')]
[36m[2025-06-29 16:32:10,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1409024. Throughput: 0: 74.1. Samples: 1411568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:10,970][60274] Avg episode reward: [(0, '362.574')]
[36m[2025-06-29 16:32:15,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1409024. Throughput: 0: 74.7. Samples: 1412028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:15,949][60274] Avg episode reward: [(0, '354.794')]
[36m[2025-06-29 16:32:20,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1409024. Throughput: 0: 74.7. Samples: 1412260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:20,984][60274] Avg episode reward: [(0, '355.623')]
[36m[2025-06-29 16:32:26,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1409024. Throughput: 0: 76.6. Samples: 1412728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:26,003][60274] Avg episode reward: [(0, '353.431')]
[36m[2025-06-29 16:32:30,952][60274] Fps is (10 sec: 410.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1413120. Throughput: 0: 75.1. Samples: 1413128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:30,953][60274] Avg episode reward: [(0, '349.281')]
[36m[2025-06-29 16:32:35,966][60274] Fps is (10 sec: 411.1, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1413120. Throughput: 0: 73.5. Samples: 1413268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:35,967][60274] Avg episode reward: [(0, '348.652')]
[36m[2025-06-29 16:32:40,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1413120. Throughput: 0: 70.9. Samples: 1413576. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:40,975][60274] Avg episode reward: [(0, '344.849')]
[36m[2025-06-29 16:32:46,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1413120. Throughput: 0: 67.0. Samples: 1413876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:46,008][60274] Avg episode reward: [(0, '338.553')]
[36m[2025-06-29 16:32:50,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 65.4. Samples: 1414028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:50,967][60274] Avg episode reward: [(0, '338.011')]
[36m[2025-06-29 16:32:56,049][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 60.9. Samples: 1414312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:32:56,050][60274] Avg episode reward: [(0, '323.349')]
[31m[18001927 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[18001927 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[18001927 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 16:33:00,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 56.9. Samples: 1414588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:33:00,974][60274] Avg episode reward: [(0, '318.991')]
[37m[1m[2025-06-29 16:33:01,094][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005520_1413120.pth...
[36m[2025-06-29 16:33:01,174][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005456_1396736.pth
[36m[2025-06-29 16:33:06,046][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 54.7. Samples: 1414724. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:33:06,047][60274] Avg episode reward: [(0, '324.634')]
[36m[2025-06-29 16:33:10,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 51.1. Samples: 1415028. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:33:10,975][60274] Avg episode reward: [(0, '328.242')]
[36m[2025-06-29 16:33:16,034][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 49.3. Samples: 1415352. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:33:16,035][60274] Avg episode reward: [(0, '328.242')]
[36m[2025-06-29 16:33:21,007][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 49.6. Samples: 1415500. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:33:21,008][60274] Avg episode reward: [(0, '334.095')]
[36m[2025-06-29 16:33:25,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 51.1. Samples: 1415876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:33:25,992][60274] Avg episode reward: [(0, '332.846')]
[36m[2025-06-29 16:33:30,960][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 52.1. Samples: 1416220. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:33:30,961][60274] Avg episode reward: [(0, '330.594')]
[36m[2025-06-29 16:33:35,977][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 52.9. Samples: 1416408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:33:35,977][60274] Avg episode reward: [(0, '329.658')]
[36m[2025-06-29 16:33:41,011][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 55.2. Samples: 1416796. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:33:41,012][60274] Avg episode reward: [(0, '331.445')]
[36m[2025-06-29 16:33:46,012][60274] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 69.4). Total num frames: 1413120. Throughput: 0: 57.3. Samples: 1417168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:33:46,012][60274] Avg episode reward: [(0, '337.439')]
[36m[2025-06-29 16:33:50,978][60274] Fps is (10 sec: 411.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 58.0. Samples: 1417328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:33:50,978][60274] Avg episode reward: [(0, '337.448')]
[36m[2025-06-29 16:33:55,974][60274] Fps is (10 sec: 411.1, 60 sec: 68.4, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 58.5. Samples: 1417660. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:33:55,975][60274] Avg episode reward: [(0, '340.029')]
[36m[2025-06-29 16:34:01,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 58.7. Samples: 1417992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:34:01,003][60274] Avg episode reward: [(0, '350.339')]
[36m[2025-06-29 16:34:05,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.4, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 60.1. Samples: 1418200. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:34:05,964][60274] Avg episode reward: [(0, '339.524')]
[36m[2025-06-29 16:34:11,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 60.1. Samples: 1418580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:34:11,004][60274] Avg episode reward: [(0, '340.145')]
[36m[2025-06-29 16:34:15,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 61.3. Samples: 1418980. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:34:15,980][60274] Avg episode reward: [(0, '341.430')]
[36m[2025-06-29 16:34:21,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 61.4. Samples: 1419172. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:34:21,006][60274] Avg episode reward: [(0, '341.261')]
[36m[2025-06-29 16:34:25,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 63.5. Samples: 1419648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:34:25,957][60274] Avg episode reward: [(0, '345.072')]
[36m[2025-06-29 16:34:30,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 65.4. Samples: 1420108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:34:30,978][60274] Avg episode reward: [(0, '345.468')]
[36m[2025-06-29 16:34:35,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 66.7. Samples: 1420328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:34:35,957][60274] Avg episode reward: [(0, '351.346')]
[36m[2025-06-29 16:34:41,028][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1417216. Throughput: 0: 69.0. Samples: 1420768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:34:41,029][60274] Avg episode reward: [(0, '352.914')]
[36m[2025-06-29 16:34:45,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1417216. Throughput: 0: 71.9. Samples: 1421224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:34:45,955][60274] Avg episode reward: [(0, '352.790')]
[36m[2025-06-29 16:34:50,947][60274] Fps is (10 sec: 413.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1421312. Throughput: 0: 71.2. Samples: 1421404. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 16:34:50,948][60274] Avg episode reward: [(0, '350.949')]
[36m[2025-06-29 16:34:55,972][60274] Fps is (10 sec: 408.9, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1421312. Throughput: 0: 73.0. Samples: 1421864. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 16:34:55,972][60274] Avg episode reward: [(0, '354.064')]
[36m[2025-06-29 16:35:00,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1421312. Throughput: 0: 73.8. Samples: 1422300. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 16:35:00,968][60274] Avg episode reward: [(0, '355.254')]
[37m[1m[2025-06-29 16:35:01,017][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005552_1421312.pth...
[36m[2025-06-29 16:35:01,075][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005488_1404928.pth
[36m[2025-06-29 16:35:05,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1421312. Throughput: 0: 74.0. Samples: 1422500. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 16:35:05,951][60274] Avg episode reward: [(0, '354.443')]
[36m[2025-06-29 16:35:10,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1421312. Throughput: 0: 73.4. Samples: 1422952. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 16:35:10,976][60274] Avg episode reward: [(0, '357.383')]
[36m[2025-06-29 16:35:15,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1421312. Throughput: 0: 73.8. Samples: 1423428. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 16:35:15,978][60274] Avg episode reward: [(0, '348.990')]
[36m[2025-06-29 16:35:20,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1421312. Throughput: 0: 74.1. Samples: 1423664. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 16:35:20,961][60274] Avg episode reward: [(0, '363.916')]
[36m[2025-06-29 16:35:25,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1421312. Throughput: 0: 74.9. Samples: 1424132. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 16:35:25,951][60274] Avg episode reward: [(0, '365.377')]
[36m[2025-06-29 16:35:30,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1421312. Throughput: 0: 74.3. Samples: 1424568. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 16:35:30,955][60274] Avg episode reward: [(0, '357.647')]
[36m[2025-06-29 16:35:35,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1421312. Throughput: 0: 75.6. Samples: 1424808. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-06-29 16:35:35,956][60274] Avg episode reward: [(0, '358.716')]
[36m[2025-06-29 16:35:41,154][60274] Fps is (10 sec: 401.6, 60 sec: 136.2, 300 sec: 69.4). Total num frames: 1425408. Throughput: 0: 76.3. Samples: 1425312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:35:41,154][60274] Avg episode reward: [(0, '341.626')]
[36m[2025-06-29 16:35:45,979][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 69.4). Total num frames: 1425408. Throughput: 0: 76.8. Samples: 1425756. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:35:45,979][60274] Avg episode reward: [(0, '343.656')]
[36m[2025-06-29 16:35:50,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1425408. Throughput: 0: 77.6. Samples: 1425992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:35:50,948][60274] Avg episode reward: [(0, '337.341')]
[36m[2025-06-29 16:35:55,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1425408. Throughput: 0: 78.3. Samples: 1426472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:35:55,950][60274] Avg episode reward: [(0, '323.292')]
[36m[2025-06-29 16:36:00,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1425408. Throughput: 0: 77.8. Samples: 1426928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:36:00,982][60274] Avg episode reward: [(0, '324.343')]
[36m[2025-06-29 16:36:05,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1425408. Throughput: 0: 77.7. Samples: 1427164. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:36:05,990][60274] Avg episode reward: [(0, '314.244')]
[36m[2025-06-29 16:36:10,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1425408. Throughput: 0: 77.4. Samples: 1427616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:36:10,952][60274] Avg episode reward: [(0, '320.911')]
[36m[2025-06-29 16:36:15,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1425408. Throughput: 0: 77.8. Samples: 1428072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:36:15,968][60274] Avg episode reward: [(0, '321.025')]
[36m[2025-06-29 16:36:20,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1425408. Throughput: 0: 77.5. Samples: 1428296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:36:20,986][60274] Avg episode reward: [(0, '315.938')]
[36m[2025-06-29 16:36:25,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1425408. Throughput: 0: 76.7. Samples: 1428748. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:36:25,961][60274] Avg episode reward: [(0, '306.637')]
[36m[2025-06-29 16:36:30,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 55.5). Total num frames: 1425408. Throughput: 0: 77.1. Samples: 1429224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:36:30,948][60274] Avg episode reward: [(0, '287.495')]
[36m[2025-06-29 16:36:35,997][60274] Fps is (10 sec: 408.1, 60 sec: 136.4, 300 sec: 69.4). Total num frames: 1429504. Throughput: 0: 77.5. Samples: 1429484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:36:35,997][60274] Avg episode reward: [(0, '281.777')]
[36m[2025-06-29 16:36:40,996][60274] Fps is (10 sec: 407.7, 60 sec: 68.4, 300 sec: 69.4). Total num frames: 1429504. Throughput: 0: 76.5. Samples: 1429916. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:36:40,996][60274] Avg episode reward: [(0, '291.999')]
[36m[2025-06-29 16:36:45,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1429504. Throughput: 0: 77.5. Samples: 1430412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:36:45,958][60274] Avg episode reward: [(0, '297.142')]
[36m[2025-06-29 16:36:50,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1429504. Throughput: 0: 77.6. Samples: 1430656. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:36:50,969][60274] Avg episode reward: [(0, '305.555')]
[36m[2025-06-29 16:36:55,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1429504. Throughput: 0: 79.0. Samples: 1431172. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:36:55,981][60274] Avg episode reward: [(0, '300.659')]
[36m[2025-06-29 16:37:00,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1429504. Throughput: 0: 80.1. Samples: 1431676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:37:00,983][60274] Avg episode reward: [(0, '301.122')]
[37m[1m[2025-06-29 16:37:01,032][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005584_1429504.pth...
[36m[2025-06-29 16:37:01,088][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005520_1413120.pth
[36m[2025-06-29 16:37:05,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1429504. Throughput: 0: 80.0. Samples: 1431896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:37:05,968][60274] Avg episode reward: [(0, '285.536')]
[36m[2025-06-29 16:37:10,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1429504. Throughput: 0: 81.3. Samples: 1432408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:37:10,952][60274] Avg episode reward: [(0, '288.366')]
[36m[2025-06-29 16:37:15,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1429504. Throughput: 0: 81.2. Samples: 1432880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:37:15,959][60274] Avg episode reward: [(0, '285.927')]
[36m[2025-06-29 16:37:20,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1429504. Throughput: 0: 80.9. Samples: 1433120. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:37:20,949][60274] Avg episode reward: [(0, '296.112')]
[36m[2025-06-29 16:37:25,970][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 82.0. Samples: 1433604. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:37:25,971][60274] Avg episode reward: [(0, '295.483')]
[36m[2025-06-29 16:37:30,977][60274] Fps is (10 sec: 408.4, 60 sec: 136.5, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 79.7. Samples: 1434000. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:37:30,978][60274] Avg episode reward: [(0, '294.251')]
[36m[2025-06-29 16:37:35,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 79.6. Samples: 1434240. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:37:35,983][60274] Avg episode reward: [(0, '294.252')]
[36m[2025-06-29 16:37:40,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 79.2. Samples: 1434736. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:37:40,975][60274] Avg episode reward: [(0, '300.303')]
[36m[2025-06-29 16:37:45,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 79.2. Samples: 1435236. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:37:45,959][60274] Avg episode reward: [(0, '291.150')]
[36m[2025-06-29 16:37:50,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 79.3. Samples: 1435464. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:37:50,965][60274] Avg episode reward: [(0, '297.264')]
[36m[2025-06-29 16:37:55,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 78.7. Samples: 1435952. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:37:55,992][60274] Avg episode reward: [(0, '299.001')]
[36m[2025-06-29 16:38:00,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 78.4. Samples: 1436408. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:38:00,986][60274] Avg episode reward: [(0, '285.136')]
[36m[2025-06-29 16:38:05,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 78.4. Samples: 1436648. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:38:05,966][60274] Avg episode reward: [(0, '278.575')]
[36m[2025-06-29 16:38:10,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 78.6. Samples: 1437140. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:38:10,953][60274] Avg episode reward: [(0, '283.862')]
[36m[2025-06-29 16:38:15,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1433600. Throughput: 0: 79.9. Samples: 1437592. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:38:15,957][60274] Avg episode reward: [(0, '282.809')]
[36m[2025-06-29 16:38:20,992][60274] Fps is (10 sec: 408.0, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1437696. Throughput: 0: 78.5. Samples: 1437772. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:38:20,992][60274] Avg episode reward: [(0, '300.787')]
[36m[2025-06-29 16:38:26,007][60274] Fps is (10 sec: 407.5, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1437696. Throughput: 0: 78.4. Samples: 1438268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:38:26,008][60274] Avg episode reward: [(0, '307.584')]
[36m[2025-06-29 16:38:30,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1437696. Throughput: 0: 77.7. Samples: 1438732. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:38:30,951][60274] Avg episode reward: [(0, '303.194')]
[36m[2025-06-29 16:38:35,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1437696. Throughput: 0: 77.7. Samples: 1438964. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:38:35,991][60274] Avg episode reward: [(0, '285.681')]
[31m[18345035 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[18345035 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[18345035 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 16:38:40,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1437696. Throughput: 0: 77.1. Samples: 1439420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:38:40,948][60274] Avg episode reward: [(0, '273.601')]
[36m[2025-06-29 16:38:45,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1437696. Throughput: 0: 76.3. Samples: 1439840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:38:45,983][60274] Avg episode reward: [(0, '274.255')]
[36m[2025-06-29 16:38:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1437696. Throughput: 0: 75.7. Samples: 1440056. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:38:50,977][60274] Avg episode reward: [(0, '291.927')]
[36m[2025-06-29 16:38:55,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1437696. Throughput: 0: 73.3. Samples: 1440440. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:38:55,984][60274] Avg episode reward: [(0, '295.679')]
[36m[2025-06-29 16:39:00,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1437696. Throughput: 0: 73.1. Samples: 1440884. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:00,981][60274] Avg episode reward: [(0, '308.280')]
[37m[1m[2025-06-29 16:39:01,052][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005616_1437696.pth...
[36m[2025-06-29 16:39:01,111][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005552_1421312.pth
[36m[2025-06-29 16:39:05,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1437696. Throughput: 0: 73.6. Samples: 1441084. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:05,972][60274] Avg episode reward: [(0, '308.396')]
[36m[2025-06-29 16:39:10,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1437696. Throughput: 0: 72.6. Samples: 1441532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:10,968][60274] Avg episode reward: [(0, '306.926')]
[36m[2025-06-29 16:39:15,951][60274] Fps is (10 sec: 410.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1441792. Throughput: 0: 70.9. Samples: 1441924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:15,951][60274] Avg episode reward: [(0, '320.515')]
[36m[2025-06-29 16:39:20,951][60274] Fps is (10 sec: 410.3, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1441792. Throughput: 0: 70.9. Samples: 1442152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:20,952][60274] Avg episode reward: [(0, '308.050')]
[36m[2025-06-29 16:39:25,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1441792. Throughput: 0: 71.0. Samples: 1442616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:25,979][60274] Avg episode reward: [(0, '316.615')]
[36m[2025-06-29 16:39:30,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1441792. Throughput: 0: 71.4. Samples: 1443052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:30,994][60274] Avg episode reward: [(0, '326.287')]
[36m[2025-06-29 16:39:35,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1441792. Throughput: 0: 71.5. Samples: 1443276. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:35,981][60274] Avg episode reward: [(0, '317.219')]
[36m[2025-06-29 16:39:41,001][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1441792. Throughput: 0: 72.8. Samples: 1443716. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:41,001][60274] Avg episode reward: [(0, '318.343')]
[36m[2025-06-29 16:39:45,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1441792. Throughput: 0: 72.9. Samples: 1444160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:45,950][60274] Avg episode reward: [(0, '318.914')]
[36m[2025-06-29 16:39:50,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1441792. Throughput: 0: 73.4. Samples: 1444384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:50,956][60274] Avg episode reward: [(0, '306.883')]
[36m[2025-06-29 16:39:55,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1441792. Throughput: 0: 74.3. Samples: 1444876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:39:55,975][60274] Avg episode reward: [(0, '317.879')]
[36m[2025-06-29 16:40:00,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1441792. Throughput: 0: 76.2. Samples: 1445352. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:00,952][60274] Avg episode reward: [(0, '309.254')]
[36m[2025-06-29 16:40:05,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1441792. Throughput: 0: 76.1. Samples: 1445576. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:05,962][60274] Avg episode reward: [(0, '322.649')]
[36m[2025-06-29 16:40:10,960][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1445888. Throughput: 0: 75.2. Samples: 1446000. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:10,960][60274] Avg episode reward: [(0, '319.597')]
[36m[2025-06-29 16:40:15,971][60274] Fps is (10 sec: 409.2, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1445888. Throughput: 0: 76.4. Samples: 1446488. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:15,971][60274] Avg episode reward: [(0, '326.500')]
[36m[2025-06-29 16:40:20,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1445888. Throughput: 0: 76.3. Samples: 1446708. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:20,960][60274] Avg episode reward: [(0, '313.407')]
[36m[2025-06-29 16:40:25,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1445888. Throughput: 0: 76.8. Samples: 1447168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:25,957][60274] Avg episode reward: [(0, '318.760')]
[36m[2025-06-29 16:40:30,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1445888. Throughput: 0: 77.0. Samples: 1447624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:30,951][60274] Avg episode reward: [(0, '314.312')]
[36m[2025-06-29 16:40:35,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 1445888. Throughput: 0: 77.2. Samples: 1447860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:35,988][60274] Avg episode reward: [(0, '323.474')]
[36m[2025-06-29 16:40:40,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1445888. Throughput: 0: 77.2. Samples: 1448348. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:40,959][60274] Avg episode reward: [(0, '323.201')]
[36m[2025-06-29 16:40:45,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1445888. Throughput: 0: 76.8. Samples: 1448812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:45,983][60274] Avg episode reward: [(0, '309.291')]
[36m[2025-06-29 16:40:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1445888. Throughput: 0: 76.9. Samples: 1449036. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:50,962][60274] Avg episode reward: [(0, '302.695')]
[36m[2025-06-29 16:40:55,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1445888. Throughput: 0: 78.3. Samples: 1449524. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:40:55,947][60274] Avg episode reward: [(0, '301.518')]
[36m[2025-06-29 16:41:00,974][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1449984. Throughput: 0: 77.9. Samples: 1449992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:00,974][60274] Avg episode reward: [(0, '310.999')]
[37m[1m[2025-06-29 16:41:01,020][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005664_1449984.pth...
[36m[2025-06-29 16:41:01,077][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005584_1429504.pth
[36m[2025-06-29 16:41:05,972][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1449984. Throughput: 0: 77.2. Samples: 1450184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:05,972][60274] Avg episode reward: [(0, '302.208')]
[36m[2025-06-29 16:41:10,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1449984. Throughput: 0: 77.9. Samples: 1450676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:10,980][60274] Avg episode reward: [(0, '301.693')]
[36m[2025-06-29 16:41:15,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1449984. Throughput: 0: 78.7. Samples: 1451168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:15,990][60274] Avg episode reward: [(0, '312.745')]
[36m[2025-06-29 16:41:20,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1449984. Throughput: 0: 79.0. Samples: 1451412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:20,977][60274] Avg episode reward: [(0, '314.121')]
[36m[2025-06-29 16:41:25,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1449984. Throughput: 0: 79.4. Samples: 1451920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:25,958][60274] Avg episode reward: [(0, '313.050')]
[36m[2025-06-29 16:41:30,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1449984. Throughput: 0: 79.7. Samples: 1452396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:30,952][60274] Avg episode reward: [(0, '327.725')]
[36m[2025-06-29 16:41:35,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1449984. Throughput: 0: 79.6. Samples: 1452620. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:35,973][60274] Avg episode reward: [(0, '328.230')]
[36m[2025-06-29 16:41:40,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1449984. Throughput: 0: 79.7. Samples: 1453112. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:40,959][60274] Avg episode reward: [(0, '333.838')]
[36m[2025-06-29 16:41:45,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1449984. Throughput: 0: 80.1. Samples: 1453596. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:45,975][60274] Avg episode reward: [(0, '332.839')]
[36m[2025-06-29 16:41:50,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1449984. Throughput: 0: 81.0. Samples: 1453832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:41:50,989][60274] Avg episode reward: [(0, '344.211')]
[36m[2025-06-29 16:41:55,950][60274] Fps is (10 sec: 410.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1454080. Throughput: 0: 79.4. Samples: 1454248. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:41:55,950][60274] Avg episode reward: [(0, '353.395')]
[36m[2025-06-29 16:42:00,962][60274] Fps is (10 sec: 410.7, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1454080. Throughput: 0: 78.8. Samples: 1454712. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:42:00,962][60274] Avg episode reward: [(0, '337.139')]
[36m[2025-06-29 16:42:05,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1454080. Throughput: 0: 78.6. Samples: 1454948. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:42:05,967][60274] Avg episode reward: [(0, '340.446')]
[36m[2025-06-29 16:42:11,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1454080. Throughput: 0: 78.0. Samples: 1455432. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:42:11,003][60274] Avg episode reward: [(0, '348.015')]
[36m[2025-06-29 16:42:15,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1454080. Throughput: 0: 77.8. Samples: 1455900. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:42:15,972][60274] Avg episode reward: [(0, '343.988')]
[36m[2025-06-29 16:42:21,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1454080. Throughput: 0: 78.2. Samples: 1456140. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:42:21,005][60274] Avg episode reward: [(0, '344.153')]
[36m[2025-06-29 16:42:25,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1454080. Throughput: 0: 77.5. Samples: 1456600. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:42:25,947][60274] Avg episode reward: [(0, '353.379')]
[36m[2025-06-29 16:42:30,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1454080. Throughput: 0: 77.2. Samples: 1457068. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:42:30,970][60274] Avg episode reward: [(0, '358.937')]
[36m[2025-06-29 16:42:36,006][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1454080. Throughput: 0: 77.3. Samples: 1457312. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:42:36,007][60274] Avg episode reward: [(0, '354.452')]
[36m[2025-06-29 16:42:40,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1454080. Throughput: 0: 78.9. Samples: 1457800. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:42:40,967][60274] Avg episode reward: [(0, '355.963')]
[36m[2025-06-29 16:42:45,973][60274] Fps is (10 sec: 411.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1458176. Throughput: 0: 78.6. Samples: 1458248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:42:45,973][60274] Avg episode reward: [(0, '361.442')]
[36m[2025-06-29 16:42:50,989][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1458176. Throughput: 0: 78.8. Samples: 1458496. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:42:50,990][60274] Avg episode reward: [(0, '372.178')]
[36m[2025-06-29 16:42:55,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1458176. Throughput: 0: 78.9. Samples: 1458980. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:42:55,956][60274] Avg episode reward: [(0, '354.939')]
[36m[2025-06-29 16:43:00,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1458176. Throughput: 0: 79.0. Samples: 1459452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:43:00,949][60274] Avg episode reward: [(0, '348.842')]
[37m[1m[2025-06-29 16:43:00,996][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005696_1458176.pth...
[36m[2025-06-29 16:43:01,059][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005616_1437696.pth
[36m[2025-06-29 16:43:05,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1458176. Throughput: 0: 78.9. Samples: 1459688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:43:05,964][60274] Avg episode reward: [(0, '354.393')]
[36m[2025-06-29 16:43:10,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1458176. Throughput: 0: 78.4. Samples: 1460132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:43:10,975][60274] Avg episode reward: [(0, '340.606')]
[36m[2025-06-29 16:43:15,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1458176. Throughput: 0: 79.2. Samples: 1460632. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:43:15,966][60274] Avg episode reward: [(0, '333.556')]
[36m[2025-06-29 16:43:20,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1458176. Throughput: 0: 79.3. Samples: 1460876. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:43:20,964][60274] Avg episode reward: [(0, '334.024')]
[36m[2025-06-29 16:43:25,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1458176. Throughput: 0: 79.0. Samples: 1461356. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:43:25,975][60274] Avg episode reward: [(0, '322.092')]
[36m[2025-06-29 16:43:30,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1458176. Throughput: 0: 80.1. Samples: 1461852. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:43:30,963][60274] Avg episode reward: [(0, '327.055')]
[36m[2025-06-29 16:43:36,208][60274] Fps is (10 sec: 400.3, 60 sec: 136.1, 300 sec: 83.2). Total num frames: 1462272. Throughput: 0: 79.7. Samples: 1462100. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:43:36,209][60274] Avg episode reward: [(0, '322.474')]
[36m[2025-06-29 16:43:40,973][60274] Fps is (10 sec: 409.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1462272. Throughput: 0: 78.9. Samples: 1462532. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:43:40,973][60274] Avg episode reward: [(0, '315.927')]
[36m[2025-06-29 16:43:45,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1462272. Throughput: 0: 79.5. Samples: 1463032. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:43:45,989][60274] Avg episode reward: [(0, '315.571')]
[36m[2025-06-29 16:43:50,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1462272. Throughput: 0: 79.8. Samples: 1463280. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:43:50,988][60274] Avg episode reward: [(0, '313.588')]
[36m[2025-06-29 16:43:56,020][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1462272. Throughput: 0: 80.5. Samples: 1463756. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:43:56,021][60274] Avg episode reward: [(0, '308.968')]
[36m[2025-06-29 16:44:01,012][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1462272. Throughput: 0: 80.2. Samples: 1464244. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:44:01,013][60274] Avg episode reward: [(0, '302.364')]
[36m[2025-06-29 16:44:05,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1462272. Throughput: 0: 80.6. Samples: 1464504. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:44:05,974][60274] Avg episode reward: [(0, '293.330')]
[36m[2025-06-29 16:44:10,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1462272. Throughput: 0: 80.8. Samples: 1464992. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:44:10,981][60274] Avg episode reward: [(0, '309.532')]
[36m[2025-06-29 16:44:15,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1462272. Throughput: 0: 80.5. Samples: 1465476. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:44:15,992][60274] Avg episode reward: [(0, '287.392')]
[36m[2025-06-29 16:44:20,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1462272. Throughput: 0: 81.1. Samples: 1465728. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:44:20,952][60274] Avg episode reward: [(0, '289.698')]
[36m[2025-06-29 16:44:25,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1462272. Throughput: 0: 82.2. Samples: 1466232. Policy #0 lag: (min: 12.0, avg: 12.0, max: 28.0)
[36m[2025-06-29 16:44:25,978][60274] Avg episode reward: [(0, '286.222')]
[36m[2025-06-29 16:44:30,954][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1466368. Throughput: 0: 80.6. Samples: 1466656. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:44:30,954][60274] Avg episode reward: [(0, '284.106')]
[36m[2025-06-29 16:44:35,962][60274] Fps is (10 sec: 410.3, 60 sec: 68.5, 300 sec: 83.3). Total num frames: 1466368. Throughput: 0: 80.7. Samples: 1466908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:44:35,962][60274] Avg episode reward: [(0, '283.766')]
[36m[2025-06-29 16:44:40,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1466368. Throughput: 0: 80.8. Samples: 1467388. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:44:40,955][60274] Avg episode reward: [(0, '276.227')]
[36m[2025-06-29 16:44:46,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1466368. Throughput: 0: 80.5. Samples: 1467868. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:44:46,005][60274] Avg episode reward: [(0, '283.842')]
[36m[2025-06-29 16:44:50,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1466368. Throughput: 0: 79.9. Samples: 1468100. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:44:50,985][60274] Avg episode reward: [(0, '298.427')]
[36m[2025-06-29 16:44:55,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1466368. Throughput: 0: 80.0. Samples: 1468592. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:44:55,987][60274] Avg episode reward: [(0, '298.910')]
[36m[2025-06-29 16:45:00,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1466368. Throughput: 0: 79.9. Samples: 1469072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:45:00,988][60274] Avg episode reward: [(0, '308.377')]
[37m[1m[2025-06-29 16:45:01,037][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005728_1466368.pth...
[36m[2025-06-29 16:45:01,093][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005664_1449984.pth
[36m[2025-06-29 16:45:05,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1466368. Throughput: 0: 79.6. Samples: 1469312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:45:05,952][60274] Avg episode reward: [(0, '313.131')]
[36m[2025-06-29 16:45:10,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1466368. Throughput: 0: 78.9. Samples: 1469784. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:45:10,992][60274] Avg episode reward: [(0, '309.026')]
[36m[2025-06-29 16:45:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1466368. Throughput: 0: 80.2. Samples: 1470264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:45:15,952][60274] Avg episode reward: [(0, '305.900')]
[36m[2025-06-29 16:45:20,950][60274] Fps is (10 sec: 411.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1470464. Throughput: 0: 79.2. Samples: 1470472. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 16:45:20,950][60274] Avg episode reward: [(0, '305.589')]
[36m[2025-06-29 16:45:25,976][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1470464. Throughput: 0: 79.3. Samples: 1470960. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 16:45:25,976][60274] Avg episode reward: [(0, '303.303')]
[36m[2025-06-29 16:45:30,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1470464. Throughput: 0: 79.4. Samples: 1471440. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 16:45:30,965][60274] Avg episode reward: [(0, '317.528')]
[36m[2025-06-29 16:45:35,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1470464. Throughput: 0: 79.4. Samples: 1471672. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 16:45:35,952][60274] Avg episode reward: [(0, '309.208')]
[36m[2025-06-29 16:45:40,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1470464. Throughput: 0: 79.6. Samples: 1472172. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 16:45:40,981][60274] Avg episode reward: [(0, '319.878')]
[36m[2025-06-29 16:45:45,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1470464. Throughput: 0: 80.1. Samples: 1472672. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 16:45:45,954][60274] Avg episode reward: [(0, '321.227')]
[36m[2025-06-29 16:45:51,009][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1470464. Throughput: 0: 79.9. Samples: 1472912. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 16:45:51,010][60274] Avg episode reward: [(0, '330.669')]
[36m[2025-06-29 16:45:55,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1470464. Throughput: 0: 80.1. Samples: 1473388. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 16:45:55,975][60274] Avg episode reward: [(0, '344.916')]
[36m[2025-06-29 16:46:00,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1470464. Throughput: 0: 80.3. Samples: 1473880. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 16:46:00,979][60274] Avg episode reward: [(0, '344.204')]
[36m[2025-06-29 16:46:05,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1470464. Throughput: 0: 81.4. Samples: 1474136. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[36m[2025-06-29 16:46:05,975][60274] Avg episode reward: [(0, '342.772')]
[36m[2025-06-29 16:46:10,971][60274] Fps is (10 sec: 409.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1474560. Throughput: 0: 80.2. Samples: 1474568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:46:10,971][60274] Avg episode reward: [(0, '353.303')]
[36m[2025-06-29 16:46:15,977][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1474560. Throughput: 0: 80.4. Samples: 1475060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:46:15,978][60274] Avg episode reward: [(0, '360.180')]
[36m[2025-06-29 16:46:20,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1474560. Throughput: 0: 80.5. Samples: 1475296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:46:20,993][60274] Avg episode reward: [(0, '366.909')]
[36m[2025-06-29 16:46:25,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1474560. Throughput: 0: 80.6. Samples: 1475800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:46:25,993][60274] Avg episode reward: [(0, '376.214')]
[37m[1m[2025-06-29 16:46:26,040][60274] Saving new best policy, reward=376.214!
[36m[2025-06-29 16:46:30,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1474560. Throughput: 0: 79.9. Samples: 1476268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:46:30,951][60274] Avg episode reward: [(0, '374.836')]
[36m[2025-06-29 16:46:35,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1474560. Throughput: 0: 80.5. Samples: 1476532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:46:35,957][60274] Avg episode reward: [(0, '366.478')]
[36m[2025-06-29 16:46:40,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1474560. Throughput: 0: 81.0. Samples: 1477032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:46:40,960][60274] Avg episode reward: [(0, '361.993')]
[36m[2025-06-29 16:46:45,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1474560. Throughput: 0: 80.5. Samples: 1477504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:46:45,995][60274] Avg episode reward: [(0, '359.921')]
[36m[2025-06-29 16:46:50,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1474560. Throughput: 0: 80.1. Samples: 1477740. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:46:50,960][60274] Avg episode reward: [(0, '346.093')]
[36m[2025-06-29 16:46:55,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1474560. Throughput: 0: 81.6. Samples: 1478240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:46:55,950][60274] Avg episode reward: [(0, '350.301')]
[36m[2025-06-29 16:47:00,968][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1478656. Throughput: 0: 80.4. Samples: 1478676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:47:00,968][60274] Avg episode reward: [(0, '349.665')]
[37m[1m[2025-06-29 16:47:01,014][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005776_1478656.pth...
[36m[2025-06-29 16:47:01,068][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005696_1458176.pth
[36m[2025-06-29 16:47:05,975][60274] Fps is (10 sec: 408.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1478656. Throughput: 0: 80.6. Samples: 1478920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:47:05,976][60274] Avg episode reward: [(0, '358.766')]
[36m[2025-06-29 16:47:10,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1478656. Throughput: 0: 80.7. Samples: 1479428. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:47:10,953][60274] Avg episode reward: [(0, '363.732')]
[36m[2025-06-29 16:47:15,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1478656. Throughput: 0: 80.4. Samples: 1479884. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:47:15,949][60274] Avg episode reward: [(0, '351.966')]
[36m[2025-06-29 16:47:20,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1478656. Throughput: 0: 80.0. Samples: 1480132. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:47:20,953][60274] Avg episode reward: [(0, '354.909')]
[36m[2025-06-29 16:47:25,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1478656. Throughput: 0: 79.3. Samples: 1480604. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:47:26,000][60274] Avg episode reward: [(0, '351.141')]
[36m[2025-06-29 16:47:30,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1478656. Throughput: 0: 79.7. Samples: 1481088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:47:30,969][60274] Avg episode reward: [(0, '351.954')]
[36m[2025-06-29 16:47:35,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1478656. Throughput: 0: 80.0. Samples: 1481340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:47:35,964][60274] Avg episode reward: [(0, '355.895')]
[36m[2025-06-29 16:47:40,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1478656. Throughput: 0: 79.5. Samples: 1481820. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:47:40,985][60274] Avg episode reward: [(0, '381.107')]
[37m[1m[2025-06-29 16:47:41,032][60274] Saving new best policy, reward=381.107!
[36m[2025-06-29 16:47:45,946][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1478656. Throughput: 0: 81.1. Samples: 1482324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:47:45,947][60274] Avg episode reward: [(0, '371.848')]
[36m[2025-06-29 16:47:51,416][60274] Fps is (10 sec: 392.7, 60 sec: 135.5, 300 sec: 83.2). Total num frames: 1482752. Throughput: 0: 80.2. Samples: 1482564. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:47:51,417][60274] Avg episode reward: [(0, '369.146')]
[36m[2025-06-29 16:47:55,949][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1482752. Throughput: 0: 79.7. Samples: 1483012. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:47:55,949][60274] Avg episode reward: [(0, '371.426')]
[36m[2025-06-29 16:48:00,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1482752. Throughput: 0: 80.2. Samples: 1483492. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:48:00,961][60274] Avg episode reward: [(0, '366.057')]
[36m[2025-06-29 16:48:05,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1482752. Throughput: 0: 79.6. Samples: 1483716. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:48:05,983][60274] Avg episode reward: [(0, '357.540')]
[36m[2025-06-29 16:48:10,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1482752. Throughput: 0: 80.3. Samples: 1484212. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:48:10,948][60274] Avg episode reward: [(0, '349.467')]
[36m[2025-06-29 16:48:15,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1482752. Throughput: 0: 80.0. Samples: 1484688. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:48:15,963][60274] Avg episode reward: [(0, '361.620')]
[36m[2025-06-29 16:48:20,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1482752. Throughput: 0: 79.7. Samples: 1484928. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:48:20,988][60274] Avg episode reward: [(0, '358.645')]
[36m[2025-06-29 16:48:25,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1482752. Throughput: 0: 79.9. Samples: 1485412. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:48:25,965][60274] Avg episode reward: [(0, '357.917')]
[36m[2025-06-29 16:48:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.5). Total num frames: 1482752. Throughput: 0: 79.2. Samples: 1485892. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:48:30,989][60274] Avg episode reward: [(0, '364.555')]
[36m[2025-06-29 16:48:35,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1482752. Throughput: 0: 80.4. Samples: 1486148. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:48:35,983][60274] Avg episode reward: [(0, '354.261')]
[36m[2025-06-29 16:48:40,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1482752. Throughput: 0: 80.6. Samples: 1486644. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:48:40,986][60274] Avg episode reward: [(0, '359.907')]
[36m[2025-06-29 16:48:45,958][60274] Fps is (10 sec: 410.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1486848. Throughput: 0: 79.9. Samples: 1487088. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:48:45,959][60274] Avg episode reward: [(0, '364.783')]
[36m[2025-06-29 16:48:50,969][60274] Fps is (10 sec: 410.3, 60 sec: 68.8, 300 sec: 83.3). Total num frames: 1486848. Throughput: 0: 80.0. Samples: 1487316. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:48:50,969][60274] Avg episode reward: [(0, '357.756')]
[36m[2025-06-29 16:48:55,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1486848. Throughput: 0: 80.2. Samples: 1487824. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:48:55,958][60274] Avg episode reward: [(0, '338.713')]
[36m[2025-06-29 16:49:00,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1486848. Throughput: 0: 79.9. Samples: 1488284. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:49:00,955][60274] Avg episode reward: [(0, '334.839')]
[37m[1m[2025-06-29 16:49:01,004][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005808_1486848.pth...
[36m[2025-06-29 16:49:01,065][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005728_1466368.pth
[36m[2025-06-29 16:49:05,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1486848. Throughput: 0: 79.9. Samples: 1488524. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:49:05,968][60274] Avg episode reward: [(0, '342.397')]
[36m[2025-06-29 16:49:10,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1486848. Throughput: 0: 79.3. Samples: 1488984. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:49:10,985][60274] Avg episode reward: [(0, '337.382')]
[36m[2025-06-29 16:49:15,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1486848. Throughput: 0: 79.5. Samples: 1489468. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:49:15,966][60274] Avg episode reward: [(0, '336.412')]
[36m[2025-06-29 16:49:20,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1486848. Throughput: 0: 79.4. Samples: 1489720. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:49:20,989][60274] Avg episode reward: [(0, '320.289')]
[36m[2025-06-29 16:49:25,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1486848. Throughput: 0: 79.6. Samples: 1490224. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:49:25,959][60274] Avg episode reward: [(0, '306.096')]
[36m[2025-06-29 16:49:30,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1486848. Throughput: 0: 80.1. Samples: 1490692. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:49:30,978][60274] Avg episode reward: [(0, '304.030')]
[36m[2025-06-29 16:49:35,967][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1490944. Throughput: 0: 80.3. Samples: 1490928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:49:35,967][60274] Avg episode reward: [(0, '309.741')]
[36m[2025-06-29 16:49:40,979][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1490944. Throughput: 0: 78.4. Samples: 1491352. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:49:40,980][60274] Avg episode reward: [(0, '314.054')]
[36m[2025-06-29 16:49:45,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1490944. Throughput: 0: 78.8. Samples: 1491832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:49:45,954][60274] Avg episode reward: [(0, '313.566')]
[36m[2025-06-29 16:49:51,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1490944. Throughput: 0: 78.5. Samples: 1492060. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:49:51,000][60274] Avg episode reward: [(0, '322.101')]
[36m[2025-06-29 16:49:55,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1490944. Throughput: 0: 78.7. Samples: 1492524. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:49:55,984][60274] Avg episode reward: [(0, '330.863')]
[36m[2025-06-29 16:50:00,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1490944. Throughput: 0: 78.5. Samples: 1493000. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:00,969][60274] Avg episode reward: [(0, '330.767')]
[36m[2025-06-29 16:50:05,997][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1490944. Throughput: 0: 78.2. Samples: 1493240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:05,997][60274] Avg episode reward: [(0, '335.338')]
[36m[2025-06-29 16:50:10,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1490944. Throughput: 0: 77.9. Samples: 1493728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:10,957][60274] Avg episode reward: [(0, '338.003')]
[36m[2025-06-29 16:50:15,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1490944. Throughput: 0: 78.5. Samples: 1494224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:15,949][60274] Avg episode reward: [(0, '341.610')]
[36m[2025-06-29 16:50:20,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1490944. Throughput: 0: 79.0. Samples: 1494480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:20,949][60274] Avg episode reward: [(0, '346.662')]
[36m[2025-06-29 16:50:26,039][60274] Fps is (10 sec: 405.9, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1495040. Throughput: 0: 79.9. Samples: 1494952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:26,039][60274] Avg episode reward: [(0, '342.414')]
[36m[2025-06-29 16:50:30,962][60274] Fps is (10 sec: 409.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1495040. Throughput: 0: 79.5. Samples: 1495412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:30,963][60274] Avg episode reward: [(0, '351.559')]
[36m[2025-06-29 16:50:35,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1495040. Throughput: 0: 80.3. Samples: 1495668. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:35,954][60274] Avg episode reward: [(0, '349.665')]
[36m[2025-06-29 16:50:40,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1495040. Throughput: 0: 80.8. Samples: 1496160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:40,994][60274] Avg episode reward: [(0, '353.861')]
[36m[2025-06-29 16:50:45,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1495040. Throughput: 0: 81.0. Samples: 1496644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:45,980][60274] Avg episode reward: [(0, '349.545')]
[36m[2025-06-29 16:50:50,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1495040. Throughput: 0: 81.0. Samples: 1496884. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:50,982][60274] Avg episode reward: [(0, '361.693')]
[36m[2025-06-29 16:50:55,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1495040. Throughput: 0: 81.2. Samples: 1497384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:50:55,968][60274] Avg episode reward: [(0, '352.570')]
[36m[2025-06-29 16:51:00,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1495040. Throughput: 0: 81.7. Samples: 1497900. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:51:00,959][60274] Avg episode reward: [(0, '351.879')]
[37m[1m[2025-06-29 16:51:01,007][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005840_1495040.pth...
[36m[2025-06-29 16:51:01,063][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005776_1478656.pth
[36m[2025-06-29 16:51:05,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1495040. Throughput: 0: 81.7. Samples: 1498156. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:51:05,948][60274] Avg episode reward: [(0, '360.021')]
[36m[2025-06-29 16:51:10,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1495040. Throughput: 0: 82.3. Samples: 1498648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:51:10,962][60274] Avg episode reward: [(0, '361.834')]
[36m[2025-06-29 16:51:15,975][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1499136. Throughput: 0: 82.9. Samples: 1499144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:51:15,975][60274] Avg episode reward: [(0, '377.554')]
[36m[2025-06-29 16:51:20,963][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1499136. Throughput: 0: 81.8. Samples: 1499348. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:51:20,963][60274] Avg episode reward: [(0, '372.310')]
[36m[2025-06-29 16:51:25,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1499136. Throughput: 0: 82.1. Samples: 1499852. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:51:25,988][60274] Avg episode reward: [(0, '366.047')]
[36m[2025-06-29 16:51:30,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1499136. Throughput: 0: 82.4. Samples: 1500348. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:51:30,950][60274] Avg episode reward: [(0, '368.940')]
[36m[2025-06-29 16:51:35,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1499136. Throughput: 0: 82.9. Samples: 1500612. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:51:35,951][60274] Avg episode reward: [(0, '372.248')]
[36m[2025-06-29 16:51:40,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1499136. Throughput: 0: 82.7. Samples: 1501108. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:51:40,982][60274] Avg episode reward: [(0, '360.302')]
[36m[2025-06-29 16:51:45,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1499136. Throughput: 0: 82.7. Samples: 1501624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:51:45,965][60274] Avg episode reward: [(0, '347.901')]
[36m[2025-06-29 16:51:50,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1499136. Throughput: 0: 82.4. Samples: 1501868. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:51:50,975][60274] Avg episode reward: [(0, '347.088')]
[36m[2025-06-29 16:51:55,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1499136. Throughput: 0: 82.2. Samples: 1502348. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:51:55,954][60274] Avg episode reward: [(0, '348.982')]
[36m[2025-06-29 16:52:00,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1499136. Throughput: 0: 82.4. Samples: 1502848. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:52:00,953][60274] Avg episode reward: [(0, '334.944')]
[36m[2025-06-29 16:52:05,976][60274] Fps is (10 sec: 408.7, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1503232. Throughput: 0: 83.0. Samples: 1503084. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:52:05,977][60274] Avg episode reward: [(0, '352.215')]
[36m[2025-06-29 16:52:10,972][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1503232. Throughput: 0: 81.5. Samples: 1503516. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:52:10,973][60274] Avg episode reward: [(0, '358.102')]
[36m[2025-06-29 16:52:15,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1503232. Throughput: 0: 81.3. Samples: 1504008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:52:15,980][60274] Avg episode reward: [(0, '358.472')]
[36m[2025-06-29 16:52:20,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1503232. Throughput: 0: 81.0. Samples: 1504256. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:52:20,951][60274] Avg episode reward: [(0, '357.650')]
[36m[2025-06-29 16:52:25,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1503232. Throughput: 0: 81.2. Samples: 1504764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:52:25,982][60274] Avg episode reward: [(0, '364.788')]
[36m[2025-06-29 16:52:30,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1503232. Throughput: 0: 80.5. Samples: 1505248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:52:30,962][60274] Avg episode reward: [(0, '366.629')]
[36m[2025-06-29 16:52:35,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1503232. Throughput: 0: 80.6. Samples: 1505492. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:52:35,952][60274] Avg episode reward: [(0, '359.491')]
[36m[2025-06-29 16:52:40,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1503232. Throughput: 0: 80.5. Samples: 1505972. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:52:40,975][60274] Avg episode reward: [(0, '359.085')]
[36m[2025-06-29 16:52:45,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 1503232. Throughput: 0: 80.7. Samples: 1506480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:52:45,952][60274] Avg episode reward: [(0, '378.707')]
[36m[2025-06-29 16:52:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1503232. Throughput: 0: 80.7. Samples: 1506716. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:52:50,976][60274] Avg episode reward: [(0, '391.102')]
[37m[1m[2025-06-29 16:52:51,022][60274] Saving new best policy, reward=391.102!
[36m[2025-06-29 16:52:56,510][60274] Fps is (10 sec: 388.0, 60 sec: 135.3, 300 sec: 83.2). Total num frames: 1507328. Throughput: 0: 81.1. Samples: 1507208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:52:56,511][60274] Avg episode reward: [(0, '375.289')]
[36m[2025-06-29 16:53:00,952][60274] Fps is (10 sec: 410.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1507328. Throughput: 0: 81.0. Samples: 1507652. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:53:00,953][60274] Avg episode reward: [(0, '381.805')]
[37m[1m[2025-06-29 16:53:01,003][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005888_1507328.pth...
[36m[2025-06-29 16:53:01,063][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005808_1486848.pth
[36m[2025-06-29 16:53:05,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1507328. Throughput: 0: 80.3. Samples: 1507868. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:53:05,955][60274] Avg episode reward: [(0, '378.191')]
[36m[2025-06-29 16:53:10,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1507328. Throughput: 0: 79.4. Samples: 1508336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:53:10,993][60274] Avg episode reward: [(0, '385.395')]
[36m[2025-06-29 16:53:15,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1507328. Throughput: 0: 79.8. Samples: 1508840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:53:15,968][60274] Avg episode reward: [(0, '388.250')]
[36m[2025-06-29 16:53:20,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1507328. Throughput: 0: 80.1. Samples: 1509096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:53:20,973][60274] Avg episode reward: [(0, '385.956')]
[36m[2025-06-29 16:53:25,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1507328. Throughput: 0: 80.3. Samples: 1509584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:53:25,952][60274] Avg episode reward: [(0, '383.057')]
[36m[2025-06-29 16:53:30,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1507328. Throughput: 0: 79.6. Samples: 1510064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:53:30,980][60274] Avg episode reward: [(0, '385.677')]
[36m[2025-06-29 16:53:35,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1507328. Throughput: 0: 80.2. Samples: 1510324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:53:35,977][60274] Avg episode reward: [(0, '388.555')]
[36m[2025-06-29 16:53:40,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1507328. Throughput: 0: 80.9. Samples: 1510808. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:53:40,987][60274] Avg episode reward: [(0, '402.095')]
[37m[1m[2025-06-29 16:53:41,034][60274] Saving new best policy, reward=402.095!
[36m[2025-06-29 16:53:45,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1507328. Throughput: 0: 80.9. Samples: 1511296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:53:45,992][60274] Avg episode reward: [(0, '395.218')]
[36m[2025-06-29 16:53:50,979][60274] Fps is (10 sec: 409.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1511424. Throughput: 0: 80.1. Samples: 1511476. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 16:53:50,979][60274] Avg episode reward: [(0, '397.772')]
[36m[2025-06-29 16:53:55,995][60274] Fps is (10 sec: 409.5, 60 sec: 68.9, 300 sec: 83.3). Total num frames: 1511424. Throughput: 0: 80.8. Samples: 1511972. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 16:53:55,996][60274] Avg episode reward: [(0, '409.213')]
[37m[1m[2025-06-29 16:53:55,998][60274] Saving new best policy, reward=409.213!
[36m[2025-06-29 16:54:00,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1511424. Throughput: 0: 79.9. Samples: 1512436. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 16:54:00,988][60274] Avg episode reward: [(0, '399.973')]
[36m[2025-06-29 16:54:05,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1511424. Throughput: 0: 79.9. Samples: 1512688. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 16:54:05,954][60274] Avg episode reward: [(0, '399.147')]
[36m[2025-06-29 16:54:10,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1511424. Throughput: 0: 79.8. Samples: 1513176. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 16:54:10,948][60274] Avg episode reward: [(0, '387.567')]
[36m[2025-06-29 16:54:15,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1511424. Throughput: 0: 79.9. Samples: 1513656. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 16:54:15,953][60274] Avg episode reward: [(0, '379.399')]
[36m[2025-06-29 16:54:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1511424. Throughput: 0: 79.1. Samples: 1513884. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 16:54:20,985][60274] Avg episode reward: [(0, '382.410')]
[36m[2025-06-29 16:54:25,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1511424. Throughput: 0: 79.2. Samples: 1514372. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 16:54:25,981][60274] Avg episode reward: [(0, '384.776')]
[36m[2025-06-29 16:54:30,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1511424. Throughput: 0: 78.9. Samples: 1514844. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 16:54:30,969][60274] Avg episode reward: [(0, '403.866')]
[36m[2025-06-29 16:54:36,017][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1511424. Throughput: 0: 80.5. Samples: 1515100. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 16:54:36,018][60274] Avg episode reward: [(0, '414.697')]
[37m[1m[2025-06-29 16:54:36,021][60274] Saving new best policy, reward=414.697!
[36m[2025-06-29 16:54:40,965][60274] Fps is (10 sec: 409.7, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1515520. Throughput: 0: 79.1. Samples: 1515528. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:54:40,965][60274] Avg episode reward: [(0, '409.387')]
[36m[2025-06-29 16:54:45,982][60274] Fps is (10 sec: 411.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1515520. Throughput: 0: 79.6. Samples: 1516016. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:54:45,982][60274] Avg episode reward: [(0, '379.465')]
[36m[2025-06-29 16:54:50,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1515520. Throughput: 0: 79.1. Samples: 1516252. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:54:50,983][60274] Avg episode reward: [(0, '390.994')]
[36m[2025-06-29 16:54:55,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1515520. Throughput: 0: 79.0. Samples: 1516732. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:54:55,963][60274] Avg episode reward: [(0, '403.696')]
[36m[2025-06-29 16:55:00,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1515520. Throughput: 0: 79.5. Samples: 1517236. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:55:00,967][60274] Avg episode reward: [(0, '399.851')]
[37m[1m[2025-06-29 16:55:01,014][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005920_1515520.pth...
[36m[2025-06-29 16:55:01,071][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005840_1495040.pth
[36m[2025-06-29 16:55:05,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1515520. Throughput: 0: 79.7. Samples: 1517468. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:55:05,968][60274] Avg episode reward: [(0, '406.043')]
[36m[2025-06-29 16:55:10,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1515520. Throughput: 0: 79.5. Samples: 1517948. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:55:10,950][60274] Avg episode reward: [(0, '413.729')]
[36m[2025-06-29 16:55:15,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1515520. Throughput: 0: 80.0. Samples: 1518444. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:55:15,984][60274] Avg episode reward: [(0, '424.082')]
[37m[1m[2025-06-29 16:55:16,029][60274] Saving new best policy, reward=424.082!
[36m[2025-06-29 16:55:20,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1515520. Throughput: 0: 79.6. Samples: 1518680. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:55:20,970][60274] Avg episode reward: [(0, '408.904')]
[36m[2025-06-29 16:55:25,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1515520. Throughput: 0: 81.1. Samples: 1519176. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 16:55:25,964][60274] Avg episode reward: [(0, '411.209')]
[36m[2025-06-29 16:55:30,961][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1519616. Throughput: 0: 80.2. Samples: 1519624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:55:30,961][60274] Avg episode reward: [(0, '417.761')]
[36m[2025-06-29 16:55:35,963][60274] Fps is (10 sec: 409.6, 60 sec: 136.7, 300 sec: 83.3). Total num frames: 1519616. Throughput: 0: 80.2. Samples: 1519860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:55:35,963][60274] Avg episode reward: [(0, '393.452')]
[36m[2025-06-29 16:55:40,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1519616. Throughput: 0: 80.8. Samples: 1520368. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:55:40,952][60274] Avg episode reward: [(0, '380.290')]
[36m[2025-06-29 16:55:45,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1519616. Throughput: 0: 80.0. Samples: 1520836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:55:45,960][60274] Avg episode reward: [(0, '362.252')]
[36m[2025-06-29 16:55:50,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1519616. Throughput: 0: 80.6. Samples: 1521096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:55:50,955][60274] Avg episode reward: [(0, '380.876')]
[36m[2025-06-29 16:55:55,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1519616. Throughput: 0: 81.4. Samples: 1521616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:55:55,988][60274] Avg episode reward: [(0, '362.834')]
[36m[2025-06-29 16:56:00,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1519616. Throughput: 0: 81.2. Samples: 1522096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:56:00,958][60274] Avg episode reward: [(0, '365.574')]
[36m[2025-06-29 16:56:06,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1519616. Throughput: 0: 81.0. Samples: 1522328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:56:06,003][60274] Avg episode reward: [(0, '381.778')]
[36m[2025-06-29 16:56:10,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1519616. Throughput: 0: 80.4. Samples: 1522792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:56:10,948][60274] Avg episode reward: [(0, '376.289')]
[36m[2025-06-29 16:56:15,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1519616. Throughput: 0: 80.8. Samples: 1523260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:56:15,984][60274] Avg episode reward: [(0, '368.349')]
[36m[2025-06-29 16:56:21,526][60274] Fps is (10 sec: 387.2, 60 sec: 135.3, 300 sec: 83.2). Total num frames: 1523712. Throughput: 0: 80.1. Samples: 1523508. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:56:21,527][60274] Avg episode reward: [(0, '368.555')]
[36m[2025-06-29 16:56:25,992][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1523712. Throughput: 0: 79.5. Samples: 1523948. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:56:25,992][60274] Avg episode reward: [(0, '358.856')]
[36m[2025-06-29 16:56:30,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1523712. Throughput: 0: 79.3. Samples: 1524404. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:56:30,954][60274] Avg episode reward: [(0, '355.622')]
[36m[2025-06-29 16:56:35,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1523712. Throughput: 0: 79.0. Samples: 1524652. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:56:35,985][60274] Avg episode reward: [(0, '366.359')]
[36m[2025-06-29 16:56:40,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1523712. Throughput: 0: 77.8. Samples: 1525116. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:56:40,983][60274] Avg episode reward: [(0, '364.582')]
[36m[2025-06-29 16:56:45,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1523712. Throughput: 0: 77.5. Samples: 1525584. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:56:45,952][60274] Avg episode reward: [(0, '362.766')]
[36m[2025-06-29 16:56:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1523712. Throughput: 0: 77.7. Samples: 1525824. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:56:50,976][60274] Avg episode reward: [(0, '362.551')]
[36m[2025-06-29 16:56:55,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1523712. Throughput: 0: 78.6. Samples: 1526332. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:56:55,966][60274] Avg episode reward: [(0, '361.806')]
[36m[2025-06-29 16:57:00,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1523712. Throughput: 0: 79.7. Samples: 1526844. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:57:00,949][60274] Avg episode reward: [(0, '347.507')]
[37m[1m[2025-06-29 16:57:00,996][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005952_1523712.pth...
[36m[2025-06-29 16:57:01,052][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005888_1507328.pth
[36m[2025-06-29 16:57:05,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1523712. Throughput: 0: 80.7. Samples: 1527092. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:57:05,964][60274] Avg episode reward: [(0, '345.222')]
[36m[2025-06-29 16:57:10,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1523712. Throughput: 0: 81.2. Samples: 1527600. Policy #0 lag: (min: 13.0, avg: 13.0, max: 29.0)
[36m[2025-06-29 16:57:10,949][60274] Avg episode reward: [(0, '348.332')]
[36m[2025-06-29 16:57:15,981][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1527808. Throughput: 0: 80.4. Samples: 1528024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:57:15,982][60274] Avg episode reward: [(0, '341.854')]
[36m[2025-06-29 16:57:20,976][60274] Fps is (10 sec: 408.5, 60 sec: 68.9, 300 sec: 83.3). Total num frames: 1527808. Throughput: 0: 80.1. Samples: 1528256. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:57:20,976][60274] Avg episode reward: [(0, '339.995')]
[36m[2025-06-29 16:57:25,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1527808. Throughput: 0: 80.8. Samples: 1528752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:57:25,956][60274] Avg episode reward: [(0, '343.172')]
[36m[2025-06-29 16:57:30,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1527808. Throughput: 0: 81.1. Samples: 1529236. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:57:30,962][60274] Avg episode reward: [(0, '350.040')]
[36m[2025-06-29 16:57:35,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1527808. Throughput: 0: 80.8. Samples: 1529460. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:57:35,982][60274] Avg episode reward: [(0, '358.252')]
[36m[2025-06-29 16:57:40,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1527808. Throughput: 0: 80.1. Samples: 1529936. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:57:40,967][60274] Avg episode reward: [(0, '349.421')]
[36m[2025-06-29 16:57:45,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1527808. Throughput: 0: 79.7. Samples: 1530432. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:57:45,988][60274] Avg episode reward: [(0, '352.381')]
[36m[2025-06-29 16:57:50,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 1527808. Throughput: 0: 79.7. Samples: 1530676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:57:50,950][60274] Avg episode reward: [(0, '339.821')]
[36m[2025-06-29 16:57:55,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1527808. Throughput: 0: 79.0. Samples: 1531160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:57:55,991][60274] Avg episode reward: [(0, '344.337')]
[36m[2025-06-29 16:58:00,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1527808. Throughput: 0: 80.4. Samples: 1531644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 16:58:00,981][60274] Avg episode reward: [(0, '338.379')]
[36m[2025-06-29 16:58:05,986][60274] Fps is (10 sec: 409.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1531904. Throughput: 0: 80.5. Samples: 1531880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:58:05,986][60274] Avg episode reward: [(0, '333.939')]
[36m[2025-06-29 16:58:11,015][60274] Fps is (10 sec: 408.2, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1531904. Throughput: 0: 79.3. Samples: 1532324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:58:11,015][60274] Avg episode reward: [(0, '312.888')]
[36m[2025-06-29 16:58:15,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1531904. Throughput: 0: 79.1. Samples: 1532796. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:58:15,972][60274] Avg episode reward: [(0, '304.911')]
[36m[2025-06-29 16:58:20,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1531904. Throughput: 0: 79.9. Samples: 1533052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:58:20,961][60274] Avg episode reward: [(0, '314.088')]
[36m[2025-06-29 16:58:25,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1531904. Throughput: 0: 80.3. Samples: 1533548. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:58:25,951][60274] Avg episode reward: [(0, '315.523')]
[36m[2025-06-29 16:58:30,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1531904. Throughput: 0: 80.0. Samples: 1534032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:58:30,978][60274] Avg episode reward: [(0, '307.920')]
[36m[2025-06-29 16:58:35,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1531904. Throughput: 0: 79.9. Samples: 1534272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:58:35,974][60274] Avg episode reward: [(0, '305.021')]
[36m[2025-06-29 16:58:40,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1531904. Throughput: 0: 80.2. Samples: 1534768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:58:40,959][60274] Avg episode reward: [(0, '305.460')]
[36m[2025-06-29 16:58:45,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1531904. Throughput: 0: 80.4. Samples: 1535260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:58:45,959][60274] Avg episode reward: [(0, '306.616')]
[36m[2025-06-29 16:58:50,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1531904. Throughput: 0: 80.3. Samples: 1535492. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 16:58:50,950][60274] Avg episode reward: [(0, '300.573')]
[36m[2025-06-29 16:58:55,948][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1536000. Throughput: 0: 80.8. Samples: 1535956. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:58:55,948][60274] Avg episode reward: [(0, '301.057')]
[36m[2025-06-29 16:59:00,956][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1536000. Throughput: 0: 79.8. Samples: 1536388. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:59:00,956][60274] Avg episode reward: [(0, '302.327')]
[37m[1m[2025-06-29 16:59:01,006][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006000_1536000.pth...
[36m[2025-06-29 16:59:01,067][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005920_1515520.pth
[36m[2025-06-29 16:59:05,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1536000. Throughput: 0: 79.5. Samples: 1536628. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:59:05,969][60274] Avg episode reward: [(0, '307.630')]
[36m[2025-06-29 16:59:10,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1536000. Throughput: 0: 79.6. Samples: 1537128. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:59:10,947][60274] Avg episode reward: [(0, '311.837')]
[36m[2025-06-29 16:59:15,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1536000. Throughput: 0: 79.0. Samples: 1537588. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:59:15,966][60274] Avg episode reward: [(0, '311.954')]
[36m[2025-06-29 16:59:21,003][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1536000. Throughput: 0: 78.9. Samples: 1537824. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:59:21,004][60274] Avg episode reward: [(0, '315.569')]
[36m[2025-06-29 16:59:25,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1536000. Throughput: 0: 78.7. Samples: 1538308. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:59:25,964][60274] Avg episode reward: [(0, '318.054')]
[36m[2025-06-29 16:59:31,008][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1536000. Throughput: 0: 78.8. Samples: 1538812. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:59:31,008][60274] Avg episode reward: [(0, '314.460')]
[36m[2025-06-29 16:59:35,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1536000. Throughput: 0: 79.3. Samples: 1539060. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:59:35,963][60274] Avg episode reward: [(0, '316.760')]
[36m[2025-06-29 16:59:40,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1536000. Throughput: 0: 80.0. Samples: 1539556. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:59:40,950][60274] Avg episode reward: [(0, '325.102')]
[36m[2025-06-29 16:59:46,002][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1536000. Throughput: 0: 81.1. Samples: 1540040. Policy #0 lag: (min: 0.0, avg: 0.0, max: 16.0)
[36m[2025-06-29 16:59:46,003][60274] Avg episode reward: [(0, '312.779')]
[36m[2025-06-29 16:59:50,964][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1540096. Throughput: 0: 79.9. Samples: 1540224. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:59:50,964][60274] Avg episode reward: [(0, '321.784')]
[36m[2025-06-29 16:59:55,949][60274] Fps is (10 sec: 411.8, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1540096. Throughput: 0: 79.6. Samples: 1540708. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 16:59:55,949][60274] Avg episode reward: [(0, '320.852')]
[36m[2025-06-29 17:00:00,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1540096. Throughput: 0: 80.2. Samples: 1541200. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 17:00:00,985][60274] Avg episode reward: [(0, '333.080')]
[36m[2025-06-29 17:00:05,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1540096. Throughput: 0: 80.5. Samples: 1541444. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 17:00:05,970][60274] Avg episode reward: [(0, '344.742')]
[36m[2025-06-29 17:00:10,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1540096. Throughput: 0: 80.7. Samples: 1541940. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 17:00:10,966][60274] Avg episode reward: [(0, '351.216')]
[36m[2025-06-29 17:00:15,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1540096. Throughput: 0: 80.2. Samples: 1542420. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 17:00:15,989][60274] Avg episode reward: [(0, '343.641')]
[36m[2025-06-29 17:00:20,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1540096. Throughput: 0: 80.0. Samples: 1542660. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 17:00:20,975][60274] Avg episode reward: [(0, '347.680')]
[36m[2025-06-29 17:00:25,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1540096. Throughput: 0: 80.5. Samples: 1543180. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 17:00:25,959][60274] Avg episode reward: [(0, '354.813')]
[36m[2025-06-29 17:00:30,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1540096. Throughput: 0: 80.3. Samples: 1543648. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 17:00:30,947][60274] Avg episode reward: [(0, '356.071')]
[36m[2025-06-29 17:00:35,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1540096. Throughput: 0: 81.3. Samples: 1543884. Policy #0 lag: (min: 5.0, avg: 5.0, max: 21.0)
[36m[2025-06-29 17:00:35,970][60274] Avg episode reward: [(0, '339.652')]
[36m[2025-06-29 17:00:40,978][60274] Fps is (10 sec: 408.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1544192. Throughput: 0: 80.2. Samples: 1544320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:00:40,978][60274] Avg episode reward: [(0, '345.069')]
[36m[2025-06-29 17:00:45,958][60274] Fps is (10 sec: 410.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1544192. Throughput: 0: 80.7. Samples: 1544828. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:00:45,958][60274] Avg episode reward: [(0, '334.687')]
[36m[2025-06-29 17:00:50,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1544192. Throughput: 0: 80.6. Samples: 1545072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:00:50,993][60274] Avg episode reward: [(0, '330.915')]
[36m[2025-06-29 17:00:55,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1544192. Throughput: 0: 79.6. Samples: 1545524. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:00:55,985][60274] Avg episode reward: [(0, '331.992')]
[36m[2025-06-29 17:01:00,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1544192. Throughput: 0: 79.9. Samples: 1546016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:00,978][60274] Avg episode reward: [(0, '319.745')]
[37m[1m[2025-06-29 17:01:01,035][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006032_1544192.pth...
[36m[2025-06-29 17:01:01,091][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000005952_1523712.pth
[36m[2025-06-29 17:01:05,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1544192. Throughput: 0: 80.1. Samples: 1546264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:05,965][60274] Avg episode reward: [(0, '322.578')]
[36m[2025-06-29 17:01:10,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1544192. Throughput: 0: 78.8. Samples: 1546728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:10,956][60274] Avg episode reward: [(0, '324.053')]
[36m[2025-06-29 17:01:15,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.6). Total num frames: 1544192. Throughput: 0: 78.8. Samples: 1547196. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:15,983][60274] Avg episode reward: [(0, '334.976')]
[36m[2025-06-29 17:01:20,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1544192. Throughput: 0: 79.2. Samples: 1547448. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:20,965][60274] Avg episode reward: [(0, '340.879')]
[36m[2025-06-29 17:01:25,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1544192. Throughput: 0: 80.1. Samples: 1547924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:25,956][60274] Avg episode reward: [(0, '332.430')]
[36m[2025-06-29 17:01:30,977][60274] Fps is (10 sec: 409.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1548288. Throughput: 0: 77.9. Samples: 1548336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:30,977][60274] Avg episode reward: [(0, '339.563')]
[36m[2025-06-29 17:01:35,971][60274] Fps is (10 sec: 408.9, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1548288. Throughput: 0: 78.0. Samples: 1548580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:35,972][60274] Avg episode reward: [(0, '344.883')]
[36m[2025-06-29 17:01:40,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1548288. Throughput: 0: 79.5. Samples: 1549100. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:40,986][60274] Avg episode reward: [(0, '327.924')]
[36m[2025-06-29 17:01:45,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1548288. Throughput: 0: 79.6. Samples: 1549596. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:45,956][60274] Avg episode reward: [(0, '325.345')]
[36m[2025-06-29 17:01:50,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1548288. Throughput: 0: 78.9. Samples: 1549816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:50,956][60274] Avg episode reward: [(0, '334.084')]
[36m[2025-06-29 17:01:55,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1548288. Throughput: 0: 79.8. Samples: 1550320. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:01:55,957][60274] Avg episode reward: [(0, '313.738')]
[36m[2025-06-29 17:02:00,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1548288. Throughput: 0: 80.9. Samples: 1550836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:02:00,991][60274] Avg episode reward: [(0, '321.395')]
[36m[2025-06-29 17:02:05,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1548288. Throughput: 0: 80.6. Samples: 1551076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:02:05,958][60274] Avg episode reward: [(0, '330.988')]
[36m[2025-06-29 17:02:10,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1548288. Throughput: 0: 80.7. Samples: 1551556. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:02:10,964][60274] Avg episode reward: [(0, '316.908')]
[36m[2025-06-29 17:02:15,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1548288. Throughput: 0: 82.4. Samples: 1552044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:02:15,960][60274] Avg episode reward: [(0, '309.236')]
[36m[2025-06-29 17:02:20,990][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1552384. Throughput: 0: 82.5. Samples: 1552292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:02:20,991][60274] Avg episode reward: [(0, '302.102')]
[36m[2025-06-29 17:02:25,947][60274] Fps is (10 sec: 410.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1552384. Throughput: 0: 80.7. Samples: 1552728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:02:25,947][60274] Avg episode reward: [(0, '312.292')]
[36m[2025-06-29 17:02:30,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1552384. Throughput: 0: 80.3. Samples: 1553212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:02:30,986][60274] Avg episode reward: [(0, '318.350')]
[36m[2025-06-29 17:02:35,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1552384. Throughput: 0: 80.8. Samples: 1553456. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:02:35,993][60274] Avg episode reward: [(0, '318.674')]
[36m[2025-06-29 17:02:40,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1552384. Throughput: 0: 80.1. Samples: 1553924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:02:40,949][60274] Avg episode reward: [(0, '318.874')]
[33m[19787564 ms][navigation_task] - WARNING : Curriculum Level: 40, Curriculum progress fraction: 0.2857142857142857 (navigation_task.py:262)
[33m[19787565 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.7548828125
[33mCrash Rate: 0.20751953125
[33mTimeout Rate: 0.03759765625 (navigation_task.py:265)
[33m[19787565 ms][navigation_task] - WARNING : 
[33mSuccesses: 1546
[33mCrashes : 425
[33mTimeouts: 77 (navigation_task.py:268)
[36m[2025-06-29 17:02:45,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1552384. Throughput: 0: 79.5. Samples: 1554412. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:02:45,995][60274] Avg episode reward: [(0, '313.384')]
[36m[2025-06-29 17:02:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1552384. Throughput: 0: 79.4. Samples: 1554648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:02:50,961][60274] Avg episode reward: [(0, '324.051')]
[36m[2025-06-29 17:02:55,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1552384. Throughput: 0: 79.1. Samples: 1555116. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:02:55,962][60274] Avg episode reward: [(0, '327.327')]
[36m[2025-06-29 17:03:00,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1552384. Throughput: 0: 79.3. Samples: 1555616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:03:00,986][60274] Avg episode reward: [(0, '321.984')]
[37m[1m[2025-06-29 17:03:01,032][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006064_1552384.pth...
[36m[2025-06-29 17:03:01,087][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006000_1536000.pth
[36m[2025-06-29 17:03:05,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1552384. Throughput: 0: 79.0. Samples: 1555848. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:03:05,980][60274] Avg episode reward: [(0, '339.589')]
[36m[2025-06-29 17:03:10,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1552384. Throughput: 0: 80.2. Samples: 1556336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:03:10,961][60274] Avg episode reward: [(0, '350.928')]
[36m[2025-06-29 17:03:15,981][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1556480. Throughput: 0: 78.9. Samples: 1556764. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:03:15,982][60274] Avg episode reward: [(0, '360.001')]
[36m[2025-06-29 17:03:20,973][60274] Fps is (10 sec: 409.1, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1556480. Throughput: 0: 78.7. Samples: 1556996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:03:20,973][60274] Avg episode reward: [(0, '360.858')]
[36m[2025-06-29 17:03:25,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1556480. Throughput: 0: 78.7. Samples: 1557468. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:03:25,981][60274] Avg episode reward: [(0, '350.911')]
[36m[2025-06-29 17:03:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1556480. Throughput: 0: 78.7. Samples: 1557952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:03:30,990][60274] Avg episode reward: [(0, '359.022')]
[36m[2025-06-29 17:03:35,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1556480. Throughput: 0: 79.1. Samples: 1558208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:03:35,953][60274] Avg episode reward: [(0, '375.220')]
[36m[2025-06-29 17:03:40,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1556480. Throughput: 0: 80.1. Samples: 1558720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:03:40,957][60274] Avg episode reward: [(0, '377.894')]
[36m[2025-06-29 17:03:45,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1556480. Throughput: 0: 80.0. Samples: 1559212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:03:45,961][60274] Avg episode reward: [(0, '386.560')]
[36m[2025-06-29 17:03:50,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1556480. Throughput: 0: 79.9. Samples: 1559444. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:03:50,970][60274] Avg episode reward: [(0, '356.035')]
[36m[2025-06-29 17:03:55,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1556480. Throughput: 0: 80.2. Samples: 1559944. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:03:55,959][60274] Avg episode reward: [(0, '357.889')]
[36m[2025-06-29 17:04:00,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1556480. Throughput: 0: 82.1. Samples: 1560456. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:04:00,951][60274] Avg episode reward: [(0, '370.312')]
[36m[2025-06-29 17:04:05,953][60274] Fps is (10 sec: 409.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1560576. Throughput: 0: 81.0. Samples: 1560640. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:04:05,954][60274] Avg episode reward: [(0, '381.613')]
[36m[2025-06-29 17:04:10,950][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1560576. Throughput: 0: 81.8. Samples: 1561148. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:04:10,951][60274] Avg episode reward: [(0, '396.705')]
[36m[2025-06-29 17:04:15,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1560576. Throughput: 0: 82.2. Samples: 1561648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:04:15,977][60274] Avg episode reward: [(0, '394.519')]
[36m[2025-06-29 17:04:20,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1560576. Throughput: 0: 81.9. Samples: 1561896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:04:20,981][60274] Avg episode reward: [(0, '403.957')]
[36m[2025-06-29 17:04:25,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1560576. Throughput: 0: 81.7. Samples: 1562396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:04:25,971][60274] Avg episode reward: [(0, '382.437')]
[36m[2025-06-29 17:04:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1560576. Throughput: 0: 81.0. Samples: 1562856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:04:30,974][60274] Avg episode reward: [(0, '391.570')]
[36m[2025-06-29 17:04:35,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1560576. Throughput: 0: 81.4. Samples: 1563104. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:04:35,948][60274] Avg episode reward: [(0, '390.179')]
[36m[2025-06-29 17:04:40,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1560576. Throughput: 0: 81.1. Samples: 1563596. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:04:40,966][60274] Avg episode reward: [(0, '410.274')]
[36m[2025-06-29 17:04:45,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1560576. Throughput: 0: 80.7. Samples: 1564092. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:04:45,994][60274] Avg episode reward: [(0, '401.073')]
[36m[2025-06-29 17:04:50,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1560576. Throughput: 0: 82.0. Samples: 1564332. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:04:50,967][60274] Avg episode reward: [(0, '396.036')]
[36m[2025-06-29 17:04:55,985][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1564672. Throughput: 0: 80.4. Samples: 1564768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:04:55,985][60274] Avg episode reward: [(0, '369.815')]
[36m[2025-06-29 17:05:00,956][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1564672. Throughput: 0: 80.6. Samples: 1565272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:05:00,957][60274] Avg episode reward: [(0, '363.171')]
[37m[1m[2025-06-29 17:05:01,013][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006112_1564672.pth...
[36m[2025-06-29 17:05:01,070][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006032_1544192.pth
[36m[2025-06-29 17:05:05,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1564672. Throughput: 0: 80.3. Samples: 1565508. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:05:05,961][60274] Avg episode reward: [(0, '370.725')]
[36m[2025-06-29 17:05:10,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1564672. Throughput: 0: 80.0. Samples: 1565996. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:05:10,951][60274] Avg episode reward: [(0, '382.378')]
[36m[2025-06-29 17:05:15,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1564672. Throughput: 0: 80.4. Samples: 1566472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:05:15,953][60274] Avg episode reward: [(0, '390.333')]
[36m[2025-06-29 17:05:20,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1564672. Throughput: 0: 80.3. Samples: 1566720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:05:20,973][60274] Avg episode reward: [(0, '376.749')]
[36m[2025-06-29 17:05:25,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1564672. Throughput: 0: 80.6. Samples: 1567224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:05:25,984][60274] Avg episode reward: [(0, '373.630')]
[36m[2025-06-29 17:05:30,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1564672. Throughput: 0: 80.1. Samples: 1567692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:05:30,960][60274] Avg episode reward: [(0, '379.909')]
[36m[2025-06-29 17:05:35,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1564672. Throughput: 0: 80.0. Samples: 1567932. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:05:35,988][60274] Avg episode reward: [(0, '381.808')]
[36m[2025-06-29 17:05:40,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1564672. Throughput: 0: 81.3. Samples: 1568428. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:05:40,985][60274] Avg episode reward: [(0, '408.003')]
[36m[2025-06-29 17:05:45,952][60274] Fps is (10 sec: 411.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1568768. Throughput: 0: 80.1. Samples: 1568876. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 17:05:45,952][60274] Avg episode reward: [(0, '411.438')]
[36m[2025-06-29 17:05:50,970][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1568768. Throughput: 0: 80.6. Samples: 1569136. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 17:05:50,970][60274] Avg episode reward: [(0, '421.392')]
[36m[2025-06-29 17:05:55,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1568768. Throughput: 0: 80.4. Samples: 1569616. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 17:05:55,969][60274] Avg episode reward: [(0, '414.134')]
[36m[2025-06-29 17:06:00,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1568768. Throughput: 0: 81.1. Samples: 1570124. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 17:06:00,987][60274] Avg episode reward: [(0, '403.240')]
[36m[2025-06-29 17:06:05,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1568768. Throughput: 0: 81.1. Samples: 1570368. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 17:06:05,964][60274] Avg episode reward: [(0, '395.476')]
[36m[2025-06-29 17:06:10,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1568768. Throughput: 0: 81.3. Samples: 1570880. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 17:06:10,971][60274] Avg episode reward: [(0, '382.386')]
[36m[2025-06-29 17:06:15,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1568768. Throughput: 0: 81.7. Samples: 1571372. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 17:06:15,981][60274] Avg episode reward: [(0, '395.443')]
[36m[2025-06-29 17:06:20,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1568768. Throughput: 0: 81.9. Samples: 1571620. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 17:06:20,994][60274] Avg episode reward: [(0, '400.585')]
[36m[2025-06-29 17:06:25,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1568768. Throughput: 0: 81.7. Samples: 1572104. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 17:06:25,972][60274] Avg episode reward: [(0, '419.265')]
[36m[2025-06-29 17:06:30,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1568768. Throughput: 0: 82.2. Samples: 1572576. Policy #0 lag: (min: 6.0, avg: 6.0, max: 22.0)
[36m[2025-06-29 17:06:30,971][60274] Avg episode reward: [(0, '396.865')]
[36m[2025-06-29 17:06:35,972][60274] Fps is (10 sec: 409.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1572864. Throughput: 0: 82.0. Samples: 1572828. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:06:35,973][60274] Avg episode reward: [(0, '414.961')]
[36m[2025-06-29 17:06:40,960][60274] Fps is (10 sec: 410.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1572864. Throughput: 0: 81.6. Samples: 1573288. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:06:40,960][60274] Avg episode reward: [(0, '411.207')]
[36m[2025-06-29 17:06:45,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1572864. Throughput: 0: 81.1. Samples: 1573772. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:06:45,949][60274] Avg episode reward: [(0, '431.847')]
[37m[1m[2025-06-29 17:06:45,994][60274] Saving new best policy, reward=431.847!
[36m[2025-06-29 17:06:50,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1572864. Throughput: 0: 81.1. Samples: 1574016. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:06:50,958][60274] Avg episode reward: [(0, '428.356')]
[36m[2025-06-29 17:06:55,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1572864. Throughput: 0: 80.8. Samples: 1574516. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:06:55,953][60274] Avg episode reward: [(0, '422.485')]
[36m[2025-06-29 17:07:00,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1572864. Throughput: 0: 80.9. Samples: 1575012. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:07:00,993][60274] Avg episode reward: [(0, '428.023')]
[37m[1m[2025-06-29 17:07:01,076][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006144_1572864.pth...
[36m[2025-06-29 17:07:01,134][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006064_1552384.pth
[36m[2025-06-29 17:07:05,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1572864. Throughput: 0: 80.0. Samples: 1575220. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:07:05,970][60274] Avg episode reward: [(0, '421.014')]
[36m[2025-06-29 17:07:10,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1572864. Throughput: 0: 80.7. Samples: 1575732. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:07:10,948][60274] Avg episode reward: [(0, '433.702')]
[37m[1m[2025-06-29 17:07:10,999][60274] Saving new best policy, reward=433.702!
[36m[2025-06-29 17:07:15,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1572864. Throughput: 0: 81.2. Samples: 1576228. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:07:15,951][60274] Avg episode reward: [(0, '421.353')]
[36m[2025-06-29 17:07:20,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1572864. Throughput: 0: 81.2. Samples: 1576484. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:07:20,978][60274] Avg episode reward: [(0, '408.480')]
[36m[2025-06-29 17:07:25,965][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1576960. Throughput: 0: 81.8. Samples: 1576968. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 17:07:25,965][60274] Avg episode reward: [(0, '406.894')]
[36m[2025-06-29 17:07:30,977][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1576960. Throughput: 0: 81.5. Samples: 1577444. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 17:07:30,977][60274] Avg episode reward: [(0, '423.779')]
[36m[2025-06-29 17:07:35,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1576960. Throughput: 0: 81.4. Samples: 1577680. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 17:07:35,977][60274] Avg episode reward: [(0, '410.930')]
[36m[2025-06-29 17:07:40,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1576960. Throughput: 0: 81.2. Samples: 1578172. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 17:07:40,988][60274] Avg episode reward: [(0, '413.043')]
[36m[2025-06-29 17:07:45,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1576960. Throughput: 0: 81.6. Samples: 1578684. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 17:07:45,981][60274] Avg episode reward: [(0, '412.092')]
[36m[2025-06-29 17:07:50,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1576960. Throughput: 0: 82.3. Samples: 1578924. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 17:07:50,969][60274] Avg episode reward: [(0, '438.028')]
[37m[1m[2025-06-29 17:07:51,018][60274] Saving new best policy, reward=438.028!
[36m[2025-06-29 17:07:55,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1576960. Throughput: 0: 81.2. Samples: 1579388. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 17:07:55,995][60274] Avg episode reward: [(0, '428.284')]
[36m[2025-06-29 17:08:00,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1576960. Throughput: 0: 80.9. Samples: 1579868. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 17:08:00,972][60274] Avg episode reward: [(0, '462.340')]
[37m[1m[2025-06-29 17:08:01,019][60274] Saving new best policy, reward=462.340!
[36m[2025-06-29 17:08:05,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1576960. Throughput: 0: 80.9. Samples: 1580120. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 17:08:05,949][60274] Avg episode reward: [(0, '463.993')]
[37m[1m[2025-06-29 17:08:06,011][60274] Saving new best policy, reward=463.993!
[36m[2025-06-29 17:08:10,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1576960. Throughput: 0: 80.4. Samples: 1580584. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-06-29 17:08:10,953][60274] Avg episode reward: [(0, '454.966')]
[36m[2025-06-29 17:08:16,100][60274] Fps is (10 sec: 403.5, 60 sec: 136.2, 300 sec: 83.3). Total num frames: 1581056. Throughput: 0: 80.0. Samples: 1581052. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:08:16,101][60274] Avg episode reward: [(0, '449.271')]
[36m[2025-06-29 17:08:20,990][60274] Fps is (10 sec: 408.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1581056. Throughput: 0: 78.9. Samples: 1581232. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:08:20,991][60274] Avg episode reward: [(0, '448.540')]
[36m[2025-06-29 17:08:25,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1581056. Throughput: 0: 78.7. Samples: 1581712. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:08:25,952][60274] Avg episode reward: [(0, '458.875')]
[36m[2025-06-29 17:08:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1581056. Throughput: 0: 76.6. Samples: 1582132. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:08:30,973][60274] Avg episode reward: [(0, '462.203')]
[36m[2025-06-29 17:08:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1581056. Throughput: 0: 76.3. Samples: 1582360. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:08:35,973][60274] Avg episode reward: [(0, '450.214')]
[36m[2025-06-29 17:08:40,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1581056. Throughput: 0: 77.0. Samples: 1582852. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:08:40,992][60274] Avg episode reward: [(0, '432.281')]
[36m[2025-06-29 17:08:45,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1581056. Throughput: 0: 76.5. Samples: 1583312. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:08:45,988][60274] Avg episode reward: [(0, '451.612')]
[36m[2025-06-29 17:08:50,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1581056. Throughput: 0: 75.7. Samples: 1583532. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:08:50,996][60274] Avg episode reward: [(0, '458.205')]
[36m[2025-06-29 17:08:55,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1581056. Throughput: 0: 74.9. Samples: 1583956. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:08:55,948][60274] Avg episode reward: [(0, '452.196')]
[36m[2025-06-29 17:09:00,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1581056. Throughput: 0: 74.4. Samples: 1584392. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:09:00,987][60274] Avg episode reward: [(0, '467.772')]
[37m[1m[2025-06-29 17:09:01,040][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006176_1581056.pth...
[36m[2025-06-29 17:09:01,100][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006112_1564672.pth
[37m[1m[2025-06-29 17:09:01,107][60274] Saving new best policy, reward=467.772!
[36m[2025-06-29 17:09:05,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1581056. Throughput: 0: 75.3. Samples: 1584616. Policy #0 lag: (min: 3.0, avg: 3.0, max: 19.0)
[36m[2025-06-29 17:09:05,958][60274] Avg episode reward: [(0, '474.584')]
[37m[1m[2025-06-29 17:09:06,004][60274] Saving new best policy, reward=474.584!
[36m[2025-06-29 17:09:11,074][60274] Fps is (10 sec: 406.0, 60 sec: 136.3, 300 sec: 83.3). Total num frames: 1585152. Throughput: 0: 74.6. Samples: 1585076. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:09:11,074][60274] Avg episode reward: [(0, '480.862')]
[37m[1m[2025-06-29 17:09:11,130][60274] Saving new best policy, reward=480.862!
[36m[2025-06-29 17:09:16,002][60274] Fps is (10 sec: 407.8, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 1585152. Throughput: 0: 74.3. Samples: 1585476. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:09:16,002][60274] Avg episode reward: [(0, '474.925')]
[36m[2025-06-29 17:09:20,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1585152. Throughput: 0: 74.6. Samples: 1585716. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:09:20,971][60274] Avg episode reward: [(0, '492.828')]
[37m[1m[2025-06-29 17:09:21,021][60274] Saving new best policy, reward=492.828!
[36m[2025-06-29 17:09:25,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1585152. Throughput: 0: 73.8. Samples: 1586168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:09:25,955][60274] Avg episode reward: [(0, '470.929')]
[36m[2025-06-29 17:09:31,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1585152. Throughput: 0: 73.2. Samples: 1586608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:09:31,006][60274] Avg episode reward: [(0, '460.960')]
[36m[2025-06-29 17:09:35,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1585152. Throughput: 0: 73.3. Samples: 1586828. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:09:35,967][60274] Avg episode reward: [(0, '466.838')]
[36m[2025-06-29 17:09:40,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1585152. Throughput: 0: 73.9. Samples: 1587284. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:09:40,969][60274] Avg episode reward: [(0, '448.347')]
[36m[2025-06-29 17:09:45,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1585152. Throughput: 0: 74.7. Samples: 1587752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:09:45,981][60274] Avg episode reward: [(0, '447.287')]
[36m[2025-06-29 17:09:50,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1585152. Throughput: 0: 75.0. Samples: 1587992. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:09:50,959][60274] Avg episode reward: [(0, '451.467')]
[36m[2025-06-29 17:09:55,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1585152. Throughput: 0: 76.0. Samples: 1588488. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:09:55,954][60274] Avg episode reward: [(0, '443.054')]
[36m[2025-06-29 17:10:00,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1585152. Throughput: 0: 77.9. Samples: 1588980. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:00,972][60274] Avg episode reward: [(0, '429.001')]
[36m[2025-06-29 17:10:05,958][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1589248. Throughput: 0: 78.3. Samples: 1589240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:05,958][60274] Avg episode reward: [(0, '434.114')]
[36m[2025-06-29 17:10:10,947][60274] Fps is (10 sec: 410.6, 60 sec: 68.4, 300 sec: 83.3). Total num frames: 1589248. Throughput: 0: 78.4. Samples: 1589696. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:10,947][60274] Avg episode reward: [(0, '438.397')]
[36m[2025-06-29 17:10:15,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1589248. Throughput: 0: 80.0. Samples: 1590208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:15,991][60274] Avg episode reward: [(0, '431.013')]
[36m[2025-06-29 17:10:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1589248. Throughput: 0: 80.7. Samples: 1590460. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:20,985][60274] Avg episode reward: [(0, '429.682')]
[36m[2025-06-29 17:10:25,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1589248. Throughput: 0: 81.3. Samples: 1590944. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:25,973][60274] Avg episode reward: [(0, '434.673')]
[36m[2025-06-29 17:10:30,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1589248. Throughput: 0: 82.0. Samples: 1591440. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:30,955][60274] Avg episode reward: [(0, '446.326')]
[36m[2025-06-29 17:10:35,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1589248. Throughput: 0: 82.1. Samples: 1591688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:35,963][60274] Avg episode reward: [(0, '435.271')]
[36m[2025-06-29 17:10:40,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1589248. Throughput: 0: 81.7. Samples: 1592168. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:40,972][60274] Avg episode reward: [(0, '406.195')]
[36m[2025-06-29 17:10:45,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1589248. Throughput: 0: 82.1. Samples: 1592672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:45,947][60274] Avg episode reward: [(0, '404.255')]
[36m[2025-06-29 17:10:50,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1589248. Throughput: 0: 82.0. Samples: 1592928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:10:50,948][60274] Avg episode reward: [(0, '400.328')]
[36m[2025-06-29 17:10:55,967][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1593344. Throughput: 0: 81.2. Samples: 1593352. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:10:55,967][60274] Avg episode reward: [(0, '406.615')]
[36m[2025-06-29 17:11:00,956][60274] Fps is (10 sec: 409.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1593344. Throughput: 0: 81.0. Samples: 1593852. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:11:00,957][60274] Avg episode reward: [(0, '395.290')]
[37m[1m[2025-06-29 17:11:01,020][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006224_1593344.pth...
[36m[2025-06-29 17:11:01,080][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006144_1572864.pth
[36m[2025-06-29 17:11:05,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1593344. Throughput: 0: 80.6. Samples: 1594084. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:11:05,960][60274] Avg episode reward: [(0, '397.147')]
[36m[2025-06-29 17:11:10,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1593344. Throughput: 0: 79.9. Samples: 1594540. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:11:10,968][60274] Avg episode reward: [(0, '402.806')]
[36m[2025-06-29 17:11:15,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1593344. Throughput: 0: 79.5. Samples: 1595020. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:11:15,969][60274] Avg episode reward: [(0, '404.228')]
[36m[2025-06-29 17:11:20,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1593344. Throughput: 0: 78.9. Samples: 1595236. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:11:20,957][60274] Avg episode reward: [(0, '404.977')]
[36m[2025-06-29 17:11:25,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1593344. Throughput: 0: 78.8. Samples: 1595712. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:11:25,973][60274] Avg episode reward: [(0, '424.283')]
[36m[2025-06-29 17:11:30,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1593344. Throughput: 0: 78.2. Samples: 1596192. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:11:30,957][60274] Avg episode reward: [(0, '419.222')]
[36m[2025-06-29 17:11:35,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1593344. Throughput: 0: 78.3. Samples: 1596452. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:11:35,947][60274] Avg episode reward: [(0, '400.125')]
[36m[2025-06-29 17:11:40,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1593344. Throughput: 0: 79.8. Samples: 1596944. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:11:40,987][60274] Avg episode reward: [(0, '390.586')]
[36m[2025-06-29 17:11:45,955][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1597440. Throughput: 0: 79.9. Samples: 1597448. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:11:45,956][60274] Avg episode reward: [(0, '390.096')]
[36m[2025-06-29 17:11:50,990][60274] Fps is (10 sec: 409.4, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1597440. Throughput: 0: 79.4. Samples: 1597660. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:11:50,990][60274] Avg episode reward: [(0, '392.895')]
[36m[2025-06-29 17:11:55,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1597440. Throughput: 0: 80.3. Samples: 1598156. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:11:55,980][60274] Avg episode reward: [(0, '409.176')]
[36m[2025-06-29 17:12:00,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1597440. Throughput: 0: 81.2. Samples: 1598676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:12:00,968][60274] Avg episode reward: [(0, '411.899')]
[36m[2025-06-29 17:12:05,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1597440. Throughput: 0: 82.2. Samples: 1598940. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:12:05,999][60274] Avg episode reward: [(0, '413.488')]
[36m[2025-06-29 17:12:10,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1597440. Throughput: 0: 82.9. Samples: 1599440. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:12:10,969][60274] Avg episode reward: [(0, '413.249')]
[36m[2025-06-29 17:12:15,994][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1597440. Throughput: 0: 83.1. Samples: 1599936. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:12:15,994][60274] Avg episode reward: [(0, '423.303')]
[36m[2025-06-29 17:12:20,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1597440. Throughput: 0: 83.1. Samples: 1600192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:12:20,978][60274] Avg episode reward: [(0, '427.352')]
[36m[2025-06-29 17:12:25,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1597440. Throughput: 0: 83.9. Samples: 1600716. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:12:25,964][60274] Avg episode reward: [(0, '434.712')]
[36m[2025-06-29 17:12:30,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1597440. Throughput: 0: 83.4. Samples: 1601204. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:12:30,991][60274] Avg episode reward: [(0, '455.098')]
[36m[2025-06-29 17:12:35,988][60274] Fps is (10 sec: 408.6, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1601536. Throughput: 0: 84.4. Samples: 1601456. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:12:35,989][60274] Avg episode reward: [(0, '450.587')]
[36m[2025-06-29 17:12:40,978][60274] Fps is (10 sec: 410.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1601536. Throughput: 0: 82.9. Samples: 1601888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:12:40,978][60274] Avg episode reward: [(0, '452.374')]
[36m[2025-06-29 17:12:45,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1601536. Throughput: 0: 82.4. Samples: 1602384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:12:45,984][60274] Avg episode reward: [(0, '443.636')]
[36m[2025-06-29 17:12:50,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1601536. Throughput: 0: 82.1. Samples: 1602636. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:12:50,993][60274] Avg episode reward: [(0, '454.651')]
[36m[2025-06-29 17:12:55,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1601536. Throughput: 0: 82.4. Samples: 1603148. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:12:55,948][60274] Avg episode reward: [(0, '453.903')]
[36m[2025-06-29 17:13:00,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1601536. Throughput: 0: 82.1. Samples: 1603628. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:13:00,963][60274] Avg episode reward: [(0, '436.816')]
[37m[1m[2025-06-29 17:13:01,023][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006256_1601536.pth...
[36m[2025-06-29 17:13:01,137][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006176_1581056.pth
[36m[2025-06-29 17:13:05,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1601536. Throughput: 0: 81.5. Samples: 1603856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:13:05,959][60274] Avg episode reward: [(0, '442.794')]
[36m[2025-06-29 17:13:10,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 1601536. Throughput: 0: 81.3. Samples: 1604372. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:13:10,955][60274] Avg episode reward: [(0, '445.092')]
[36m[2025-06-29 17:13:15,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1601536. Throughput: 0: 81.7. Samples: 1604880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:13:15,969][60274] Avg episode reward: [(0, '435.783')]
[36m[2025-06-29 17:13:20,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1601536. Throughput: 0: 82.0. Samples: 1605144. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:13:20,959][60274] Avg episode reward: [(0, '461.818')]
[36m[2025-06-29 17:13:25,969][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1605632. Throughput: 0: 83.4. Samples: 1605640. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:13:25,969][60274] Avg episode reward: [(0, '475.126')]
[36m[2025-06-29 17:13:30,960][60274] Fps is (10 sec: 409.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1605632. Throughput: 0: 81.4. Samples: 1606044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:13:30,961][60274] Avg episode reward: [(0, '469.239')]
[36m[2025-06-29 17:13:35,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1605632. Throughput: 0: 81.2. Samples: 1606288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:13:35,968][60274] Avg episode reward: [(0, '471.517')]
[36m[2025-06-29 17:13:40,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1605632. Throughput: 0: 80.9. Samples: 1606788. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:13:40,959][60274] Avg episode reward: [(0, '459.243')]
[36m[2025-06-29 17:13:45,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1605632. Throughput: 0: 81.6. Samples: 1607300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:13:45,966][60274] Avg episode reward: [(0, '480.951')]
[36m[2025-06-29 17:13:50,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1605632. Throughput: 0: 81.6. Samples: 1607528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:13:50,962][60274] Avg episode reward: [(0, '461.326')]
[36m[2025-06-29 17:13:55,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1605632. Throughput: 0: 79.8. Samples: 1607968. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:13:55,990][60274] Avg episode reward: [(0, '439.228')]
[36m[2025-06-29 17:14:00,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1605632. Throughput: 0: 79.3. Samples: 1608448. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:14:00,973][60274] Avg episode reward: [(0, '432.442')]
[36m[2025-06-29 17:14:05,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 1605632. Throughput: 0: 78.9. Samples: 1608692. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:14:05,956][60274] Avg episode reward: [(0, '429.080')]
[36m[2025-06-29 17:14:10,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1605632. Throughput: 0: 78.0. Samples: 1609152. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:14:10,967][60274] Avg episode reward: [(0, '420.731')]
[36m[2025-06-29 17:14:15,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1605632. Throughput: 0: 80.4. Samples: 1609664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:14:15,999][60274] Avg episode reward: [(0, '421.353')]
[36m[2025-06-29 17:14:20,968][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1609728. Throughput: 0: 78.8. Samples: 1609836. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 17:14:20,969][60274] Avg episode reward: [(0, '419.754')]
[36m[2025-06-29 17:14:25,947][60274] Fps is (10 sec: 411.7, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1609728. Throughput: 0: 77.5. Samples: 1610276. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 17:14:25,947][60274] Avg episode reward: [(0, '433.297')]
[36m[2025-06-29 17:14:30,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1609728. Throughput: 0: 76.5. Samples: 1610744. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 17:14:30,993][60274] Avg episode reward: [(0, '436.793')]
[36m[2025-06-29 17:14:35,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1609728. Throughput: 0: 76.5. Samples: 1610972. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 17:14:35,978][60274] Avg episode reward: [(0, '425.090')]
[36m[2025-06-29 17:14:40,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1609728. Throughput: 0: 77.2. Samples: 1611440. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 17:14:40,972][60274] Avg episode reward: [(0, '417.004')]
[36m[2025-06-29 17:14:45,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1609728. Throughput: 0: 76.6. Samples: 1611896. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 17:14:45,966][60274] Avg episode reward: [(0, '415.429')]
[36m[2025-06-29 17:14:50,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1609728. Throughput: 0: 76.5. Samples: 1612136. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 17:14:50,964][60274] Avg episode reward: [(0, '437.662')]
[36m[2025-06-29 17:14:55,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1609728. Throughput: 0: 76.8. Samples: 1612608. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 17:14:55,954][60274] Avg episode reward: [(0, '444.333')]
[31m[20523183 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[20523184 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[20523184 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 17:15:00,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1609728. Throughput: 0: 75.6. Samples: 1613064. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 17:15:00,989][60274] Avg episode reward: [(0, '428.945')]
[37m[1m[2025-06-29 17:15:01,040][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006288_1609728.pth...
[36m[2025-06-29 17:15:01,097][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006224_1593344.pth
[36m[2025-06-29 17:15:05,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1609728. Throughput: 0: 76.5. Samples: 1613280. Policy #0 lag: (min: 2.0, avg: 2.0, max: 18.0)
[36m[2025-06-29 17:15:05,981][60274] Avg episode reward: [(0, '428.408')]
[36m[2025-06-29 17:15:10,980][60274] Fps is (10 sec: 410.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1613824. Throughput: 0: 77.0. Samples: 1613744. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:15:10,981][60274] Avg episode reward: [(0, '430.714')]
[36m[2025-06-29 17:15:15,956][60274] Fps is (10 sec: 410.6, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1613824. Throughput: 0: 76.4. Samples: 1614180. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:15:15,957][60274] Avg episode reward: [(0, '436.680')]
[36m[2025-06-29 17:15:20,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1613824. Throughput: 0: 76.5. Samples: 1614416. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:15:20,990][60274] Avg episode reward: [(0, '439.662')]
[36m[2025-06-29 17:15:25,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1613824. Throughput: 0: 76.6. Samples: 1614888. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:15:25,967][60274] Avg episode reward: [(0, '446.583')]
[36m[2025-06-29 17:15:30,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1613824. Throughput: 0: 77.0. Samples: 1615360. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:15:30,963][60274] Avg episode reward: [(0, '444.327')]
[36m[2025-06-29 17:15:36,024][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1613824. Throughput: 0: 76.7. Samples: 1615592. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:15:36,024][60274] Avg episode reward: [(0, '438.463')]
[36m[2025-06-29 17:15:40,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1613824. Throughput: 0: 76.2. Samples: 1616036. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:15:40,967][60274] Avg episode reward: [(0, '439.893')]
[36m[2025-06-29 17:15:45,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1613824. Throughput: 0: 76.0. Samples: 1616484. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:15:45,982][60274] Avg episode reward: [(0, '441.498')]
[36m[2025-06-29 17:15:50,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1613824. Throughput: 0: 76.1. Samples: 1616704. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:15:50,980][60274] Avg episode reward: [(0, '437.294')]
[36m[2025-06-29 17:15:55,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1613824. Throughput: 0: 76.3. Samples: 1617176. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:15:55,961][60274] Avg episode reward: [(0, '469.338')]
[36m[2025-06-29 17:16:00,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1613824. Throughput: 0: 76.9. Samples: 1617640. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:16:00,951][60274] Avg episode reward: [(0, '459.301')]
[36m[2025-06-29 17:16:05,955][60274] Fps is (10 sec: 409.8, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1617920. Throughput: 0: 76.5. Samples: 1617856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:05,955][60274] Avg episode reward: [(0, '452.811')]
[36m[2025-06-29 17:16:10,951][60274] Fps is (10 sec: 409.6, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1617920. Throughput: 0: 75.4. Samples: 1618280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:10,951][60274] Avg episode reward: [(0, '461.427')]
[36m[2025-06-29 17:16:15,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1617920. Throughput: 0: 75.2. Samples: 1618744. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:15,986][60274] Avg episode reward: [(0, '473.471')]
[36m[2025-06-29 17:16:20,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1617920. Throughput: 0: 75.9. Samples: 1619004. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:20,966][60274] Avg episode reward: [(0, '472.087')]
[36m[2025-06-29 17:16:25,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1617920. Throughput: 0: 76.3. Samples: 1619468. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:25,950][60274] Avg episode reward: [(0, '468.779')]
[36m[2025-06-29 17:16:30,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1617920. Throughput: 0: 76.6. Samples: 1619928. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:30,953][60274] Avg episode reward: [(0, '460.538')]
[36m[2025-06-29 17:16:35,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1617920. Throughput: 0: 76.8. Samples: 1620160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:35,991][60274] Avg episode reward: [(0, '452.316')]
[36m[2025-06-29 17:16:40,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1617920. Throughput: 0: 76.9. Samples: 1620636. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:40,980][60274] Avg episode reward: [(0, '446.014')]
[36m[2025-06-29 17:16:45,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1617920. Throughput: 0: 77.3. Samples: 1621120. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:45,953][60274] Avg episode reward: [(0, '462.604')]
[36m[2025-06-29 17:16:50,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1617920. Throughput: 0: 77.9. Samples: 1621360. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:50,957][60274] Avg episode reward: [(0, '436.475')]
[36m[2025-06-29 17:16:55,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1617920. Throughput: 0: 79.4. Samples: 1621852. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:16:55,952][60274] Avg episode reward: [(0, '447.015')]
[36m[2025-06-29 17:17:01,018][60274] Fps is (10 sec: 407.1, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1622016. Throughput: 0: 77.3. Samples: 1622224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:17:01,018][60274] Avg episode reward: [(0, '421.632')]
[37m[1m[2025-06-29 17:17:01,105][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006336_1622016.pth...
[36m[2025-06-29 17:17:01,174][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006256_1601536.pth
[36m[2025-06-29 17:17:05,970][60274] Fps is (10 sec: 408.9, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1622016. Throughput: 0: 75.6. Samples: 1622408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:17:05,970][60274] Avg episode reward: [(0, '424.942')]
[36m[2025-06-29 17:17:10,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1622016. Throughput: 0: 76.2. Samples: 1622896. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:17:10,961][60274] Avg episode reward: [(0, '427.571')]
[36m[2025-06-29 17:17:15,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1622016. Throughput: 0: 77.0. Samples: 1623396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:17:15,989][60274] Avg episode reward: [(0, '417.478')]
[36m[2025-06-29 17:17:20,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1622016. Throughput: 0: 77.3. Samples: 1623640. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:17:20,985][60274] Avg episode reward: [(0, '419.900')]
[36m[2025-06-29 17:17:25,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1622016. Throughput: 0: 78.2. Samples: 1624156. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:17:25,967][60274] Avg episode reward: [(0, '413.504')]
[36m[2025-06-29 17:17:30,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1622016. Throughput: 0: 78.7. Samples: 1624664. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:17:30,967][60274] Avg episode reward: [(0, '415.857')]
[36m[2025-06-29 17:17:35,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1622016. Throughput: 0: 78.8. Samples: 1624908. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:17:35,967][60274] Avg episode reward: [(0, '427.162')]
[36m[2025-06-29 17:17:40,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1622016. Throughput: 0: 79.4. Samples: 1625424. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:17:40,952][60274] Avg episode reward: [(0, '417.584')]
[36m[2025-06-29 17:17:45,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1622016. Throughput: 0: 82.2. Samples: 1625920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:17:45,966][60274] Avg episode reward: [(0, '409.144')]
[36m[2025-06-29 17:17:50,956][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1626112. Throughput: 0: 82.5. Samples: 1626120. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:17:50,957][60274] Avg episode reward: [(0, '423.816')]
[36m[2025-06-29 17:17:55,952][60274] Fps is (10 sec: 410.2, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1626112. Throughput: 0: 81.7. Samples: 1626572. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:17:55,952][60274] Avg episode reward: [(0, '412.061')]
[36m[2025-06-29 17:18:00,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1626112. Throughput: 0: 81.1. Samples: 1627044. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:18:00,959][60274] Avg episode reward: [(0, '415.166')]
[36m[2025-06-29 17:18:05,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1626112. Throughput: 0: 81.5. Samples: 1627304. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:18:05,967][60274] Avg episode reward: [(0, '413.747')]
[36m[2025-06-29 17:18:10,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1626112. Throughput: 0: 81.5. Samples: 1627824. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:18:10,971][60274] Avg episode reward: [(0, '415.821')]
[36m[2025-06-29 17:18:15,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1626112. Throughput: 0: 82.0. Samples: 1628356. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:18:15,984][60274] Avg episode reward: [(0, '407.756')]
[36m[2025-06-29 17:18:20,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1626112. Throughput: 0: 82.5. Samples: 1628620. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:18:20,955][60274] Avg episode reward: [(0, '427.261')]
[36m[2025-06-29 17:18:25,947][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1626112. Throughput: 0: 82.2. Samples: 1629124. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:18:25,948][60274] Avg episode reward: [(0, '438.249')]
[36m[2025-06-29 17:18:30,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1626112. Throughput: 0: 82.0. Samples: 1629612. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:18:30,982][60274] Avg episode reward: [(0, '445.052')]
[36m[2025-06-29 17:18:35,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1626112. Throughput: 0: 83.1. Samples: 1629860. Policy #0 lag: (min: 9.0, avg: 9.0, max: 25.0)
[36m[2025-06-29 17:18:35,957][60274] Avg episode reward: [(0, '447.603')]
[36m[2025-06-29 17:18:40,989][60274] Fps is (10 sec: 409.3, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1630208. Throughput: 0: 83.0. Samples: 1630308. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:18:40,989][60274] Avg episode reward: [(0, '455.503')]
[36m[2025-06-29 17:18:45,965][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1630208. Throughput: 0: 83.8. Samples: 1630816. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:18:45,965][60274] Avg episode reward: [(0, '465.884')]
[31m[20756131 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[20756131 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[20756131 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 17:18:50,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1630208. Throughput: 0: 83.7. Samples: 1631068. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:18:50,955][60274] Avg episode reward: [(0, '459.353')]
[36m[2025-06-29 17:18:55,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1630208. Throughput: 0: 83.5. Samples: 1631580. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:18:55,948][60274] Avg episode reward: [(0, '465.066')]
[36m[2025-06-29 17:19:00,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1630208. Throughput: 0: 82.5. Samples: 1632064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:00,950][60274] Avg episode reward: [(0, '452.084')]
[37m[1m[2025-06-29 17:19:00,999][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006368_1630208.pth...
[36m[2025-06-29 17:19:01,057][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006288_1609728.pth
[36m[2025-06-29 17:19:05,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1630208. Throughput: 0: 81.7. Samples: 1632300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:05,981][60274] Avg episode reward: [(0, '458.406')]
[36m[2025-06-29 17:19:10,998][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1630208. Throughput: 0: 81.5. Samples: 1632796. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:10,998][60274] Avg episode reward: [(0, '460.461')]
[36m[2025-06-29 17:19:15,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1630208. Throughput: 0: 82.0. Samples: 1633304. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:15,986][60274] Avg episode reward: [(0, '477.169')]
[36m[2025-06-29 17:19:20,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1630208. Throughput: 0: 82.3. Samples: 1633564. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:20,949][60274] Avg episode reward: [(0, '471.311')]
[36m[2025-06-29 17:19:25,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1630208. Throughput: 0: 82.8. Samples: 1634032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:25,972][60274] Avg episode reward: [(0, '471.284')]
[36m[2025-06-29 17:19:30,961][60274] Fps is (10 sec: 409.1, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1634304. Throughput: 0: 80.8. Samples: 1634452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:30,961][60274] Avg episode reward: [(0, '463.407')]
[36m[2025-06-29 17:19:35,986][60274] Fps is (10 sec: 409.0, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1634304. Throughput: 0: 80.7. Samples: 1634700. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:35,986][60274] Avg episode reward: [(0, '470.868')]
[36m[2025-06-29 17:19:40,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1634304. Throughput: 0: 79.8. Samples: 1635172. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:40,962][60274] Avg episode reward: [(0, '456.054')]
[36m[2025-06-29 17:19:45,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1634304. Throughput: 0: 79.6. Samples: 1635648. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:45,962][60274] Avg episode reward: [(0, '453.102')]
[36m[2025-06-29 17:19:50,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1634304. Throughput: 0: 79.2. Samples: 1635860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:50,949][60274] Avg episode reward: [(0, '463.913')]
[36m[2025-06-29 17:19:55,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1634304. Throughput: 0: 79.5. Samples: 1636372. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:19:55,970][60274] Avg episode reward: [(0, '454.011')]
[36m[2025-06-29 17:20:00,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1634304. Throughput: 0: 79.0. Samples: 1636856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:20:00,957][60274] Avg episode reward: [(0, '443.626')]
[36m[2025-06-29 17:20:05,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1634304. Throughput: 0: 78.3. Samples: 1637092. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:20:05,987][60274] Avg episode reward: [(0, '444.573')]
[36m[2025-06-29 17:20:10,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1634304. Throughput: 0: 78.6. Samples: 1637568. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:20:10,962][60274] Avg episode reward: [(0, '458.581')]
[36m[2025-06-29 17:20:15,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1634304. Throughput: 0: 78.4. Samples: 1637980. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:20:15,958][60274] Avg episode reward: [(0, '456.464')]
[36m[2025-06-29 17:20:20,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1634304. Throughput: 0: 78.0. Samples: 1638208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:20:20,957][60274] Avg episode reward: [(0, '444.118')]
[36m[2025-06-29 17:20:25,964][60274] Fps is (10 sec: 409.3, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1638400. Throughput: 0: 76.3. Samples: 1638604. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 17:20:25,965][60274] Avg episode reward: [(0, '449.519')]
[36m[2025-06-29 17:20:30,949][60274] Fps is (10 sec: 409.9, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1638400. Throughput: 0: 76.5. Samples: 1639088. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 17:20:30,949][60274] Avg episode reward: [(0, '443.846')]
[36m[2025-06-29 17:20:35,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1638400. Throughput: 0: 77.1. Samples: 1639332. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 17:20:35,975][60274] Avg episode reward: [(0, '449.667')]
[36m[2025-06-29 17:20:40,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1638400. Throughput: 0: 75.8. Samples: 1639784. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 17:20:40,980][60274] Avg episode reward: [(0, '457.023')]
[36m[2025-06-29 17:20:46,005][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1638400. Throughput: 0: 75.3. Samples: 1640248. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 17:20:46,006][60274] Avg episode reward: [(0, '469.379')]
[36m[2025-06-29 17:20:50,948][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1638400. Throughput: 0: 75.2. Samples: 1640472. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 17:20:50,949][60274] Avg episode reward: [(0, '469.464')]
[36m[2025-06-29 17:20:55,978][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1638400. Throughput: 0: 74.4. Samples: 1640916. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 17:20:55,979][60274] Avg episode reward: [(0, '487.719')]
[36m[2025-06-29 17:21:00,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1638400. Throughput: 0: 75.1. Samples: 1641364. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 17:21:00,988][60274] Avg episode reward: [(0, '473.521')]
[37m[1m[2025-06-29 17:21:01,049][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006400_1638400.pth...
[36m[2025-06-29 17:21:01,109][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006336_1622016.pth
[36m[2025-06-29 17:21:06,006][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1638400. Throughput: 0: 75.3. Samples: 1641600. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 17:21:06,006][60274] Avg episode reward: [(0, '475.296')]
[36m[2025-06-29 17:21:10,991][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1638400. Throughput: 0: 76.2. Samples: 1642036. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-06-29 17:21:10,992][60274] Avg episode reward: [(0, '451.178')]
[36m[2025-06-29 17:21:16,158][60274] Fps is (10 sec: 403.5, 60 sec: 136.1, 300 sec: 83.3). Total num frames: 1642496. Throughput: 0: 75.3. Samples: 1642492. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:21:16,158][60274] Avg episode reward: [(0, '461.743')]
[36m[2025-06-29 17:21:20,992][60274] Fps is (10 sec: 409.6, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1642496. Throughput: 0: 74.1. Samples: 1642668. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:21:20,992][60274] Avg episode reward: [(0, '456.701')]
[36m[2025-06-29 17:21:25,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1642496. Throughput: 0: 72.4. Samples: 1643040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:21:25,970][60274] Avg episode reward: [(0, '466.900')]
[36m[2025-06-29 17:21:30,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1642496. Throughput: 0: 71.2. Samples: 1643452. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:21:30,989][60274] Avg episode reward: [(0, '481.676')]
[36m[2025-06-29 17:21:35,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1642496. Throughput: 0: 71.0. Samples: 1643668. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:21:35,951][60274] Avg episode reward: [(0, '492.943')]
[37m[1m[2025-06-29 17:21:36,017][60274] Saving new best policy, reward=492.943!
[36m[2025-06-29 17:21:40,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1642496. Throughput: 0: 71.6. Samples: 1644136. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:21:40,980][60274] Avg episode reward: [(0, '496.494')]
[37m[1m[2025-06-29 17:21:41,031][60274] Saving new best policy, reward=496.494!
[36m[2025-06-29 17:21:45,986][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1642496. Throughput: 0: 71.9. Samples: 1644600. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:21:45,986][60274] Avg episode reward: [(0, '494.403')]
[36m[2025-06-29 17:21:50,958][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1642496. Throughput: 0: 72.0. Samples: 1644836. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:21:50,958][60274] Avg episode reward: [(0, '480.720')]
[36m[2025-06-29 17:21:55,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1642496. Throughput: 0: 72.6. Samples: 1645300. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:21:55,951][60274] Avg episode reward: [(0, '492.252')]
[36m[2025-06-29 17:22:00,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1642496. Throughput: 0: 73.8. Samples: 1645800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:00,986][60274] Avg episode reward: [(0, '502.331')]
[37m[1m[2025-06-29 17:22:01,041][60274] Saving new best policy, reward=502.331!
[36m[2025-06-29 17:22:05,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1642496. Throughput: 0: 75.3. Samples: 1646056. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:05,980][60274] Avg episode reward: [(0, '500.084')]
[36m[2025-06-29 17:22:11,005][60274] Fps is (10 sec: 408.8, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1646592. Throughput: 0: 78.2. Samples: 1646560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:11,006][60274] Avg episode reward: [(0, '506.588')]
[37m[1m[2025-06-29 17:22:11,058][60274] Saving new best policy, reward=506.588!
[36m[2025-06-29 17:22:15,984][60274] Fps is (10 sec: 409.4, 60 sec: 68.5, 300 sec: 83.3). Total num frames: 1646592. Throughput: 0: 78.1. Samples: 1646968. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:15,985][60274] Avg episode reward: [(0, '494.405')]
[36m[2025-06-29 17:22:20,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1646592. Throughput: 0: 78.8. Samples: 1647212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:20,951][60274] Avg episode reward: [(0, '503.152')]
[36m[2025-06-29 17:22:26,004][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1646592. Throughput: 0: 78.6. Samples: 1647676. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:26,004][60274] Avg episode reward: [(0, '490.374')]
[36m[2025-06-29 17:22:30,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1646592. Throughput: 0: 77.9. Samples: 1648104. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:30,978][60274] Avg episode reward: [(0, '493.582')]
[36m[2025-06-29 17:22:35,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1646592. Throughput: 0: 77.2. Samples: 1648308. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:35,960][60274] Avg episode reward: [(0, '479.164')]
[31m[20985351 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[20985351 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[20985351 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-06-29 17:22:40,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1646592. Throughput: 0: 76.1. Samples: 1648728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:40,968][60274] Avg episode reward: [(0, '463.572')]
[36m[2025-06-29 17:22:45,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1646592. Throughput: 0: 75.3. Samples: 1649188. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:45,954][60274] Avg episode reward: [(0, '471.491')]
[36m[2025-06-29 17:22:50,975][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1646592. Throughput: 0: 74.3. Samples: 1649400. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:50,975][60274] Avg episode reward: [(0, '464.492')]
[36m[2025-06-29 17:22:55,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1646592. Throughput: 0: 73.3. Samples: 1649856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:22:55,986][60274] Avg episode reward: [(0, '462.289')]
[36m[2025-06-29 17:23:00,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1646592. Throughput: 0: 73.9. Samples: 1650292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:23:00,963][60274] Avg episode reward: [(0, '472.141')]
[37m[1m[2025-06-29 17:23:01,017][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006432_1646592.pth...
[36m[2025-06-29 17:23:01,072][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006368_1630208.pth
[36m[2025-06-29 17:23:06,000][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1646592. Throughput: 0: 73.1. Samples: 1650504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:23:06,001][60274] Avg episode reward: [(0, '450.605')]
[36m[2025-06-29 17:23:10,971][60274] Fps is (10 sec: 409.3, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1650688. Throughput: 0: 71.1. Samples: 1650872. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 17:23:10,971][60274] Avg episode reward: [(0, '471.768')]
[36m[2025-06-29 17:23:15,989][60274] Fps is (10 sec: 410.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1650688. Throughput: 0: 71.4. Samples: 1651316. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 17:23:15,990][60274] Avg episode reward: [(0, '480.011')]
[36m[2025-06-29 17:23:20,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1650688. Throughput: 0: 71.7. Samples: 1651532. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 17:23:20,953][60274] Avg episode reward: [(0, '468.152')]
[36m[2025-06-29 17:23:25,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1650688. Throughput: 0: 73.0. Samples: 1652012. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 17:23:25,984][60274] Avg episode reward: [(0, '465.736')]
[36m[2025-06-29 17:23:30,980][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1650688. Throughput: 0: 73.6. Samples: 1652500. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 17:23:30,981][60274] Avg episode reward: [(0, '433.103')]
[36m[2025-06-29 17:23:35,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1650688. Throughput: 0: 73.9. Samples: 1652724. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 17:23:35,979][60274] Avg episode reward: [(0, '436.891')]
[36m[2025-06-29 17:23:40,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1650688. Throughput: 0: 73.8. Samples: 1653176. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 17:23:40,990][60274] Avg episode reward: [(0, '429.779')]
[36m[2025-06-29 17:23:45,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1650688. Throughput: 0: 74.6. Samples: 1653648. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 17:23:45,969][60274] Avg episode reward: [(0, '439.998')]
[36m[2025-06-29 17:23:50,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1650688. Throughput: 0: 75.5. Samples: 1653900. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 17:23:50,963][60274] Avg episode reward: [(0, '428.204')]
[36m[2025-06-29 17:23:55,966][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1650688. Throughput: 0: 77.1. Samples: 1654340. Policy #0 lag: (min: 1.0, avg: 1.0, max: 17.0)
[36m[2025-06-29 17:23:55,966][60274] Avg episode reward: [(0, '423.118')]
[36m[2025-06-29 17:24:00,969][60274] Fps is (10 sec: 409.4, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1654784. Throughput: 0: 77.3. Samples: 1654792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:00,969][60274] Avg episode reward: [(0, '425.096')]
[36m[2025-06-29 17:24:05,955][60274] Fps is (10 sec: 410.0, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1654784. Throughput: 0: 77.2. Samples: 1655008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:05,955][60274] Avg episode reward: [(0, '408.224')]
[36m[2025-06-29 17:24:10,995][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1654784. Throughput: 0: 77.0. Samples: 1655480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:10,995][60274] Avg episode reward: [(0, '414.725')]
[36m[2025-06-29 17:24:15,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1654784. Throughput: 0: 76.8. Samples: 1655956. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:15,954][60274] Avg episode reward: [(0, '427.778')]
[36m[2025-06-29 17:24:20,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1654784. Throughput: 0: 77.1. Samples: 1656192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:20,961][60274] Avg episode reward: [(0, '409.746')]
[36m[2025-06-29 17:24:25,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1654784. Throughput: 0: 76.5. Samples: 1656616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:25,985][60274] Avg episode reward: [(0, '424.588')]
[36m[2025-06-29 17:24:30,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1654784. Throughput: 0: 75.9. Samples: 1657064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:30,973][60274] Avg episode reward: [(0, '407.990')]
[36m[2025-06-29 17:24:36,002][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1654784. Throughput: 0: 75.4. Samples: 1657296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:36,002][60274] Avg episode reward: [(0, '424.087')]
[36m[2025-06-29 17:24:40,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1654784. Throughput: 0: 76.5. Samples: 1657780. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:40,952][60274] Avg episode reward: [(0, '408.653')]
[36m[2025-06-29 17:24:45,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1654784. Throughput: 0: 76.3. Samples: 1658224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:45,973][60274] Avg episode reward: [(0, '405.229')]
[36m[2025-06-29 17:24:50,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1654784. Throughput: 0: 76.1. Samples: 1658432. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:50,952][60274] Avg episode reward: [(0, '384.766')]
[36m[2025-06-29 17:24:55,952][60274] Fps is (10 sec: 410.5, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1658880. Throughput: 0: 75.2. Samples: 1658860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:24:55,953][60274] Avg episode reward: [(0, '396.472')]
[36m[2025-06-29 17:25:00,950][60274] Fps is (10 sec: 409.7, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1658880. Throughput: 0: 73.9. Samples: 1659280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:25:00,951][60274] Avg episode reward: [(0, '414.811')]
[37m[1m[2025-06-29 17:25:01,022][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006480_1658880.pth...
[36m[2025-06-29 17:25:01,080][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006400_1638400.pth
[36m[2025-06-29 17:25:05,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1658880. Throughput: 0: 73.3. Samples: 1659492. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:25:05,951][60274] Avg episode reward: [(0, '400.159')]
[36m[2025-06-29 17:25:10,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1658880. Throughput: 0: 74.0. Samples: 1659944. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:25:10,988][60274] Avg episode reward: [(0, '391.259')]
[36m[2025-06-29 17:25:15,996][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1658880. Throughput: 0: 74.0. Samples: 1660396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:25:15,996][60274] Avg episode reward: [(0, '397.560')]
[36m[2025-06-29 17:25:20,993][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1658880. Throughput: 0: 74.1. Samples: 1660632. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:25:20,994][60274] Avg episode reward: [(0, '395.671')]
[36m[2025-06-29 17:25:25,992][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1658880. Throughput: 0: 74.0. Samples: 1661112. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:25:25,992][60274] Avg episode reward: [(0, '414.561')]
[36m[2025-06-29 17:25:30,959][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1658880. Throughput: 0: 74.8. Samples: 1661588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:25:30,959][60274] Avg episode reward: [(0, '391.736')]
[36m[2025-06-29 17:25:35,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1658880. Throughput: 0: 75.2. Samples: 1661820. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:25:35,981][60274] Avg episode reward: [(0, '376.305')]
[36m[2025-06-29 17:25:40,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1658880. Throughput: 0: 76.8. Samples: 1662316. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:25:40,970][60274] Avg episode reward: [(0, '365.619')]
[36m[2025-06-29 17:25:45,964][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1658880. Throughput: 0: 78.5. Samples: 1662812. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:25:45,964][60274] Avg episode reward: [(0, '374.296')]
[36m[2025-06-29 17:25:50,973][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1662976. Throughput: 0: 78.2. Samples: 1663012. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 17:25:50,973][60274] Avg episode reward: [(0, '368.571')]
[36m[2025-06-29 17:25:55,993][60274] Fps is (10 sec: 408.4, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1662976. Throughput: 0: 79.7. Samples: 1663532. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 17:25:55,994][60274] Avg episode reward: [(0, '365.493')]
[36m[2025-06-29 17:26:00,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1662976. Throughput: 0: 81.3. Samples: 1664052. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 17:26:00,950][60274] Avg episode reward: [(0, '358.441')]
[36m[2025-06-29 17:26:05,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1662976. Throughput: 0: 81.4. Samples: 1664292. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 17:26:05,967][60274] Avg episode reward: [(0, '361.229')]
[36m[2025-06-29 17:26:10,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.5). Total num frames: 1662976. Throughput: 0: 82.2. Samples: 1664808. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 17:26:10,971][60274] Avg episode reward: [(0, '371.733')]
[36m[2025-06-29 17:26:15,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1662976. Throughput: 0: 82.6. Samples: 1665304. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 17:26:15,965][60274] Avg episode reward: [(0, '343.692')]
[36m[2025-06-29 17:26:20,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1662976. Throughput: 0: 82.7. Samples: 1665540. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 17:26:20,953][60274] Avg episode reward: [(0, '353.233')]
[36m[2025-06-29 17:26:25,961][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1662976. Throughput: 0: 82.7. Samples: 1666036. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 17:26:25,961][60274] Avg episode reward: [(0, '336.535')]
[36m[2025-06-29 17:26:30,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1662976. Throughput: 0: 82.8. Samples: 1666540. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 17:26:30,986][60274] Avg episode reward: [(0, '352.853')]
[36m[2025-06-29 17:26:35,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1662976. Throughput: 0: 83.8. Samples: 1666780. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-06-29 17:26:35,957][60274] Avg episode reward: [(0, '362.204')]
[36m[2025-06-29 17:26:40,974][60274] Fps is (10 sec: 410.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1667072. Throughput: 0: 82.1. Samples: 1667224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:26:40,974][60274] Avg episode reward: [(0, '367.415')]
[36m[2025-06-29 17:26:45,963][60274] Fps is (10 sec: 409.3, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1667072. Throughput: 0: 81.6. Samples: 1667724. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:26:45,963][60274] Avg episode reward: [(0, '340.711')]
[36m[2025-06-29 17:26:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1667072. Throughput: 0: 81.8. Samples: 1667972. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:26:50,976][60274] Avg episode reward: [(0, '343.273')]
[36m[2025-06-29 17:26:55,951][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1667072. Throughput: 0: 81.5. Samples: 1668472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:26:55,952][60274] Avg episode reward: [(0, '363.280')]
[36m[2025-06-29 17:27:00,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1667072. Throughput: 0: 81.3. Samples: 1668964. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:00,968][60274] Avg episode reward: [(0, '350.844')]
[37m[1m[2025-06-29 17:27:01,015][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006512_1667072.pth...
[36m[2025-06-29 17:27:01,072][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006432_1646592.pth
[36m[2025-06-29 17:27:05,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1667072. Throughput: 0: 81.5. Samples: 1669212. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:05,991][60274] Avg episode reward: [(0, '342.845')]
[36m[2025-06-29 17:27:10,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1667072. Throughput: 0: 81.2. Samples: 1669688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:10,950][60274] Avg episode reward: [(0, '343.776')]
[36m[2025-06-29 17:27:15,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1667072. Throughput: 0: 81.1. Samples: 1670192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:15,999][60274] Avg episode reward: [(0, '351.487')]
[36m[2025-06-29 17:27:20,950][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1667072. Throughput: 0: 81.4. Samples: 1670444. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:20,950][60274] Avg episode reward: [(0, '362.456')]
[36m[2025-06-29 17:27:25,977][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1667072. Throughput: 0: 82.6. Samples: 1670940. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:25,977][60274] Avg episode reward: [(0, '368.943')]
[36m[2025-06-29 17:27:30,966][60274] Fps is (10 sec: 408.9, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1671168. Throughput: 0: 81.8. Samples: 1671404. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:30,966][60274] Avg episode reward: [(0, '381.227')]
[36m[2025-06-29 17:27:35,979][60274] Fps is (10 sec: 409.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1671168. Throughput: 0: 81.3. Samples: 1671632. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:35,979][60274] Avg episode reward: [(0, '368.007')]
[36m[2025-06-29 17:27:40,971][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1671168. Throughput: 0: 79.9. Samples: 1672068. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:40,971][60274] Avg episode reward: [(0, '373.345')]
[36m[2025-06-29 17:27:45,990][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1671168. Throughput: 0: 79.7. Samples: 1672552. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:45,990][60274] Avg episode reward: [(0, '365.245')]
[36m[2025-06-29 17:27:50,985][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1671168. Throughput: 0: 79.6. Samples: 1672792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:50,985][60274] Avg episode reward: [(0, '356.874')]
[36m[2025-06-29 17:27:56,033][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1671168. Throughput: 0: 79.4. Samples: 1673268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:27:56,033][60274] Avg episode reward: [(0, '367.397')]
[36m[2025-06-29 17:28:00,984][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1671168. Throughput: 0: 78.3. Samples: 1673716. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:00,984][60274] Avg episode reward: [(0, '384.265')]
[36m[2025-06-29 17:28:05,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1671168. Throughput: 0: 78.0. Samples: 1673960. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:05,999][60274] Avg episode reward: [(0, '389.143')]
[36m[2025-06-29 17:28:10,974][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1671168. Throughput: 0: 76.8. Samples: 1674396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:10,974][60274] Avg episode reward: [(0, '392.948')]
[36m[2025-06-29 17:28:15,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1671168. Throughput: 0: 76.5. Samples: 1674844. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:15,953][60274] Avg episode reward: [(0, '395.214')]
[36m[2025-06-29 17:28:20,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1671168. Throughput: 0: 75.9. Samples: 1675044. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:20,954][60274] Avg episode reward: [(0, '387.092')]
[36m[2025-06-29 17:28:25,981][60274] Fps is (10 sec: 408.5, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1675264. Throughput: 0: 74.4. Samples: 1675416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:25,981][60274] Avg episode reward: [(0, '387.196')]
[36m[2025-06-29 17:28:30,975][60274] Fps is (10 sec: 408.7, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1675264. Throughput: 0: 73.5. Samples: 1675860. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:30,976][60274] Avg episode reward: [(0, '362.026')]
[36m[2025-06-29 17:28:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1675264. Throughput: 0: 73.4. Samples: 1676092. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:35,972][60274] Avg episode reward: [(0, '371.721')]
[36m[2025-06-29 17:28:40,949][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1675264. Throughput: 0: 74.2. Samples: 1676600. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:40,949][60274] Avg episode reward: [(0, '389.466')]
[36m[2025-06-29 17:28:45,979][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1675264. Throughput: 0: 74.6. Samples: 1677072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:45,980][60274] Avg episode reward: [(0, '371.138')]
[36m[2025-06-29 17:28:50,969][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1675264. Throughput: 0: 72.7. Samples: 1677228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:50,969][60274] Avg episode reward: [(0, '380.158')]
[36m[2025-06-29 17:28:55,962][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1675264. Throughput: 0: 72.2. Samples: 1677644. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:28:55,962][60274] Avg episode reward: [(0, '385.140')]
[36m[2025-06-29 17:29:00,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1675264. Throughput: 0: 71.9. Samples: 1678080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:29:00,971][60274] Avg episode reward: [(0, '394.073')]
[37m[1m[2025-06-29 17:29:01,024][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006544_1675264.pth...
[36m[2025-06-29 17:29:01,097][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006480_1658880.pth
[36m[2025-06-29 17:29:05,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1675264. Throughput: 0: 71.9. Samples: 1678280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:29:05,988][60274] Avg episode reward: [(0, '393.001')]
[36m[2025-06-29 17:29:10,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1675264. Throughput: 0: 74.1. Samples: 1678748. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:29:10,960][60274] Avg episode reward: [(0, '412.647')]
[36m[2025-06-29 17:29:15,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1675264. Throughput: 0: 75.5. Samples: 1679260. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:29:15,989][60274] Avg episode reward: [(0, '412.823')]
[36m[2025-06-29 17:29:20,947][60274] Fps is (10 sec: 410.1, 60 sec: 136.5, 300 sec: 83.3). Total num frames: 1679360. Throughput: 0: 74.8. Samples: 1679456. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:29:20,947][60274] Avg episode reward: [(0, '415.858')]
[36m[2025-06-29 17:29:25,952][60274] Fps is (10 sec: 411.1, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1679360. Throughput: 0: 74.8. Samples: 1679964. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:29:25,952][60274] Avg episode reward: [(0, '401.697')]
[36m[2025-06-29 17:29:30,960][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1679360. Throughput: 0: 75.8. Samples: 1680480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:29:30,960][60274] Avg episode reward: [(0, '418.467')]
[36m[2025-06-29 17:29:35,972][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1679360. Throughput: 0: 77.9. Samples: 1680732. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:29:35,973][60274] Avg episode reward: [(0, '413.332')]
[36m[2025-06-29 17:29:40,989][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1679360. Throughput: 0: 79.7. Samples: 1681232. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:29:40,989][60274] Avg episode reward: [(0, '425.041')]
[36m[2025-06-29 17:29:45,988][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1679360. Throughput: 0: 80.9. Samples: 1681724. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:29:45,989][60274] Avg episode reward: [(0, '425.570')]
[36m[2025-06-29 17:29:50,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1679360. Throughput: 0: 82.2. Samples: 1681976. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:29:50,976][60274] Avg episode reward: [(0, '413.919')]
[36m[2025-06-29 17:29:55,965][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1679360. Throughput: 0: 82.5. Samples: 1682460. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:29:55,966][60274] Avg episode reward: [(0, '411.361')]
[36m[2025-06-29 17:30:00,952][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1679360. Throughput: 0: 82.1. Samples: 1682952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:30:00,952][60274] Avg episode reward: [(0, '420.595')]
[36m[2025-06-29 17:30:05,956][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1679360. Throughput: 0: 83.2. Samples: 1683200. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-06-29 17:30:05,957][60274] Avg episode reward: [(0, '417.113')]
[36m[2025-06-29 17:30:10,997][60274] Fps is (10 sec: 407.7, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1683456. Throughput: 0: 82.0. Samples: 1683656. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:30:10,998][60274] Avg episode reward: [(0, '401.416')]
[36m[2025-06-29 17:30:15,966][60274] Fps is (10 sec: 409.2, 60 sec: 136.6, 300 sec: 83.3). Total num frames: 1683456. Throughput: 0: 80.6. Samples: 1684108. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:30:15,967][60274] Avg episode reward: [(0, '412.781')]
[36m[2025-06-29 17:30:20,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1683456. Throughput: 0: 79.8. Samples: 1684324. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:30:20,982][60274] Avg episode reward: [(0, '400.579')]
[36m[2025-06-29 17:30:25,970][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1683456. Throughput: 0: 79.4. Samples: 1684804. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:30:25,970][60274] Avg episode reward: [(0, '409.757')]
[36m[2025-06-29 17:30:30,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1683456. Throughput: 0: 79.3. Samples: 1685292. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:30:30,968][60274] Avg episode reward: [(0, '423.670')]
[36m[2025-06-29 17:30:35,982][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1683456. Throughput: 0: 78.7. Samples: 1685516. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:30:35,983][60274] Avg episode reward: [(0, '417.907')]
[36m[2025-06-29 17:30:40,955][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1683456. Throughput: 0: 77.6. Samples: 1685952. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:30:40,955][60274] Avg episode reward: [(0, '420.045')]
[36m[2025-06-29 17:30:45,957][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1683456. Throughput: 0: 76.6. Samples: 1686400. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:30:45,957][60274] Avg episode reward: [(0, '431.517')]
[36m[2025-06-29 17:30:50,968][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1683456. Throughput: 0: 76.3. Samples: 1686636. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:30:50,968][60274] Avg episode reward: [(0, '414.777')]
[36m[2025-06-29 17:30:55,954][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1683456. Throughput: 0: 76.1. Samples: 1687076. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:30:55,954][60274] Avg episode reward: [(0, '405.314')]
[36m[2025-06-29 17:31:00,967][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1683456. Throughput: 0: 75.2. Samples: 1687492. Policy #0 lag: (min: 14.0, avg: 14.0, max: 30.0)
[36m[2025-06-29 17:31:00,967][60274] Avg episode reward: [(0, '434.166')]
[37m[1m[2025-06-29 17:31:01,036][60274] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006576_1683456.pth...
[36m[2025-06-29 17:31:01,098][60274] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/team_entity_test/checkpoint_p0/checkpoint_000006512_1667072.pth
[36m[2025-06-29 17:31:05,996][60274] Fps is (10 sec: 407.9, 60 sec: 136.4, 300 sec: 83.3). Total num frames: 1687552. Throughput: 0: 73.3. Samples: 1687624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:05,996][60274] Avg episode reward: [(0, '420.644')]
[36m[2025-06-29 17:31:10,954][60274] Fps is (10 sec: 410.1, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1687552. Throughput: 0: 70.8. Samples: 1687988. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:10,954][60274] Avg episode reward: [(0, '429.518')]
[36m[2025-06-29 17:31:16,008][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1687552. Throughput: 0: 67.7. Samples: 1688340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:16,008][60274] Avg episode reward: [(0, '419.423')]
[36m[2025-06-29 17:31:20,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1687552. Throughput: 0: 66.0. Samples: 1688484. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:20,964][60274] Avg episode reward: [(0, '403.548')]
[36m[2025-06-29 17:31:25,999][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1687552. Throughput: 0: 64.1. Samples: 1688840. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:26,000][60274] Avg episode reward: [(0, '406.551')]
[36m[2025-06-29 17:31:30,963][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1687552. Throughput: 0: 63.6. Samples: 1689264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:30,963][60274] Avg episode reward: [(0, '431.739')]
[36m[2025-06-29 17:31:35,976][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1687552. Throughput: 0: 62.7. Samples: 1689456. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:35,977][60274] Avg episode reward: [(0, '416.158')]
[36m[2025-06-29 17:31:40,953][60274] Fps is (10 sec: 0.0, 60 sec: 68.3, 300 sec: 69.4). Total num frames: 1687552. Throughput: 0: 64.2. Samples: 1689964. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:40,953][60274] Avg episode reward: [(0, '427.447')]
[36m[2025-06-29 17:31:45,973][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1687552. Throughput: 0: 65.5. Samples: 1690440. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:45,973][60274] Avg episode reward: [(0, '423.974')]
[36m[2025-06-29 17:31:50,983][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1687552. Throughput: 0: 66.7. Samples: 1690624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:50,983][60274] Avg episode reward: [(0, '426.597')]
[36m[2025-06-29 17:31:55,987][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1687552. Throughput: 0: 68.9. Samples: 1691092. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:31:55,987][60274] Avg episode reward: [(0, '440.542')]
[36m[2025-06-29 17:32:00,981][60274] Fps is (10 sec: 0.0, 60 sec: 68.2, 300 sec: 69.4). Total num frames: 1687552. Throughput: 0: 71.4. Samples: 1691552. Policy #0 lag: (min: 15.0, avg: 15.0, max: 31.0)
[36m[2025-06-29 17:32:00,981][60274] Avg episode reward: [(0, '437.212')]
[36m[2025-06-29 17:32:05,966][60274] Fps is (10 sec: 410.4, 60 sec: 68.3, 300 sec: 83.3). Total num frames: 1691648. Throughput: 0: 72.2. Samples: 1691732. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:32:05,966][60274] Avg episode reward: [(0, '428.680')]
[36m[2025-06-29 17:32:10,969][60274] Fps is (10 sec: 410.1, 60 sec: 68.2, 300 sec: 83.3). Total num frames: 1691648. Throughput: 0: 75.2. Samples: 1692220. Policy #0 lag: (min: 8.0, avg: 8.0, max: 24.0)
[36m[2025-06-29 17:32:10,969][60274] Avg episode reward: [(0, '431.097')]
[37m[1m[2025-06-29 17:32:12,751][60274] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 60274], exiting...
[37m[1m[2025-06-29 17:32:12,752][60274] Runner profile tree view:
[37m[1mmain_loop: 21544.1743
[37m[1m[2025-06-29 17:32:12,752][60274] Collected {0: 1691648}, FPS: 78.5