{"global_step": 2560, "_timestamp": 1751550984.2305913, "stats/master_process_memory_mb": 7506.3515625, "_runtime": 52, "_step": 5, "train/lr": 0.00044999999227002263, "train/actual_lr": 0.00044999999227002263, "train/obs_running_mean": 0.24690191447734833, "train/obs_running_std": 0.9556501507759094, "train/returns_running_mean": -8.608165740966797, "train/returns_running_std": 1.7270736694335938, "train/valids_fraction": 1.0, "train/same_policy_fraction": 1.0, "train/grad_norm": 0.9999996423721313, "train/loss": 0.47296926379203796, "train/value": -0.31879308819770813, "train/entropy": 4.082220077514648, "train/policy_loss": -0.0033066272735595703, "train/kl_loss": 0.0014267581282183528, "train/value_loss": 0.47893136739730835, "train/exploration_loss": -0.0040822201408445835, "train/act_min": -3.003183364868164, "train/act_max": 4.20444393157959, "train/adv_min": -2.3135976791381836, "train/adv_max": 2.6370317935943604, "train/adv_std": 0.9089205265045166, "train/adv_mean": 0.455069899559021, "train/max_abs_logprob": 0.761380136013031, "train/action_mean": 0.0133085697889328, "train/action_mean_min": -0.49744847416877747, "train/action_mean_max": 0.7774029970169067, "train/action_log_std_mean": -0.0581984743475914, "train/action_log_std_min": -0.6537768840789795, "train/action_log_std_max": 0.4513249695301056, "train/action_stddev_mean": 0.9590190649032593, "train/action_stddev_min": 0.5200778245925903, "train/action_stddev_max": 1.5703915357589722, "train/adam_max_second_moment": 0.004296779166907072, "train/version_diff_avg": 4.5, "train/version_diff_min": 4.0, "train/version_diff_max": 20.0, "perf/_fps": 102.85844421386719, "stats/memory_policy_worker": 7506.3515625, "stats/gpu_mem_policy_worker": 55.15622329711914, "stats/gpu_cache_policy_worker": 92.27468872070312, "stats/avg_request_count": 1.0, "stats/memory_learner": 7506.3515625, "stats/gpu_mem_learner": 55.72556686401367, "stats/gpu_cache_learner": 92.27468872070312, "perf/_sample_throughput": 67.31077575683594, "reward/reward": -102.9905014038086, "reward/reward_min": -133.3094024658203, "reward/reward_max": -61.5833854675293, "len/len": 7.039999961853027, "len/len_min": 2.0, "len/len_max": 12.0, "policy_stats/avg_min_raw_reward": -100.0, "policy_stats/avg_max_raw_reward": 2.3661835193634033, "train/kl_divergence": 0.03140665590763092, "train/kl_divergence_max": 0.08986730873584747, "train/value_delta": 0.14476527273654938, "train/value_delta_max": 0.43555349111557007, "train/fraction_clipped": 0.375, "train/ratio_mean": 0.18400081992149353, "train/ratio_min": 0.3766821324825287, "train/ratio_max": 1.959649682044983, "train/num_sgd_steps": 16.0}