Importing module 'gym_38' (/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
[36m[2025-07-02 15:32:05,778][582981] Queried available GPUs: 0
[37m[1m[2025-07-02 15:32:05,779][582981] Environment var CUDA_VISIBLE_DEVICES is 0
PyTorch version 1.13.1
Device count 1
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
Warp 1.0.0-beta.5 initialized:
   CUDA Toolkit: 11.5, Driver: 12.4
   Devices:
     "cpu"    | x86_64
     "cuda:0" | NVIDIA GeForce RTX 4080 Laptop GPU (sm_89)
   Kernel cache: /home/ziyar/.cache/warp/1.0.0-beta.5
[SUBPROCESS] FORCING viewer mode for rollout worker: headless=False
[SUBPROCESS] DCE task action_space_dim: 3
[SUBPROCESS] Target Sample Factory action space: 3D
[SUBPROCESS] Setting num_envs to 128 based on env_agents=128
[SUBPROCESS] Set SF_ENV_AGENTS=128 environment variable
[SUBPROCESS] DCE config batch_size: 16384
[SUBPROCESS] Using MAXIMUM PARALLELIZATION DCE CONFIG (128 environments)
[SUBPROCESS] FORCING headless=False for rollout worker
[SUBPROCESS] FORCING viewer mode for rollout worker
Registered quad_with_obstacles and dce_navigation_task in subprocess
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles', '--train_for_env_steps=100000000', '--experiment=HIGH_CONFIG_128ENV_4', '--async_rl=True', '--use_env_info_cache=False', '--normalize_input=True', '--async_rl=False', '--serial_mode=True']
Not connected to PVD
+++ Using GPU PhysX
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/utils/cpp_extension.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging  # type: ignore[attr-defined]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Using /home/ziyar/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
Emitting ninja build file /home/ziyar/.cache/torch_extensions/py38_cu117/gymtorch/build.ninja...
Building extension module gymtorch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module gymtorch...
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/graph.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping, Set, Iterable
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/readwrite/graphml.py:346: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  (np.int, "int"), (np.int8, "int"),
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/torch_utils.py:135: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  def get_axis_params(value, axis_idx, x_value=0., dtype=np.float, n_dims=3):
[37m[2028 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : DCE Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task.py:22)
[37m[2028 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : DCE Navigation Task - Final headless mode: False (dce_navigation_task.py:29)
[37m[2028 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : Found SF_ENV_AGENTS environment variable: 128 (dce_navigation_task.py:39)
[37m[2028 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : Detected env_agents=128 from environment - setting environment count. (dce_navigation_task.py:45)
[37m[2028 ms][base_task] - INFO : Setting seed: 2683173015 (base_task.py:38)
[37m[2028 ms][navigation_task] - INFO : Building environment for navigation task. (navigation_task.py:44)
[37m[2028 ms][navigation_task] - INFO : Sim Name: base_sim, Env Name: env_with_obstacles, Robot Name: lmf2, Controller Name: lmf2_velocity_control (navigation_task.py:45)
[37m[2028 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[2028 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[2028 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[2028 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[2028 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[2028 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[2029 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[2029 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[2029 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[2029 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[2029 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[2029 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[2029 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
[37m[3060 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[3060 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[3275 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[3275 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[3275 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[3275 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[3275 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[3275 ms][BaseRobot] - INFO : Initializing controller lmf2_velocity_control (base_robot.py:29)
[33m[3275 ms][base_multirotor] - WARNING : Creating 128 multirotors. (base_multirotor.py:32)
[37m[3275 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[3275 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[3275 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3276 ms][asset_loader] - INFO : Loading asset: panel.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3278 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3279 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3281 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3283 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3283 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3284 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3285 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3286 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3287 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3288 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3289 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3298 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[3691 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[3691 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[3691 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[3906 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[3920 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[3920 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[4004 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[4004 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[4170 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 9 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[4381 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[4382 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[36m[2025-07-02 15:32:11,030][583094] Env info: EnvInfo(obs_space=Dict('obs': Box(-inf, inf, (81,), float32)), action_space=Box(-1.0, 1.0, (3,), float32), num_agents=128, gpu_actions=True, gpu_observations=True, action_splits=None, all_discrete=None, frameskip=1, reward_shaping_scheme=None, env_info_protocol_version=1)
[36m[2025-07-02 15:32:11,813][582981] Starting experiment with the following configuration:
[36mhelp=False
[36malgo=APPO
[36menv=quad_with_obstacles
[36mexperiment=HIGH_CONFIG_128ENV_4
[36mtrain_dir=/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir
[36mrestart_behavior=resume
[36mdevice=gpu
[36mseed=None
[36mnum_policies=1
[36masync_rl=False
[36mserial_mode=True
[36mbatched_sampling=True
[36mnum_batches_to_accumulate=1
[36mworker_num_splits=1
[36mpolicy_workers_per_policy=1
[36mmax_policy_lag=1000
[36mnum_workers=1
[36mnum_envs_per_worker=1
[36mbatch_size=16384
[36mnum_batches_per_epoch=8
[36mnum_epochs=4
[36mrollout=32
[36mrecurrence=32
[36mshuffle_minibatches=False
[36mgamma=0.98
[36mreward_scale=0.1
[36mreward_clip=1000.0
[36mvalue_bootstrap=True
[36mnormalize_returns=True
[36mexploration_loss_coeff=0.001
[36mvalue_loss_coeff=2.0
[36mkl_loss_coeff=0.1
[36mexploration_loss=entropy
[36mgae_lambda=0.95
[36mppo_clip_ratio=0.2
[36mppo_clip_value=1.0
[36mwith_vtrace=False
[36mvtrace_rho=1.0
[36mvtrace_c=1.0
[36moptimizer=adam
[36madam_eps=1e-06
[36madam_beta1=0.9
[36madam_beta2=0.999
[36mmax_grad_norm=1.0
[36mlearning_rate=0.0003
[36mlr_schedule=kl_adaptive_epoch
[36mlr_schedule_kl_threshold=0.016
[36mlr_adaptive_min=1e-06
[36mlr_adaptive_max=0.01
[36mobs_subtract_mean=0.0
[36mobs_scale=1.0
[36mnormalize_input=True
[36mnormalize_input_keys=None
[36mdecorrelate_experience_max_seconds=0
[36mdecorrelate_envs_on_one_worker=True
[36mactor_worker_gpus=[0]
[36mset_workers_cpu_affinity=True
[36mforce_envs_single_thread=False
[36mdefault_niceness=0
[36mlog_to_file=True
[36mexperiment_summaries_interval=10
[36mflush_summaries_interval=30
[36mstats_avg=100
[36msummaries_use_frameskip=True
[36mheartbeat_interval=20
[36mheartbeat_reporting_interval=180
[36mtrain_for_env_steps=100000000
[36mtrain_for_seconds=10000000000
[36msave_every_sec=120
[36mkeep_checkpoints=5
[36mload_checkpoint_kind=latest
[36msave_milestones_sec=-1
[36msave_best_every_sec=5
[36msave_best_metric=reward
[36msave_best_after=100000
[36mbenchmark=False
[36mencoder_mlp_layers=[512, 256, 64]
[36mencoder_conv_architecture=convnet_simple
[36mencoder_conv_mlp_layers=[]
[36muse_rnn=True
[36mrnn_size=64
[36mrnn_type=gru
[36mrnn_num_layers=1
[36mdecoder_mlp_layers=[]
[36mnonlinearity=elu
[36mpolicy_initialization=torch_default
[36mpolicy_init_gain=1.0
[36mactor_critic_share_weights=True
[36madaptive_stddev=True
[36mcontinuous_tanh_scale=0.0
[36minitial_stddev=1.0
[36muse_env_info_cache=False
[36menv_gpu_actions=True
[36menv_gpu_observations=True
[36menv_frameskip=1
[36menv_framestack=1
[36mpixel_format=CHW
[36muse_record_episode_statistics=False
[36mwith_wandb=True
[36mwandb_user=ziya-ruso-ucl
[36mwandb_project=vae_rl_navigation
[36mwandb_group=dce_navigation_training
[36mwandb_job_type=SF
[36mwandb_tags=['aerial_gym', 'dce', 'navigation', 'sample_factory']
[36mwith_pbt=False
[36mpbt_mix_policies_in_one_env=True
[36mpbt_period_env_steps=5000000
[36mpbt_start_mutation=20000000
[36mpbt_replace_fraction=0.3
[36mpbt_mutation_rate=0.15
[36mpbt_replace_reward_gap=0.1
[36mpbt_replace_reward_gap_absolute=1e-06
[36mpbt_optimize_gamma=False
[36mpbt_target_objective=true_objective
[36mpbt_perturb_min=1.1
[36mpbt_perturb_max=1.5
[36menv_agents=128
[36mheadless=False
[36mobs_key=obs
[36msubtask=None
[36mige_api_version=preview4
[36meval_stats=False
[36maction_space_dim=3
[36mcommand_line=--env=quad_with_obstacles --train_for_env_steps=100000000 --experiment=HIGH_CONFIG_128ENV_4 --async_rl=True --use_env_info_cache=False --normalize_input=True --headless=False --async_rl=False --serial_mode=True
[36mcli_args={'env': 'quad_with_obstacles', 'experiment': 'HIGH_CONFIG_128ENV_4', 'async_rl': False, 'serial_mode': True, 'normalize_input': True, 'train_for_env_steps': 100000000, 'use_env_info_cache': False, 'headless': False}
[36mgit_hash=7f68834735119b0b96b7f43bc6752d65d9292d8e
[36mgit_repo_name=git@github.com:rusoziya/aerial_gym_simulator.git
[36mwandb_unique_id=HIGH_CONFIG_128ENV_4_20250702_153201_984438
[36m[2025-07-02 15:32:11,814][582981] Saving configuration to /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/config.json...
[36m[2025-07-02 15:32:11,860][582981] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-02 15:32:11,861][582981] Rollout worker 0 uses device cuda:0
[36m[2025-07-02 15:32:11,861][582981] In synchronous mode, we only accumulate one batch. Setting num_batches_to_accumulate to 1
[36m[2025-07-02 15:32:11,918][582981] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-02 15:32:11,918][582981] InferenceWorker_p0-w0: min num requests: 1
[36m[2025-07-02 15:32:11,919][582981] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-02 15:32:11,919][582981] Starting seed is not provided
[36m[2025-07-02 15:32:11,920][582981] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-02 15:32:11,920][582981] Initializing actor-critic model on device cuda:0
[36m[2025-07-02 15:32:11,920][582981] RunningMeanStd input shape: (81,)
[36m[2025-07-02 15:32:11,920][582981] RunningMeanStd input shape: (1,)
[36m[2025-07-02 15:32:11,947][582981] Created Actor Critic model with architecture:
[36m[2025-07-02 15:32:11,947][582981] ActorCriticSharedWeights(
[36m  (obs_normalizer): ObservationNormalizer(
[36m    (running_mean_std): RunningMeanStdDictInPlace(
[36m      (running_mean_std): ModuleDict(
[36m        (obs): RunningMeanStdInPlace()
[36m      )
[36m    )
[36m  )
[36m  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
[36m  (encoder): MultiInputEncoder(
[36m    (encoders): ModuleDict(
[36m      (obs): MlpEncoder(
[36m        (mlp_head): RecursiveScriptModule(
[36m          original_name=Sequential
[36m          (0): RecursiveScriptModule(original_name=Linear)
[36m          (1): RecursiveScriptModule(original_name=ELU)
[36m          (2): RecursiveScriptModule(original_name=Linear)
[36m          (3): RecursiveScriptModule(original_name=ELU)
[36m          (4): RecursiveScriptModule(original_name=Linear)
[36m          (5): RecursiveScriptModule(original_name=ELU)
[36m        )
[36m      )
[36m    )
[36m  )
[36m  (core): ModelCoreRNN(
[36m    (core): GRU(64, 64)
[36m  )
[36m  (decoder): MlpDecoder(
[36m    (mlp): Identity()
[36m  )
[36m  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
[36m  (action_parameterization): ActionParameterizationDefault(
[36m    (distribution_linear): Linear(in_features=64, out_features=6, bias=True)
[36m  )
[36m)
[36m[2025-07-02 15:32:12,385][582981] Using optimizer <class 'torch.optim.adam.Adam'>
[33m[2025-07-02 15:32:12,386][582981] No checkpoints found
[36m[2025-07-02 15:32:12,386][582981] Did not load from checkpoint, starting from scratch!
[36m[2025-07-02 15:32:12,386][582981] Initialized policy 0 weights for model version 0
[36m[2025-07-02 15:32:12,387][582981] LearnerWorker_p0 finished initialization!
[36m[2025-07-02 15:32:12,387][582981] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-02 15:32:12,415][582981] Inference worker 0-0 is ready!
[37m[1m[2025-07-02 15:32:12,416][582981] All inference workers are ready! Signal rollout workers to start!
[36m[2025-07-02 15:32:12,416][582981] EnvRunner 0-0 uses policy 0
[37m[12749 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : DCE Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task.py:22)
[37m[12749 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : DCE Navigation Task - Final headless mode: False (dce_navigation_task.py:29)
[37m[12749 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : Found SF_ENV_AGENTS environment variable: 128 (dce_navigation_task.py:39)
[37m[12749 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : Detected env_agents=128 from environment - setting environment count. (dce_navigation_task.py:45)
[37m[12750 ms][base_task] - INFO : Setting seed: 2778504260 (base_task.py:38)
[37m[12750 ms][navigation_task] - INFO : Building environment for navigation task. (navigation_task.py:44)
[37m[12750 ms][navigation_task] - INFO : Sim Name: base_sim, Env Name: env_with_obstacles, Robot Name: lmf2, Controller Name: lmf2_velocity_control (navigation_task.py:45)
[37m[12750 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[12750 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[12750 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[12750 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[12750 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[12750 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
creating render graph
Module warp.utils load on device 'cuda:0' took 1.35 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 7.64 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 12.54 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.69 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 128
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[37m[12751 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[12751 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[12751 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[12751 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[12751 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[12751 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[12751 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[37m[13797 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[13799 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[14002 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[14002 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[14002 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[14002 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[14002 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[14002 ms][BaseRobot] - INFO : Initializing controller lmf2_velocity_control (base_robot.py:29)
[33m[14002 ms][base_multirotor] - WARNING : Creating 128 multirotors. (base_multirotor.py:32)
[37m[14002 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[14002 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[14002 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14003 ms][asset_loader] - INFO : Loading asset: panel.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14005 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14006 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14008 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14009 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14009 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14010 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14011 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14012 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14013 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14014 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14015 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[14025 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[14042 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[14042 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[14042 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[14234 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[14250 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[14250 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[14333 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[14333 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[14486 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 9 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[14683 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[14684 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles', '--train_for_env_steps=100000000', '--experiment=HIGH_CONFIG_128ENV_4', '--async_rl=True', '--use_env_info_cache=False', '--normalize_input=True', '--async_rl=False', '--serial_mode=True']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.67 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 7.99 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 11.94 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.83 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 128
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[36m[2025-07-02 15:32:15,030][582981] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[31m[17247 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[17248 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
[31m         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
[31m         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
[31m         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
[31m         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
[31m         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
[31m         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
[31m         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
[31m        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
[31m        126, 127], device='cuda:0') (navigation_task.py:196)
[31m[17250 ms][navigation_task] - CRITICAL : Time at crash: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:32:19,945][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 78.1. Samples: 384. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:32:19,946][582981] Avg episode reward: [(0, '-100.114')]
[33m[20330 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[31m[20615 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[20615 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([41], device='cuda:0') (navigation_task.py:196)
[31m[20616 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[21230 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[21230 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([119], device='cuda:0') (navigation_task.py:196)
[31m[21230 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[24041 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[24042 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([49], device='cuda:0') (navigation_task.py:196)
[31m[24042 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:32:24,953][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 748.2. Samples: 7424. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:32:24,953][582981] Avg episode reward: [(0, '-80.766')]
[36m[2025-07-02 15:32:29,984][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 796.1. Samples: 11904. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:32:29,984][582981] Avg episode reward: [(0, '-100.909')]
[37m[1m[2025-07-02 15:32:32,056][582981] Heartbeat connected on Batcher_0
[37m[1m[2025-07-02 15:32:32,056][582981] Heartbeat connected on LearnerWorker_p0
[37m[1m[2025-07-02 15:32:32,056][582981] Heartbeat connected on InferenceWorker_p0-w0
[37m[1m[2025-07-02 15:32:32,056][582981] Heartbeat connected on RolloutWorker_w0
[36m[2025-07-02 15:32:34,937][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1028.8. Samples: 20480. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:32:34,938][582981] Avg episode reward: [(0, '-99.153')]
[31m[36762 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[36762 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([93], device='cuda:0') (navigation_task.py:196)
[31m[36762 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:32:39,897][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1183.9. Samples: 29440. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:32:39,897][582981] Avg episode reward: [(0, '-101.020')]
[31m[42631 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[42631 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([85], device='cuda:0') (navigation_task.py:196)
[31m[42631 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:32:44,972][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1137.1. Samples: 34048. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:32:44,973][582981] Avg episode reward: [(0, '-95.265')]
[31m[46825 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[46826 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([64], device='cuda:0') (navigation_task.py:196)
[31m[46826 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[48521 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[48522 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([42], device='cuda:0') (navigation_task.py:196)
[31m[48522 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:32:49,920][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1236.3. Samples: 43136. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:32:49,920][582981] Avg episode reward: [(0, '-98.729')]
[31m[51195 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[51195 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([69], device='cuda:0') (navigation_task.py:196)
[31m[51196 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[52162 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[52163 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([125], device='cuda:0') (navigation_task.py:196)
[31m[52163 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:32:54,887][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1326.3. Samples: 52864. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:32:54,887][582981] Avg episode reward: [(0, '-99.122')]
[33m[58418 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[58418 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[58418 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2048
[33mTimeouts: 0 (navigation_task.py:268)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:275: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/success_rate"] = torch.tensor(success_rate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:276: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/crash_rate"] = torch.tensor(crash_rate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:277: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/timeout_rate"] = torch.tensor(timeout_rate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:278: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/total_successes"] = torch.tensor(self.success_aggregate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:279: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/total_crashes"] = torch.tensor(self.crashes_aggregate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:280: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/total_timeouts"] = torch.tensor(self.timeouts_aggregate, dtype=torch.float32)
[36m[2025-07-02 15:32:59,928][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1274.3. Samples: 57216. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:32:59,929][582981] Avg episode reward: [(0, '-98.473')]
[31m[62210 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[62210 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([94], device='cuda:0') (navigation_task.py:196)
[31m[62210 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:33:04,908][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1463.3. Samples: 66176. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:33:04,908][582981] Avg episode reward: [(0, '-97.464')]
[36m[2025-07-02 15:33:09,899][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1512.2. Samples: 75392. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:33:09,899][582981] Avg episode reward: [(0, '-100.526')]
[31m[70604 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[70604 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([43], device='cuda:0') (navigation_task.py:196)
[31m[70604 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[74030 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[74030 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([10], device='cuda:0') (navigation_task.py:196)
[31m[74031 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:33:14,923][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1518.1. Samples: 80128. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:33:14,923][582981] Avg episode reward: [(0, '-99.821')]
[36m[2025-07-02 15:33:19,889][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1532.0. Samples: 89344. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:33:19,889][582981] Avg episode reward: [(0, '-103.719')]
[36m[2025-07-02 15:33:24,925][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1532.2. Samples: 98432. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:33:24,925][582981] Avg episode reward: [(0, '-97.360')]
[31m[86460 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[86461 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([17], device='cuda:0') (navigation_task.py:196)
[31m[86461 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:33:29,907][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1532.5. Samples: 102912. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:33:29,907][582981] Avg episode reward: [(0, '-99.503')]
[31m[91963 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[91963 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([62], device='cuda:0') (navigation_task.py:196)
[31m[91963 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[92211 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[92212 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([56], device='cuda:0') (navigation_task.py:196)
[31m[92212 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[94859 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[94859 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([23], device='cuda:0') (navigation_task.py:196)
[31m[94860 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:33:34,880][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1531.7. Samples: 112000. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:33:34,880][582981] Avg episode reward: [(0, '-98.009')]
[33m[97368 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[97369 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[97369 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2049
[33mTimeouts: 0 (navigation_task.py:268)
[36m[2025-07-02 15:33:39,929][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1509.0. Samples: 120832. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:33:39,930][582981] Avg episode reward: [(0, '-97.190')]
[31m[103368 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[103369 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([122], device='cuda:0') (navigation_task.py:196)
[31m[103369 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:33:44,905][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1502.6. Samples: 124800. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 15:33:44,906][582981] Avg episode reward: [(0, '-98.704')]
[31m[107404 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[107404 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([73], device='cuda:0') (navigation_task.py:196)
[31m[107404 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/nn/modules/module.py:1194: UserWarning: operator() profile_node %104 : int[] = prim::profile_ivalue(%102)
 does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)
  return forward_call(*input, **kwargs)
[36m[2025-07-02 15:33:49,887][582981] Fps is (10 sec: 13163.0, 60 sec: 2185.7, 300 sec: 1381.8). Total num frames: 131072. Throughput: 0: 1457.0. Samples: 131712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:33:49,887][582981] Avg episode reward: [(0, '-102.972')]
[37m[1m[2025-07-02 15:33:49,978][582981] Saving new best policy, reward=-102.972!
[36m[2025-07-02 15:33:54,924][582981] Fps is (10 sec: 13082.6, 60 sec: 2183.2, 300 sec: 1312.1). Total num frames: 131072. Throughput: 0: 1438.5. Samples: 140160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:33:54,924][582981] Avg episode reward: [(0, '-96.249')]
[37m[1m[2025-07-02 15:33:55,013][582981] Saving new best policy, reward=-96.249!
[36m[2025-07-02 15:33:59,966][582981] Fps is (10 sec: 0.0, 60 sec: 2183.2, 300 sec: 1249.1). Total num frames: 131072. Throughput: 0: 1435.1. Samples: 144768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:33:59,966][582981] Avg episode reward: [(0, '-100.549')]
[31m[121446 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[121446 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([24], device='cuda:0') (navigation_task.py:196)
[31m[121447 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[123439 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[123440 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([45], device='cuda:0') (navigation_task.py:196)
[31m[123440 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:34:04,943][582981] Fps is (10 sec: 0.0, 60 sec: 2183.3, 300 sec: 1192.5). Total num frames: 131072. Throughput: 0: 1386.4. Samples: 151808. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:04,943][582981] Avg episode reward: [(0, '-95.875')]
[37m[1m[2025-07-02 15:34:05,061][582981] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000032_131072.pth...
[37m[1m[2025-07-02 15:34:05,066][582981] Saving new best policy, reward=-95.875!
[31m[127471 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[127471 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([105], device='cuda:0') (navigation_task.py:196)
[31m[127472 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:34:09,937][582981] Fps is (10 sec: 0.0, 60 sec: 2183.1, 300 sec: 1140.7). Total num frames: 131072. Throughput: 0: 1342.2. Samples: 158848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:09,937][582981] Avg episode reward: [(0, '-103.700')]
[36m[2025-07-02 15:34:14,883][582981] Fps is (10 sec: 0.0, 60 sec: 2186.0, 300 sec: 1093.6). Total num frames: 131072. Throughput: 0: 1334.8. Samples: 162944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:14,883][582981] Avg episode reward: [(0, '-99.846')]
[36m[2025-07-02 15:34:19,900][582981] Fps is (10 sec: 0.0, 60 sec: 2184.1, 300 sec: 1049.7). Total num frames: 131072. Throughput: 0: 1324.9. Samples: 171648. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:19,900][582981] Avg episode reward: [(0, '-99.606')]
[31m[142168 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[142168 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([12], device='cuda:0') (navigation_task.py:196)
[31m[142169 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[143213 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[143213 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[143213 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2050
[33mTimeouts: 0 (navigation_task.py:268)
[36m[2025-07-02 15:34:24,914][582981] Fps is (10 sec: 0.0, 60 sec: 2184.9, 300 sec: 1009.1). Total num frames: 131072. Throughput: 0: 1314.6. Samples: 179968. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:24,915][582981] Avg episode reward: [(0, '-102.857')]
[31m[150038 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[150038 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([1], device='cuda:0') (navigation_task.py:196)
[31m[150038 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:34:29,983][582981] Fps is (10 sec: 0.0, 60 sec: 2181.8, 300 sec: 971.2). Total num frames: 131072. Throughput: 0: 1314.7. Samples: 184064. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:29,984][582981] Avg episode reward: [(0, '-95.490')]
[37m[1m[2025-07-02 15:34:30,077][582981] Saving new best policy, reward=-95.490!
[31m[150488 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[150488 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([113], device='cuda:0') (navigation_task.py:196)
[31m[150488 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:34:34,891][582981] Fps is (10 sec: 0.0, 60 sec: 2184.1, 300 sec: 937.2). Total num frames: 131072. Throughput: 0: 1319.7. Samples: 191104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:34,891][582981] Avg episode reward: [(0, '-95.944')]
[36m[2025-07-02 15:34:39,891][582981] Fps is (10 sec: 0.0, 60 sec: 2185.9, 300 sec: 904.8). Total num frames: 131072. Throughput: 0: 1329.3. Samples: 199936. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:39,891][582981] Avg episode reward: [(0, '-97.881')]
[31m[161050 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[161050 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([57], device='cuda:0') (navigation_task.py:196)
[31m[161050 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[161296 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[161297 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([106], device='cuda:0') (navigation_task.py:196)
[31m[161297 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[163444 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[163445 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([89], device='cuda:0') (navigation_task.py:196)
[31m[163445 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:34:44,912][582981] Fps is (10 sec: 0.0, 60 sec: 2184.3, 300 sec: 874.5). Total num frames: 131072. Throughput: 0: 1327.1. Samples: 204416. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:44,912][582981] Avg episode reward: [(0, '-98.279')]
[31m[167839 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[167839 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([23], device='cuda:0') (navigation_task.py:196)
[31m[167839 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:34:49,918][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 846.2). Total num frames: 131072. Throughput: 0: 1371.8. Samples: 213504. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:49,918][582981] Avg episode reward: [(0, '-97.974')]
[36m[2025-07-02 15:34:54,966][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 819.5). Total num frames: 131072. Throughput: 0: 1415.6. Samples: 222592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:54,966][582981] Avg episode reward: [(0, '-101.342')]
[31m[176631 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[176632 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([83], device='cuda:0') (navigation_task.py:196)
[31m[176633 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[177075 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[177075 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([10], device='cuda:0') (navigation_task.py:196)
[31m[177076 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[179557 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[179557 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([106], device='cuda:0') (navigation_task.py:196)
[31m[179557 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:34:59,902][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 795.0). Total num frames: 131072. Throughput: 0: 1421.6. Samples: 226944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:34:59,902][582981] Avg episode reward: [(0, '-100.337')]
[31m[181128 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[181129 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([9], device='cuda:0') (navigation_task.py:196)
[31m[181129 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[185027 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[185027 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[185027 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2048
[33mTimeouts: 0 (navigation_task.py:268)
[36m[2025-07-02 15:35:04,895][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 771.6). Total num frames: 131072. Throughput: 0: 1439.4. Samples: 236416. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:35:04,895][582981] Avg episode reward: [(0, '-102.592')]
[36m[2025-07-02 15:35:09,943][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 749.4). Total num frames: 131072. Throughput: 0: 1458.3. Samples: 245632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:35:09,943][582981] Avg episode reward: [(0, '-98.534')]
[31m[194888 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[194888 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([13], device='cuda:0') (navigation_task.py:196)
[31m[194888 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:35:14,927][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 728.6). Total num frames: 131072. Throughput: 0: 1469.6. Samples: 250112. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:35:14,928][582981] Avg episode reward: [(0, '-98.597')]
[31m[195423 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[195424 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([49], device='cuda:0') (navigation_task.py:196)
[31m[195424 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[195737 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[195738 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([64], device='cuda:0') (navigation_task.py:196)
[31m[195738 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[199705 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[199706 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([114], device='cuda:0') (navigation_task.py:196)
[31m[199706 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:35:19,887][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 709.0). Total num frames: 131072. Throughput: 0: 1507.7. Samples: 258944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:35:19,888][582981] Avg episode reward: [(0, '-97.281')]
[36m[2025-07-02 15:35:24,905][582981] Fps is (10 sec: 13137.2, 60 sec: 2184.9, 300 sec: 1380.6). Total num frames: 262144. Throughput: 0: 1490.0. Samples: 267008. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:35:24,905][582981] Avg episode reward: [(0, '-97.879')]
[36m[2025-07-02 15:35:29,947][582981] Fps is (10 sec: 13029.7, 60 sec: 2185.9, 300 sec: 1344.9). Total num frames: 262144. Throughput: 0: 1492.2. Samples: 271616. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:35:29,947][582981] Avg episode reward: [(0, '-94.815')]
[37m[1m[2025-07-02 15:35:30,028][582981] Saving new best policy, reward=-94.815!
[31m[211070 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[211070 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([9], device='cuda:0') (navigation_task.py:196)
[31m[211070 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[212582 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[212583 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([56], device='cuda:0') (navigation_task.py:196)
[31m[212583 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:35:34,936][582981] Fps is (10 sec: 0.0, 60 sec: 2182.9, 300 sec: 1311.3). Total num frames: 262144. Throughput: 0: 1498.4. Samples: 280960. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:35:34,936][582981] Avg episode reward: [(0, '-99.698')]
[36m[2025-07-02 15:35:39,916][582981] Fps is (10 sec: 0.0, 60 sec: 2183.6, 300 sec: 1279.5). Total num frames: 262144. Throughput: 0: 1500.7. Samples: 290048. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:35:39,916][582981] Avg episode reward: [(0, '-99.118')]
[36m[2025-07-02 15:35:44,911][582981] Fps is (10 sec: 0.0, 60 sec: 2184.6, 300 sec: 1249.0). Total num frames: 262144. Throughput: 0: 1507.3. Samples: 294784. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:35:44,911][582981] Avg episode reward: [(0, '-98.476')]
[33m[227501 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[227502 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[227502 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2052
[33mTimeouts: 0 (navigation_task.py:268)
[36m[2025-07-02 15:35:49,966][582981] Fps is (10 sec: 0.0, 60 sec: 2182.8, 300 sec: 1219.6). Total num frames: 262144. Throughput: 0: 1493.8. Samples: 303744. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:35:49,966][582981] Avg episode reward: [(0, '-99.824')]
[36m[2025-07-02 15:35:54,882][582981] Fps is (10 sec: 0.0, 60 sec: 2187.6, 300 sec: 1192.4). Total num frames: 262144. Throughput: 0: 1486.8. Samples: 312448. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:35:54,882][582981] Avg episode reward: [(0, '-97.076')]
[31m[237032 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[237032 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([48], device='cuda:0') (navigation_task.py:196)
[31m[237032 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[238141 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[238141 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([8], device='cuda:0') (navigation_task.py:196)
[31m[238141 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:35:59,889][582981] Fps is (10 sec: 0.0, 60 sec: 2185.0, 300 sec: 1165.8). Total num frames: 262144. Throughput: 0: 1491.8. Samples: 317184. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:35:59,889][582981] Avg episode reward: [(0, '-102.406')]
[31m[240273 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[240273 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([113], device='cuda:0') (navigation_task.py:196)
[31m[240274 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[242493 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[242493 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([67], device='cuda:0') (navigation_task.py:196)
[31m[242494 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[242917 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[242917 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([114], device='cuda:0') (navigation_task.py:196)
[31m[242917 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:36:04,910][582981] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1140.4). Total num frames: 262144. Throughput: 0: 1492.6. Samples: 326144. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:36:04,910][582981] Avg episode reward: [(0, '-100.133')]
[37m[1m[2025-07-02 15:36:05,006][582981] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000064_262144.pth...
[36m[2025-07-02 15:36:09,899][582981] Fps is (10 sec: 0.0, 60 sec: 2186.1, 300 sec: 1116.1). Total num frames: 262144. Throughput: 0: 1479.3. Samples: 333568. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:36:09,899][582981] Avg episode reward: [(0, '-98.342')]
[31m[251329 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[251329 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([111], device='cuda:0') (navigation_task.py:196)
[31m[251329 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[252388 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[252388 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([113], device='cuda:0') (navigation_task.py:196)
[31m[252388 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:36:14,905][582981] Fps is (10 sec: 0.0, 60 sec: 2185.3, 300 sec: 1092.8). Total num frames: 262144. Throughput: 0: 1474.8. Samples: 337920. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:36:14,905][582981] Avg episode reward: [(0, '-96.700')]
[36m[2025-07-02 15:36:19,904][582981] Fps is (10 sec: 0.0, 60 sec: 2183.9, 300 sec: 1070.5). Total num frames: 262144. Throughput: 0: 1463.1. Samples: 346752. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:36:19,905][582981] Avg episode reward: [(0, '-99.079')]
[31m[264628 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[264629 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([91], device='cuda:0') (navigation_task.py:196)
[31m[264629 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:36:24,959][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1048.9). Total num frames: 262144. Throughput: 0: 1455.0. Samples: 355584. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:36:24,959][582981] Avg episode reward: [(0, '-95.995')]
[36m[2025-07-02 15:36:29,937][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1028.4). Total num frames: 262144. Throughput: 0: 1455.5. Samples: 360320. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:36:29,938][582981] Avg episode reward: [(0, '-109.307')]
[33m[272333 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[272333 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[272334 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2051
[33mTimeouts: 0 (navigation_task.py:268)
[31m[275265 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[275266 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([114], device='cuda:0') (navigation_task.py:196)
[31m[275267 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:36:34,967][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1008.5). Total num frames: 262144. Throughput: 0: 1456.3. Samples: 369280. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:36:34,967][582981] Avg episode reward: [(0, '-94.555')]
[37m[1m[2025-07-02 15:36:35,056][582981] Saving new best policy, reward=-94.555!
[36m[2025-07-02 15:36:39,925][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 989.6). Total num frames: 262144. Throughput: 0: 1472.0. Samples: 378752. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:36:39,925][582981] Avg episode reward: [(0, '-106.037')]
[31m[283436 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[283436 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([42], device='cuda:0') (navigation_task.py:196)
[31m[283437 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:36:44,905][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 971.4). Total num frames: 262144. Throughput: 0: 1464.4. Samples: 383104. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:36:44,906][582981] Avg episode reward: [(0, '-98.443')]
[36m[2025-07-02 15:36:49,981][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 953.4). Total num frames: 262144. Throughput: 0: 1417.2. Samples: 390016. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 15:36:49,981][582981] Avg episode reward: [(0, '-98.870')]
[36m[2025-07-02 15:36:55,005][582981] Fps is (10 sec: 12977.7, 60 sec: 2180.1, 300 sec: 1404.5). Total num frames: 393216. Throughput: 0: 1382.0. Samples: 395904. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:36:55,006][582981] Avg episode reward: [(0, '-98.449')]
[31m[296439 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[296440 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([113], device='cuda:0') (navigation_task.py:196)
[31m[296440 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:36:59,962][582981] Fps is (10 sec: 13131.5, 60 sec: 2181.9, 300 sec: 1380.0). Total num frames: 393216. Throughput: 0: 1357.9. Samples: 399104. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:36:59,963][582981] Avg episode reward: [(0, '-96.393')]
[31m[303424 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[303424 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([62], device='cuda:0') (navigation_task.py:196)
[31m[303424 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:37:04,929][582981] Fps is (10 sec: 0.0, 60 sec: 2183.9, 300 sec: 1356.4). Total num frames: 393216. Throughput: 0: 1322.0. Samples: 406272. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:04,929][582981] Avg episode reward: [(0, '-96.256')]
[36m[2025-07-02 15:37:09,897][582981] Fps is (10 sec: 0.0, 60 sec: 2184.6, 300 sec: 1333.5). Total num frames: 393216. Throughput: 0: 1330.2. Samples: 415360. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:09,897][582981] Avg episode reward: [(0, '-98.493')]
[31m[314445 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[314445 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([10], device='cuda:0') (navigation_task.py:196)
[31m[314446 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:37:14,919][582981] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1333.1). Total num frames: 393216. Throughput: 0: 1320.4. Samples: 419712. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:14,919][582981] Avg episode reward: [(0, '-100.362')]
[36m[2025-07-02 15:37:19,944][582981] Fps is (10 sec: 0.0, 60 sec: 2183.1, 300 sec: 1333.0). Total num frames: 393216. Throughput: 0: 1331.9. Samples: 429184. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:19,944][582981] Avg episode reward: [(0, '-100.908')]
[31m[321660 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[321660 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([119], device='cuda:0') (navigation_task.py:196)
[31m[321660 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[322464 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[322465 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[322465 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2048
[33mTimeouts: 0 (navigation_task.py:268)
[36m[2025-07-02 15:37:24,944][582981] Fps is (10 sec: 0.0, 60 sec: 2185.1, 300 sec: 1333.1). Total num frames: 393216. Throughput: 0: 1327.8. Samples: 438528. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:24,944][582981] Avg episode reward: [(0, '-100.669')]
[31m[327748 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[327749 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([67], device='cuda:0') (navigation_task.py:196)
[31m[327749 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[330003 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[330003 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([87], device='cuda:0') (navigation_task.py:196)
[31m[330003 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:37:29,972][582981] Fps is (10 sec: 0.0, 60 sec: 2183.3, 300 sec: 1332.8). Total num frames: 393216. Throughput: 0: 1326.4. Samples: 442880. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:29,972][582981] Avg episode reward: [(0, '-97.579')]
[31m[331338 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[331339 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([9], device='cuda:0') (navigation_task.py:196)
[31m[331339 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[333248 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[333249 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([77], device='cuda:0') (navigation_task.py:196)
[31m[333249 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:37:34,947][582981] Fps is (10 sec: 0.0, 60 sec: 2185.3, 300 sec: 1332.7). Total num frames: 393216. Throughput: 0: 1374.9. Samples: 451840. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:34,947][582981] Avg episode reward: [(0, '-103.701')]
[36m[2025-07-02 15:37:39,879][582981] Fps is (10 sec: 0.0, 60 sec: 2186.2, 300 sec: 1333.4). Total num frames: 393216. Throughput: 0: 1446.2. Samples: 460800. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:39,879][582981] Avg episode reward: [(0, '-95.880')]
[36m[2025-07-02 15:37:44,961][582981] Fps is (10 sec: 0.0, 60 sec: 2182.5, 300 sec: 1332.7). Total num frames: 393216. Throughput: 0: 1470.6. Samples: 465280. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:44,961][582981] Avg episode reward: [(0, '-98.346')]
[36m[2025-07-02 15:37:49,916][582981] Fps is (10 sec: 0.0, 60 sec: 2186.9, 300 sec: 1332.8). Total num frames: 393216. Throughput: 0: 1488.1. Samples: 473216. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:49,916][582981] Avg episode reward: [(0, '-91.469')]
[37m[1m[2025-07-02 15:37:50,011][582981] Saving new best policy, reward=-91.469!
[36m[2025-07-02 15:37:54,948][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 393216. Throughput: 0: 1474.6. Samples: 481792. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:54,948][582981] Avg episode reward: [(0, '-100.725')]
[31m[356214 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[356214 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([92], device='cuda:0') (navigation_task.py:196)
[31m[356215 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:37:59,964][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 393216. Throughput: 0: 1466.3. Samples: 485760. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:37:59,964][582981] Avg episode reward: [(0, '-96.828')]
[31m[364727 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[364727 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([38], device='cuda:0') (navigation_task.py:196)
[31m[364727 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:38:04,882][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 393216. Throughput: 0: 1452.7. Samples: 494464. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:38:04,882][582981] Avg episode reward: [(0, '-96.834')]
[31m[365302 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[365302 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([85], device='cuda:0') (navigation_task.py:196)
[31m[365302 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[37m[1m[2025-07-02 15:38:05,003][582981] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000096_393216.pth...
[31m[365686 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[365686 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([64], device='cuda:0') (navigation_task.py:196)
[31m[365687 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[367154 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[367155 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([56], device='cuda:0') (navigation_task.py:196)
[31m[367155 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[367611 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[367611 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([55], device='cuda:0') (navigation_task.py:196)
[31m[367611 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:38:09,887][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 393216. Throughput: 0: 1409.8. Samples: 501888. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:38:09,887][582981] Avg episode reward: [(0, '-96.853')]
[33m[372732 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[372732 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[372732 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2049
[33mTimeouts: 0 (navigation_task.py:268)
[31m[374285 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[374286 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([9], device='cuda:0') (navigation_task.py:196)
[31m[374286 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:38:14,981][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.5). Total num frames: 393216. Throughput: 0: 1396.3. Samples: 505728. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:38:14,981][582981] Avg episode reward: [(0, '-99.698')]
[36m[2025-07-02 15:38:20,043][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.4). Total num frames: 393216. Throughput: 0: 1359.6. Samples: 513152. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:38:20,043][582981] Avg episode reward: [(0, '-102.247')]
[31m[382728 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[382728 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([56], device='cuda:0') (navigation_task.py:196)
[31m[382728 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:38:24,990][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.6). Total num frames: 393216. Throughput: 0: 1296.7. Samples: 519296. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-02 15:38:24,991][582981] Avg episode reward: [(0, '-99.985')]
[31m[387065 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[387066 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([33], device='cuda:0') (navigation_task.py:196)
[31m[387066 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:38:29,917][582981] Fps is (10 sec: 13274.5, 60 sec: 2186.5, 300 sec: 1777.0). Total num frames: 524288. Throughput: 0: 1261.3. Samples: 521984. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:38:29,918][582981] Avg episode reward: [(0, '-95.963')]
[36m[2025-07-02 15:38:34,899][582981] Fps is (10 sec: 13227.8, 60 sec: 2186.3, 300 sec: 1777.4). Total num frames: 524288. Throughput: 0: 1215.0. Samples: 527872. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:38:34,899][582981] Avg episode reward: [(0, '-99.944')]
[36m[2025-07-02 15:38:39,926][582981] Fps is (10 sec: 0.0, 60 sec: 2182.8, 300 sec: 1777.1). Total num frames: 524288. Throughput: 0: 1192.4. Samples: 535424. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:38:39,927][582981] Avg episode reward: [(0, '-97.794')]
[36m[2025-07-02 15:38:44,901][582981] Fps is (10 sec: 0.0, 60 sec: 2186.7, 300 sec: 1332.9). Total num frames: 524288. Throughput: 0: 1187.8. Samples: 539136. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:38:44,901][582981] Avg episode reward: [(0, '-98.311')]
[36m[2025-07-02 15:38:49,933][582981] Fps is (10 sec: 0.0, 60 sec: 2183.9, 300 sec: 1332.9). Total num frames: 524288. Throughput: 0: 1182.0. Samples: 547712. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:38:49,933][582981] Avg episode reward: [(0, '-99.443')]
[36m[2025-07-02 15:38:54,920][582981] Fps is (10 sec: 0.0, 60 sec: 2185.5, 300 sec: 1333.1). Total num frames: 524288. Throughput: 0: 1202.3. Samples: 556032. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:38:54,920][582981] Avg episode reward: [(0, '-98.221')]
[36m[2025-07-02 15:38:59,900][582981] Fps is (10 sec: 0.0, 60 sec: 2186.9, 300 sec: 1333.1). Total num frames: 524288. Throughput: 0: 1219.6. Samples: 560512. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:38:59,900][582981] Avg episode reward: [(0, '-102.596')]
[36m[2025-07-02 15:39:04,923][582981] Fps is (10 sec: 0.0, 60 sec: 2183.0, 300 sec: 1333.0). Total num frames: 524288. Throughput: 0: 1237.8. Samples: 568704. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:04,924][582981] Avg episode reward: [(0, '-95.889')]
[36m[2025-07-02 15:39:09,924][582981] Fps is (10 sec: 0.0, 60 sec: 2183.2, 300 sec: 1332.7). Total num frames: 524288. Throughput: 0: 1301.8. Samples: 577792. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:09,924][582981] Avg episode reward: [(0, '-96.164')]
[33m[432274 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[432274 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.99951171875
[33mTimeout Rate: 0.00048828125 (navigation_task.py:265)
[33m[432274 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2047
[33mTimeouts: 1 (navigation_task.py:268)
[31m[433390 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[433391 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([16], device='cuda:0') (navigation_task.py:196)
[31m[433391 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:39:14,908][582981] Fps is (10 sec: 0.0, 60 sec: 2187.2, 300 sec: 1332.9). Total num frames: 524288. Throughput: 0: 1345.7. Samples: 582528. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:14,908][582981] Avg episode reward: [(0, '-101.109')]
[31m[437271 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[437272 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([64], device='cuda:0') (navigation_task.py:196)
[31m[437272 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[439152 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[439153 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([61], device='cuda:0') (navigation_task.py:196)
[31m[439153 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:39:19,905][582981] Fps is (10 sec: 0.0, 60 sec: 2189.6, 300 sec: 1333.0). Total num frames: 524288. Throughput: 0: 1419.2. Samples: 591744. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:19,905][582981] Avg episode reward: [(0, '-99.304')]
[31m[442005 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[442005 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([99], device='cuda:0') (navigation_task.py:196)
[31m[442005 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:39:24,917][582981] Fps is (10 sec: 0.0, 60 sec: 2187.2, 300 sec: 1333.2). Total num frames: 524288. Throughput: 0: 1459.5. Samples: 601088. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:24,917][582981] Avg episode reward: [(0, '-92.777')]
[31m[448088 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[448088 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([57], device='cuda:0') (navigation_task.py:196)
[31m[448088 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:39:29,918][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 524288. Throughput: 0: 1478.6. Samples: 605696. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:29,918][582981] Avg episode reward: [(0, '-99.985')]
[31m[452196 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[452197 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([90], device='cuda:0') (navigation_task.py:196)
[31m[452197 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[452667 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[452667 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([83], device='cuda:0') (navigation_task.py:196)
[31m[452668 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:39:34,886][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 524288. Throughput: 0: 1494.9. Samples: 614912. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:34,886][582981] Avg episode reward: [(0, '-94.368')]
[31m[457748 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[457749 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([33], device='cuda:0') (navigation_task.py:196)
[31m[457749 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:39:39,951][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 524288. Throughput: 0: 1517.9. Samples: 624384. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:39,951][582981] Avg episode reward: [(0, '-93.552')]
[31m[463371 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[463371 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([17], device='cuda:0') (navigation_task.py:196)
[31m[463371 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:39:44,879][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 524288. Throughput: 0: 1528.2. Samples: 629248. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:44,880][582981] Avg episode reward: [(0, '-95.680')]
[36m[2025-07-02 15:39:49,904][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 524288. Throughput: 0: 1548.0. Samples: 638336. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:49,904][582981] Avg episode reward: [(0, '-101.252')]
[31m[472064 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[472064 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([97], device='cuda:0') (navigation_task.py:196)
[31m[472064 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:39:54,975][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.6). Total num frames: 524288. Throughput: 0: 1559.8. Samples: 648064. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 15:39:54,975][582981] Avg episode reward: [(0, '-100.141')]
[31m[476202 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[476203 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([13], device='cuda:0') (navigation_task.py:196)
[31m[476203 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[478498 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[478498 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([48], device='cuda:0') (navigation_task.py:196)
[31m[478498 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:39:59,889][582981] Fps is (10 sec: 13127.5, 60 sec: 2184.9, 300 sec: 1777.3). Total num frames: 655360. Throughput: 0: 1553.7. Samples: 652416. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:39:59,889][582981] Avg episode reward: [(0, '-94.370')]
[31m[483878 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[483878 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([62], device='cuda:0') (navigation_task.py:196)
[31m[483878 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[483973 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[483973 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.9985373020172119
[33mTimeout Rate: 0.0014627011260017753 (navigation_task.py:265)
[33m[483974 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2048
[33mTimeouts: 3 (navigation_task.py:268)
[36m[2025-07-02 15:40:04,929][582981] Fps is (10 sec: 13167.2, 60 sec: 2184.3, 300 sec: 1777.3). Total num frames: 655360. Throughput: 0: 1546.5. Samples: 661376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:04,930][582981] Avg episode reward: [(0, '-98.089')]
[37m[1m[2025-07-02 15:40:05,007][582981] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000160_655360.pth...
[36m[2025-07-02 15:40:09,925][582981] Fps is (10 sec: 0.0, 60 sec: 2184.5, 300 sec: 1777.3). Total num frames: 655360. Throughput: 0: 1547.1. Samples: 670720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:09,925][582981] Avg episode reward: [(0, '-92.427')]
[36m[2025-07-02 15:40:14,881][582981] Fps is (10 sec: 0.0, 60 sec: 2185.5, 300 sec: 1777.3). Total num frames: 655360. Throughput: 0: 1548.7. Samples: 675328. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:14,881][582981] Avg episode reward: [(0, '-96.880')]
[36m[2025-07-02 15:40:19,883][582981] Fps is (10 sec: 0.0, 60 sec: 2185.3, 300 sec: 1333.0). Total num frames: 655360. Throughput: 0: 1550.3. Samples: 684672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:19,883][582981] Avg episode reward: [(0, '-94.615')]
[36m[2025-07-02 15:40:24,903][582981] Fps is (10 sec: 0.0, 60 sec: 2185.0, 300 sec: 1333.1). Total num frames: 655360. Throughput: 0: 1551.9. Samples: 694144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:24,903][582981] Avg episode reward: [(0, '-98.476')]
[36m[2025-07-02 15:40:29,966][582981] Fps is (10 sec: 0.0, 60 sec: 2182.8, 300 sec: 1332.8). Total num frames: 655360. Throughput: 0: 1541.6. Samples: 698752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:29,966][582981] Avg episode reward: [(0, '-103.460')]
[31m[511510 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[511510 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([64], device='cuda:0') (navigation_task.py:196)
[31m[511511 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[513248 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[513248 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([9], device='cuda:0') (navigation_task.py:196)
[31m[513249 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:40:34,933][582981] Fps is (10 sec: 0.0, 60 sec: 2182.8, 300 sec: 1332.9). Total num frames: 655360. Throughput: 0: 1549.2. Samples: 708096. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:34,933][582981] Avg episode reward: [(0, '-96.844')]
[36m[2025-07-02 15:40:39,886][582981] Fps is (10 sec: 0.0, 60 sec: 2186.9, 300 sec: 1333.0). Total num frames: 655360. Throughput: 0: 1544.8. Samples: 717440. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:39,886][582981] Avg episode reward: [(0, '-98.333')]
[31m[524265 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[524265 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([122], device='cuda:0') (navigation_task.py:196)
[31m[524265 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:40:44,890][582981] Fps is (10 sec: 0.0, 60 sec: 2184.2, 300 sec: 1333.3). Total num frames: 655360. Throughput: 0: 1547.3. Samples: 722048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:44,890][582981] Avg episode reward: [(0, '-97.482')]
[36m[2025-07-02 15:40:49,894][582981] Fps is (10 sec: 0.0, 60 sec: 2184.9, 300 sec: 1332.9). Total num frames: 655360. Throughput: 0: 1560.0. Samples: 731520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:49,894][582981] Avg episode reward: [(0, '-98.183')]
[31m[530356 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[530357 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([120], device='cuda:0') (navigation_task.py:196)
[31m[530357 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:40:54,950][582981] Fps is (10 sec: 0.0, 60 sec: 2185.4, 300 sec: 1332.7). Total num frames: 655360. Throughput: 0: 1557.9. Samples: 740864. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:54,950][582981] Avg episode reward: [(0, '-99.968')]
[31m[540151 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[540151 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([55], device='cuda:0') (navigation_task.py:196)
[31m[540151 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:40:59,922][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 655360. Throughput: 0: 1557.3. Samples: 745472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:40:59,923][582981] Avg episode reward: [(0, '-90.547')]
[37m[1m[2025-07-02 15:40:59,997][582981] Saving new best policy, reward=-90.547!
[33m[543059 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[543059 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.99267578125
[33mTimeout Rate: 0.00732421875 (navigation_task.py:265)
[33m[543059 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2033
[33mTimeouts: 15 (navigation_task.py:268)
[36m[2025-07-02 15:41:04,925][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 655360. Throughput: 0: 1554.4. Samples: 754688. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:41:04,926][582981] Avg episode reward: [(0, '-99.247')]
[31m[548983 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[548983 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([26], device='cuda:0') (navigation_task.py:196)
[31m[548983 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:41:09,898][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 655360. Throughput: 0: 1550.4. Samples: 763904. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:41:09,898][582981] Avg episode reward: [(0, '-97.709')]
[36m[2025-07-02 15:41:14,886][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 655360. Throughput: 0: 1550.1. Samples: 768384. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:41:14,886][582981] Avg episode reward: [(0, '-101.983')]
[36m[2025-07-02 15:41:19,955][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 655360. Throughput: 0: 1549.5. Samples: 777856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:41:19,955][582981] Avg episode reward: [(0, '-90.395')]
[37m[1m[2025-07-02 15:41:19,964][582981] Saving new best policy, reward=-90.395!
[31m[560834 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[560834 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([57], device='cuda:0') (navigation_task.py:196)
[31m[560834 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[563285 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[563286 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([97], device='cuda:0') (navigation_task.py:196)
[31m[563286 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:41:24,958][582981] Fps is (10 sec: 13013.5, 60 sec: 2182.5, 300 sec: 1777.1). Total num frames: 786432. Throughput: 0: 1542.1. Samples: 786944. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:41:24,958][582981] Avg episode reward: [(0, '-95.833')]
[36m[2025-07-02 15:41:29,957][582981] Fps is (10 sec: 13105.0, 60 sec: 2184.9, 300 sec: 1777.3). Total num frames: 786432. Throughput: 0: 1545.1. Samples: 791680. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:41:29,957][582981] Avg episode reward: [(0, '-90.570')]
[36m[2025-07-02 15:41:34,929][582981] Fps is (10 sec: 0.0, 60 sec: 2184.7, 300 sec: 1777.2). Total num frames: 786432. Throughput: 0: 1537.7. Samples: 800768. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:41:34,929][582981] Avg episode reward: [(0, '-88.234')]
[37m[1m[2025-07-02 15:41:35,008][582981] Saving new best policy, reward=-88.234!
[36m[2025-07-02 15:41:39,938][582981] Fps is (10 sec: 0.0, 60 sec: 2182.6, 300 sec: 1777.1). Total num frames: 786432. Throughput: 0: 1527.9. Samples: 809600. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:41:39,938][582981] Avg episode reward: [(0, '-91.884')]
[36m[2025-07-02 15:41:44,941][582981] Fps is (10 sec: 0.0, 60 sec: 2182.7, 300 sec: 1777.5). Total num frames: 786432. Throughput: 0: 1524.0. Samples: 814080. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:41:44,941][582981] Avg episode reward: [(0, '-87.645')]
[37m[1m[2025-07-02 15:41:45,029][582981] Saving new best policy, reward=-87.645!
[36m[2025-07-02 15:41:49,953][582981] Fps is (10 sec: 0.0, 60 sec: 2182.4, 300 sec: 1333.2). Total num frames: 786432. Throughput: 0: 1515.2. Samples: 822912. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:41:49,953][582981] Avg episode reward: [(0, '-93.254')]
[31m[591493 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[591493 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([105], device='cuda:0') (navigation_task.py:196)
[31m[591493 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[593134 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[593134 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([41], device='cuda:0') (navigation_task.py:196)
[31m[593134 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[595029 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[595029 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([8], device='cuda:0') (navigation_task.py:196)
[31m[595030 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:41:54,888][582981] Fps is (10 sec: 0.0, 60 sec: 2186.8, 300 sec: 1333.3). Total num frames: 786432. Throughput: 0: 1510.7. Samples: 831872. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:41:54,888][582981] Avg episode reward: [(0, '-96.467')]
[31m[599943 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[599944 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([106], device='cuda:0') (navigation_task.py:196)
[31m[599944 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:41:59,919][582981] Fps is (10 sec: 0.0, 60 sec: 2184.7, 300 sec: 1333.0). Total num frames: 786432. Throughput: 0: 1509.3. Samples: 836352. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:41:59,919][582981] Avg episode reward: [(0, '-87.774')]
[36m[2025-07-02 15:42:04,904][582981] Fps is (10 sec: 0.0, 60 sec: 2185.3, 300 sec: 1332.9). Total num frames: 786432. Throughput: 0: 1506.4. Samples: 845568. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:42:04,905][582981] Avg episode reward: [(0, '-98.031')]
[37m[1m[2025-07-02 15:42:04,982][582981] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000192_786432.pth...
[36m[2025-07-02 15:42:09,889][582981] Fps is (10 sec: 0.0, 60 sec: 2184.9, 300 sec: 1333.1). Total num frames: 786432. Throughput: 0: 1515.6. Samples: 855040. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:42:09,889][582981] Avg episode reward: [(0, '-97.280')]
[33m[611195 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[611195 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0009756097570061684
[33mCrash Rate: 0.9702439308166504
[33mTimeout Rate: 0.028780488297343254 (navigation_task.py:265)
[33m[611195 ms][navigation_task] - WARNING : 
[33mSuccesses: 2
[33mCrashes : 1989
[33mTimeouts: 59 (navigation_task.py:268)
[31m[612911 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[612911 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([85], device='cuda:0') (navigation_task.py:196)
[31m[612912 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[615159 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[615160 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([96], device='cuda:0') (navigation_task.py:196)
[31m[615160 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:42:14,939][582981] Fps is (10 sec: 0.0, 60 sec: 2182.6, 300 sec: 1333.0). Total num frames: 786432. Throughput: 0: 1513.9. Samples: 859776. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:42:14,939][582981] Avg episode reward: [(0, '-91.291')]
[36m[2025-07-02 15:42:19,929][582981] Fps is (10 sec: 0.0, 60 sec: 2185.5, 300 sec: 1333.0). Total num frames: 786432. Throughput: 0: 1518.9. Samples: 869120. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:42:19,929][582981] Avg episode reward: [(0, '-92.828')]
[36m[2025-07-02 15:42:24,922][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 786432. Throughput: 0: 1528.0. Samples: 878336. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:42:24,923][582981] Avg episode reward: [(0, '-92.806')]
[36m[2025-07-02 15:42:29,957][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 786432. Throughput: 0: 1529.8. Samples: 882944. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:42:29,958][582981] Avg episode reward: [(0, '-92.422')]
[31m[631301 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[631301 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([120], device='cuda:0') (navigation_task.py:196)
[31m[631302 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[632796 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[632797 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([105], device='cuda:0') (navigation_task.py:196)
[31m[632797 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:42:34,898][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 786432. Throughput: 0: 1535.0. Samples: 891904. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:42:34,898][582981] Avg episode reward: [(0, '-94.418')]
[36m[2025-07-02 15:42:39,929][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 786432. Throughput: 0: 1509.0. Samples: 899840. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:42:39,930][582981] Avg episode reward: [(0, '-89.566')]
[36m[2025-07-02 15:42:44,977][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 786432. Throughput: 0: 1494.2. Samples: 903680. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:42:44,977][582981] Avg episode reward: [(0, '-89.739')]
[31m[649798 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[649798 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([23], device='cuda:0') (navigation_task.py:196)
[31m[649799 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:42:49,897][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 786432. Throughput: 0: 1465.1. Samples: 911488. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 15:42:49,897][582981] Avg episode reward: [(0, '-103.083')]
[36m[2025-07-02 15:42:54,937][582981] Fps is (10 sec: 13159.2, 60 sec: 2182.7, 300 sec: 1777.4). Total num frames: 917504. Throughput: 0: 1437.7. Samples: 919808. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:42:54,938][582981] Avg episode reward: [(0, '-90.299')]
[31m[657290 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[657290 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([24], device='cuda:0') (navigation_task.py:196)
[31m[657291 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:42:59,885][582981] Fps is (10 sec: 13122.8, 60 sec: 2185.8, 300 sec: 1777.2). Total num frames: 917504. Throughput: 0: 1432.5. Samples: 924160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:42:59,885][582981] Avg episode reward: [(0, '-66.244')]
[37m[1m[2025-07-02 15:42:59,960][582981] Saving new best policy, reward=-66.244!
[36m[2025-07-02 15:43:04,901][582981] Fps is (10 sec: 0.0, 60 sec: 2184.6, 300 sec: 1777.2). Total num frames: 917504. Throughput: 0: 1434.5. Samples: 933632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:04,901][582981] Avg episode reward: [(0, '-74.196')]
[36m[2025-07-02 15:43:09,946][582981] Fps is (10 sec: 0.0, 60 sec: 2182.5, 300 sec: 1777.5). Total num frames: 917504. Throughput: 0: 1438.5. Samples: 943104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:09,946][582981] Avg episode reward: [(0, '-83.303')]
[31m[670327 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[670327 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([98], device='cuda:0') (navigation_task.py:196)
[31m[670327 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:43:14,924][582981] Fps is (10 sec: 0.0, 60 sec: 2185.1, 300 sec: 1778.0). Total num frames: 917504. Throughput: 0: 1446.0. Samples: 947968. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:14,924][582981] Avg episode reward: [(0, '-74.858')]
[31m[679967 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[679967 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([105], device='cuda:0') (navigation_task.py:196)
[31m[679967 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:43:19,911][582981] Fps is (10 sec: 0.0, 60 sec: 2185.2, 300 sec: 1777.7). Total num frames: 917504. Throughput: 0: 1447.4. Samples: 957056. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:19,911][582981] Avg episode reward: [(0, '-74.809')]
[31m[683418 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[683419 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([120], device='cuda:0') (navigation_task.py:196)
[31m[683419 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:43:24,981][582981] Fps is (10 sec: 0.0, 60 sec: 2182.4, 300 sec: 1332.6). Total num frames: 917504. Throughput: 0: 1471.7. Samples: 966144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:24,982][582981] Avg episode reward: [(0, '-71.087')]
[36m[2025-07-02 15:43:29,927][582981] Fps is (10 sec: 0.0, 60 sec: 2185.6, 300 sec: 1332.8). Total num frames: 917504. Throughput: 0: 1492.1. Samples: 970752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:29,928][582981] Avg episode reward: [(0, '-92.906')]
[33m[690391 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[690391 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.00048804294783622026
[33mCrash Rate: 0.9175207614898682
[33mTimeout Rate: 0.08199121803045273 (navigation_task.py:265)
[33m[690391 ms][navigation_task] - WARNING : 
[33mSuccesses: 1
[33mCrashes : 1880
[33mTimeouts: 168 (navigation_task.py:268)
[36m[2025-07-02 15:43:34,885][582981] Fps is (10 sec: 0.0, 60 sec: 2185.0, 300 sec: 1333.1). Total num frames: 917504. Throughput: 0: 1525.0. Samples: 980096. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:34,885][582981] Avg episode reward: [(0, '-81.435')]
[36m[2025-07-02 15:43:39,933][582981] Fps is (10 sec: 0.0, 60 sec: 2184.4, 300 sec: 1332.8). Total num frames: 917504. Throughput: 0: 1553.2. Samples: 989696. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:39,933][582981] Avg episode reward: [(0, '-74.698')]
[31m[701368 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[701368 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([6], device='cuda:0') (navigation_task.py:196)
[31m[701368 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[702282 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[702283 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([62], device='cuda:0') (navigation_task.py:196)
[31m[702284 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:43:44,892][582981] Fps is (10 sec: 0.0, 60 sec: 2187.6, 300 sec: 1333.1). Total num frames: 917504. Throughput: 0: 1558.5. Samples: 994304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:44,893][582981] Avg episode reward: [(0, '-85.134')]
[31m[707926 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[707927 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([6], device='cuda:0') (navigation_task.py:196)
[31m[707927 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:43:49,906][582981] Fps is (10 sec: 0.0, 60 sec: 2184.2, 300 sec: 1333.0). Total num frames: 917504. Throughput: 0: 1561.4. Samples: 1003904. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:49,906][582981] Avg episode reward: [(0, '-75.490')]
[31m[712146 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[712147 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([67], device='cuda:0') (navigation_task.py:196)
[31m[712147 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:43:54,952][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 917504. Throughput: 0: 1558.5. Samples: 1013248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:54,952][582981] Avg episode reward: [(0, '-72.352')]
[36m[2025-07-02 15:43:59,912][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 917504. Throughput: 0: 1553.5. Samples: 1017856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:43:59,912][582981] Avg episode reward: [(0, '-87.888')]
[36m[2025-07-02 15:44:04,928][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 917504. Throughput: 0: 1552.5. Samples: 1026944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:04,928][582981] Avg episode reward: [(0, '-72.818')]
[37m[1m[2025-07-02 15:44:05,008][582981] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000224_917504.pth...
[36m[2025-07-02 15:44:05,012][582981] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000032_131072.pth
[31m[727617 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[727617 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([61], device='cuda:0') (navigation_task.py:196)
[31m[727617 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:44:09,927][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 917504. Throughput: 0: 1552.1. Samples: 1035904. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:09,928][582981] Avg episode reward: [(0, '-89.952')]
[31m[731723 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[731724 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([85], device='cuda:0') (navigation_task.py:196)
[31m[731724 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[732155 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[732155 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([77], device='cuda:0') (navigation_task.py:196)
[31m[732156 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:44:14,929][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 917504. Throughput: 0: 1550.2. Samples: 1040512. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:14,930][582981] Avg episode reward: [(0, '-83.903')]
[31m[739278 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[739278 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([98], device='cuda:0') (navigation_task.py:196)
[31m[739278 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:44:19,933][582981] Fps is (10 sec: 13099.5, 60 sec: 2183.7, 300 sec: 1777.1). Total num frames: 1048576. Throughput: 0: 1548.6. Samples: 1049856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:19,934][582981] Avg episode reward: [(0, '-79.843')]
[31m[741771 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[741772 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([67], device='cuda:0') (navigation_task.py:196)
[31m[741772 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:44:24,896][582981] Fps is (10 sec: 13151.6, 60 sec: 2187.7, 300 sec: 1777.4). Total num frames: 1048576. Throughput: 0: 1540.1. Samples: 1058944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:24,896][582981] Avg episode reward: [(0, '-61.896')]
[37m[1m[2025-07-02 15:44:24,972][582981] Saving new best policy, reward=-61.896!
[36m[2025-07-02 15:44:29,962][582981] Fps is (10 sec: 0.0, 60 sec: 2183.3, 300 sec: 1776.8). Total num frames: 1048576. Throughput: 0: 1539.3. Samples: 1063680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:29,962][582981] Avg episode reward: [(0, '-55.947')]
[37m[1m[2025-07-02 15:44:30,049][582981] Saving new best policy, reward=-55.947!
[36m[2025-07-02 15:44:34,917][582981] Fps is (10 sec: 0.0, 60 sec: 2183.4, 300 sec: 1777.5). Total num frames: 1048576. Throughput: 0: 1541.3. Samples: 1073280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:34,917][582981] Avg episode reward: [(0, '-58.616')]
[31m[759976 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[759977 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([93], device='cuda:0') (navigation_task.py:196)
[31m[759977 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:44:39,906][582981] Fps is (10 sec: 0.0, 60 sec: 2185.5, 300 sec: 1777.1). Total num frames: 1048576. Throughput: 0: 1546.1. Samples: 1082752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:39,906][582981] Avg episode reward: [(0, '-65.239')]
[36m[2025-07-02 15:44:44,915][582981] Fps is (10 sec: 0.0, 60 sec: 2183.7, 300 sec: 1777.2). Total num frames: 1048576. Throughput: 0: 1547.3. Samples: 1087488. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:44,916][582981] Avg episode reward: [(0, '-55.416')]
[37m[1m[2025-07-02 15:44:44,999][582981] Saving new best policy, reward=-55.416!
[36m[2025-07-02 15:44:49,898][582981] Fps is (10 sec: 0.0, 60 sec: 2184.8, 300 sec: 1777.7). Total num frames: 1048576. Throughput: 0: 1556.9. Samples: 1096960. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:49,898][582981] Avg episode reward: [(0, '-67.537')]
[36m[2025-07-02 15:44:54,910][582981] Fps is (10 sec: 0.0, 60 sec: 2186.0, 300 sec: 1332.8). Total num frames: 1048576. Throughput: 0: 1565.0. Samples: 1106304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:54,910][582981] Avg episode reward: [(0, '-67.853')]
[33m[777645 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[777645 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.006338371429592371
[33mCrash Rate: 0.8274012804031372
[33mTimeout Rate: 0.16626036167144775 (navigation_task.py:265)
[33m[777645 ms][navigation_task] - WARNING : 
[33mSuccesses: 13
[33mCrashes : 1697
[33mTimeouts: 341 (navigation_task.py:268)
[36m[2025-07-02 15:44:59,922][582981] Fps is (10 sec: 0.0, 60 sec: 2184.2, 300 sec: 1333.0). Total num frames: 1048576. Throughput: 0: 1570.4. Samples: 1111168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:44:59,922][582981] Avg episode reward: [(0, '-54.151')]
[37m[1m[2025-07-02 15:44:59,998][582981] Saving new best policy, reward=-54.151!
[36m[2025-07-02 15:45:04,918][582981] Fps is (10 sec: 0.0, 60 sec: 2184.9, 300 sec: 1333.0). Total num frames: 1048576. Throughput: 0: 1567.8. Samples: 1120384. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:04,918][582981] Avg episode reward: [(0, '-62.602')]
[36m[2025-07-02 15:45:09,960][582981] Fps is (10 sec: 0.0, 60 sec: 2183.4, 300 sec: 1332.6). Total num frames: 1048576. Throughput: 0: 1565.1. Samples: 1129472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:09,960][582981] Avg episode reward: [(0, '-59.025')]
[36m[2025-07-02 15:45:14,885][582981] Fps is (10 sec: 0.0, 60 sec: 2186.1, 300 sec: 1332.9). Total num frames: 1048576. Throughput: 0: 1570.0. Samples: 1134208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:14,885][582981] Avg episode reward: [(0, '-36.990')]
[37m[1m[2025-07-02 15:45:14,968][582981] Saving new best policy, reward=-36.990!
[36m[2025-07-02 15:45:19,920][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1048576. Throughput: 0: 1564.4. Samples: 1143680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:19,920][582981] Avg episode reward: [(0, '-67.063')]
[31m[801309 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[801310 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([118], device='cuda:0') (navigation_task.py:196)
[31m[801310 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[801988 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[801988 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([127], device='cuda:0') (navigation_task.py:196)
[31m[801989 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[803117 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[803118 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([120], device='cuda:0') (navigation_task.py:196)
[31m[803118 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:45:24,918][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 1048576. Throughput: 0: 1561.2. Samples: 1153024. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:24,918][582981] Avg episode reward: [(0, '-51.643')]
[31m[809591 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[809591 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([111], device='cuda:0') (navigation_task.py:196)
[31m[809592 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:45:29,951][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1048576. Throughput: 0: 1563.2. Samples: 1157888. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:29,951][582981] Avg episode reward: [(0, '-69.397')]
[36m[2025-07-02 15:45:34,934][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 1048576. Throughput: 0: 1557.5. Samples: 1167104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:34,934][582981] Avg episode reward: [(0, '-45.356')]
[31m[818825 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[818826 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([62], device='cuda:0') (navigation_task.py:196)
[31m[818826 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:45:39,891][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1048576. Throughput: 0: 1562.3. Samples: 1176576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:39,891][582981] Avg episode reward: [(0, '-56.358')]
[36m[2025-07-02 15:45:44,882][582981] Fps is (10 sec: 13176.4, 60 sec: 2185.8, 300 sec: 1777.3). Total num frames: 1179648. Throughput: 0: 1551.6. Samples: 1180928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:44,882][582981] Avg episode reward: [(0, '-59.693')]
[36m[2025-07-02 15:45:49,885][582981] Fps is (10 sec: 13115.0, 60 sec: 2185.0, 300 sec: 1777.6). Total num frames: 1179648. Throughput: 0: 1551.4. Samples: 1190144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:49,885][582981] Avg episode reward: [(0, '-46.066')]
[36m[2025-07-02 15:45:54,937][582981] Fps is (10 sec: 0.0, 60 sec: 2183.6, 300 sec: 1777.2). Total num frames: 1179648. Throughput: 0: 1559.6. Samples: 1199616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:54,937][582981] Avg episode reward: [(0, '-39.782')]
[36m[2025-07-02 15:45:59,889][582981] Fps is (10 sec: 0.0, 60 sec: 2185.7, 300 sec: 1777.5). Total num frames: 1179648. Throughput: 0: 1558.6. Samples: 1204352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:45:59,889][582981] Avg episode reward: [(0, '-28.792')]
[37m[1m[2025-07-02 15:45:59,969][582981] Saving new best policy, reward=-28.792!
[36m[2025-07-02 15:46:04,952][582981] Fps is (10 sec: 0.0, 60 sec: 2183.3, 300 sec: 1776.9). Total num frames: 1179648. Throughput: 0: 1566.2. Samples: 1214208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:04,952][582981] Avg episode reward: [(0, '-41.170')]
[37m[1m[2025-07-02 15:46:05,036][582981] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000288_1179648.pth...
[36m[2025-07-02 15:46:05,040][582981] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000064_262144.pth
[36m[2025-07-02 15:46:09,903][582981] Fps is (10 sec: 0.0, 60 sec: 2186.6, 300 sec: 1777.1). Total num frames: 1179648. Throughput: 0: 1562.1. Samples: 1223296. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:09,903][582981] Avg episode reward: [(0, '-49.074')]
[36m[2025-07-02 15:46:14,886][582981] Fps is (10 sec: 0.0, 60 sec: 2184.5, 300 sec: 1777.7). Total num frames: 1179648. Throughput: 0: 1555.3. Samples: 1227776. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:14,886][582981] Avg episode reward: [(0, '-43.373')]
[36m[2025-07-02 15:46:19,892][582981] Fps is (10 sec: 0.0, 60 sec: 2185.6, 300 sec: 1333.2). Total num frames: 1179648. Throughput: 0: 1534.6. Samples: 1236096. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:19,892][582981] Avg episode reward: [(0, '-26.581')]
[37m[1m[2025-07-02 15:46:19,981][582981] Saving new best policy, reward=-26.581!
[31m[861528 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[861528 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([56], device='cuda:0') (navigation_task.py:196)
[31m[861528 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:46:24,947][582981] Fps is (10 sec: 0.0, 60 sec: 2183.5, 300 sec: 1333.0). Total num frames: 1179648. Throughput: 0: 1517.0. Samples: 1244928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:24,947][582981] Avg episode reward: [(0, '-53.122')]
[36m[2025-07-02 15:46:29,906][582981] Fps is (10 sec: 0.0, 60 sec: 2186.2, 300 sec: 1333.0). Total num frames: 1179648. Throughput: 0: 1515.3. Samples: 1249152. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:29,906][582981] Avg episode reward: [(0, '-32.537')]
[36m[2025-07-02 15:46:34,940][582981] Fps is (10 sec: 0.0, 60 sec: 2184.3, 300 sec: 1332.9). Total num frames: 1179648. Throughput: 0: 1502.9. Samples: 1257856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:34,940][582981] Avg episode reward: [(0, '-33.619')]
[33m[878059 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[878059 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.024890189990401268
[33mCrash Rate: 0.6783797144889832
[33mTimeout Rate: 0.296730101108551 (navigation_task.py:265)
[33m[878059 ms][navigation_task] - WARNING : 
[33mSuccesses: 51
[33mCrashes : 1390
[33mTimeouts: 608 (navigation_task.py:268)
[36m[2025-07-02 15:46:39,901][582981] Fps is (10 sec: 0.0, 60 sec: 2184.1, 300 sec: 1333.1). Total num frames: 1179648. Throughput: 0: 1503.0. Samples: 1267200. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:39,902][582981] Avg episode reward: [(0, '-61.138')]
[36m[2025-07-02 15:46:44,947][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1179648. Throughput: 0: 1491.4. Samples: 1271552. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:44,948][582981] Avg episode reward: [(0, '-53.021')]
[36m[2025-07-02 15:46:49,902][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1179648. Throughput: 0: 1475.1. Samples: 1280512. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:49,902][582981] Avg episode reward: [(0, '-39.921')]
[31m[894366 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[894367 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([96], device='cuda:0') (navigation_task.py:196)
[31m[894367 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:46:54,944][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1179648. Throughput: 0: 1469.2. Samples: 1289472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:54,944][582981] Avg episode reward: [(0, '-46.092')]
[31m[898557 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[898558 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([61], device='cuda:0') (navigation_task.py:196)
[31m[898558 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:46:59,900][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1179648. Throughput: 0: 1461.6. Samples: 1293568. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:46:59,900][582981] Avg episode reward: [(0, '-39.962')]
[36m[2025-07-02 15:47:04,901][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1179648. Throughput: 0: 1481.6. Samples: 1302784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:47:04,902][582981] Avg episode reward: [(0, '-44.056')]
[36m[2025-07-02 15:47:09,922][582981] Fps is (10 sec: 13078.3, 60 sec: 2183.8, 300 sec: 1777.3). Total num frames: 1310720. Throughput: 0: 1474.2. Samples: 1311232. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:09,922][582981] Avg episode reward: [(0, '-45.487')]
[31m[912345 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[912346 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([61], device='cuda:0') (navigation_task.py:196)
[31m[912346 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:47:14,958][582981] Fps is (10 sec: 13033.8, 60 sec: 2181.9, 300 sec: 1777.1). Total num frames: 1310720. Throughput: 0: 1483.1. Samples: 1315968. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:14,958][582981] Avg episode reward: [(0, '-20.560')]
[37m[1m[2025-07-02 15:47:15,041][582981] Saving new best policy, reward=-20.560!
[31m[919030 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[919030 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([9], device='cuda:0') (navigation_task.py:196)
[31m[919031 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:47:19,902][582981] Fps is (10 sec: 0.0, 60 sec: 2184.2, 300 sec: 1777.4). Total num frames: 1310720. Throughput: 0: 1494.6. Samples: 1325056. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:19,902][582981] Avg episode reward: [(0, '-25.278')]
[36m[2025-07-02 15:47:24,942][582981] Fps is (10 sec: 0.0, 60 sec: 2184.7, 300 sec: 1777.3). Total num frames: 1310720. Throughput: 0: 1492.0. Samples: 1334400. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:24,943][582981] Avg episode reward: [(0, '-30.560')]
[36m[2025-07-02 15:47:29,929][582981] Fps is (10 sec: 0.0, 60 sec: 2183.7, 300 sec: 1777.1). Total num frames: 1310720. Throughput: 0: 1496.8. Samples: 1338880. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:29,929][582981] Avg episode reward: [(0, '-16.219')]
[37m[1m[2025-07-02 15:47:30,031][582981] Saving new best policy, reward=-16.219!
[36m[2025-07-02 15:47:34,945][582981] Fps is (10 sec: 0.0, 60 sec: 2184.4, 300 sec: 1777.2). Total num frames: 1310720. Throughput: 0: 1491.9. Samples: 1347712. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:34,945][582981] Avg episode reward: [(0, '-33.179')]
[31m[940243 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[940244 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([6], device='cuda:0') (navigation_task.py:196)
[31m[940245 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:47:39,945][582981] Fps is (10 sec: 0.0, 60 sec: 2182.9, 300 sec: 1777.4). Total num frames: 1310720. Throughput: 0: 1490.4. Samples: 1356544. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:39,945][582981] Avg episode reward: [(0, '-15.403')]
[37m[1m[2025-07-02 15:47:40,034][582981] Saving new best policy, reward=-15.403!
[36m[2025-07-02 15:47:44,879][582981] Fps is (10 sec: 0.0, 60 sec: 2187.0, 300 sec: 1777.4). Total num frames: 1310720. Throughput: 0: 1502.6. Samples: 1361152. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:44,880][582981] Avg episode reward: [(0, '-23.671')]
[31m[945819 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[945819 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([111], device='cuda:0') (navigation_task.py:196)
[31m[945820 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:47:49,920][582981] Fps is (10 sec: 0.0, 60 sec: 2183.9, 300 sec: 1333.0). Total num frames: 1310720. Throughput: 0: 1487.0. Samples: 1369728. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:49,920][582981] Avg episode reward: [(0, '-39.093')]
[36m[2025-07-02 15:47:54,884][582981] Fps is (10 sec: 0.0, 60 sec: 2186.7, 300 sec: 1332.9). Total num frames: 1310720. Throughput: 0: 1508.8. Samples: 1379072. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:54,884][582981] Avg episode reward: [(0, '-36.133')]
[36m[2025-07-02 15:47:59,926][582981] Fps is (10 sec: 0.0, 60 sec: 2183.6, 300 sec: 1332.8). Total num frames: 1310720. Throughput: 0: 1502.9. Samples: 1383552. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:47:59,926][582981] Avg episode reward: [(0, '-24.820')]
[31m[962002 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[962003 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([113], device='cuda:0') (navigation_task.py:196)
[31m[962003 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:48:04,937][582981] Fps is (10 sec: 0.0, 60 sec: 2183.2, 300 sec: 1333.0). Total num frames: 1310720. Throughput: 0: 1512.1. Samples: 1393152. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:48:04,937][582981] Avg episode reward: [(0, '-10.688')]
[37m[1m[2025-07-02 15:48:05,025][582981] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000320_1310720.pth...
[36m[2025-07-02 15:48:05,029][582981] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_4/checkpoint_p0/checkpoint_000000096_393216.pth
[37m[1m[2025-07-02 15:48:05,029][582981] Saving new best policy, reward=-10.688!
[36m[2025-07-02 15:48:09,948][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1310720. Throughput: 0: 1513.1. Samples: 1402496. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:48:09,948][582981] Avg episode reward: [(0, '-32.834')]
[36m[2025-07-02 15:48:14,939][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1310720. Throughput: 0: 1515.8. Samples: 1407104. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:48:14,939][582981] Avg episode reward: [(0, '-23.976')]
[31m[980205 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[980206 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([62], device='cuda:0') (navigation_task.py:196)
[31m[980206 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:48:19,906][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.3). Total num frames: 1310720. Throughput: 0: 1525.9. Samples: 1416320. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:48:19,906][582981] Avg episode reward: [(0, '-14.785')]
[36m[2025-07-02 15:48:24,921][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1310720. Throughput: 0: 1536.8. Samples: 1425664. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:48:24,921][582981] Avg episode reward: [(0, '-37.072')]
[33m[987853 ms][navigation_task] - WARNING : Curriculum Level: 30, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[987853 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.035139091312885284
[33mCrash Rate: 0.5514885187149048
[33mTimeout Rate: 0.41337236762046814 (navigation_task.py:265)
[33m[987853 ms][navigation_task] - WARNING : 
[33mSuccesses: 72
[33mCrashes : 1130
[33mTimeouts: 847 (navigation_task.py:268)
[31m[988773 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[988773 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([60], device='cuda:0') (navigation_task.py:196)
[31m[988773 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[989513 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[989513 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([93], device='cuda:0') (navigation_task.py:196)
[31m[989514 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:48:29,888][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1310720. Throughput: 0: 1541.4. Samples: 1430528. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-02 15:48:29,889][582981] Avg episode reward: [(0, '-17.760')]
[36m[2025-07-02 15:48:34,909][582981] Fps is (10 sec: 13122.7, 60 sec: 2185.8, 300 sec: 1777.4). Total num frames: 1441792. Throughput: 0: 1562.0. Samples: 1440000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:48:34,910][582981] Avg episode reward: [(0, '-15.480')]
[36m[2025-07-02 15:48:39,882][582981] Fps is (10 sec: 13115.8, 60 sec: 2186.8, 300 sec: 1777.3). Total num frames: 1441792. Throughput: 0: 1564.5. Samples: 1449472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:48:39,882][582981] Avg episode reward: [(0, '-16.681')]
[36m[2025-07-02 15:48:44,937][582981] Fps is (10 sec: 0.0, 60 sec: 2182.4, 300 sec: 1777.1). Total num frames: 1441792. Throughput: 0: 1569.7. Samples: 1454208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:48:44,937][582981] Avg episode reward: [(0, '-9.075')]
[37m[1m[2025-07-02 15:48:45,019][582981] Saving new best policy, reward=-9.075!
[36m[2025-07-02 15:48:49,917][582981] Fps is (10 sec: 0.0, 60 sec: 2184.6, 300 sec: 1777.5). Total num frames: 1441792. Throughput: 0: 1570.8. Samples: 1463808. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:48:49,918][582981] Avg episode reward: [(0, '-12.057')]
[36m[2025-07-02 15:48:54,946][582981] Fps is (10 sec: 0.0, 60 sec: 2182.3, 300 sec: 1777.0). Total num frames: 1441792. Throughput: 0: 1558.8. Samples: 1472640. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:48:54,946][582981] Avg episode reward: [(0, '-12.412')]
[36m[2025-07-02 15:48:59,936][582981] Fps is (10 sec: 0.0, 60 sec: 2184.1, 300 sec: 1777.2). Total num frames: 1441792. Throughput: 0: 1558.8. Samples: 1477248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:48:59,937][582981] Avg episode reward: [(0, '-16.366')]
[36m[2025-07-02 15:49:04,883][582981] Fps is (10 sec: 0.0, 60 sec: 2186.5, 300 sec: 1777.5). Total num frames: 1441792. Throughput: 0: 1551.0. Samples: 1486080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:49:04,883][582981] Avg episode reward: [(0, '-22.478')]
[31m[1028446 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1028447 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([112], device='cuda:0') (navigation_task.py:196)
[31m[1028447 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:49:09,925][582981] Fps is (10 sec: 0.0, 60 sec: 2185.3, 300 sec: 1777.3). Total num frames: 1441792. Throughput: 0: 1544.4. Samples: 1495168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:49:09,926][582981] Avg episode reward: [(0, '-18.737')]
[31m[1034152 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1034152 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([49], device='cuda:0') (navigation_task.py:196)
[31m[1034153 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:49:14,886][582981] Fps is (10 sec: 0.0, 60 sec: 2186.5, 300 sec: 1333.2). Total num frames: 1441792. Throughput: 0: 1538.9. Samples: 1499776. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:49:14,886][582981] Avg episode reward: [(0, '-8.257')]
[37m[1m[2025-07-02 15:49:14,980][582981] Saving new best policy, reward=-8.257!
[36m[2025-07-02 15:49:19,927][582981] Fps is (10 sec: 0.0, 60 sec: 2183.7, 300 sec: 1332.8). Total num frames: 1441792. Throughput: 0: 1518.3. Samples: 1508352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:49:19,928][582981] Avg episode reward: [(0, '-14.170')]
[31m[1044590 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1044591 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([10], device='cuda:0') (navigation_task.py:196)
[31m[1044591 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:49:24,968][582981] Fps is (10 sec: 0.0, 60 sec: 2182.8, 300 sec: 1332.9). Total num frames: 1441792. Throughput: 0: 1482.0. Samples: 1516288. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:49:24,968][582981] Avg episode reward: [(0, '-22.160')]
[36m[2025-07-02 15:49:29,960][582981] Fps is (10 sec: 0.0, 60 sec: 2181.9, 300 sec: 1332.7). Total num frames: 1441792. Throughput: 0: 1472.7. Samples: 1520512. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:49:29,960][582981] Avg episode reward: [(0, '-17.265')]
[31m[1051638 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1051638 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([23], device='cuda:0') (navigation_task.py:196)
[31m[1051638 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[1054395 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1054395 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([48], device='cuda:0') (navigation_task.py:196)
[31m[1054396 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 15:49:34,891][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1441792. Throughput: 0: 1451.5. Samples: 1529088. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:49:34,891][582981] Avg episode reward: [(0, '-25.886')]
[36m[2025-07-02 15:49:39,918][582981] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1441792. Throughput: 0: 1460.1. Samples: 1538304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 15:49:39,918][582981] Avg episode reward: [(0, '-15.357')]
[37m[1m[2025-07-02 15:49:41,340][582981] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 582981], exiting...
[37m[1m[2025-07-02 15:49:41,340][582981] Runner profile tree view:
[37m[1mmain_loop: 1049.4206
[37m[1m[2025-07-02 15:49:41,349][582981] Collected {0: 1441792}, FPS: 1373.9