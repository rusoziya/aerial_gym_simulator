Importing module 'gym_38' (/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
[36m[2025-07-02 13:04:05,017][524661] Queried available GPUs: 0
[37m[1m[2025-07-02 13:04:05,018][524661] Environment var CUDA_VISIBLE_DEVICES is 0
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/utils/cpp_extension.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging  # type: ignore[attr-defined]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Using /home/ziyar/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
Emitting ninja build file /home/ziyar/.cache/torch_extensions/py38_cu117/gymtorch/build.ninja...
Building extension module gymtorch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module gymtorch...
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/graph.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping, Set, Iterable
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/readwrite/graphml.py:346: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  (np.int, "int"), (np.int8, "int"),
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/torch_utils.py:135: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  def get_axis_params(value, axis_idx, x_value=0., dtype=np.float, n_dims=3):
[37m[1775 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : DCE Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task.py:22)
[37m[1775 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : DCE Navigation Task - Final headless mode: False (dce_navigation_task.py:29)
[37m[1775 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : Found SF_ENV_AGENTS environment variable: 128 (dce_navigation_task.py:39)
[37m[1775 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : Detected env_agents=128 from environment - setting environment count. (dce_navigation_task.py:45)
[37m[1775 ms][base_task] - INFO : Setting seed: 3639299644 (base_task.py:38)
[37m[1775 ms][navigation_task] - INFO : Building environment for navigation task. (navigation_task.py:44)
[37m[1775 ms][navigation_task] - INFO : Sim Name: base_sim, Env Name: env_with_obstacles, Robot Name: lmf2, Controller Name: lmf2_velocity_control (navigation_task.py:45)
[37m[1775 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[1775 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[1776 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[1776 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[1776 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[1776 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[1776 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[1776 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[1776 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[1777 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[1777 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[1777 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[1777 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
PyTorch version 1.13.1
Device count 1
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
Warp 1.0.0-beta.5 initialized:
   CUDA Toolkit: 11.5, Driver: 12.4
   Devices:
     "cpu"    | x86_64
     "cuda:0" | NVIDIA GeForce RTX 4080 Laptop GPU (sm_89)
   Kernel cache: /home/ziyar/.cache/warp/1.0.0-beta.5
[SUBPROCESS] FORCING viewer mode for rollout worker: headless=False
[SUBPROCESS] DCE task action_space_dim: 3
[SUBPROCESS] Target Sample Factory action space: 3D
[SUBPROCESS] Setting num_envs to 128 based on env_agents=128
[SUBPROCESS] Set SF_ENV_AGENTS=128 environment variable
[SUBPROCESS] DCE config batch_size: 16384
[SUBPROCESS] Using MAXIMUM PARALLELIZATION DCE CONFIG (128 environments)
[SUBPROCESS] FORCING headless=False for rollout worker
[SUBPROCESS] FORCING viewer mode for rollout worker
Registered quad_with_obstacles and dce_navigation_task in subprocess
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles', '--train_for_env_steps=100000000', '--experiment=HIGH_CONFIG_128ENV_1', '--async_rl=True', '--use_env_info_cache=False', '--normalize_input=True', '--async_rl=False', '--serial_mode=True']
Not connected to PVD
+++ Using GPU PhysX
[37m[2775 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[2775 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[2981 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[2981 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[2981 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[2981 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[2981 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[2981 ms][BaseRobot] - INFO : Initializing controller lmf2_velocity_control (base_robot.py:29)
[33m[2981 ms][base_multirotor] - WARNING : Creating 128 multirotors. (base_multirotor.py:32)
[37m[2981 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[2981 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[2981 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2981 ms][asset_loader] - INFO : Loading asset: panel.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2983 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2984 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2987 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2988 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2989 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2990 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2990 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2991 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2992 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2993 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2994 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3003 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[3370 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[3370 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[3370 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[3569 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[3582 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[3582 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[3658 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[3658 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[3820 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 9 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[4017 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[4018 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.30 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 7.68 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 12.15 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.81 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 128
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[36m[2025-07-02 13:04:09,858][524771] Env info: EnvInfo(obs_space=Dict('obs': Box(-inf, inf, (81,), float32)), action_space=Box(-1.0, 1.0, (3,), float32), num_agents=128, gpu_actions=True, gpu_observations=True, action_splits=None, all_discrete=None, frameskip=1, reward_shaping_scheme=None, env_info_protocol_version=1)
[36m[2025-07-02 13:04:10,587][524661] Starting experiment with the following configuration:
[36mhelp=False
[36malgo=APPO
[36menv=quad_with_obstacles
[36mexperiment=HIGH_CONFIG_128ENV_1
[36mtrain_dir=/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir
[36mrestart_behavior=resume
[36mdevice=gpu
[36mseed=None
[36mnum_policies=1
[36masync_rl=False
[36mserial_mode=True
[36mbatched_sampling=True
[36mnum_batches_to_accumulate=2
[36mworker_num_splits=1
[36mpolicy_workers_per_policy=1
[36mmax_policy_lag=1000
[36mnum_workers=1
[36mnum_envs_per_worker=1
[36mbatch_size=16384
[36mnum_batches_per_epoch=8
[36mnum_epochs=4
[36mrollout=32
[36mrecurrence=32
[36mshuffle_minibatches=False
[36mgamma=0.98
[36mreward_scale=0.1
[36mreward_clip=1000.0
[36mvalue_bootstrap=True
[36mnormalize_returns=True
[36mexploration_loss_coeff=0.001
[36mvalue_loss_coeff=2.0
[36mkl_loss_coeff=0.1
[36mexploration_loss=entropy
[36mgae_lambda=0.95
[36mppo_clip_ratio=0.2
[36mppo_clip_value=1.0
[36mwith_vtrace=False
[36mvtrace_rho=1.0
[36mvtrace_c=1.0
[36moptimizer=adam
[36madam_eps=1e-06
[36madam_beta1=0.9
[36madam_beta2=0.999
[36mmax_grad_norm=1.0
[36mlearning_rate=0.0003
[36mlr_schedule=kl_adaptive_epoch
[36mlr_schedule_kl_threshold=0.016
[36mlr_adaptive_min=1e-06
[36mlr_adaptive_max=0.01
[36mobs_subtract_mean=0.0
[36mobs_scale=1.0
[36mnormalize_input=True
[36mnormalize_input_keys=None
[36mdecorrelate_experience_max_seconds=0
[36mdecorrelate_envs_on_one_worker=True
[36mactor_worker_gpus=[0]
[36mset_workers_cpu_affinity=True
[36mforce_envs_single_thread=False
[36mdefault_niceness=0
[36mlog_to_file=True
[36mexperiment_summaries_interval=10
[36mflush_summaries_interval=30
[36mstats_avg=100
[36msummaries_use_frameskip=True
[36mheartbeat_interval=20
[36mheartbeat_reporting_interval=180
[36mtrain_for_env_steps=100000000
[36mtrain_for_seconds=10000000000
[36msave_every_sec=120
[36mkeep_checkpoints=5
[36mload_checkpoint_kind=latest
[36msave_milestones_sec=-1
[36msave_best_every_sec=5
[36msave_best_metric=reward
[36msave_best_after=100000
[36mbenchmark=False
[36mencoder_mlp_layers=[512, 256, 64]
[36mencoder_conv_architecture=convnet_simple
[36mencoder_conv_mlp_layers=[]
[36muse_rnn=True
[36mrnn_size=64
[36mrnn_type=gru
[36mrnn_num_layers=1
[36mdecoder_mlp_layers=[]
[36mnonlinearity=elu
[36mpolicy_initialization=torch_default
[36mpolicy_init_gain=1.0
[36mactor_critic_share_weights=True
[36madaptive_stddev=True
[36mcontinuous_tanh_scale=0.0
[36minitial_stddev=1.0
[36muse_env_info_cache=False
[36menv_gpu_actions=True
[36menv_gpu_observations=True
[36menv_frameskip=1
[36menv_framestack=1
[36mpixel_format=CHW
[36muse_record_episode_statistics=False
[36mwith_wandb=True
[36mwandb_user=ziya-ruso-ucl
[36mwandb_project=vae_rl_navigation
[36mwandb_group=dce_navigation_training
[36mwandb_job_type=SF
[36mwandb_tags=['aerial_gym', 'dce', 'navigation', 'sample_factory']
[36mwith_pbt=False
[36mpbt_mix_policies_in_one_env=True
[36mpbt_period_env_steps=5000000
[36mpbt_start_mutation=20000000
[36mpbt_replace_fraction=0.3
[36mpbt_mutation_rate=0.15
[36mpbt_replace_reward_gap=0.1
[36mpbt_replace_reward_gap_absolute=1e-06
[36mpbt_optimize_gamma=False
[36mpbt_target_objective=true_objective
[36mpbt_perturb_min=1.1
[36mpbt_perturb_max=1.5
[36menv_agents=128
[36mheadless=False
[36mobs_key=obs
[36msubtask=None
[36mige_api_version=preview4
[36meval_stats=False
[36maction_space_dim=3
[36mcommand_line=--env=quad_with_obstacles --train_for_env_steps=100000000 --experiment=HIGH_CONFIG_128ENV_1 --async_rl=True --use_env_info_cache=False --normalize_input=True --headless=False --async_rl=False --serial_mode=True
[36mcli_args={'env': 'quad_with_obstacles', 'experiment': 'HIGH_CONFIG_128ENV_1', 'async_rl': False, 'serial_mode': True, 'normalize_input': True, 'train_for_env_steps': 100000000, 'use_env_info_cache': False, 'headless': False}
[36mgit_hash=7f68834735119b0b96b7f43bc6752d65d9292d8e
[36mgit_repo_name=git@github.com:rusoziya/aerial_gym_simulator.git
[36mwandb_unique_id=HIGH_CONFIG_128ENV_1_20250702_130401_766217
[36m[2025-07-02 13:04:10,587][524661] Saving configuration to /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/config.json...
[36m[2025-07-02 13:04:10,670][524661] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-02 13:04:10,671][524661] Rollout worker 0 uses device cuda:0
[36m[2025-07-02 13:04:10,672][524661] In synchronous mode, we only accumulate one batch. Setting num_batches_to_accumulate to 1
[36m[2025-07-02 13:04:10,729][524661] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-02 13:04:10,729][524661] InferenceWorker_p0-w0: min num requests: 1
[36m[2025-07-02 13:04:10,731][524661] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-02 13:04:10,732][524661] Starting seed is not provided
[36m[2025-07-02 13:04:10,732][524661] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-02 13:04:10,732][524661] Initializing actor-critic model on device cuda:0
[36m[2025-07-02 13:04:10,733][524661] RunningMeanStd input shape: (81,)
[36m[2025-07-02 13:04:10,734][524661] RunningMeanStd input shape: (1,)
[36m[2025-07-02 13:04:10,765][524661] Created Actor Critic model with architecture:
[36m[2025-07-02 13:04:10,765][524661] ActorCriticSharedWeights(
[36m  (obs_normalizer): ObservationNormalizer(
[36m    (running_mean_std): RunningMeanStdDictInPlace(
[36m      (running_mean_std): ModuleDict(
[36m        (obs): RunningMeanStdInPlace()
[36m      )
[36m    )
[36m  )
[36m  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
[36m  (encoder): MultiInputEncoder(
[36m    (encoders): ModuleDict(
[36m      (obs): MlpEncoder(
[36m        (mlp_head): RecursiveScriptModule(
[36m          original_name=Sequential
[36m          (0): RecursiveScriptModule(original_name=Linear)
[36m          (1): RecursiveScriptModule(original_name=ELU)
[36m          (2): RecursiveScriptModule(original_name=Linear)
[36m          (3): RecursiveScriptModule(original_name=ELU)
[36m          (4): RecursiveScriptModule(original_name=Linear)
[36m          (5): RecursiveScriptModule(original_name=ELU)
[36m        )
[36m      )
[36m    )
[36m  )
[36m  (core): ModelCoreRNN(
[36m    (core): GRU(64, 64)
[36m  )
[36m  (decoder): MlpDecoder(
[36m    (mlp): Identity()
[36m  )
[36m  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
[36m  (action_parameterization): ActionParameterizationDefault(
[36m    (distribution_linear): Linear(in_features=64, out_features=6, bias=True)
[36m  )
[36m)
[36m[2025-07-02 13:04:11,198][524661] Using optimizer <class 'torch.optim.adam.Adam'>
[33m[2025-07-02 13:04:11,199][524661] No checkpoints found
[36m[2025-07-02 13:04:11,199][524661] Did not load from checkpoint, starting from scratch!
[36m[2025-07-02 13:04:11,199][524661] Initialized policy 0 weights for model version 0
[36m[2025-07-02 13:04:11,199][524661] LearnerWorker_p0 finished initialization!
[36m[2025-07-02 13:04:11,199][524661] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-02 13:04:11,219][524661] Inference worker 0-0 is ready!
[37m[1m[2025-07-02 13:04:11,219][524661] All inference workers are ready! Signal rollout workers to start!
[36m[2025-07-02 13:04:11,220][524661] EnvRunner 0-0 uses policy 0
[37m[11736 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : DCE Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task.py:22)
[37m[11736 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : DCE Navigation Task - Final headless mode: False (dce_navigation_task.py:29)
[37m[11736 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : Found SF_ENV_AGENTS environment variable: 128 (dce_navigation_task.py:39)
[37m[11736 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task] - INFO : Detected env_agents=128 from environment - setting environment count. (dce_navigation_task.py:45)
[37m[11737 ms][base_task] - INFO : Setting seed: 3574535669 (base_task.py:38)
[37m[11737 ms][navigation_task] - INFO : Building environment for navigation task. (navigation_task.py:44)
[37m[11737 ms][navigation_task] - INFO : Sim Name: base_sim, Env Name: env_with_obstacles, Robot Name: lmf2, Controller Name: lmf2_velocity_control (navigation_task.py:45)
[37m[11737 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[11737 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[11737 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[11737 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[11737 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[11737 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[11738 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[11738 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[11738 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[11738 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[11738 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[11738 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[11738 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles', '--train_for_env_steps=100000000', '--experiment=HIGH_CONFIG_128ENV_1', '--async_rl=True', '--use_env_info_cache=False', '--normalize_input=True', '--async_rl=False', '--serial_mode=True']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.65 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 8.02 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 12.00 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.83 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 128
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[37m[12738 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[12739 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[12944 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[12944 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[12945 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[12945 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[12945 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[12945 ms][BaseRobot] - INFO : Initializing controller lmf2_velocity_control (base_robot.py:29)
[33m[12945 ms][base_multirotor] - WARNING : Creating 128 multirotors. (base_multirotor.py:32)
[37m[12945 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[12945 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[12945 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12945 ms][asset_loader] - INFO : Loading asset: panel.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12948 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12949 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12952 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12953 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12954 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12956 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12957 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12958 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12959 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12960 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12961 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12969 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[12986 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[12986 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[12986 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[13181 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[13195 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[13195 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[13274 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[13274 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[13438 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 9 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[13633 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[13635 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[31m[16210 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[16211 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
[31m         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
[31m         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
[31m         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
[31m         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
[31m         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
[31m         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
[31m         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
[31m        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
[31m        126, 127], device='cuda:0') (navigation_task.py:196)
[31m[16213 ms][navigation_task] - CRITICAL : Time at crash: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:04:17,257][524661] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:04:17,258][524661] Avg episode reward: [(0, '-100.000')]
[33m[19445 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[36m[2025-07-02 13:04:19,333][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 185.0. Samples: 384. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:04:19,334][524661] Avg episode reward: [(0, '-99.495')]
[33m[20878 ms][IGE_viewer_control] - WARNING : Camera follow: False (IGE_viewer_control.py:217)
[31m[24673 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[24673 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([78], device='cuda:0') (navigation_task.py:196)
[31m[24674 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:04:24,401][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1003.4. Samples: 7168. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:04:24,402][524661] Avg episode reward: [(0, '-85.347')]
[36m[2025-07-02 13:04:29,309][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1338.2. Samples: 16128. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:04:29,310][524661] Avg episode reward: [(0, '-99.701')]
[37m[1m[2025-07-02 13:04:30,843][524661] Heartbeat connected on Batcher_0
[37m[1m[2025-07-02 13:04:30,843][524661] Heartbeat connected on LearnerWorker_p0
[37m[1m[2025-07-02 13:04:30,843][524661] Heartbeat connected on InferenceWorker_p0-w0
[37m[1m[2025-07-02 13:04:30,843][524661] Heartbeat connected on RolloutWorker_w0
[36m[2025-07-02 13:04:34,335][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1206.7. Samples: 20608. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:04:34,336][524661] Avg episode reward: [(0, '-96.408')]
[36m[2025-07-02 13:04:39,332][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1356.8. Samples: 29952. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:04:39,332][524661] Avg episode reward: [(0, '-96.523')]
[31m[40904 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[40905 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([47], device='cuda:0') (navigation_task.py:196)
[31m[40905 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[44185 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[44185 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([123], device='cuda:0') (navigation_task.py:196)
[31m[44186 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:04:44,376][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1439.6. Samples: 39040. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:04:44,376][524661] Avg episode reward: [(0, '-97.479')]
[31m[45277 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[45278 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([60], device='cuda:0') (navigation_task.py:196)
[31m[45278 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:04:49,383][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1358.7. Samples: 43648. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:04:49,383][524661] Avg episode reward: [(0, '-100.700')]
[31m[50473 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[50474 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([96], device='cuda:0') (navigation_task.py:196)
[31m[50474 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[52120 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[52120 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([73], device='cuda:0') (navigation_task.py:196)
[31m[52120 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:04:54,320][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1426.3. Samples: 52864. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:04:54,321][524661] Avg episode reward: [(0, '-94.220')]
[31m[57191 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[57192 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([105], device='cuda:0') (navigation_task.py:196)
[31m[57192 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[57396 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[57397 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([26], device='cuda:0') (navigation_task.py:196)
[31m[57397 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:04:59,363][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1459.2. Samples: 61440. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:04:59,363][524661] Avg episode reward: [(0, '-94.871')]
[33m[60523 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[60523 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[60523 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2052
[33mTimeouts: 0 (navigation_task.py:268)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:275: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/success_rate"] = torch.tensor(success_rate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:276: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/crash_rate"] = torch.tensor(crash_rate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:277: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/timeout_rate"] = torch.tensor(timeout_rate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:278: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/total_successes"] = torch.tensor(self.success_aggregate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:279: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/total_crashes"] = torch.tensor(self.crashes_aggregate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py:280: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/total_timeouts"] = torch.tensor(self.timeouts_aggregate, dtype=torch.float32)
[31m[64083 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[64084 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([108], device='cuda:0') (navigation_task.py:196)
[31m[64084 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[64717 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[64717 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([123], device='cuda:0') (navigation_task.py:196)
[31m[64717 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:05:04,407][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1454.0. Samples: 65920. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:05:04,407][524661] Avg episode reward: [(0, '-100.009')]
[36m[2025-07-02 13:05:09,371][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1511.4. Samples: 75136. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:05:09,371][524661] Avg episode reward: [(0, '-95.375')]
[31m[74438 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[74438 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([103], device='cuda:0') (navigation_task.py:196)
[31m[74438 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:05:14,338][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1509.4. Samples: 84096. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:05:14,338][524661] Avg episode reward: [(0, '-98.545')]
[36m[2025-07-02 13:05:19,374][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1514.8. Samples: 88832. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:05:19,374][524661] Avg episode reward: [(0, '-94.840')]
[31m[80918 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[80919 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([104], device='cuda:0') (navigation_task.py:196)
[31m[80919 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:05:24,367][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1512.1. Samples: 98048. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:05:24,367][524661] Avg episode reward: [(0, '-95.461')]
[31m[88634 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[88634 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([88], device='cuda:0') (navigation_task.py:196)
[31m[88635 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[89294 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[89295 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([0], device='cuda:0') (navigation_task.py:196)
[31m[89295 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:05:29,342][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1505.9. Samples: 106752. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:05:29,342][524661] Avg episode reward: [(0, '-102.250')]
[31m[93289 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[93289 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([89], device='cuda:0') (navigation_task.py:196)
[31m[93290 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[93537 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[93538 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([50], device='cuda:0') (navigation_task.py:196)
[31m[93538 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:05:34,335][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1506.3. Samples: 111360. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:05:34,336][524661] Avg episode reward: [(0, '-98.900')]
[36m[2025-07-02 13:05:39,324][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1501.8. Samples: 120448. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:05:39,324][524661] Avg episode reward: [(0, '-101.830')]
[31m[100840 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[100841 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([41], device='cuda:0') (navigation_task.py:196)
[31m[100841 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[101948 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[101948 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[101948 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2054
[33mTimeouts: 0 (navigation_task.py:268)
[31m[103725 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[103726 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([126], device='cuda:0') (navigation_task.py:196)
[31m[103726 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:05:44,334][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1519.9. Samples: 129792. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-02 13:05:44,334][524661] Avg episode reward: [(0, '-97.591')]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/nn/modules/module.py:1194: UserWarning: operator() profile_node %104 : int[] = prim::profile_ivalue(%102)
 does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)
  return forward_call(*input, **kwargs)
[36m[2025-07-02 13:05:49,344][524661] Fps is (10 sec: 13081.5, 60 sec: 2186.0, 300 sec: 1423.4). Total num frames: 131072. Throughput: 0: 1498.3. Samples: 133248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:05:49,344][524661] Avg episode reward: [(0, '-98.121')]
[37m[1m[2025-07-02 13:05:49,426][524661] Saving new best policy, reward=-98.121!
[31m[112747 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[112747 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([63], device='cuda:0') (navigation_task.py:196)
[31m[112748 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:05:54,334][524661] Fps is (10 sec: 13106.9, 60 sec: 2184.0, 300 sec: 1350.2). Total num frames: 131072. Throughput: 0: 1491.7. Samples: 142208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:05:54,334][524661] Avg episode reward: [(0, '-101.402')]
[36m[2025-07-02 13:05:59,319][524661] Fps is (10 sec: 0.0, 60 sec: 2186.1, 300 sec: 1284.2). Total num frames: 131072. Throughput: 0: 1482.6. Samples: 150784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:05:59,319][524661] Avg episode reward: [(0, '-96.042')]
[37m[1m[2025-07-02 13:05:59,415][524661] Saving new best policy, reward=-96.042!
[31m[121267 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[121268 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([77], device='cuda:0') (navigation_task.py:196)
[31m[121268 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[123532 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[123533 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([77], device='cuda:0') (navigation_task.py:196)
[31m[123533 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:06:04,329][524661] Fps is (10 sec: 0.0, 60 sec: 2187.4, 300 sec: 1224.2). Total num frames: 131072. Throughput: 0: 1483.4. Samples: 155520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:04,329][524661] Avg episode reward: [(0, '-103.237')]
[37m[1m[2025-07-02 13:06:04,412][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000032_131072.pth...
[31m[125732 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[125733 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([69], device='cuda:0') (navigation_task.py:196)
[31m[125733 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:06:09,363][524661] Fps is (10 sec: 0.0, 60 sec: 2184.8, 300 sec: 1169.2). Total num frames: 131072. Throughput: 0: 1487.8. Samples: 164992. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:09,363][524661] Avg episode reward: [(0, '-94.353')]
[37m[1m[2025-07-02 13:06:09,455][524661] Saving new best policy, reward=-94.353!
[31m[130790 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[130790 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([27], device='cuda:0') (navigation_task.py:196)
[31m[130790 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:06:14,342][524661] Fps is (10 sec: 0.0, 60 sec: 2184.4, 300 sec: 1119.5). Total num frames: 131072. Throughput: 0: 1470.6. Samples: 172928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:14,342][524661] Avg episode reward: [(0, '-100.573')]
[31m[135659 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[135660 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([19], device='cuda:0') (navigation_task.py:196)
[31m[135660 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:06:19,363][524661] Fps is (10 sec: 0.0, 60 sec: 2184.9, 300 sec: 1073.4). Total num frames: 131072. Throughput: 0: 1449.8. Samples: 176640. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:19,364][524661] Avg episode reward: [(0, '-92.934')]
[37m[1m[2025-07-02 13:06:19,463][524661] Saving new best policy, reward=-92.934!
[36m[2025-07-02 13:06:24,395][524661] Fps is (10 sec: 0.0, 60 sec: 2183.5, 300 sec: 1030.9). Total num frames: 131072. Throughput: 0: 1431.3. Samples: 184960. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:24,396][524661] Avg episode reward: [(0, '-97.768')]
[31m[147458 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[147459 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([107], device='cuda:0') (navigation_task.py:196)
[31m[147459 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[147775 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[147775 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[147775 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2049
[33mTimeouts: 0 (navigation_task.py:268)
[36m[2025-07-02 13:06:29,347][524661] Fps is (10 sec: 0.0, 60 sec: 2184.3, 300 sec: 992.3). Total num frames: 131072. Throughput: 0: 1421.8. Samples: 193792. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:29,347][524661] Avg episode reward: [(0, '-101.550')]
[31m[150189 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[150189 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([96], device='cuda:0') (navigation_task.py:196)
[31m[150189 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:06:34,381][524661] Fps is (10 sec: 0.0, 60 sec: 2182.9, 300 sec: 955.9). Total num frames: 131072. Throughput: 0: 1440.9. Samples: 198144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:34,381][524661] Avg episode reward: [(0, '-98.504')]
[31m[155723 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[155723 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([2], device='cuda:0') (navigation_task.py:196)
[31m[155724 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[157142 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[157142 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([122], device='cuda:0') (navigation_task.py:196)
[31m[157142 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[157560 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[157560 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([5], device='cuda:0') (navigation_task.py:196)
[31m[157561 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[157645 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[157646 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([63], device='cuda:0') (navigation_task.py:196)
[31m[157646 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[159543 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[159543 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([53], device='cuda:0') (navigation_task.py:196)
[31m[159544 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:06:39,317][524661] Fps is (10 sec: 0.0, 60 sec: 2184.8, 300 sec: 922.7). Total num frames: 131072. Throughput: 0: 1448.4. Samples: 207360. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:39,317][524661] Avg episode reward: [(0, '-102.193')]
[31m[163931 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[163932 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([96], device='cuda:0') (navigation_task.py:196)
[31m[163932 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[164564 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[164564 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([106], device='cuda:0') (navigation_task.py:196)
[31m[164564 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:06:44,341][524661] Fps is (10 sec: 0.0, 60 sec: 2184.3, 300 sec: 891.1). Total num frames: 131072. Throughput: 0: 1458.5. Samples: 216448. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:44,341][524661] Avg episode reward: [(0, '-96.788')]
[31m[167895 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[167896 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([ 84, 116], device='cuda:0') (navigation_task.py:196)
[31m[167896 ms][navigation_task] - CRITICAL : Time at crash: tensor([1, 1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:06:49,405][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 861.5). Total num frames: 131072. Throughput: 0: 1453.9. Samples: 221056. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:49,405][524661] Avg episode reward: [(0, '-101.040')]
[31m[174045 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[174045 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([107], device='cuda:0') (navigation_task.py:196)
[31m[174046 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[174343 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[174344 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([100], device='cuda:0') (navigation_task.py:196)
[31m[174344 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:06:54,357][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 834.3). Total num frames: 131072. Throughput: 0: 1445.2. Samples: 230016. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:54,357][524661] Avg episode reward: [(0, '-99.020')]
[31m[175687 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[175688 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([71], device='cuda:0') (navigation_task.py:196)
[31m[175688 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[177767 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[177767 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([71], device='cuda:0') (navigation_task.py:196)
[31m[177768 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:06:59,309][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 808.8). Total num frames: 131072. Throughput: 0: 1363.5. Samples: 234240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:06:59,309][524661] Avg episode reward: [(0, '-98.716')]
[31m[180865 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[180865 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([102], device='cuda:0') (navigation_task.py:196)
[31m[180866 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[183122 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[183123 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([17], device='cuda:0') (navigation_task.py:196)
[31m[183123 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:07:04,317][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 784.6). Total num frames: 131072. Throughput: 0: 1455.0. Samples: 242048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:04,317][524661] Avg episode reward: [(0, '-95.021')]
[31m[189239 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[189239 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([71], device='cuda:0') (navigation_task.py:196)
[31m[189239 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:07:09,363][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 761.6). Total num frames: 131072. Throughput: 0: 1457.4. Samples: 250496. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:09,364][524661] Avg episode reward: [(0, '-98.456')]
[31m[191871 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[191871 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([71], device='cuda:0') (navigation_task.py:196)
[31m[191872 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[192154 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[192155 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task.py:265)
[33m[192155 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2048
[33mTimeouts: 0 (navigation_task.py:268)
[36m[2025-07-02 13:07:14,347][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 740.1). Total num frames: 131072. Throughput: 0: 1433.6. Samples: 258304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:14,347][524661] Avg episode reward: [(0, '-95.236')]
[31m[195493 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[195493 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([99], device='cuda:0') (navigation_task.py:196)
[31m[195493 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:07:19,333][524661] Fps is (10 sec: 13146.6, 60 sec: 2185.6, 300 sec: 1439.8). Total num frames: 262144. Throughput: 0: 1423.7. Samples: 262144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:19,333][524661] Avg episode reward: [(0, '-98.822')]
[31m[204441 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[204441 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([90], device='cuda:0') (navigation_task.py:196)
[31m[204442 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:07:24,379][524661] Fps is (10 sec: 13065.2, 60 sec: 2185.1, 300 sec: 1400.9). Total num frames: 262144. Throughput: 0: 1391.8. Samples: 270080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:24,380][524661] Avg episode reward: [(0, '-94.700')]
[36m[2025-07-02 13:07:29,361][524661] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1364.6). Total num frames: 262144. Throughput: 0: 1384.6. Samples: 278784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:29,361][524661] Avg episode reward: [(0, '-95.688')]
[36m[2025-07-02 13:07:34,353][524661] Fps is (10 sec: 0.0, 60 sec: 2185.6, 300 sec: 1330.0). Total num frames: 262144. Throughput: 0: 1386.8. Samples: 283392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:34,353][524661] Avg episode reward: [(0, '-96.736')]
[36m[2025-07-02 13:07:39,363][524661] Fps is (10 sec: 0.0, 60 sec: 2182.9, 300 sec: 1297.1). Total num frames: 262144. Throughput: 0: 1379.4. Samples: 292096. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:39,363][524661] Avg episode reward: [(0, '-95.253')]
[31m[222860 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[222860 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([89], device='cuda:0') (navigation_task.py:196)
[31m[222860 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[223131 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[223132 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([112], device='cuda:0') (navigation_task.py:196)
[31m[223132 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:07:44,322][524661] Fps is (10 sec: 0.0, 60 sec: 2185.2, 300 sec: 1266.0). Total num frames: 262144. Throughput: 0: 1481.5. Samples: 300928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:44,322][524661] Avg episode reward: [(0, '-98.062')]
[36m[2025-07-02 13:07:49,334][524661] Fps is (10 sec: 0.0, 60 sec: 2187.1, 300 sec: 1236.1). Total num frames: 262144. Throughput: 0: 1404.6. Samples: 305280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:49,335][524661] Avg episode reward: [(0, '-99.183')]
[36m[2025-07-02 13:07:54,313][524661] Fps is (10 sec: 0.0, 60 sec: 2186.1, 300 sec: 1207.7). Total num frames: 262144. Throughput: 0: 1418.1. Samples: 314240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:54,313][524661] Avg episode reward: [(0, '-99.195')]
[31m[239157 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[239158 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([75], device='cuda:0') (navigation_task.py:196)
[31m[239158 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[239728 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[239729 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.9995121955871582
[33mTimeout Rate: 0.0004878048785030842 (navigation_task.py:265)
[33m[239729 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2049
[33mTimeouts: 1 (navigation_task.py:268)
[36m[2025-07-02 13:07:59,321][524661] Fps is (10 sec: 0.0, 60 sec: 2184.1, 300 sec: 1180.5). Total num frames: 262144. Throughput: 0: 1451.5. Samples: 323584. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:07:59,322][524661] Avg episode reward: [(0, '-95.093')]
[31m[244204 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[244204 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([4], device='cuda:0') (navigation_task.py:196)
[31m[244204 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:08:04,382][524661] Fps is (10 sec: 0.0, 60 sec: 2182.2, 300 sec: 1154.2). Total num frames: 262144. Throughput: 0: 1466.1. Samples: 328192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:04,383][524661] Avg episode reward: [(0, '-98.647')]
[37m[1m[2025-07-02 13:08:04,466][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000064_262144.pth...
[31m[246887 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[246887 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([43], device='cuda:0') (navigation_task.py:196)
[31m[246887 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:08:09,324][524661] Fps is (10 sec: 0.0, 60 sec: 2186.0, 300 sec: 1129.6). Total num frames: 262144. Throughput: 0: 1498.0. Samples: 337408. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:09,324][524661] Avg episode reward: [(0, '-99.266')]
[31m[249887 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[249887 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([104], device='cuda:0') (navigation_task.py:196)
[31m[249888 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[251418 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[251419 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([5], device='cuda:0') (navigation_task.py:196)
[31m[251419 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[252846 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[252846 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([93], device='cuda:0') (navigation_task.py:196)
[31m[252847 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:08:14,365][524661] Fps is (10 sec: 0.0, 60 sec: 2183.9, 300 sec: 1105.6). Total num frames: 262144. Throughput: 0: 1507.4. Samples: 346624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:14,366][524661] Avg episode reward: [(0, '-100.028')]
[31m[255394 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[255395 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([123], device='cuda:0') (navigation_task.py:196)
[31m[255395 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[256216 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[256216 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([75], device='cuda:0') (navigation_task.py:196)
[31m[256216 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:08:19,348][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1082.8). Total num frames: 262144. Throughput: 0: 1502.0. Samples: 350976. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:19,348][524661] Avg episode reward: [(0, '-95.170')]
[36m[2025-07-02 13:08:24,396][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1060.7). Total num frames: 262144. Throughput: 0: 1517.8. Samples: 360448. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:24,396][524661] Avg episode reward: [(0, '-100.129')]
[31m[265734 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[265734 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([58], device='cuda:0') (navigation_task.py:196)
[31m[265735 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[266156 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[266156 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([117], device='cuda:0') (navigation_task.py:196)
[31m[266157 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:08:29,363][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1039.8). Total num frames: 262144. Throughput: 0: 1531.8. Samples: 369920. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:29,363][524661] Avg episode reward: [(0, '-98.605')]
[36m[2025-07-02 13:08:34,374][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1019.6). Total num frames: 262144. Throughput: 0: 1529.0. Samples: 374144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:34,374][524661] Avg episode reward: [(0, '-97.925')]
[31m[275426 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[275426 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([71], device='cuda:0') (navigation_task.py:196)
[31m[275427 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:08:39,366][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1000.1). Total num frames: 262144. Throughput: 0: 1531.3. Samples: 383232. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:39,366][524661] Avg episode reward: [(0, '-91.982')]
[37m[1m[2025-07-02 13:08:39,444][524661] Saving new best policy, reward=-91.982!
[31m[281622 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[281622 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([11], device='cuda:0') (navigation_task.py:196)
[31m[281622 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[283951 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[283951 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([123], device='cuda:0') (navigation_task.py:196)
[31m[283951 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[284488 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[284488 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([117], device='cuda:0') (navigation_task.py:196)
[31m[284488 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[284488 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[284489 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.9995126724243164
[33mTimeout Rate: 0.000487329438328743 (navigation_task.py:265)
[33m[284489 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2051
[33mTimeouts: 1 (navigation_task.py:268)
[36m[2025-07-02 13:08:44,329][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 981.5). Total num frames: 262144. Throughput: 0: 1535.7. Samples: 392704. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:44,329][524661] Avg episode reward: [(0, '-96.361')]
[31m[287600 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[287600 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([124], device='cuda:0') (navigation_task.py:196)
[31m[287601 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:08:49,365][524661] Fps is (10 sec: 13107.5, 60 sec: 2183.4, 300 sec: 1445.1). Total num frames: 393216. Throughput: 0: 1528.0. Samples: 396928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:49,366][524661] Avg episode reward: [(0, '-100.494')]
[31m[290880 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[290881 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([63], device='cuda:0') (navigation_task.py:196)
[31m[290881 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:08:54,391][524661] Fps is (10 sec: 13026.2, 60 sec: 2181.7, 300 sec: 1418.9). Total num frames: 393216. Throughput: 0: 1519.5. Samples: 405888. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:54,392][524661] Avg episode reward: [(0, '-97.591')]
[31m[298217 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[298217 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([109], device='cuda:0') (navigation_task.py:196)
[31m[298218 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:08:59,364][524661] Fps is (10 sec: 0.0, 60 sec: 2183.0, 300 sec: 1393.9). Total num frames: 393216. Throughput: 0: 1513.3. Samples: 414720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:08:59,364][524661] Avg episode reward: [(0, '-99.541')]
[31m[302974 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[302974 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([28], device='cuda:0') (navigation_task.py:196)
[31m[302975 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:09:04,386][524661] Fps is (10 sec: 0.0, 60 sec: 2184.4, 300 sec: 1369.5). Total num frames: 393216. Throughput: 0: 1517.6. Samples: 419328. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:04,386][524661] Avg episode reward: [(0, '-91.064')]
[37m[1m[2025-07-02 13:09:04,467][524661] Saving new best policy, reward=-91.064!
[31m[305824 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[305824 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([2], device='cuda:0') (navigation_task.py:196)
[31m[305824 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[307489 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[307489 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([74], device='cuda:0') (navigation_task.py:196)
[31m[307490 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:09:09,377][524661] Fps is (10 sec: 0.0, 60 sec: 2182.6, 300 sec: 1346.1). Total num frames: 393216. Throughput: 0: 1513.9. Samples: 428544. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:09,377][524661] Avg episode reward: [(0, '-95.662')]
[31m[312886 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[312886 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([80], device='cuda:0') (navigation_task.py:196)
[31m[312886 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:09:14,376][524661] Fps is (10 sec: 0.0, 60 sec: 2184.2, 300 sec: 1332.7). Total num frames: 393216. Throughput: 0: 1504.3. Samples: 437632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:14,376][524661] Avg episode reward: [(0, '-96.702')]
[31m[318058 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[318058 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([104], device='cuda:0') (navigation_task.py:196)
[31m[318059 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:09:19,391][524661] Fps is (10 sec: 0.0, 60 sec: 2183.0, 300 sec: 1333.0). Total num frames: 393216. Throughput: 0: 1515.5. Samples: 442368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:19,391][524661] Avg episode reward: [(0, '-97.451')]
[31m[320165 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[320165 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([69], device='cuda:0') (navigation_task.py:196)
[31m[320165 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:09:24,333][524661] Fps is (10 sec: 0.0, 60 sec: 2186.8, 300 sec: 1332.8). Total num frames: 393216. Throughput: 0: 1511.5. Samples: 451200. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:24,333][524661] Avg episode reward: [(0, '-98.082')]
[36m[2025-07-02 13:09:29,367][524661] Fps is (10 sec: 0.0, 60 sec: 2184.4, 300 sec: 1332.8). Total num frames: 393216. Throughput: 0: 1500.6. Samples: 460288. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:29,367][524661] Avg episode reward: [(0, '-95.050')]
[31m[331958 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[331959 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([115], device='cuda:0') (navigation_task.py:196)
[31m[331959 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:09:34,382][524661] Fps is (10 sec: 0.0, 60 sec: 2184.3, 300 sec: 1332.7). Total num frames: 393216. Throughput: 0: 1509.9. Samples: 464896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:34,382][524661] Avg episode reward: [(0, '-98.132')]
[33m[335472 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[335472 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.9980478286743164
[33mTimeout Rate: 0.001952171791344881 (navigation_task.py:265)
[33m[335472 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2045
[33mTimeouts: 4 (navigation_task.py:268)
[36m[2025-07-02 13:09:39,347][524661] Fps is (10 sec: 0.0, 60 sec: 2185.2, 300 sec: 1333.1). Total num frames: 393216. Throughput: 0: 1520.4. Samples: 474240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:39,347][524661] Avg episode reward: [(0, '-97.172')]
[31m[342577 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[342578 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([63], device='cuda:0') (navigation_task.py:196)
[31m[342578 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:09:44,380][524661] Fps is (10 sec: 0.0, 60 sec: 2182.7, 300 sec: 1332.9). Total num frames: 393216. Throughput: 0: 1515.5. Samples: 482944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:44,380][524661] Avg episode reward: [(0, '-97.666')]
[31m[348460 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[348461 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([122], device='cuda:0') (navigation_task.py:196)
[31m[348461 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:09:49,337][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 393216. Throughput: 0: 1520.6. Samples: 487680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:49,338][524661] Avg episode reward: [(0, '-101.989')]
[31m[349899 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[349900 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([110], device='cuda:0') (navigation_task.py:196)
[31m[349900 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[353566 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[353566 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([86], device='cuda:0') (navigation_task.py:196)
[31m[353567 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:09:54,333][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 393216. Throughput: 0: 1520.4. Samples: 496896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:54,333][524661] Avg episode reward: [(0, '-92.441')]
[36m[2025-07-02 13:09:59,381][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 393216. Throughput: 0: 1507.4. Samples: 505472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:09:59,381][524661] Avg episode reward: [(0, '-97.288')]
[31m[363192 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[363192 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([34], device='cuda:0') (navigation_task.py:196)
[31m[363193 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[363707 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[363708 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([52], device='cuda:0') (navigation_task.py:196)
[31m[363708 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:10:04,317][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 393216. Throughput: 0: 1510.0. Samples: 510208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:10:04,317][524661] Avg episode reward: [(0, '-103.769')]
[37m[1m[2025-07-02 13:10:04,404][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000096_393216.pth...
[31m[365925 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[365926 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([4], device='cuda:0') (navigation_task.py:196)
[31m[365926 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:10:09,359][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 393216. Throughput: 0: 1503.8. Samples: 518912. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:10:09,359][524661] Avg episode reward: [(0, '-94.877')]
[31m[370720 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[370720 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([108], device='cuda:0') (navigation_task.py:196)
[31m[370720 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:10:14,341][524661] Fps is (10 sec: 13074.9, 60 sec: 2185.8, 300 sec: 1777.4). Total num frames: 524288. Throughput: 0: 1497.0. Samples: 527616. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:10:14,341][524661] Avg episode reward: [(0, '-99.594')]
[31m[376509 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[376510 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([78], device='cuda:0') (navigation_task.py:196)
[31m[376510 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:10:19,407][524661] Fps is (10 sec: 13044.6, 60 sec: 2183.9, 300 sec: 1777.0). Total num frames: 524288. Throughput: 0: 1489.7. Samples: 531968. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:10:19,407][524661] Avg episode reward: [(0, '-87.452')]
[37m[1m[2025-07-02 13:10:19,497][524661] Saving new best policy, reward=-87.452!
[31m[382235 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[382236 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([12], device='cuda:0') (navigation_task.py:196)
[31m[382236 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:10:24,338][524661] Fps is (10 sec: 0.0, 60 sec: 2184.3, 300 sec: 1777.3). Total num frames: 524288. Throughput: 0: 1473.7. Samples: 540544. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:10:24,338][524661] Avg episode reward: [(0, '-97.489')]
[36m[2025-07-02 13:10:29,379][524661] Fps is (10 sec: 0.0, 60 sec: 2184.1, 300 sec: 1777.0). Total num frames: 524288. Throughput: 0: 1473.4. Samples: 549248. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:10:29,379][524661] Avg episode reward: [(0, '-97.052')]
[33m[390514 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[390514 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.997560977935791
[33mTimeout Rate: 0.002439024392515421 (navigation_task.py:265)
[33m[390514 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2045
[33mTimeouts: 5 (navigation_task.py:268)
[36m[2025-07-02 13:10:34,356][524661] Fps is (10 sec: 0.0, 60 sec: 2185.5, 300 sec: 1777.1). Total num frames: 524288. Throughput: 0: 1472.8. Samples: 553984. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:10:34,356][524661] Avg episode reward: [(0, '-94.327')]
[36m[2025-07-02 13:10:39,348][524661] Fps is (10 sec: 0.0, 60 sec: 2184.5, 300 sec: 1777.2). Total num frames: 524288. Throughput: 0: 1470.1. Samples: 563072. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:10:39,349][524661] Avg episode reward: [(0, '-101.720')]
[36m[2025-07-02 13:10:44,322][524661] Fps is (10 sec: 0.0, 60 sec: 2186.6, 300 sec: 1333.0). Total num frames: 524288. Throughput: 0: 1475.4. Samples: 571776. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:10:44,322][524661] Avg episode reward: [(0, '-93.714')]
[36m[2025-07-02 13:10:49,389][524661] Fps is (10 sec: 0.0, 60 sec: 2182.6, 300 sec: 1332.7). Total num frames: 524288. Throughput: 0: 1462.5. Samples: 576128. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:10:49,390][524661] Avg episode reward: [(0, '-97.144')]
[31m[410095 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[410096 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([26], device='cuda:0') (navigation_task.py:196)
[31m[410096 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:10:54,314][524661] Fps is (10 sec: 0.0, 60 sec: 2185.2, 300 sec: 1333.0). Total num frames: 524288. Throughput: 0: 1437.9. Samples: 583552. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:10:54,315][524661] Avg episode reward: [(0, '-97.744')]
[31m[418019 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[418020 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([50], device='cuda:0') (navigation_task.py:196)
[31m[418020 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[419752 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[419753 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([83], device='cuda:0') (navigation_task.py:196)
[31m[419753 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:10:59,354][524661] Fps is (10 sec: 0.0, 60 sec: 2185.5, 300 sec: 1332.8). Total num frames: 524288. Throughput: 0: 1424.6. Samples: 591744. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:10:59,355][524661] Avg episode reward: [(0, '-93.149')]
[36m[2025-07-02 13:11:04,370][524661] Fps is (10 sec: 0.0, 60 sec: 2182.6, 300 sec: 1332.9). Total num frames: 524288. Throughput: 0: 1420.5. Samples: 595840. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:11:04,370][524661] Avg episode reward: [(0, '-94.664')]
[36m[2025-07-02 13:11:09,372][524661] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1332.8). Total num frames: 524288. Throughput: 0: 1424.0. Samples: 604672. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:11:09,373][524661] Avg episode reward: [(0, '-97.514')]
[36m[2025-07-02 13:11:14,405][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 524288. Throughput: 0: 1429.9. Samples: 613632. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:11:14,405][524661] Avg episode reward: [(0, '-92.572')]
[36m[2025-07-02 13:11:19,311][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.3). Total num frames: 524288. Throughput: 0: 1406.6. Samples: 617216. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:11:19,311][524661] Avg episode reward: [(0, '-100.898')]
[31m[444193 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[444193 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([53], device='cuda:0') (navigation_task.py:196)
[31m[444194 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:11:24,323][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 524288. Throughput: 0: 1388.9. Samples: 625536. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:11:24,323][524661] Avg episode reward: [(0, '-97.706')]
[31m[447709 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[447709 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([72], device='cuda:0') (navigation_task.py:196)
[31m[447709 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:11:29,408][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 524288. Throughput: 0: 1368.4. Samples: 633472. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:11:29,408][524661] Avg episode reward: [(0, '-98.622')]
[33m[454018 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[454018 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.992682933807373
[33mTimeout Rate: 0.007317073177546263 (navigation_task.py:265)
[33m[454018 ms][navigation_task] - WARNING : 
[33mSuccesses: 0
[33mCrashes : 2035
[33mTimeouts: 15 (navigation_task.py:268)
[36m[2025-07-02 13:11:34,317][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 524288. Throughput: 0: 1353.3. Samples: 636928. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:11:34,318][524661] Avg episode reward: [(0, '-97.047')]
[36m[2025-07-02 13:11:39,389][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 524288. Throughput: 0: 1343.2. Samples: 644096. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:11:39,389][524661] Avg episode reward: [(0, '-98.434')]
[31m[460225 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[460226 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([10], device='cuda:0') (navigation_task.py:196)
[31m[460226 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[460964 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[460965 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([110], device='cuda:0') (navigation_task.py:196)
[31m[460965 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:11:44,396][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 524288. Throughput: 0: 1352.7. Samples: 652672. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-02 13:11:44,397][524661] Avg episode reward: [(0, '-91.408')]
[36m[2025-07-02 13:11:49,358][524661] Fps is (10 sec: 13147.5, 60 sec: 2185.7, 300 sec: 1777.2). Total num frames: 655360. Throughput: 0: 1351.5. Samples: 656640. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:11:49,358][524661] Avg episode reward: [(0, '-97.869')]
[36m[2025-07-02 13:11:54,325][524661] Fps is (10 sec: 13201.5, 60 sec: 2184.1, 300 sec: 1777.2). Total num frames: 655360. Throughput: 0: 1358.2. Samples: 665728. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:11:54,325][524661] Avg episode reward: [(0, '-92.177')]
[36m[2025-07-02 13:11:59,381][524661] Fps is (10 sec: 0.0, 60 sec: 2183.6, 300 sec: 1776.9). Total num frames: 655360. Throughput: 0: 1329.1. Samples: 673408. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:11:59,381][524661] Avg episode reward: [(0, '-90.395')]
[36m[2025-07-02 13:12:04,337][524661] Fps is (10 sec: 0.0, 60 sec: 2185.7, 300 sec: 1777.4). Total num frames: 655360. Throughput: 0: 1341.8. Samples: 677632. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:04,337][524661] Avg episode reward: [(0, '-92.604')]
[37m[1m[2025-07-02 13:12:04,494][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000160_655360.pth...
[31m[488987 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[488988 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([116], device='cuda:0') (navigation_task.py:196)
[31m[488988 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:12:09,354][524661] Fps is (10 sec: 0.0, 60 sec: 2185.2, 300 sec: 1777.2). Total num frames: 655360. Throughput: 0: 1347.3. Samples: 686208. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:09,355][524661] Avg episode reward: [(0, '-90.524')]
[36m[2025-07-02 13:12:14,328][524661] Fps is (10 sec: 0.0, 60 sec: 2187.3, 300 sec: 1333.0). Total num frames: 655360. Throughput: 0: 1364.9. Samples: 694784. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:14,328][524661] Avg episode reward: [(0, '-93.943')]
[36m[2025-07-02 13:12:19,327][524661] Fps is (10 sec: 0.0, 60 sec: 2183.9, 300 sec: 1333.2). Total num frames: 655360. Throughput: 0: 1382.1. Samples: 699136. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:19,327][524661] Avg episode reward: [(0, '-91.078')]
[31m[500401 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[500402 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([71], device='cuda:0') (navigation_task.py:196)
[31m[500402 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:12:24,382][524661] Fps is (10 sec: 0.0, 60 sec: 2182.4, 300 sec: 1332.8). Total num frames: 655360. Throughput: 0: 1413.9. Samples: 707712. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:24,382][524661] Avg episode reward: [(0, '-92.564')]
[36m[2025-07-02 13:12:29,326][524661] Fps is (10 sec: 0.0, 60 sec: 2187.5, 300 sec: 1333.1). Total num frames: 655360. Throughput: 0: 1421.6. Samples: 716544. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:29,326][524661] Avg episode reward: [(0, '-94.723')]
[36m[2025-07-02 13:12:34,308][524661] Fps is (10 sec: 0.0, 60 sec: 2184.9, 300 sec: 1333.2). Total num frames: 655360. Throughput: 0: 1435.2. Samples: 721152. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:34,309][524661] Avg episode reward: [(0, '-88.945')]
[31m[518095 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[518095 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([15], device='cuda:0') (navigation_task.py:196)
[31m[518095 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[518701 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[518702 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([77], device='cuda:0') (navigation_task.py:196)
[31m[518702 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:12:39,322][524661] Fps is (10 sec: 0.0, 60 sec: 2187.0, 300 sec: 1332.9). Total num frames: 655360. Throughput: 0: 1428.0. Samples: 729984. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:39,323][524661] Avg episode reward: [(0, '-94.102')]
[33m[524009 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[524009 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.00048804294783622026
[33mCrash Rate: 0.9673011302947998
[33mTimeout Rate: 0.032210834324359894 (navigation_task.py:265)
[33m[524009 ms][navigation_task] - WARNING : 
[33mSuccesses: 1
[33mCrashes : 1982
[33mTimeouts: 66 (navigation_task.py:268)
[36m[2025-07-02 13:12:44,314][524661] Fps is (10 sec: 0.0, 60 sec: 2187.5, 300 sec: 1333.0). Total num frames: 655360. Throughput: 0: 1455.7. Samples: 738816. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:44,314][524661] Avg episode reward: [(0, '-89.636')]
[36m[2025-07-02 13:12:49,341][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 655360. Throughput: 0: 1439.1. Samples: 742400. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:49,342][524661] Avg episode reward: [(0, '-95.817')]
[31m[532955 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[532956 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([71], device='cuda:0') (navigation_task.py:196)
[31m[532957 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:12:54,356][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 655360. Throughput: 0: 1430.7. Samples: 750592. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:54,357][524661] Avg episode reward: [(0, '-95.325')]
[36m[2025-07-02 13:12:59,333][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 655360. Throughput: 0: 1439.1. Samples: 759552. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:12:59,333][524661] Avg episode reward: [(0, '-90.379')]
[36m[2025-07-02 13:13:04,362][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 655360. Throughput: 0: 1441.0. Samples: 764032. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:13:04,362][524661] Avg episode reward: [(0, '-85.781')]
[37m[1m[2025-07-02 13:13:04,440][524661] Saving new best policy, reward=-85.781!
[36m[2025-07-02 13:13:09,386][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 655360. Throughput: 0: 1450.5. Samples: 772992. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:13:09,386][524661] Avg episode reward: [(0, '-92.260')]
[31m[550026 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[550027 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([71], device='cuda:0') (navigation_task.py:196)
[31m[550027 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[553924 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[553924 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([10], device='cuda:0') (navigation_task.py:196)
[31m[553924 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[554780 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[554781 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([57], device='cuda:0') (navigation_task.py:196)
[31m[554781 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:13:14,405][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 655360. Throughput: 0: 1445.3. Samples: 781696. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-02 13:13:14,405][524661] Avg episode reward: [(0, '-94.507')]
[36m[2025-07-02 13:13:19,353][524661] Fps is (10 sec: 13150.7, 60 sec: 2183.6, 300 sec: 1777.5). Total num frames: 786432. Throughput: 0: 1432.2. Samples: 785664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:13:19,353][524661] Avg episode reward: [(0, '-85.961')]
[36m[2025-07-02 13:13:24,325][524661] Fps is (10 sec: 13212.3, 60 sec: 2186.6, 300 sec: 1777.5). Total num frames: 786432. Throughput: 0: 1433.5. Samples: 794496. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:13:24,326][524661] Avg episode reward: [(0, '-83.734')]
[37m[1m[2025-07-02 13:13:24,424][524661] Saving new best policy, reward=-83.734!
[36m[2025-07-02 13:13:29,353][524661] Fps is (10 sec: 0.0, 60 sec: 2183.6, 300 sec: 1777.4). Total num frames: 786432. Throughput: 0: 1440.9. Samples: 803712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:13:29,353][524661] Avg episode reward: [(0, '-84.639')]
[31m[573378 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[573378 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([20], device='cuda:0') (navigation_task.py:196)
[31m[573378 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[573990 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[573990 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([100], device='cuda:0') (navigation_task.py:196)
[31m[573990 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:13:34,385][524661] Fps is (10 sec: 0.0, 60 sec: 2181.7, 300 sec: 1777.1). Total num frames: 786432. Throughput: 0: 1460.6. Samples: 808192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:13:34,386][524661] Avg episode reward: [(0, '-80.863')]
[37m[1m[2025-07-02 13:13:34,474][524661] Saving new best policy, reward=-80.863!
[31m[575039 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[575039 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([75], device='cuda:0') (navigation_task.py:196)
[31m[575039 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[578670 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[578671 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([93], device='cuda:0') (navigation_task.py:196)
[31m[578671 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:13:39,310][524661] Fps is (10 sec: 0.0, 60 sec: 2185.0, 300 sec: 1777.4). Total num frames: 786432. Throughput: 0: 1483.5. Samples: 817280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:13:39,311][524661] Avg episode reward: [(0, '-82.484')]
[36m[2025-07-02 13:13:44,318][524661] Fps is (10 sec: 0.0, 60 sec: 2184.4, 300 sec: 1333.2). Total num frames: 786432. Throughput: 0: 1479.6. Samples: 826112. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:13:44,318][524661] Avg episode reward: [(0, '-88.806')]
[31m[586805 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[586806 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([99], device='cuda:0') (navigation_task.py:196)
[31m[586806 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:13:49,342][524661] Fps is (10 sec: 0.0, 60 sec: 2184.5, 300 sec: 1333.2). Total num frames: 786432. Throughput: 0: 1482.6. Samples: 830720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:13:49,342][524661] Avg episode reward: [(0, '-84.742')]
[31m[590600 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[590600 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([105], device='cuda:0') (navigation_task.py:196)
[31m[590600 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:13:54,379][524661] Fps is (10 sec: 0.0, 60 sec: 2183.7, 300 sec: 1332.9). Total num frames: 786432. Throughput: 0: 1487.9. Samples: 839936. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:13:54,380][524661] Avg episode reward: [(0, '-83.134')]
[31m[597470 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[597471 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([78], device='cuda:0') (navigation_task.py:196)
[31m[597471 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[597553 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[597554 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([78], device='cuda:0') (navigation_task.py:196)
[31m[597554 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[598063 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[598063 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.00146484375
[33mCrash Rate: 0.935546875
[33mTimeout Rate: 0.06298828125 (navigation_task.py:265)
[33m[598063 ms][navigation_task] - WARNING : 
[33mSuccesses: 3
[33mCrashes : 1916
[33mTimeouts: 129 (navigation_task.py:268)
[36m[2025-07-02 13:13:59,387][524661] Fps is (10 sec: 0.0, 60 sec: 2182.6, 300 sec: 1332.9). Total num frames: 786432. Throughput: 0: 1491.1. Samples: 848768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:13:59,387][524661] Avg episode reward: [(0, '-81.254')]
[36m[2025-07-02 13:14:04,354][524661] Fps is (10 sec: 0.0, 60 sec: 2184.8, 300 sec: 1333.0). Total num frames: 786432. Throughput: 0: 1501.8. Samples: 853248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:04,354][524661] Avg episode reward: [(0, '-90.109')]
[37m[1m[2025-07-02 13:14:04,435][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000192_786432.pth...
[31m[605321 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[605322 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([5], device='cuda:0') (navigation_task.py:196)
[31m[605322 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:14:09,309][524661] Fps is (10 sec: 0.0, 60 sec: 2187.3, 300 sec: 1333.2). Total num frames: 786432. Throughput: 0: 1510.9. Samples: 862464. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:09,309][524661] Avg episode reward: [(0, '-84.359')]
[31m[612807 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[612808 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([19], device='cuda:0') (navigation_task.py:196)
[31m[612808 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:14:14,376][524661] Fps is (10 sec: 0.0, 60 sec: 2185.6, 300 sec: 1333.0). Total num frames: 786432. Throughput: 0: 1484.0. Samples: 870528. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:14,376][524661] Avg episode reward: [(0, '-83.342')]
[36m[2025-07-02 13:14:19,310][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 786432. Throughput: 0: 1490.1. Samples: 875136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:19,311][524661] Avg episode reward: [(0, '-76.982')]
[37m[1m[2025-07-02 13:14:19,436][524661] Saving new best policy, reward=-76.982!
[31m[622127 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[622128 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([42], device='cuda:0') (navigation_task.py:196)
[31m[622128 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:14:24,380][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 786432. Throughput: 0: 1456.9. Samples: 882944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:24,380][524661] Avg episode reward: [(0, '-72.956')]
[37m[1m[2025-07-02 13:14:24,484][524661] Saving new best policy, reward=-72.956!
[36m[2025-07-02 13:14:29,379][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 786432. Throughput: 0: 1434.5. Samples: 890752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:29,379][524661] Avg episode reward: [(0, '-75.711')]
[36m[2025-07-02 13:14:34,340][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 786432. Throughput: 0: 1419.4. Samples: 894592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:34,340][524661] Avg episode reward: [(0, '-89.487')]
[36m[2025-07-02 13:14:39,344][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 786432. Throughput: 0: 1372.1. Samples: 901632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:39,345][524661] Avg episode reward: [(0, '-83.672')]
[31m[639924 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[639925 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([36], device='cuda:0') (navigation_task.py:196)
[31m[639925 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:14:44,396][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 786432. Throughput: 0: 1353.7. Samples: 909696. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:44,396][524661] Avg episode reward: [(0, '-74.500')]
[36m[2025-07-02 13:14:49,338][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 786432. Throughput: 0: 1323.1. Samples: 912768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:49,339][524661] Avg episode reward: [(0, '-84.157')]
[31m[652867 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[652868 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([117], device='cuda:0') (navigation_task.py:196)
[31m[652868 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:14:54,378][524661] Fps is (10 sec: 13130.1, 60 sec: 2184.6, 300 sec: 1777.3). Total num frames: 917504. Throughput: 0: 1269.5. Samples: 919680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:54,378][524661] Avg episode reward: [(0, '-83.632')]
[36m[2025-07-02 13:14:59,394][524661] Fps is (10 sec: 13035.1, 60 sec: 2184.3, 300 sec: 1776.8). Total num frames: 917504. Throughput: 0: 1262.4. Samples: 927360. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:14:59,394][524661] Avg episode reward: [(0, '-54.164')]
[37m[1m[2025-07-02 13:14:59,502][524661] Saving new best policy, reward=-54.164!
[36m[2025-07-02 13:15:04,374][524661] Fps is (10 sec: 0.0, 60 sec: 2183.8, 300 sec: 1777.2). Total num frames: 917504. Throughput: 0: 1252.6. Samples: 931584. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:04,374][524661] Avg episode reward: [(0, '-46.345')]
[37m[1m[2025-07-02 13:15:04,549][524661] Saving new best policy, reward=-46.345!
[36m[2025-07-02 13:15:09,350][524661] Fps is (10 sec: 0.0, 60 sec: 2183.1, 300 sec: 1332.9). Total num frames: 917504. Throughput: 0: 1252.4. Samples: 939264. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:09,350][524661] Avg episode reward: [(0, '-72.924')]
[36m[2025-07-02 13:15:14,385][524661] Fps is (10 sec: 0.0, 60 sec: 2184.2, 300 sec: 1333.0). Total num frames: 917504. Throughput: 0: 1259.9. Samples: 947456. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:14,385][524661] Avg episode reward: [(0, '-64.509')]
[31m[675526 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[675527 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([32], device='cuda:0') (navigation_task.py:196)
[31m[675528 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[679239 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[679240 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([11], device='cuda:0') (navigation_task.py:196)
[31m[679240 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:15:19,376][524661] Fps is (10 sec: 0.0, 60 sec: 2182.1, 300 sec: 1332.8). Total num frames: 917504. Throughput: 0: 1259.1. Samples: 951296. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:19,376][524661] Avg episode reward: [(0, '-74.134')]
[36m[2025-07-02 13:15:24,325][524661] Fps is (10 sec: 0.0, 60 sec: 2186.6, 300 sec: 1333.2). Total num frames: 917504. Throughput: 0: 1294.8. Samples: 959872. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:24,325][524661] Avg episode reward: [(0, '-51.036')]
[31m[685007 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[685007 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([47], device='cuda:0') (navigation_task.py:196)
[31m[685008 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[685880 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[685881 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([18], device='cuda:0') (navigation_task.py:196)
[31m[685881 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[688692 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[688693 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([96], device='cuda:0') (navigation_task.py:196)
[31m[688693 ms][navigation_task] - CRITICAL : Time at crash: tensor([2], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:15:29,342][524661] Fps is (10 sec: 0.0, 60 sec: 2185.9, 300 sec: 1333.0). Total num frames: 917504. Throughput: 0: 1284.4. Samples: 967424. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:29,343][524661] Avg episode reward: [(0, '-50.795')]
[36m[2025-07-02 13:15:34,339][524661] Fps is (10 sec: 0.0, 60 sec: 2184.6, 300 sec: 1333.0). Total num frames: 917504. Throughput: 0: 1316.9. Samples: 972032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:34,340][524661] Avg episode reward: [(0, '-62.179')]
[33m[694982 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[694982 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.004878048785030842
[33mCrash Rate: 0.8243902325630188
[33mTimeout Rate: 0.17073170840740204 (navigation_task.py:265)
[33m[694982 ms][navigation_task] - WARNING : 
[33mSuccesses: 10
[33mCrashes : 1690
[33mTimeouts: 350 (navigation_task.py:268)
[31m[695735 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[695736 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([108], device='cuda:0') (navigation_task.py:196)
[31m[695736 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[699173 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[699173 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([19], device='cuda:0') (navigation_task.py:196)
[31m[699173 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:15:39,375][524661] Fps is (10 sec: 0.0, 60 sec: 2183.4, 300 sec: 1332.7). Total num frames: 917504. Throughput: 0: 1356.9. Samples: 980736. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:39,376][524661] Avg episode reward: [(0, '-51.595')]
[36m[2025-07-02 13:15:44,343][524661] Fps is (10 sec: 0.0, 60 sec: 2186.4, 300 sec: 1333.1). Total num frames: 917504. Throughput: 0: 1378.3. Samples: 989312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:44,344][524661] Avg episode reward: [(0, '-46.523')]
[31m[706933 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[706933 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([107], device='cuda:0') (navigation_task.py:196)
[31m[706933 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:15:49,328][524661] Fps is (10 sec: 0.0, 60 sec: 2184.9, 300 sec: 1332.9). Total num frames: 917504. Throughput: 0: 1381.0. Samples: 993664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:49,328][524661] Avg episode reward: [(0, '-75.118')]
[36m[2025-07-02 13:15:54,339][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 917504. Throughput: 0: 1408.3. Samples: 1002624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:54,340][524661] Avg episode reward: [(0, '-57.978')]
[36m[2025-07-02 13:15:59,351][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 917504. Throughput: 0: 1429.0. Samples: 1011712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:15:59,351][524661] Avg episode reward: [(0, '-66.070')]
[31m[719914 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[719915 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([78], device='cuda:0') (navigation_task.py:196)
[31m[719916 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:16:04,372][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 917504. Throughput: 0: 1450.8. Samples: 1016576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:04,372][524661] Avg episode reward: [(0, '-65.131')]
[37m[1m[2025-07-02 13:16:04,475][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000224_917504.pth...
[36m[2025-07-02 13:16:04,479][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000032_131072.pth
[31m[728557 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[728558 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([78], device='cuda:0') (navigation_task.py:196)
[31m[728558 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:16:09,322][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.3). Total num frames: 917504. Throughput: 0: 1453.6. Samples: 1025280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:09,323][524661] Avg episode reward: [(0, '-62.094')]
[36m[2025-07-02 13:16:14,345][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 917504. Throughput: 0: 1476.2. Samples: 1033856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:14,345][524661] Avg episode reward: [(0, '-70.274')]
[31m[739155 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[739155 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([90], device='cuda:0') (navigation_task.py:196)
[31m[739155 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:16:19,517][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.1). Total num frames: 917504. Throughput: 0: 1447.8. Samples: 1037440. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:19,518][524661] Avg episode reward: [(0, '-62.069')]
[36m[2025-07-02 13:16:24,387][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 917504. Throughput: 0: 1410.5. Samples: 1044224. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:24,388][524661] Avg episode reward: [(0, '-56.766')]
[31m[746433 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[746433 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([85], device='cuda:0') (navigation_task.py:196)
[31m[746434 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:16:29,313][524661] Fps is (10 sec: 13379.9, 60 sec: 2185.6, 300 sec: 1777.3). Total num frames: 1048576. Throughput: 0: 1383.3. Samples: 1051520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:29,314][524661] Avg episode reward: [(0, '-58.527')]
[31m[753398 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[753398 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([19], device='cuda:0') (navigation_task.py:196)
[31m[753399 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:16:34,338][524661] Fps is (10 sec: 13172.8, 60 sec: 2184.6, 300 sec: 1777.6). Total num frames: 1048576. Throughput: 0: 1387.8. Samples: 1056128. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:34,338][524661] Avg episode reward: [(0, '-42.461')]
[37m[1m[2025-07-02 13:16:34,442][524661] Saving new best policy, reward=-42.461!
[31m[756162 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[756163 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([77], device='cuda:0') (navigation_task.py:196)
[31m[756163 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:16:39,392][524661] Fps is (10 sec: 0.0, 60 sec: 2183.9, 300 sec: 1777.3). Total num frames: 1048576. Throughput: 0: 1346.7. Samples: 1063296. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:39,393][524661] Avg episode reward: [(0, '-29.447')]
[37m[1m[2025-07-02 13:16:39,484][524661] Saving new best policy, reward=-29.447!
[36m[2025-07-02 13:16:44,377][524661] Fps is (10 sec: 0.0, 60 sec: 2183.3, 300 sec: 1332.9). Total num frames: 1048576. Throughput: 0: 1321.9. Samples: 1071232. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:44,377][524661] Avg episode reward: [(0, '-29.948')]
[31m[765661 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[765661 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([75], device='cuda:0') (navigation_task.py:196)
[31m[765661 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:16:49,395][524661] Fps is (10 sec: 0.0, 60 sec: 2182.1, 300 sec: 1332.6). Total num frames: 1048576. Throughput: 0: 1287.9. Samples: 1074560. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:49,396][524661] Avg episode reward: [(0, '-47.168')]
[31m[772362 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[772362 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([47], device='cuda:0') (navigation_task.py:196)
[31m[772363 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:16:54,347][524661] Fps is (10 sec: 0.0, 60 sec: 2184.3, 300 sec: 1333.1). Total num frames: 1048576. Throughput: 0: 1245.2. Samples: 1081344. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:54,347][524661] Avg episode reward: [(0, '-43.478')]
[36m[2025-07-02 13:16:59,342][524661] Fps is (10 sec: 0.0, 60 sec: 2184.9, 300 sec: 1332.9). Total num frames: 1048576. Throughput: 0: 1220.3. Samples: 1088768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:16:59,342][524661] Avg episode reward: [(0, '-48.812')]
[36m[2025-07-02 13:17:04,329][524661] Fps is (10 sec: 0.0, 60 sec: 2186.1, 300 sec: 1333.1). Total num frames: 1048576. Throughput: 0: 1245.4. Samples: 1093248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:04,329][524661] Avg episode reward: [(0, '-56.454')]
[36m[2025-07-02 13:17:09,466][524661] Fps is (10 sec: 0.0, 60 sec: 2179.3, 300 sec: 1332.3). Total num frames: 1048576. Throughput: 0: 1252.2. Samples: 1100672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:09,466][524661] Avg episode reward: [(0, '-35.505')]
[31m[793598 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[793599 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([99], device='cuda:0') (navigation_task.py:196)
[31m[793599 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:17:14,390][524661] Fps is (10 sec: 0.0, 60 sec: 2182.9, 300 sec: 1332.7). Total num frames: 1048576. Throughput: 0: 1215.3. Samples: 1106304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:14,390][524661] Avg episode reward: [(0, '-39.811')]
[31m[799322 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[799323 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([63], device='cuda:0') (navigation_task.py:196)
[31m[799323 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:17:19,333][524661] Fps is (10 sec: 0.0, 60 sec: 2191.2, 300 sec: 1333.2). Total num frames: 1048576. Throughput: 0: 1191.9. Samples: 1109760. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:19,334][524661] Avg episode reward: [(0, '-46.634')]
[31m[802194 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[802195 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([77], device='cuda:0') (navigation_task.py:196)
[31m[802195 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[804104 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[804105 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([90], device='cuda:0') (navigation_task.py:196)
[31m[804105 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:17:24,390][524661] Fps is (10 sec: 0.0, 60 sec: 2184.4, 300 sec: 1332.6). Total num frames: 1048576. Throughput: 0: 1186.2. Samples: 1116672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:24,390][524661] Avg episode reward: [(0, '-52.821')]
[31m[808636 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[808637 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([88], device='cuda:0') (navigation_task.py:196)
[31m[808637 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[33m[808817 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[808817 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.01220703125
[33mCrash Rate: 0.69677734375
[33mTimeout Rate: 0.291015625 (navigation_task.py:265)
[33m[808817 ms][navigation_task] - WARNING : 
[33mSuccesses: 25
[33mCrashes : 1427
[33mTimeouts: 596 (navigation_task.py:268)
[36m[2025-07-02 13:17:29,391][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.6). Total num frames: 1048576. Throughput: 0: 1177.2. Samples: 1124224. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:29,391][524661] Avg episode reward: [(0, '-44.565')]
[36m[2025-07-02 13:17:34,378][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 1048576. Throughput: 0: 1203.7. Samples: 1128704. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:34,378][524661] Avg episode reward: [(0, '-42.474')]
[31m[815812 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[815812 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([60], device='cuda:0') (navigation_task.py:196)
[31m[815813 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:17:39,415][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.5). Total num frames: 1048576. Throughput: 0: 1249.7. Samples: 1137664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:39,415][524661] Avg episode reward: [(0, '-40.145')]
[31m[822930 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[822931 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([90], device='cuda:0') (navigation_task.py:196)
[31m[822931 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:17:44,331][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1048576. Throughput: 0: 1234.8. Samples: 1144320. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:44,331][524661] Avg episode reward: [(0, '-40.515')]
[36m[2025-07-02 13:17:49,325][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 1048576. Throughput: 0: 1217.5. Samples: 1148032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:49,326][524661] Avg episode reward: [(0, '-41.630')]
[36m[2025-07-02 13:17:54,376][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 1048576. Throughput: 0: 1222.7. Samples: 1155584. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:54,376][524661] Avg episode reward: [(0, '-38.948')]
[31m[839338 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[839339 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([11], device='cuda:0') (navigation_task.py:196)
[31m[839339 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:17:59,323][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 1048576. Throughput: 0: 1253.4. Samples: 1162624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:17:59,323][524661] Avg episode reward: [(0, '-55.522')]
[31m[841123 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[841123 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([18], device='cuda:0') (navigation_task.py:196)
[31m[841124 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[843069 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[843069 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([5], device='cuda:0') (navigation_task.py:196)
[31m[843070 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:18:04,311][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.3). Total num frames: 1048576. Throughput: 0: 1257.9. Samples: 1166336. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:18:04,311][524661] Avg episode reward: [(0, '-55.448')]
[37m[1m[2025-07-02 13:18:04,418][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000256_1048576.pth...
[36m[2025-07-02 13:18:04,422][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000064_262144.pth
[31m[846367 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[846367 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([78], device='cuda:0') (navigation_task.py:196)
[31m[846367 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:18:09,339][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 1048576. Throughput: 0: 1309.9. Samples: 1175552. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:18:09,340][524661] Avg episode reward: [(0, '-37.912')]
[36m[2025-07-02 13:18:14,362][524661] Fps is (10 sec: 13040.3, 60 sec: 2185.5, 300 sec: 1332.9). Total num frames: 1179648. Throughput: 0: 1334.9. Samples: 1184256. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:18:14,363][524661] Avg episode reward: [(0, '-18.322')]
[37m[1m[2025-07-02 13:18:14,442][524661] Saving new best policy, reward=-18.322!
[36m[2025-07-02 13:18:19,352][524661] Fps is (10 sec: 13090.5, 60 sec: 2183.9, 300 sec: 1332.8). Total num frames: 1179648. Throughput: 0: 1332.0. Samples: 1188608. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:18:19,352][524661] Avg episode reward: [(0, '-28.723')]
[36m[2025-07-02 13:18:24,326][524661] Fps is (10 sec: 0.0, 60 sec: 2186.9, 300 sec: 1333.1). Total num frames: 1179648. Throughput: 0: 1339.5. Samples: 1197824. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:18:24,326][524661] Avg episode reward: [(0, '-32.980')]
[31m[866359 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[866360 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([116], device='cuda:0') (navigation_task.py:196)
[31m[866360 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[867726 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[867727 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([27], device='cuda:0') (navigation_task.py:196)
[31m[867727 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[869767 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[869767 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([8], device='cuda:0') (navigation_task.py:196)
[31m[869767 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:18:29,360][524661] Fps is (10 sec: 0.0, 60 sec: 2185.7, 300 sec: 1333.1). Total num frames: 1179648. Throughput: 0: 1390.0. Samples: 1206912. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:18:29,360][524661] Avg episode reward: [(0, '-37.508')]
[31m[870881 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[870882 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([93], device='cuda:0') (navigation_task.py:196)
[31m[870882 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:18:34,379][524661] Fps is (10 sec: 0.0, 60 sec: 2184.5, 300 sec: 1332.6). Total num frames: 1179648. Throughput: 0: 1412.0. Samples: 1211648. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:18:34,379][524661] Avg episode reward: [(0, '-42.129')]
[36m[2025-07-02 13:18:39,352][524661] Fps is (10 sec: 0.0, 60 sec: 2186.8, 300 sec: 1332.8). Total num frames: 1179648. Throughput: 0: 1448.6. Samples: 1220736. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:18:39,352][524661] Avg episode reward: [(0, '-32.507')]
[36m[2025-07-02 13:18:44,374][524661] Fps is (10 sec: 0.0, 60 sec: 2183.0, 300 sec: 1332.8). Total num frames: 1179648. Throughput: 0: 1400.7. Samples: 1225728. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:18:44,375][524661] Avg episode reward: [(0, '-19.344')]
[36m[2025-07-02 13:18:49,319][524661] Fps is (10 sec: 0.0, 60 sec: 2184.8, 300 sec: 1333.2). Total num frames: 1179648. Throughput: 0: 1365.1. Samples: 1227776. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:18:49,319][524661] Avg episode reward: [(0, '-31.098')]
[36m[2025-07-02 13:18:54,414][524661] Fps is (10 sec: 0.0, 60 sec: 2183.2, 300 sec: 1332.8). Total num frames: 1179648. Throughput: 0: 1258.0. Samples: 1232256. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:18:54,414][524661] Avg episode reward: [(0, '-28.393')]
[36m[2025-07-02 13:18:59,427][524661] Fps is (10 sec: 0.0, 60 sec: 2180.8, 300 sec: 1332.6). Total num frames: 1179648. Throughput: 0: 1178.8. Samples: 1237376. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:18:59,427][524661] Avg episode reward: [(0, '-32.568')]
[36m[2025-07-02 13:19:04,378][524661] Fps is (10 sec: 0.0, 60 sec: 2182.1, 300 sec: 1332.6). Total num frames: 1179648. Throughput: 0: 1159.9. Samples: 1240832. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:04,378][524661] Avg episode reward: [(0, '-30.136')]
[36m[2025-07-02 13:19:09,346][524661] Fps is (10 sec: 0.0, 60 sec: 2184.3, 300 sec: 1333.1). Total num frames: 1179648. Throughput: 0: 1140.1. Samples: 1249152. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:09,347][524661] Avg episode reward: [(0, '-24.072')]
[31m[910472 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[910472 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([92], device='cuda:0') (navigation_task.py:196)
[31m[910473 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:19:14,323][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1179648. Throughput: 0: 1127.3. Samples: 1257600. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:14,323][524661] Avg episode reward: [(0, '-31.282')]
[36m[2025-07-02 13:19:19,390][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1179648. Throughput: 0: 1103.4. Samples: 1261312. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:19,390][524661] Avg episode reward: [(0, '-21.017')]
[36m[2025-07-02 13:19:24,379][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1179648. Throughput: 0: 1063.2. Samples: 1268608. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:24,379][524661] Avg episode reward: [(0, '-12.828')]
[37m[1m[2025-07-02 13:19:24,461][524661] Saving new best policy, reward=-12.828!
[36m[2025-07-02 13:19:29,348][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1179648. Throughput: 0: 1147.0. Samples: 1277312. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:29,349][524661] Avg episode reward: [(0, '-32.774')]
[36m[2025-07-02 13:19:34,376][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1179648. Throughput: 0: 1181.8. Samples: 1281024. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:34,376][524661] Avg episode reward: [(0, '-36.232')]
[33m[936202 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[936202 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.024890189990401268
[33mCrash Rate: 0.5402635335922241
[33mTimeout Rate: 0.43484625220298767 (navigation_task.py:265)
[33m[936202 ms][navigation_task] - WARNING : 
[33mSuccesses: 51
[33mCrashes : 1107
[33mTimeouts: 891 (navigation_task.py:268)
[36m[2025-07-02 13:19:39,443][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 1179648. Throughput: 0: 1191.0. Samples: 1285888. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:39,444][524661] Avg episode reward: [(0, '-31.698')]
[36m[2025-07-02 13:19:44,330][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1179648. Throughput: 0: 1208.6. Samples: 1291648. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:44,330][524661] Avg episode reward: [(0, '-26.602')]
[36m[2025-07-02 13:19:49,337][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 888.7). Total num frames: 1179648. Throughput: 0: 1215.7. Samples: 1295488. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:49,337][524661] Avg episode reward: [(0, '-13.115')]
[31m[951652 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[951653 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([31], device='cuda:0') (navigation_task.py:196)
[31m[951653 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:19:54,392][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 888.6). Total num frames: 1179648. Throughput: 0: 1184.9. Samples: 1302528. Policy #0 lag: (min: 22.0, avg: 22.0, max: 22.0)
[36m[2025-07-02 13:19:54,392][524661] Avg episode reward: [(0, '-25.175')]
[36m[2025-07-02 13:19:59,321][524661] Fps is (10 sec: 13128.2, 60 sec: 2188.4, 300 sec: 1333.2). Total num frames: 1310720. Throughput: 0: 1191.9. Samples: 1311232. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:19:59,321][524661] Avg episode reward: [(0, '-28.643')]
[31m[960835 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[960836 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([109], device='cuda:0') (navigation_task.py:196)
[31m[960836 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[963421 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[963422 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([79], device='cuda:0') (navigation_task.py:196)
[31m[963422 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:20:04,370][524661] Fps is (10 sec: 13136.1, 60 sec: 2184.8, 300 sec: 1332.8). Total num frames: 1310720. Throughput: 0: 1206.6. Samples: 1315584. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:04,370][524661] Avg episode reward: [(0, '-17.855')]
[37m[1m[2025-07-02 13:20:04,473][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000320_1310720.pth...
[36m[2025-07-02 13:20:04,477][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000096_393216.pth
[36m[2025-07-02 13:20:09,391][524661] Fps is (10 sec: 0.0, 60 sec: 2182.9, 300 sec: 1332.9). Total num frames: 1310720. Throughput: 0: 1237.0. Samples: 1324288. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:09,392][524661] Avg episode reward: [(0, '-6.746')]
[37m[1m[2025-07-02 13:20:09,475][524661] Saving new best policy, reward=-5.903!
[36m[2025-07-02 13:20:14,315][524661] Fps is (10 sec: 0.0, 60 sec: 2184.8, 300 sec: 1333.2). Total num frames: 1310720. Throughput: 0: 1224.0. Samples: 1332352. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:14,315][524661] Avg episode reward: [(0, '-11.559')]
[36m[2025-07-02 13:20:19,384][524661] Fps is (10 sec: 0.0, 60 sec: 2184.8, 300 sec: 1332.7). Total num frames: 1310720. Throughput: 0: 1245.7. Samples: 1337088. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:19,384][524661] Avg episode reward: [(0, '-9.496')]
[31m[981272 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[981272 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([122], device='cuda:0') (navigation_task.py:196)
[31m[981273 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:20:24,360][524661] Fps is (10 sec: 0.0, 60 sec: 2185.2, 300 sec: 1332.9). Total num frames: 1310720. Throughput: 0: 1342.2. Samples: 1346176. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:24,360][524661] Avg episode reward: [(0, '-13.674')]
[31m[989499 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[989499 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([126], device='cuda:0') (navigation_task.py:196)
[31m[989500 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:20:29,313][524661] Fps is (10 sec: 0.0, 60 sec: 2185.8, 300 sec: 1333.1). Total num frames: 1310720. Throughput: 0: 1400.0. Samples: 1354624. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:29,314][524661] Avg episode reward: [(0, '-19.180')]
[36m[2025-07-02 13:20:34,316][524661] Fps is (10 sec: 0.0, 60 sec: 2186.7, 300 sec: 1333.2). Total num frames: 1310720. Throughput: 0: 1420.0. Samples: 1359360. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:34,316][524661] Avg episode reward: [(0, '-3.727')]
[37m[1m[2025-07-02 13:20:34,395][524661] Saving new best policy, reward=-3.727!
[31m[995284 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[995284 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([2], device='cuda:0') (navigation_task.py:196)
[31m[995284 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:20:39,312][524661] Fps is (10 sec: 0.0, 60 sec: 2189.3, 300 sec: 1333.1). Total num frames: 1310720. Throughput: 0: 1481.8. Samples: 1369088. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:39,312][524661] Avg episode reward: [(0, '-2.320')]
[37m[1m[2025-07-02 13:20:39,386][524661] Saving new best policy, reward=-2.320!
[31m[1001286 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1001286 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([5], device='cuda:0') (navigation_task.py:196)
[31m[1001286 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:20:44,327][524661] Fps is (10 sec: 0.0, 60 sec: 2184.6, 300 sec: 1332.9). Total num frames: 1310720. Throughput: 0: 1496.0. Samples: 1378560. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:44,327][524661] Avg episode reward: [(0, '-6.583')]
[36m[2025-07-02 13:20:49,329][524661] Fps is (10 sec: 0.0, 60 sec: 2184.8, 300 sec: 1333.0). Total num frames: 1310720. Throughput: 0: 1503.3. Samples: 1383168. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:49,329][524661] Avg episode reward: [(0, '-5.931')]
[36m[2025-07-02 13:20:54,407][524661] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1332.7). Total num frames: 1310720. Throughput: 0: 1507.0. Samples: 1392128. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:54,407][524661] Avg episode reward: [(0, '-12.921')]
[36m[2025-07-02 13:20:59,320][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 1310720. Throughput: 0: 1521.6. Samples: 1400832. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:20:59,320][524661] Avg episode reward: [(0, '-12.453')]
[36m[2025-07-02 13:21:04,405][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.6). Total num frames: 1310720. Throughput: 0: 1512.5. Samples: 1405184. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:21:04,406][524661] Avg episode reward: [(0, '-15.128')]
[31m[1027420 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1027421 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([8], device='cuda:0') (navigation_task.py:196)
[31m[1027421 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:21:09,377][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1310720. Throughput: 0: 1487.1. Samples: 1413120. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:21:09,378][524661] Avg episode reward: [(0, '-4.841')]
[36m[2025-07-02 13:21:14,367][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.6). Total num frames: 1310720. Throughput: 0: 1500.1. Samples: 1422208. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:21:14,367][524661] Avg episode reward: [(0, '-22.359')]
[31m[1038036 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1038037 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([59], device='cuda:0') (navigation_task.py:196)
[31m[1038037 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:21:19,337][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 1310720. Throughput: 0: 1495.5. Samples: 1426688. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:21:19,337][524661] Avg episode reward: [(0, '-10.456')]
[36m[2025-07-02 13:21:24,355][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 888.5). Total num frames: 1310720. Throughput: 0: 1474.8. Samples: 1435520. Policy #0 lag: (min: 24.0, avg: 24.0, max: 24.0)
[36m[2025-07-02 13:21:24,356][524661] Avg episode reward: [(0, '-7.640')]
[31m[1046276 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1046277 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([89], device='cuda:0') (navigation_task.py:196)
[31m[1046277 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:21:29,424][524661] Fps is (10 sec: 12993.7, 60 sec: 2180.5, 300 sec: 1332.5). Total num frames: 1441792. Throughput: 0: 1458.9. Samples: 1444352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:21:29,424][524661] Avg episode reward: [(0, '-7.025')]
[36m[2025-07-02 13:21:34,376][524661] Fps is (10 sec: 13080.6, 60 sec: 2182.3, 300 sec: 1333.0). Total num frames: 1441792. Throughput: 0: 1432.1. Samples: 1447680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:21:34,376][524661] Avg episode reward: [(0, '-8.545')]
[36m[2025-07-02 13:21:39,334][524661] Fps is (10 sec: 0.0, 60 sec: 2183.7, 300 sec: 1333.1). Total num frames: 1441792. Throughput: 0: 1390.3. Samples: 1454592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:21:39,335][524661] Avg episode reward: [(0, '-3.862')]
[33m[1060297 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[1060297 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.04489995166659355
[33mCrash Rate: 0.40946802496910095
[33mTimeout Rate: 0.545632004737854 (navigation_task.py:265)
[33m[1060297 ms][navigation_task] - WARNING : 
[33mSuccesses: 92
[33mCrashes : 839
[33mTimeouts: 1118 (navigation_task.py:268)
[36m[2025-07-02 13:21:44,391][524661] Fps is (10 sec: 0.0, 60 sec: 2182.2, 300 sec: 1333.0). Total num frames: 1441792. Throughput: 0: 1371.7. Samples: 1462656. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:21:44,391][524661] Avg episode reward: [(0, '-12.271')]
[36m[2025-07-02 13:21:49,367][524661] Fps is (10 sec: 0.0, 60 sec: 2183.1, 300 sec: 1332.8). Total num frames: 1441792. Throughput: 0: 1366.5. Samples: 1466624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:21:49,367][524661] Avg episode reward: [(0, '-6.380')]
[36m[2025-07-02 13:21:54,348][524661] Fps is (10 sec: 0.0, 60 sec: 2186.7, 300 sec: 1332.9). Total num frames: 1441792. Throughput: 0: 1363.4. Samples: 1474432. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:21:54,348][524661] Avg episode reward: [(0, '2.493')]
[37m[1m[2025-07-02 13:21:54,438][524661] Saving new best policy, reward=2.493!
[31m[1075554 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1075554 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([18], device='cuda:0') (navigation_task.py:196)
[31m[1075555 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:21:59,334][524661] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1332.9). Total num frames: 1441792. Throughput: 0: 1335.0. Samples: 1482240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:21:59,335][524661] Avg episode reward: [(0, '-12.303')]
[36m[2025-07-02 13:22:04,345][524661] Fps is (10 sec: 0.0, 60 sec: 2186.7, 300 sec: 1333.5). Total num frames: 1441792. Throughput: 0: 1328.1. Samples: 1486464. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:04,345][524661] Avg episode reward: [(0, '-15.967')]
[37m[1m[2025-07-02 13:22:04,438][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000352_1441792.pth...
[36m[2025-07-02 13:22:04,443][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000160_655360.pth
[36m[2025-07-02 13:22:09,347][524661] Fps is (10 sec: 0.0, 60 sec: 2185.7, 300 sec: 1333.1). Total num frames: 1441792. Throughput: 0: 1322.9. Samples: 1495040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:09,347][524661] Avg episode reward: [(0, '-5.436')]
[36m[2025-07-02 13:22:14,381][524661] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1332.7). Total num frames: 1441792. Throughput: 0: 1326.8. Samples: 1504000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:14,382][524661] Avg episode reward: [(0, '-1.627')]
[31m[1097167 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1097167 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([117], device='cuda:0') (navigation_task.py:196)
[31m[1097167 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[1097243 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1097243 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([90], device='cuda:0') (navigation_task.py:196)
[31m[1097243 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[1098882 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1098883 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([116], device='cuda:0') (navigation_task.py:196)
[31m[1098883 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:22:19,310][524661] Fps is (10 sec: 0.0, 60 sec: 2185.5, 300 sec: 1333.3). Total num frames: 1441792. Throughput: 0: 1353.1. Samples: 1508480. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:19,311][524661] Avg episode reward: [(0, '7.160')]
[37m[1m[2025-07-02 13:22:19,406][524661] Saving new best policy, reward=7.160!
[36m[2025-07-02 13:22:24,392][524661] Fps is (10 sec: 0.0, 60 sec: 2183.2, 300 sec: 1332.9). Total num frames: 1441792. Throughput: 0: 1400.5. Samples: 1517696. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:24,392][524661] Avg episode reward: [(0, '-8.572')]
[36m[2025-07-02 13:22:29,360][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1441792. Throughput: 0: 1426.0. Samples: 1526784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:29,360][524661] Avg episode reward: [(0, '-7.747')]
[36m[2025-07-02 13:22:34,358][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 1441792. Throughput: 0: 1431.1. Samples: 1531008. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:34,358][524661] Avg episode reward: [(0, '-13.634')]
[36m[2025-07-02 13:22:39,377][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 1441792. Throughput: 0: 1444.0. Samples: 1539456. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:39,378][524661] Avg episode reward: [(0, '-7.095')]
[36m[2025-07-02 13:22:44,310][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1441792. Throughput: 0: 1474.2. Samples: 1548544. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:44,311][524661] Avg episode reward: [(0, '-11.472')]
[36m[2025-07-02 13:22:49,351][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1441792. Throughput: 0: 1478.9. Samples: 1553024. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:49,351][524661] Avg episode reward: [(0, '-4.716')]
[36m[2025-07-02 13:22:54,343][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1441792. Throughput: 0: 1479.2. Samples: 1561600. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:54,343][524661] Avg episode reward: [(0, '-7.422')]
[36m[2025-07-02 13:22:59,331][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1441792. Throughput: 0: 1452.3. Samples: 1569280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:22:59,332][524661] Avg episode reward: [(0, '-13.512')]
[36m[2025-07-02 13:23:04,361][524661] Fps is (10 sec: 13083.3, 60 sec: 2183.9, 300 sec: 1777.1). Total num frames: 1572864. Throughput: 0: 1429.1. Samples: 1572864. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:04,362][524661] Avg episode reward: [(0, '-11.581')]
[31m[1148250 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1148251 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([110], device='cuda:0') (navigation_task.py:196)
[31m[1148251 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:23:09,410][524661] Fps is (10 sec: 13005.5, 60 sec: 2182.2, 300 sec: 1332.7). Total num frames: 1572864. Throughput: 0: 1390.4. Samples: 1580288. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:09,410][524661] Avg episode reward: [(0, '13.854')]
[37m[1m[2025-07-02 13:23:09,512][524661] Saving new best policy, reward=13.854!
[36m[2025-07-02 13:23:14,350][524661] Fps is (10 sec: 0.0, 60 sec: 2185.7, 300 sec: 1332.9). Total num frames: 1572864. Throughput: 0: 1357.1. Samples: 1587840. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:14,350][524661] Avg episode reward: [(0, '7.791')]
[31m[1156934 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1156934 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([78], device='cuda:0') (navigation_task.py:196)
[31m[1156934 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:23:19,352][524661] Fps is (10 sec: 0.0, 60 sec: 2183.0, 300 sec: 1332.8). Total num frames: 1572864. Throughput: 0: 1345.6. Samples: 1591552. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:19,352][524661] Avg episode reward: [(0, '1.984')]
[31m[1164172 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1164172 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([60], device='cuda:0') (navigation_task.py:196)
[31m[1164172 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:23:24,394][524661] Fps is (10 sec: 0.0, 60 sec: 2184.5, 300 sec: 1332.8). Total num frames: 1572864. Throughput: 0: 1322.2. Samples: 1598976. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:24,394][524661] Avg episode reward: [(0, '4.319')]
[31m[1169802 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1169803 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([3], device='cuda:0') (navigation_task.py:196)
[31m[1169803 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:23:29,320][524661] Fps is (10 sec: 0.0, 60 sec: 2186.0, 300 sec: 1333.2). Total num frames: 1572864. Throughput: 0: 1285.4. Samples: 1606400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:29,321][524661] Avg episode reward: [(0, '-7.231')]
[36m[2025-07-02 13:23:34,337][524661] Fps is (10 sec: 0.0, 60 sec: 2185.3, 300 sec: 1333.0). Total num frames: 1572864. Throughput: 0: 1271.9. Samples: 1610240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:34,337][524661] Avg episode reward: [(0, '-15.658')]
[31m[1177978 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1177979 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([77], device='cuda:0') (navigation_task.py:196)
[31m[1177979 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:23:39,318][524661] Fps is (10 sec: 0.0, 60 sec: 2186.7, 300 sec: 1333.2). Total num frames: 1572864. Throughput: 0: 1275.0. Samples: 1618944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:39,318][524661] Avg episode reward: [(0, '-7.796')]
[36m[2025-07-02 13:23:44,370][524661] Fps is (10 sec: 0.0, 60 sec: 2182.4, 300 sec: 1332.7). Total num frames: 1572864. Throughput: 0: 1233.4. Samples: 1624832. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:44,371][524661] Avg episode reward: [(0, '-1.219')]
[36m[2025-07-02 13:23:49,330][524661] Fps is (10 sec: 0.0, 60 sec: 2185.3, 300 sec: 1333.3). Total num frames: 1572864. Throughput: 0: 1218.3. Samples: 1627648. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:49,330][524661] Avg episode reward: [(0, '-1.260')]
[36m[2025-07-02 13:23:54,330][524661] Fps is (10 sec: 0.0, 60 sec: 2185.0, 300 sec: 1333.4). Total num frames: 1572864. Throughput: 0: 1211.0. Samples: 1634688. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:54,330][524661] Avg episode reward: [(0, '3.904')]
[33m[1197098 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[1197098 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.04345703125
[33mCrash Rate: 0.3125
[33mTimeout Rate: 0.64404296875 (navigation_task.py:265)
[33m[1197098 ms][navigation_task] - WARNING : 
[33mSuccesses: 89
[33mCrashes : 640
[33mTimeouts: 1319 (navigation_task.py:268)
[31m[1199797 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1199797 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([97], device='cuda:0') (navigation_task.py:196)
[31m[1199797 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:23:59,316][524661] Fps is (10 sec: 0.0, 60 sec: 2185.1, 300 sec: 1333.2). Total num frames: 1572864. Throughput: 0: 1207.0. Samples: 1642112. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:23:59,316][524661] Avg episode reward: [(0, '5.371')]
[36m[2025-07-02 13:24:04,350][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1572864. Throughput: 0: 1214.6. Samples: 1646208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:04,350][524661] Avg episode reward: [(0, '-6.367')]
[37m[1m[2025-07-02 13:24:04,460][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000384_1572864.pth...
[36m[2025-07-02 13:24:04,464][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000192_786432.pth
[36m[2025-07-02 13:24:09,309][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1572864. Throughput: 0: 1216.9. Samples: 1653632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:09,309][524661] Avg episode reward: [(0, '-10.874')]
[36m[2025-07-02 13:24:14,345][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 1572864. Throughput: 0: 1245.2. Samples: 1662464. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:14,345][524661] Avg episode reward: [(0, '-4.558')]
[36m[2025-07-02 13:24:19,317][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 1572864. Throughput: 0: 1260.6. Samples: 1666944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:19,318][524661] Avg episode reward: [(0, '0.392')]
[36m[2025-07-02 13:24:24,383][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1572864. Throughput: 0: 1269.6. Samples: 1676160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:24,383][524661] Avg episode reward: [(0, '5.775')]
[36m[2025-07-02 13:24:29,373][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1572864. Throughput: 0: 1319.7. Samples: 1684224. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:29,374][524661] Avg episode reward: [(0, '-3.367')]
[36m[2025-07-02 13:24:34,341][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.4). Total num frames: 1572864. Throughput: 0: 1345.1. Samples: 1688192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:34,341][524661] Avg episode reward: [(0, '-20.514')]
[36m[2025-07-02 13:24:39,355][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1572864. Throughput: 0: 1393.0. Samples: 1697408. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:39,355][524661] Avg episode reward: [(0, '-6.046')]
[36m[2025-07-02 13:24:44,340][524661] Fps is (10 sec: 13109.2, 60 sec: 2185.6, 300 sec: 1777.2). Total num frames: 1703936. Throughput: 0: 1421.5. Samples: 1706112. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:44,340][524661] Avg episode reward: [(0, '-9.576')]
[36m[2025-07-02 13:24:49,378][524661] Fps is (10 sec: 13077.1, 60 sec: 2182.8, 300 sec: 1777.3). Total num frames: 1703936. Throughput: 0: 1427.0. Samples: 1710464. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:49,378][524661] Avg episode reward: [(0, '3.812')]
[31m[1251438 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1251439 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([86], device='cuda:0') (navigation_task.py:196)
[31m[1251439 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:24:54,363][524661] Fps is (10 sec: 0.0, 60 sec: 2183.3, 300 sec: 1332.7). Total num frames: 1703936. Throughput: 0: 1457.4. Samples: 1719296. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:54,364][524661] Avg episode reward: [(0, '-1.546')]
[36m[2025-07-02 13:24:59,329][524661] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1333.1). Total num frames: 1703936. Throughput: 0: 1473.9. Samples: 1728768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:24:59,330][524661] Avg episode reward: [(0, '7.374')]
[36m[2025-07-02 13:25:04,346][524661] Fps is (10 sec: 0.0, 60 sec: 2184.7, 300 sec: 1333.1). Total num frames: 1703936. Throughput: 0: 1478.2. Samples: 1733504. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:04,346][524661] Avg episode reward: [(0, '2.742')]
[36m[2025-07-02 13:25:09,367][524661] Fps is (10 sec: 0.0, 60 sec: 2182.4, 300 sec: 1332.7). Total num frames: 1703936. Throughput: 0: 1465.4. Samples: 1742080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:09,367][524661] Avg episode reward: [(0, '0.727')]
[31m[1271232 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1271233 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([122], device='cuda:0') (navigation_task.py:196)
[31m[1271233 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:25:14,326][524661] Fps is (10 sec: 0.0, 60 sec: 2185.2, 300 sec: 1333.2). Total num frames: 1703936. Throughput: 0: 1472.1. Samples: 1750400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:14,327][524661] Avg episode reward: [(0, '13.564')]
[36m[2025-07-02 13:25:19,367][524661] Fps is (10 sec: 0.0, 60 sec: 2182.7, 300 sec: 1332.9). Total num frames: 1703936. Throughput: 0: 1469.7. Samples: 1754368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:19,367][524661] Avg episode reward: [(0, '3.033')]
[31m[1281549 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1281549 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([18], device='cuda:0') (navigation_task.py:196)
[31m[1281549 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:25:24,392][524661] Fps is (10 sec: 0.0, 60 sec: 2184.2, 300 sec: 1332.6). Total num frames: 1703936. Throughput: 0: 1426.7. Samples: 1761664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:24,393][524661] Avg episode reward: [(0, '-10.528')]
[31m[1289735 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1289736 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([90], device='cuda:0') (navigation_task.py:196)
[31m[1289736 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:25:29,347][524661] Fps is (10 sec: 0.0, 60 sec: 2185.5, 300 sec: 1332.8). Total num frames: 1703936. Throughput: 0: 1413.5. Samples: 1769728. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:29,347][524661] Avg episode reward: [(0, '6.007')]
[36m[2025-07-02 13:25:34,379][524661] Fps is (10 sec: 0.0, 60 sec: 2183.2, 300 sec: 1332.6). Total num frames: 1703936. Throughput: 0: 1410.8. Samples: 1773952. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:34,379][524661] Avg episode reward: [(0, '13.461')]
[36m[2025-07-02 13:25:39,313][524661] Fps is (10 sec: 0.0, 60 sec: 2186.1, 300 sec: 1333.0). Total num frames: 1703936. Throughput: 0: 1389.7. Samples: 1781760. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:39,313][524661] Avg episode reward: [(0, '-2.576')]
[31m[1304343 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1304344 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([5], device='cuda:0') (navigation_task.py:196)
[31m[1304344 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:25:44,319][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1703936. Throughput: 0: 1357.1. Samples: 1789824. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:44,319][524661] Avg episode reward: [(0, '-0.069')]
[31m[1308574 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1308575 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([84], device='cuda:0') (navigation_task.py:196)
[31m[1308575 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:25:49,358][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 1703936. Throughput: 0: 1336.5. Samples: 1793664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:49,358][524661] Avg episode reward: [(0, '0.305')]
[36m[2025-07-02 13:25:54,336][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1703936. Throughput: 0: 1320.7. Samples: 1801472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:54,336][524661] Avg episode reward: [(0, '-1.368')]
[31m[1318462 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1318463 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([84], device='cuda:0') (navigation_task.py:196)
[31m[1318463 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:25:59,360][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 1703936. Throughput: 0: 1310.3. Samples: 1809408. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:25:59,360][524661] Avg episode reward: [(0, '9.712')]
[31m[1321179 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1321180 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([7], device='cuda:0') (navigation_task.py:196)
[31m[1321181 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:26:04,370][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1703936. Throughput: 0: 1305.5. Samples: 1813120. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:04,370][524661] Avg episode reward: [(0, '10.816')]
[37m[1m[2025-07-02 13:26:04,475][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000416_1703936.pth...
[36m[2025-07-02 13:26:04,479][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000224_917504.pth
[36m[2025-07-02 13:26:09,333][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 1703936. Throughput: 0: 1321.6. Samples: 1821056. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:09,333][524661] Avg episode reward: [(0, '2.755')]
[33m[1330314 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[1330314 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0537109375
[33mCrash Rate: 0.2841796875
[33mTimeout Rate: 0.662109375 (navigation_task.py:265)
[33m[1330314 ms][navigation_task] - WARNING : 
[33mSuccesses: 110
[33mCrashes : 582
[33mTimeouts: 1356 (navigation_task.py:268)
[36m[2025-07-02 13:26:14,368][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1703936. Throughput: 0: 1322.0. Samples: 1829248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:14,369][524661] Avg episode reward: [(0, '3.948')]
[36m[2025-07-02 13:26:19,356][524661] Fps is (10 sec: 13076.5, 60 sec: 2184.9, 300 sec: 1777.2). Total num frames: 1835008. Throughput: 0: 1317.6. Samples: 1833216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:19,356][524661] Avg episode reward: [(0, '1.308')]
[31m[1341282 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1341282 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([124], device='cuda:0') (navigation_task.py:196)
[31m[1341282 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[1344613 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1344614 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([50], device='cuda:0') (navigation_task.py:196)
[31m[1344615 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:26:24,310][524661] Fps is (10 sec: 13184.9, 60 sec: 2187.6, 300 sec: 1333.5). Total num frames: 1835008. Throughput: 0: 1314.2. Samples: 1840896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:24,310][524661] Avg episode reward: [(0, '16.336')]
[37m[1m[2025-07-02 13:26:24,406][524661] Saving new best policy, reward=16.336!
[36m[2025-07-02 13:26:29,317][524661] Fps is (10 sec: 0.0, 60 sec: 2185.6, 300 sec: 1333.2). Total num frames: 1835008. Throughput: 0: 1311.3. Samples: 1848832. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:29,318][524661] Avg episode reward: [(0, '16.261')]
[36m[2025-07-02 13:26:34,360][524661] Fps is (10 sec: 0.0, 60 sec: 2185.2, 300 sec: 1332.8). Total num frames: 1835008. Throughput: 0: 1311.2. Samples: 1852672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:34,361][524661] Avg episode reward: [(0, '4.730')]
[36m[2025-07-02 13:26:39,366][524661] Fps is (10 sec: 0.0, 60 sec: 2182.6, 300 sec: 1333.0). Total num frames: 1835008. Throughput: 0: 1313.3. Samples: 1860608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:39,366][524661] Avg episode reward: [(0, '15.803')]
[36m[2025-07-02 13:26:44,372][524661] Fps is (10 sec: 0.0, 60 sec: 2182.6, 300 sec: 1332.9). Total num frames: 1835008. Throughput: 0: 1310.9. Samples: 1868416. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:44,373][524661] Avg episode reward: [(0, '16.111')]
[31m[1366285 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1366286 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([8], device='cuda:0') (navigation_task.py:196)
[31m[1366286 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:26:49,356][524661] Fps is (10 sec: 0.0, 60 sec: 2184.6, 300 sec: 1332.9). Total num frames: 1835008. Throughput: 0: 1317.4. Samples: 1872384. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:49,356][524661] Avg episode reward: [(0, '8.912')]
[36m[2025-07-02 13:26:54,370][524661] Fps is (10 sec: 0.0, 60 sec: 2183.3, 300 sec: 1332.8). Total num frames: 1835008. Throughput: 0: 1313.0. Samples: 1880192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:54,370][524661] Avg episode reward: [(0, '-0.358')]
[36m[2025-07-02 13:26:59,320][524661] Fps is (10 sec: 0.0, 60 sec: 2186.0, 300 sec: 1333.0). Total num frames: 1835008. Throughput: 0: 1307.0. Samples: 1888000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:26:59,320][524661] Avg episode reward: [(0, '1.161')]
[36m[2025-07-02 13:27:04,366][524661] Fps is (10 sec: 0.0, 60 sec: 2184.7, 300 sec: 1332.8). Total num frames: 1835008. Throughput: 0: 1308.2. Samples: 1892096. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:04,366][524661] Avg episode reward: [(0, '12.853')]
[36m[2025-07-02 13:27:09,321][524661] Fps is (10 sec: 0.0, 60 sec: 2185.0, 300 sec: 1333.2). Total num frames: 1835008. Throughput: 0: 1311.0. Samples: 1899904. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:09,321][524661] Avg episode reward: [(0, '17.889')]
[37m[1m[2025-07-02 13:27:09,415][524661] Saving new best policy, reward=17.889!
[36m[2025-07-02 13:27:14,383][524661] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1332.6). Total num frames: 1835008. Throughput: 0: 1306.5. Samples: 1907712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:14,383][524661] Avg episode reward: [(0, '8.839')]
[31m[1396454 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1396455 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([104], device='cuda:0') (navigation_task.py:196)
[31m[1396455 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:27:19,389][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1835008. Throughput: 0: 1310.5. Samples: 1911680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:19,389][524661] Avg episode reward: [(0, '3.515')]
[36m[2025-07-02 13:27:24,370][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1835008. Throughput: 0: 1311.2. Samples: 1919616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:24,370][524661] Avg episode reward: [(0, '1.549')]
[31m[1408862 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1408862 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([27], device='cuda:0') (navigation_task.py:196)
[31m[1408863 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:27:29,350][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1835008. Throughput: 0: 1311.9. Samples: 1927424. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:29,350][524661] Avg episode reward: [(0, '5.066')]
[36m[2025-07-02 13:27:34,371][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1835008. Throughput: 0: 1305.2. Samples: 1931136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:34,371][524661] Avg episode reward: [(0, '6.715')]
[36m[2025-07-02 13:27:39,374][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.6). Total num frames: 1835008. Throughput: 0: 1331.1. Samples: 1940096. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:39,374][524661] Avg episode reward: [(0, '11.113')]
[36m[2025-07-02 13:27:44,355][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1835008. Throughput: 0: 1355.7. Samples: 1949056. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:44,355][524661] Avg episode reward: [(0, '-2.726')]
[36m[2025-07-02 13:27:49,348][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 1835008. Throughput: 0: 1368.7. Samples: 1953664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:49,348][524661] Avg episode reward: [(0, '4.866')]
[36m[2025-07-02 13:27:54,352][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1835008. Throughput: 0: 1404.2. Samples: 1963136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:27:54,352][524661] Avg episode reward: [(0, '20.510')]
[37m[1m[2025-07-02 13:27:54,441][524661] Saving new best policy, reward=20.510!
[31m[1439775 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1439775 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([106], device='cuda:0') (navigation_task.py:196)
[31m[1439775 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:27:59,373][524661] Fps is (10 sec: 13074.6, 60 sec: 2182.6, 300 sec: 1332.9). Total num frames: 1966080. Throughput: 0: 1428.2. Samples: 1971968. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:27:59,373][524661] Avg episode reward: [(0, '7.842')]
[31m[1440626 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1440626 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([53], device='cuda:0') (navigation_task.py:196)
[31m[1440626 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:28:04,361][524661] Fps is (10 sec: 13096.2, 60 sec: 2184.7, 300 sec: 1333.2). Total num frames: 1966080. Throughput: 0: 1440.2. Samples: 1976448. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:04,361][524661] Avg episode reward: [(0, '14.282')]
[37m[1m[2025-07-02 13:28:04,439][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000480_1966080.pth...
[36m[2025-07-02 13:28:04,443][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000256_1048576.pth
[31m[1446992 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1446992 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([36], device='cuda:0') (navigation_task.py:196)
[31m[1446992 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:28:09,379][524661] Fps is (10 sec: 0.0, 60 sec: 2182.4, 300 sec: 1332.8). Total num frames: 1966080. Throughput: 0: 1481.7. Samples: 1986304. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:09,379][524661] Avg episode reward: [(0, '28.900')]
[37m[1m[2025-07-02 13:28:09,468][524661] Saving new best policy, reward=28.900!
[31m[1450915 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1450915 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([93], device='cuda:0') (navigation_task.py:196)
[31m[1450915 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:28:14,317][524661] Fps is (10 sec: 0.0, 60 sec: 2186.9, 300 sec: 1333.1). Total num frames: 1966080. Throughput: 0: 1517.2. Samples: 1995648. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:14,317][524661] Avg episode reward: [(0, '19.738')]
[36m[2025-07-02 13:28:19,380][524661] Fps is (10 sec: 0.0, 60 sec: 2184.9, 300 sec: 1333.0). Total num frames: 1966080. Throughput: 0: 1535.7. Samples: 2000256. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:19,380][524661] Avg episode reward: [(0, '15.484')]
[33m[1464077 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[1464077 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.0882926806807518
[33mCrash Rate: 0.2653658390045166
[33mTimeout Rate: 0.6463414430618286 (navigation_task.py:265)
[33m[1464077 ms][navigation_task] - WARNING : 
[33mSuccesses: 181
[33mCrashes : 544
[33mTimeouts: 1325 (navigation_task.py:268)
[31m[1464169 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1464170 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([116], device='cuda:0') (navigation_task.py:196)
[31m[1464171 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:28:24,382][524661] Fps is (10 sec: 0.0, 60 sec: 2184.1, 300 sec: 1332.7). Total num frames: 1966080. Throughput: 0: 1530.0. Samples: 2008960. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:24,382][524661] Avg episode reward: [(0, '20.994')]
[36m[2025-07-02 13:28:29,356][524661] Fps is (10 sec: 0.0, 60 sec: 2184.3, 300 sec: 1332.8). Total num frames: 1966080. Throughput: 0: 1516.1. Samples: 2017280. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:29,356][524661] Avg episode reward: [(0, '12.010')]
[36m[2025-07-02 13:28:34,360][524661] Fps is (10 sec: 0.0, 60 sec: 2184.9, 300 sec: 1332.7). Total num frames: 1966080. Throughput: 0: 1490.1. Samples: 2020736. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:34,361][524661] Avg episode reward: [(0, '13.199')]
[36m[2025-07-02 13:28:39,361][524661] Fps is (10 sec: 0.0, 60 sec: 2185.0, 300 sec: 1333.0). Total num frames: 1966080. Throughput: 0: 1458.9. Samples: 2028800. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:39,361][524661] Avg episode reward: [(0, '32.390')]
[37m[1m[2025-07-02 13:28:39,447][524661] Saving new best policy, reward=32.390!
[36m[2025-07-02 13:28:44,351][524661] Fps is (10 sec: 0.0, 60 sec: 2184.7, 300 sec: 1332.8). Total num frames: 1966080. Throughput: 0: 1457.1. Samples: 2037504. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:44,352][524661] Avg episode reward: [(0, '23.093')]
[36m[2025-07-02 13:28:49,311][524661] Fps is (10 sec: 0.0, 60 sec: 2185.9, 300 sec: 1333.0). Total num frames: 1966080. Throughput: 0: 1455.1. Samples: 2041856. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:49,311][524661] Avg episode reward: [(0, '25.729')]
[36m[2025-07-02 13:28:54,319][524661] Fps is (10 sec: 0.0, 60 sec: 2185.7, 300 sec: 1332.9). Total num frames: 1966080. Throughput: 0: 1427.0. Samples: 2050432. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:54,319][524661] Avg episode reward: [(0, '33.075')]
[37m[1m[2025-07-02 13:28:54,406][524661] Saving new best policy, reward=33.075!
[31m[1496566 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1496567 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([78], device='cuda:0') (navigation_task.py:196)
[31m[1496567 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:28:59,318][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 1966080. Throughput: 0: 1422.2. Samples: 2059648. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:28:59,319][524661] Avg episode reward: [(0, '11.731')]
[36m[2025-07-02 13:29:04,331][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 1966080. Throughput: 0: 1423.8. Samples: 2064256. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:04,332][524661] Avg episode reward: [(0, '29.763')]
[31m[1507370 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1507371 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([63], device='cuda:0') (navigation_task.py:196)
[31m[1507371 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:29:09,342][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 1966080. Throughput: 0: 1440.6. Samples: 2073728. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:09,342][524661] Avg episode reward: [(0, '27.189')]
[31m[1512694 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1512694 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([59], device='cuda:0') (navigation_task.py:196)
[31m[1512694 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:29:14,363][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 1966080. Throughput: 0: 1464.6. Samples: 2083200. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:14,364][524661] Avg episode reward: [(0, '16.743')]
[36m[2025-07-02 13:29:19,339][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 1966080. Throughput: 0: 1488.4. Samples: 2087680. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:19,339][524661] Avg episode reward: [(0, '10.503')]
[31m[1521834 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1521834 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([73], device='cuda:0') (navigation_task.py:196)
[31m[1521834 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:29:24,385][524661] Fps is (10 sec: 13079.6, 60 sec: 2184.4, 300 sec: 1777.2). Total num frames: 2097152. Throughput: 0: 1512.4. Samples: 2096896. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:24,385][524661] Avg episode reward: [(0, '18.495')]
[36m[2025-07-02 13:29:29,396][524661] Fps is (10 sec: 13033.1, 60 sec: 2183.1, 300 sec: 1776.9). Total num frames: 2097152. Throughput: 0: 1514.6. Samples: 2105728. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:29,396][524661] Avg episode reward: [(0, '29.435')]
[36m[2025-07-02 13:29:34,382][524661] Fps is (10 sec: 0.0, 60 sec: 2183.8, 300 sec: 1777.1). Total num frames: 2097152. Throughput: 0: 1519.4. Samples: 2110336. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:34,382][524661] Avg episode reward: [(0, '15.260')]
[36m[2025-07-02 13:29:39,349][524661] Fps is (10 sec: 0.0, 60 sec: 2185.0, 300 sec: 1332.9). Total num frames: 2097152. Throughput: 0: 1526.5. Samples: 2119168. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:39,349][524661] Avg episode reward: [(0, '25.155')]
[36m[2025-07-02 13:29:44,366][524661] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1333.0). Total num frames: 2097152. Throughput: 0: 1514.5. Samples: 2127872. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:44,366][524661] Avg episode reward: [(0, '14.492')]
[36m[2025-07-02 13:29:49,379][524661] Fps is (10 sec: 0.0, 60 sec: 2182.0, 300 sec: 1332.9). Total num frames: 2097152. Throughput: 0: 1517.3. Samples: 2132608. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:49,379][524661] Avg episode reward: [(0, '26.736')]
[31m[1551416 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1551417 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([112], device='cuda:0') (navigation_task.py:196)
[31m[1551417 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:29:54,316][524661] Fps is (10 sec: 0.0, 60 sec: 2184.6, 300 sec: 1333.0). Total num frames: 2097152. Throughput: 0: 1508.4. Samples: 2141568. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:54,317][524661] Avg episode reward: [(0, '24.319')]
[31m[1557582 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1557583 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([92], device='cuda:0') (navigation_task.py:196)
[31m[1557583 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:29:59,365][524661] Fps is (10 sec: 0.0, 60 sec: 2182.8, 300 sec: 1332.8). Total num frames: 2097152. Throughput: 0: 1501.8. Samples: 2150784. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:29:59,366][524661] Avg episode reward: [(0, '18.902')]
[31m[1561283 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1561283 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([124], device='cuda:0') (navigation_task.py:196)
[31m[1561283 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:30:04,367][524661] Fps is (10 sec: 0.0, 60 sec: 2183.2, 300 sec: 1332.9). Total num frames: 2097152. Throughput: 0: 1503.8. Samples: 2155392. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:30:04,368][524661] Avg episode reward: [(0, '38.751')]
[37m[1m[2025-07-02 13:30:04,445][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000512_2097152.pth...
[36m[2025-07-02 13:30:04,449][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000320_1310720.pth
[37m[1m[2025-07-02 13:30:04,450][524661] Saving new best policy, reward=38.751!
[31m[1569498 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1569498 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([88], device='cuda:0') (navigation_task.py:196)
[31m[1569499 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:30:09,311][524661] Fps is (10 sec: 0.0, 60 sec: 2185.7, 300 sec: 1333.0). Total num frames: 2097152. Throughput: 0: 1510.0. Samples: 2164736. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:30:09,311][524661] Avg episode reward: [(0, '39.616')]
[37m[1m[2025-07-02 13:30:09,393][524661] Saving new best policy, reward=39.616!
[36m[2025-07-02 13:30:14,371][524661] Fps is (10 sec: 0.0, 60 sec: 2184.3, 300 sec: 1332.9). Total num frames: 2097152. Throughput: 0: 1514.1. Samples: 2173824. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:30:14,371][524661] Avg episode reward: [(0, '24.416')]
[31m[1576136 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1576137 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([71], device='cuda:0') (navigation_task.py:196)
[31m[1576137 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:30:19,378][524661] Fps is (10 sec: 0.0, 60 sec: 2183.1, 300 sec: 1333.0). Total num frames: 2097152. Throughput: 0: 1516.2. Samples: 2178560. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:30:19,378][524661] Avg episode reward: [(0, '27.480')]
[31m[1582061 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1582062 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([108], device='cuda:0') (navigation_task.py:196)
[31m[1582062 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[1582819 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1582819 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([52], device='cuda:0') (navigation_task.py:196)
[31m[1582820 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:30:24,343][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 2097152. Throughput: 0: 1516.3. Samples: 2187392. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:30:24,343][524661] Avg episode reward: [(0, '33.729')]
[36m[2025-07-02 13:30:29,316][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 2097152. Throughput: 0: 1532.0. Samples: 2196736. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:30:29,316][524661] Avg episode reward: [(0, '27.474')]
[33m[1591710 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[1591711 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.12060546875
[33mCrash Rate: 0.25146484375
[33mTimeout Rate: 0.6279296875 (navigation_task.py:265)
[33m[1591711 ms][navigation_task] - WARNING : 
[33mSuccesses: 247
[33mCrashes : 515
[33mTimeouts: 1286 (navigation_task.py:268)
[36m[2025-07-02 13:30:34,381][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.6). Total num frames: 2097152. Throughput: 0: 1521.7. Samples: 2201088. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:30:34,381][524661] Avg episode reward: [(0, '7.710')]
[36m[2025-07-02 13:30:39,327][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 2097152. Throughput: 0: 1521.4. Samples: 2210048. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:30:39,327][524661] Avg episode reward: [(0, '33.128')]
[36m[2025-07-02 13:30:44,364][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 2097152. Throughput: 0: 1527.5. Samples: 2219520. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:30:44,364][524661] Avg episode reward: [(0, '36.979')]
[36m[2025-07-02 13:30:49,308][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 2097152. Throughput: 0: 1526.6. Samples: 2224000. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-02 13:30:49,308][524661] Avg episode reward: [(0, '33.006')]
[31m[1611892 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1611892 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([58], device='cuda:0') (navigation_task.py:196)
[31m[1611893 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:30:54,338][524661] Fps is (10 sec: 13141.2, 60 sec: 2183.7, 300 sec: 1777.4). Total num frames: 2228224. Throughput: 0: 1509.5. Samples: 2232704. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:30:54,338][524661] Avg episode reward: [(0, '32.435')]
[36m[2025-07-02 13:30:59,339][524661] Fps is (10 sec: 13066.4, 60 sec: 2185.5, 300 sec: 1777.4). Total num frames: 2228224. Throughput: 0: 1525.7. Samples: 2242432. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:30:59,340][524661] Avg episode reward: [(0, '15.927')]
[36m[2025-07-02 13:31:04,308][524661] Fps is (10 sec: 0.0, 60 sec: 2186.7, 300 sec: 1777.4). Total num frames: 2228224. Throughput: 0: 1524.1. Samples: 2247040. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:04,308][524661] Avg episode reward: [(0, '27.609')]
[36m[2025-07-02 13:31:09,329][524661] Fps is (10 sec: 0.0, 60 sec: 2183.9, 300 sec: 1777.5). Total num frames: 2228224. Throughput: 0: 1539.3. Samples: 2256640. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:09,329][524661] Avg episode reward: [(0, '38.061')]
[36m[2025-07-02 13:31:14,369][524661] Fps is (10 sec: 0.0, 60 sec: 2184.6, 300 sec: 1332.9). Total num frames: 2228224. Throughput: 0: 1528.5. Samples: 2265600. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:14,369][524661] Avg episode reward: [(0, '28.500')]
[36m[2025-07-02 13:31:19,322][524661] Fps is (10 sec: 0.0, 60 sec: 2186.6, 300 sec: 1332.9). Total num frames: 2228224. Throughput: 0: 1540.9. Samples: 2270336. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:19,322][524661] Avg episode reward: [(0, '28.889')]
[36m[2025-07-02 13:31:24,332][524661] Fps is (10 sec: 0.0, 60 sec: 2185.0, 300 sec: 1332.9). Total num frames: 2228224. Throughput: 0: 1550.1. Samples: 2279808. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:24,332][524661] Avg episode reward: [(0, '38.818')]
[36m[2025-07-02 13:31:29,347][524661] Fps is (10 sec: 0.0, 60 sec: 2183.4, 300 sec: 1333.0). Total num frames: 2228224. Throughput: 0: 1542.3. Samples: 2288896. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:29,347][524661] Avg episode reward: [(0, '26.162')]
[31m[1652077 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1652077 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([78], device='cuda:0') (navigation_task.py:196)
[31m[1652077 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[1654595 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1654595 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([93], device='cuda:0') (navigation_task.py:196)
[31m[1654595 ms][navigation_task] - CRITICAL : Time at crash: tensor([3], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:31:34,398][524661] Fps is (10 sec: 0.0, 60 sec: 2183.9, 300 sec: 1332.8). Total num frames: 2228224. Throughput: 0: 1538.6. Samples: 2293376. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:34,399][524661] Avg episode reward: [(0, '31.904')]
[36m[2025-07-02 13:31:39,399][524661] Fps is (10 sec: 0.0, 60 sec: 2181.9, 300 sec: 1332.8). Total num frames: 2228224. Throughput: 0: 1531.1. Samples: 2301696. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:39,400][524661] Avg episode reward: [(0, '28.270')]
[36m[2025-07-02 13:31:44,328][524661] Fps is (10 sec: 0.0, 60 sec: 2185.8, 300 sec: 1333.1). Total num frames: 2228224. Throughput: 0: 1502.3. Samples: 2310016. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:44,328][524661] Avg episode reward: [(0, '47.268')]
[37m[1m[2025-07-02 13:31:44,446][524661] Saving new best policy, reward=47.268!
[36m[2025-07-02 13:31:49,371][524661] Fps is (10 sec: 0.0, 60 sec: 2182.3, 300 sec: 1332.9). Total num frames: 2228224. Throughput: 0: 1485.6. Samples: 2313984. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:49,371][524661] Avg episode reward: [(0, '51.563')]
[37m[1m[2025-07-02 13:31:49,446][524661] Saving new best policy, reward=51.563!
[36m[2025-07-02 13:31:54,340][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 2228224. Throughput: 0: 1478.8. Samples: 2323200. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:54,340][524661] Avg episode reward: [(0, '38.557')]
[31m[1677656 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1677657 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([37], device='cuda:0') (navigation_task.py:196)
[31m[1677657 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:31:59,375][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 2228224. Throughput: 0: 1484.6. Samples: 2332416. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:31:59,375][524661] Avg episode reward: [(0, '14.512')]
[36m[2025-07-02 13:32:04,408][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.5). Total num frames: 2228224. Throughput: 0: 1482.0. Samples: 2337152. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:32:04,408][524661] Avg episode reward: [(0, '25.922')]
[37m[1m[2025-07-02 13:32:04,415][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000544_2228224.pth...
[36m[2025-07-02 13:32:04,423][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000352_1441792.pth
[36m[2025-07-02 13:32:09,345][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 2228224. Throughput: 0: 1470.2. Samples: 2345984. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:32:09,345][524661] Avg episode reward: [(0, '45.674')]
[36m[2025-07-02 13:32:14,376][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 2228224. Throughput: 0: 1466.8. Samples: 2354944. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-02 13:32:14,376][524661] Avg episode reward: [(0, '19.631')]
[31m[1695639 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1695640 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([41], device='cuda:0') (navigation_task.py:196)
[31m[1695640 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[1698121 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1698121 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([ 4, 60], device='cuda:0') (navigation_task.py:196)
[31m[1698122 ms][navigation_task] - CRITICAL : Time at crash: tensor([1, 1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:32:19,339][524661] Fps is (10 sec: 13114.7, 60 sec: 2183.9, 300 sec: 1777.4). Total num frames: 2359296. Throughput: 0: 1466.8. Samples: 2359296. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:32:19,339][524661] Avg episode reward: [(0, '19.669')]
[36m[2025-07-02 13:32:24,405][524661] Fps is (10 sec: 13069.4, 60 sec: 2181.9, 300 sec: 1776.9). Total num frames: 2359296. Throughput: 0: 1478.9. Samples: 2368256. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:32:24,405][524661] Avg episode reward: [(0, '40.354')]
[36m[2025-07-02 13:32:29,309][524661] Fps is (10 sec: 0.0, 60 sec: 2185.9, 300 sec: 1777.6). Total num frames: 2359296. Throughput: 0: 1499.6. Samples: 2377472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:32:29,310][524661] Avg episode reward: [(0, '27.534')]
[36m[2025-07-02 13:32:34,355][524661] Fps is (10 sec: 0.0, 60 sec: 2186.1, 300 sec: 1777.4). Total num frames: 2359296. Throughput: 0: 1513.8. Samples: 2382080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:32:34,356][524661] Avg episode reward: [(0, '25.232')]
[33m[1717744 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[1717744 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.14453125
[33mCrash Rate: 0.26025390625
[33mTimeout Rate: 0.59521484375 (navigation_task.py:265)
[33m[1717744 ms][navigation_task] - WARNING : 
[33mSuccesses: 296
[33mCrashes : 533
[33mTimeouts: 1219 (navigation_task.py:268)
[36m[2025-07-02 13:32:39,366][524661] Fps is (10 sec: 0.0, 60 sec: 2185.7, 300 sec: 1777.2). Total num frames: 2359296. Throughput: 0: 1503.8. Samples: 2390912. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:32:39,367][524661] Avg episode reward: [(0, '29.619')]
[36m[2025-07-02 13:32:44,405][524661] Fps is (10 sec: 0.0, 60 sec: 2181.7, 300 sec: 1776.9). Total num frames: 2359296. Throughput: 0: 1492.3. Samples: 2399616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:32:44,405][524661] Avg episode reward: [(0, '20.487')]
[36m[2025-07-02 13:32:49,313][524661] Fps is (10 sec: 0.0, 60 sec: 2186.6, 300 sec: 1777.5). Total num frames: 2359296. Throughput: 0: 1493.6. Samples: 2404224. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:32:49,313][524661] Avg episode reward: [(0, '45.544')]
[36m[2025-07-02 13:32:54,331][524661] Fps is (10 sec: 0.0, 60 sec: 2184.8, 300 sec: 1333.1). Total num frames: 2359296. Throughput: 0: 1490.9. Samples: 2413056. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:32:54,331][524661] Avg episode reward: [(0, '26.133')]
[36m[2025-07-02 13:32:59,308][524661] Fps is (10 sec: 0.0, 60 sec: 2187.0, 300 sec: 1333.2). Total num frames: 2359296. Throughput: 0: 1495.6. Samples: 2422144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:32:59,308][524661] Avg episode reward: [(0, '15.716')]
[36m[2025-07-02 13:33:04,336][524661] Fps is (10 sec: 0.0, 60 sec: 2187.2, 300 sec: 1333.1). Total num frames: 2359296. Throughput: 0: 1504.8. Samples: 2427008. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:33:04,336][524661] Avg episode reward: [(0, '33.049')]
[36m[2025-07-02 13:33:09,384][524661] Fps is (10 sec: 0.0, 60 sec: 2183.1, 300 sec: 1332.6). Total num frames: 2359296. Throughput: 0: 1513.9. Samples: 2436352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:33:09,384][524661] Avg episode reward: [(0, '30.860')]
[31m[1753939 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1753939 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([15], device='cuda:0') (navigation_task.py:196)
[31m[1753940 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:33:14,370][524661] Fps is (10 sec: 0.0, 60 sec: 2184.7, 300 sec: 1333.0). Total num frames: 2359296. Throughput: 0: 1497.0. Samples: 2444928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:33:14,370][524661] Avg episode reward: [(0, '25.579')]
[31m[1759736 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1759737 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([47], device='cuda:0') (navigation_task.py:196)
[31m[1759737 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:33:19,342][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 2359296. Throughput: 0: 1493.8. Samples: 2449280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:33:19,342][524661] Avg episode reward: [(0, '18.107')]
[31m[1760605 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1760605 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([77], device='cuda:0') (navigation_task.py:196)
[31m[1760605 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[1762836 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1762836 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([15], device='cuda:0') (navigation_task.py:196)
[31m[1762836 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:33:24,348][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 2359296. Throughput: 0: 1499.6. Samples: 2458368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:33:24,348][524661] Avg episode reward: [(0, '43.530')]
[36m[2025-07-02 13:33:29,315][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 2359296. Throughput: 0: 1502.0. Samples: 2467072. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:33:29,315][524661] Avg episode reward: [(0, '56.834')]
[37m[1m[2025-07-02 13:33:29,395][524661] Saving new best policy, reward=56.834!
[31m[1773351 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1773351 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([67], device='cuda:0') (navigation_task.py:196)
[31m[1773351 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:33:34,344][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 2359296. Throughput: 0: 1492.3. Samples: 2471424. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:33:34,344][524661] Avg episode reward: [(0, '47.313')]
[31m[1778564 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1778565 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([58], device='cuda:0') (navigation_task.py:196)
[31m[1778566 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:33:39,404][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.7). Total num frames: 2359296. Throughput: 0: 1505.1. Samples: 2480896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:33:39,404][524661] Avg episode reward: [(0, '40.363')]
[31m[1781868 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1781869 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([59], device='cuda:0') (navigation_task.py:196)
[31m[1781869 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:33:44,379][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.6). Total num frames: 2359296. Throughput: 0: 1499.5. Samples: 2489728. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:33:44,379][524661] Avg episode reward: [(0, '51.802')]
[36m[2025-07-02 13:33:49,353][524661] Fps is (10 sec: 13174.2, 60 sec: 2183.1, 300 sec: 1777.0). Total num frames: 2490368. Throughput: 0: 1489.9. Samples: 2494080. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:33:49,353][524661] Avg episode reward: [(0, '46.039')]
[31m[1790924 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1790924 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([117], device='cuda:0') (navigation_task.py:196)
[31m[1790925 ms][navigation_task] - CRITICAL : Time at crash: tensor([4], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[1794367 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1794367 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([119], device='cuda:0') (navigation_task.py:196)
[31m[1794367 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:33:54,402][524661] Fps is (10 sec: 13076.9, 60 sec: 2182.0, 300 sec: 1776.7). Total num frames: 2490368. Throughput: 0: 1484.2. Samples: 2503168. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:33:54,402][524661] Avg episode reward: [(0, '39.826')]
[36m[2025-07-02 13:33:59,316][524661] Fps is (10 sec: 0.0, 60 sec: 2184.2, 300 sec: 1777.3). Total num frames: 2490368. Throughput: 0: 1492.3. Samples: 2512000. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:33:59,317][524661] Avg episode reward: [(0, '41.348')]
[31m[1800432 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1800432 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([2], device='cuda:0') (navigation_task.py:196)
[31m[1800432 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:34:04,371][524661] Fps is (10 sec: 0.0, 60 sec: 2183.2, 300 sec: 1777.1). Total num frames: 2490368. Throughput: 0: 1498.1. Samples: 2516736. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:04,371][524661] Avg episode reward: [(0, '34.923')]
[37m[1m[2025-07-02 13:34:04,461][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000608_2490368.pth...
[36m[2025-07-02 13:34:04,465][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000384_1572864.pth
[36m[2025-07-02 13:34:09,329][524661] Fps is (10 sec: 0.0, 60 sec: 2186.5, 300 sec: 1777.5). Total num frames: 2490368. Throughput: 0: 1496.8. Samples: 2525696. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:09,329][524661] Avg episode reward: [(0, '30.394')]
[31m[1814077 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1814078 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([76], device='cuda:0') (navigation_task.py:196)
[31m[1814078 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:34:14,383][524661] Fps is (10 sec: 0.0, 60 sec: 2184.1, 300 sec: 1777.0). Total num frames: 2490368. Throughput: 0: 1496.8. Samples: 2534528. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:14,384][524661] Avg episode reward: [(0, '32.464')]
[31m[1818442 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1818442 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([88], device='cuda:0') (navigation_task.py:196)
[31m[1818442 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:34:19,382][524661] Fps is (10 sec: 0.0, 60 sec: 2183.1, 300 sec: 1332.9). Total num frames: 2490368. Throughput: 0: 1503.4. Samples: 2539136. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:19,383][524661] Avg episode reward: [(0, '20.398')]
[36m[2025-07-02 13:34:24,364][524661] Fps is (10 sec: 0.0, 60 sec: 2183.9, 300 sec: 1333.1). Total num frames: 2490368. Throughput: 0: 1483.3. Samples: 2547584. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:24,364][524661] Avg episode reward: [(0, '34.911')]
[36m[2025-07-02 13:34:29,372][524661] Fps is (10 sec: 0.0, 60 sec: 2182.5, 300 sec: 1333.0). Total num frames: 2490368. Throughput: 0: 1476.5. Samples: 2556160. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:29,373][524661] Avg episode reward: [(0, '52.685')]
[31m[1831958 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1831958 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([27], device='cuda:0') (navigation_task.py:196)
[31m[1831959 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:34:34,358][524661] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1332.9). Total num frames: 2490368. Throughput: 0: 1456.2. Samples: 2559616. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:34,359][524661] Avg episode reward: [(0, '39.657')]
[36m[2025-07-02 13:34:39,360][524661] Fps is (10 sec: 0.0, 60 sec: 2186.1, 300 sec: 1333.0). Total num frames: 2490368. Throughput: 0: 1420.7. Samples: 2567040. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:39,360][524661] Avg episode reward: [(0, '46.760')]
[36m[2025-07-02 13:34:44,403][524661] Fps is (10 sec: 0.0, 60 sec: 2183.7, 300 sec: 1332.8). Total num frames: 2490368. Throughput: 0: 1391.1. Samples: 2574720. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:44,403][524661] Avg episode reward: [(0, '39.151')]
[33m[1847718 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[1847718 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.1532454788684845
[33mCrash Rate: 0.2420693039894104
[33mTimeout Rate: 0.6046851873397827 (navigation_task.py:265)
[33m[1847718 ms][navigation_task] - WARNING : 
[33mSuccesses: 314
[33mCrashes : 496
[33mTimeouts: 1239 (navigation_task.py:268)
[36m[2025-07-02 13:34:49,334][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 2490368. Throughput: 0: 1360.8. Samples: 2577920. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:49,334][524661] Avg episode reward: [(0, '35.182')]
[36m[2025-07-02 13:34:54,350][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 2490368. Throughput: 0: 1327.7. Samples: 2585472. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:54,350][524661] Avg episode reward: [(0, '49.269')]
[36m[2025-07-02 13:34:59,372][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.9). Total num frames: 2490368. Throughput: 0: 1294.6. Samples: 2592768. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:34:59,372][524661] Avg episode reward: [(0, '44.492')]
[36m[2025-07-02 13:35:04,347][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 2490368. Throughput: 0: 1278.2. Samples: 2596608. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:35:04,347][524661] Avg episode reward: [(0, '27.946')]
[36m[2025-07-02 13:35:09,333][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 2490368. Throughput: 0: 1266.6. Samples: 2604544. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:35:09,333][524661] Avg episode reward: [(0, '32.694')]
[36m[2025-07-02 13:35:14,367][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 2490368. Throughput: 0: 1240.3. Samples: 2611968. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:35:14,367][524661] Avg episode reward: [(0, '33.241')]
[31m[1877312 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1877313 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([102], device='cuda:0') (navigation_task.py:196)
[31m[1877313 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:35:19,314][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.1). Total num frames: 2490368. Throughput: 0: 1261.3. Samples: 2616320. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-02 13:35:19,314][524661] Avg episode reward: [(0, '11.993')]
[36m[2025-07-02 13:35:24,374][524661] Fps is (10 sec: 13098.3, 60 sec: 2184.2, 300 sec: 1776.9). Total num frames: 2621440. Throughput: 0: 1293.8. Samples: 2625280. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:35:24,374][524661] Avg episode reward: [(0, '33.324')]
[31m[1886421 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1886421 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([53], device='cuda:0') (navigation_task.py:196)
[31m[1886421 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:35:29,358][524661] Fps is (10 sec: 13049.3, 60 sec: 2185.1, 300 sec: 1777.4). Total num frames: 2621440. Throughput: 0: 1329.7. Samples: 2634496. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:35:29,358][524661] Avg episode reward: [(0, '43.450')]
[36m[2025-07-02 13:35:34,345][524661] Fps is (10 sec: 0.0, 60 sec: 2185.0, 300 sec: 1777.1). Total num frames: 2621440. Throughput: 0: 1356.5. Samples: 2638976. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:35:34,345][524661] Avg episode reward: [(0, '62.266')]
[37m[1m[2025-07-02 13:35:34,471][524661] Saving new best policy, reward=62.266!
[36m[2025-07-02 13:35:39,360][524661] Fps is (10 sec: 0.0, 60 sec: 2184.5, 300 sec: 1777.3). Total num frames: 2621440. Throughput: 0: 1353.7. Samples: 2646400. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:35:39,360][524661] Avg episode reward: [(0, '59.045')]
[36m[2025-07-02 13:35:44,363][524661] Fps is (10 sec: 0.0, 60 sec: 2186.0, 300 sec: 1776.9). Total num frames: 2621440. Throughput: 0: 1359.9. Samples: 2653952. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:35:44,364][524661] Avg episode reward: [(0, '38.083')]
[36m[2025-07-02 13:35:49,377][524661] Fps is (10 sec: 0.0, 60 sec: 2183.0, 300 sec: 1332.8). Total num frames: 2621440. Throughput: 0: 1353.1. Samples: 2657536. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:35:49,377][524661] Avg episode reward: [(0, '35.286')]
[36m[2025-07-02 13:35:54,316][524661] Fps is (10 sec: 0.0, 60 sec: 2185.8, 300 sec: 1333.0). Total num frames: 2621440. Throughput: 0: 1337.4. Samples: 2664704. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:35:54,317][524661] Avg episode reward: [(0, '53.958')]
[36m[2025-07-02 13:35:59,326][524661] Fps is (10 sec: 0.0, 60 sec: 2186.2, 300 sec: 1332.9). Total num frames: 2621440. Throughput: 0: 1346.6. Samples: 2672512. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:35:59,326][524661] Avg episode reward: [(0, '54.356')]
[36m[2025-07-02 13:36:04,310][524661] Fps is (10 sec: 0.0, 60 sec: 2185.9, 300 sec: 1333.0). Total num frames: 2621440. Throughput: 0: 1331.3. Samples: 2676224. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:04,310][524661] Avg episode reward: [(0, '40.742')]
[31m[1924903 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1924903 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([110], device='cuda:0') (navigation_task.py:196)
[31m[1924904 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[37m[1m[2025-07-02 13:36:04,420][524661] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000640_2621440.pth...
[36m[2025-07-02 13:36:04,424][524661] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/HIGH_CONFIG_128ENV_1/checkpoint_p0/checkpoint_000000416_1703936.pth
[31m[1927709 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1927710 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([59], device='cuda:0') (navigation_task.py:196)
[31m[1927710 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:36:09,363][524661] Fps is (10 sec: 0.0, 60 sec: 2183.4, 300 sec: 1333.0). Total num frames: 2621440. Throughput: 0: 1323.0. Samples: 2684800. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:09,363][524661] Avg episode reward: [(0, '39.716')]
[36m[2025-07-02 13:36:14,382][524661] Fps is (10 sec: 0.0, 60 sec: 2184.0, 300 sec: 1332.7). Total num frames: 2621440. Throughput: 0: 1302.1. Samples: 2693120. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:14,382][524661] Avg episode reward: [(0, '45.472')]
[36m[2025-07-02 13:36:19,327][524661] Fps is (10 sec: 0.0, 60 sec: 2184.1, 300 sec: 1333.0). Total num frames: 2621440. Throughput: 0: 1294.8. Samples: 2697216. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:19,327][524661] Avg episode reward: [(0, '53.450')]
[36m[2025-07-02 13:36:24,368][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 2621440. Throughput: 0: 1322.4. Samples: 2705920. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:24,368][524661] Avg episode reward: [(0, '32.741')]
[31m[1948413 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1948413 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([107], device='cuda:0') (navigation_task.py:196)
[31m[1948414 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:36:29,322][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.3). Total num frames: 2621440. Throughput: 0: 1360.9. Samples: 2715136. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:29,322][524661] Avg episode reward: [(0, '33.318')]
[36m[2025-07-02 13:36:34,340][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 2621440. Throughput: 0: 1380.7. Samples: 2719616. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:34,340][524661] Avg episode reward: [(0, '55.727')]
[36m[2025-07-02 13:36:39,324][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.0). Total num frames: 2621440. Throughput: 0: 1416.3. Samples: 2728448. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:39,324][524661] Avg episode reward: [(0, '46.608')]
[31m[1960951 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1960951 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([86], device='cuda:0') (navigation_task.py:196)
[31m[1960951 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:36:44,310][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1333.2). Total num frames: 2621440. Throughput: 0: 1439.8. Samples: 2737280. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:44,310][524661] Avg episode reward: [(0, '63.232')]
[37m[1m[2025-07-02 13:36:44,396][524661] Saving new best policy, reward=63.232!
[36m[2025-07-02 13:36:49,371][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 2621440. Throughput: 0: 1454.4. Samples: 2741760. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:49,372][524661] Avg episode reward: [(0, '48.899')]
[36m[2025-07-02 13:36:54,409][524661] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 1332.8). Total num frames: 2621440. Throughput: 0: 1460.5. Samples: 2750592. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-02 13:36:54,410][524661] Avg episode reward: [(0, '44.227')]
[36m[2025-07-02 13:36:59,349][524661] Fps is (10 sec: 13136.6, 60 sec: 2183.7, 300 sec: 1777.6). Total num frames: 2752512. Throughput: 0: 1468.8. Samples: 2759168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:36:59,349][524661] Avg episode reward: [(0, '45.746')]
[36m[2025-07-02 13:37:04,361][524661] Fps is (10 sec: 13171.2, 60 sec: 2182.7, 300 sec: 1777.2). Total num frames: 2752512. Throughput: 0: 1472.3. Samples: 2763520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:37:04,361][524661] Avg episode reward: [(0, '65.322')]
[37m[1m[2025-07-02 13:37:04,439][524661] Saving new best policy, reward=65.322!
[33m[1985983 ms][navigation_task] - WARNING : Curriculum Level: 15, Curriculum progress fraction: 0.0 (navigation_task.py:262)
[33m[1985983 ms][navigation_task] - WARNING : 
[33mSuccess Rate: 0.20947265625
[33mCrash Rate: 0.2236328125
[33mTimeout Rate: 0.56689453125 (navigation_task.py:265)
[33m[1985984 ms][navigation_task] - WARNING : 
[33mSuccesses: 429
[33mCrashes : 458
[33mTimeouts: 1161 (navigation_task.py:268)
[31m[1987698 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1987698 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([104], device='cuda:0') (navigation_task.py:196)
[31m[1987698 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[1989859 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[1989860 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([99], device='cuda:0') (navigation_task.py:196)
[31m[1989860 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:37:09,374][524661] Fps is (10 sec: 0.0, 60 sec: 2184.1, 300 sec: 1777.3). Total num frames: 2752512. Throughput: 0: 1484.6. Samples: 2772736. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:37:09,374][524661] Avg episode reward: [(0, '96.786')]
[37m[1m[2025-07-02 13:37:09,460][524661] Saving new best policy, reward=96.786!
[36m[2025-07-02 13:37:14,358][524661] Fps is (10 sec: 0.0, 60 sec: 2185.4, 300 sec: 1332.9). Total num frames: 2752512. Throughput: 0: 1472.3. Samples: 2781440. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:37:14,358][524661] Avg episode reward: [(0, '70.106')]
[36m[2025-07-02 13:37:19,358][524661] Fps is (10 sec: 0.0, 60 sec: 2183.4, 300 sec: 1333.1). Total num frames: 2752512. Throughput: 0: 1470.0. Samples: 2785792. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:37:19,358][524661] Avg episode reward: [(0, '65.279')]
[31m[2003283 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[2003283 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([36], device='cuda:0') (navigation_task.py:196)
[31m[2003284 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[31m[2003562 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[2003562 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([44], device='cuda:0') (navigation_task.py:196)
[31m[2003563 ms][navigation_task] - CRITICAL : Time at crash: tensor([1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
[36m[2025-07-02 13:37:24,325][524661] Fps is (10 sec: 0.0, 60 sec: 2186.1, 300 sec: 1332.9). Total num frames: 2752512. Throughput: 0: 1464.8. Samples: 2794368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:37:24,326][524661] Avg episode reward: [(0, '60.339')]
[36m[2025-07-02 13:37:29,359][524661] Fps is (10 sec: 0.0, 60 sec: 2183.2, 300 sec: 1332.9). Total num frames: 2752512. Throughput: 0: 1437.7. Samples: 2802048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:37:29,360][524661] Avg episode reward: [(0, '46.083')]
[36m[2025-07-02 13:37:34,322][524661] Fps is (10 sec: 0.0, 60 sec: 2185.2, 300 sec: 1333.1). Total num frames: 2752512. Throughput: 0: 1426.6. Samples: 2805888. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-02 13:37:34,322][524661] Avg episode reward: [(0, '59.442')]
[37m[1m[2025-07-02 13:37:36,426][524661] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 524661], exiting...
[37m[1m[2025-07-02 13:37:36,426][524661] Runner profile tree view:
[37m[1mmain_loop: 2005.6945
[37m[1m[2025-07-02 13:37:36,426][524661] Collected {0: 2752512}, FPS: 1372.3