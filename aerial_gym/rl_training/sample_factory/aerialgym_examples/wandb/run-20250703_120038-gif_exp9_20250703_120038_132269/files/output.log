Importing module 'gym_38' (/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
[36m[2025-07-03 12:00:41,437][47005] Queried available GPUs: 0
[37m[1m[2025-07-03 12:00:41,437][47005] Environment var CUDA_VISIBLE_DEVICES is 0
PyTorch version 1.13.1
Device count 1
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
Warp 1.0.0-beta.5 initialized:
   CUDA Toolkit: 11.5, Driver: 12.4
   Devices:
     "cpu"    | x86_64
     "cuda:0" | NVIDIA GeForce RTX 4080 Laptop GPU (sm_89)
   Kernel cache: /home/ziyar/.cache/warp/1.0.0-beta.5
[SUBPROCESS] FORCED headless mode for all Sample Factory training: headless=True
[SUBPROCESS] This prevents Isaac Gym viewer conflicts across all processes
[SUBPROCESS] Task action_space_dim: 3
[SUBPROCESS] Target Sample Factory action space: 3D
[SUBPROCESS] Setting num_envs to 4 based on env_agents=4
[SUBPROCESS] Set SF_ENV_AGENTS=4 environment variable
[SUBPROCESS] Config batch_size: 128
[SUBPROCESS] Using MEDIUM CONFIG (4 environments)
Registered quad_with_obstacles_gate and dce_navigation_task_gate in subprocess
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles_gate', '--experiment=gif_exp9', '--train_dir=./train_dir', '--num_workers=1', '--num_envs_per_worker=1', '--env_agents=4', '--obs_key=observations', '--batch_size=128', '--num_batches_to_accumulate=2', '--rollout=32', '--learning_rate=0.0003', '--use_rnn=true', '--rnn_size=128', '--rnn_num_layers=1', '--encoder_mlp_layers', '512', '256', '128', '--gamma=0.98', '--with_wandb=true', '--wandb_project=gate_navigation_dual_camera', '--wandb_user=ziya-ruso-ucl', '--wandb_group=gate_navigation_training', '--wandb_tags', 'aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized', '--save_every_sec=120', '--save_best_every_sec=5', '--train_for_env_steps=100000000']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/utils/cpp_extension.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging  # type: ignore[attr-defined]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Using /home/ziyar/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
Emitting ninja build file /home/ziyar/.cache/torch_extensions/py38_cu117/gymtorch/build.ninja...
Building extension module gymtorch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module gymtorch...
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/graph.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping, Set, Iterable
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/readwrite/graphml.py:346: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  (np.int, "int"), (np.int8, "int"),
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/torch_utils.py:135: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  def get_axis_params(value, axis_idx, x_value=0., dtype=np.float, n_dims=3):
[37m[1805 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task_gate.py:22)
[37m[1805 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Final headless mode: False (dce_navigation_task_gate.py:29)
[37m[1805 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Found SF_ENV_AGENTS environment variable: 4 (dce_navigation_task_gate.py:39)
[37m[1805 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Detected env_agents=4 from environment - setting environment count. (dce_navigation_task_gate.py:45)
[37m[1805 ms][base_task] - INFO : Setting seed: 3559942095 (base_task.py:38)
[37m[1806 ms][navigation_task_gate] - INFO : Building environment for gate navigation task. (navigation_task_gate.py:48)
[37m[1806 ms][navigation_task_gate] - INFO : Sim Name: base_sim, Env Name: gate_env, Robot Name: lmf2, Controller Name: lmf2_position_control (navigation_task_gate.py:49)
[37m[1806 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[1806 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[1806 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[1806 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[1806 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[1806 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[1807 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[1807 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[1807 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[1807 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[1807 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[1807 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[1807 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.47 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 7.73 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 11.50 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.57 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[37m[2792 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[2792 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[2995 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[2995 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[2995 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[2995 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[2995 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[2995 ms][BaseRobot] - INFO : Initializing controller lmf2_position_control (base_robot.py:29)
[33m[2995 ms][base_multirotor] - WARNING : Creating 4 multirotors. (base_multirotor.py:32)
[37m[2995 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[2995 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[2995 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2995 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2999 ms][asset_loader] - INFO : Loading asset: tree_41.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3007 ms][asset_loader] - INFO : Loading asset: tree_62.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3016 ms][asset_loader] - INFO : Loading asset: tree_87.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3025 ms][asset_loader] - INFO : Loading asset: tree_68.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3034 ms][asset_loader] - INFO : Loading asset: tree_32.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3043 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3044 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3045 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3046 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3047 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3048 ms][asset_loader] - INFO : Loading asset: tree_21.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3056 ms][asset_loader] - INFO : Loading asset: tree_30.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3065 ms][asset_loader] - INFO : Loading asset: tree_89.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3074 ms][asset_loader] - INFO : Loading asset: tree_20.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3083 ms][asset_loader] - INFO : Loading asset: tree_54.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3092 ms][asset_loader] - INFO : Loading asset: tree_47.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3101 ms][asset_loader] - INFO : Loading asset: tree_42.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3109 ms][asset_loader] - INFO : Loading asset: tree_91.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3118 ms][asset_loader] - INFO : Loading asset: tree_38.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3127 ms][asset_loader] - INFO : Loading asset: tree_78.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3136 ms][asset_loader] - INFO : Loading asset: tree_23.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3145 ms][asset_loader] - INFO : Loading asset: tree_14.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3154 ms][asset_loader] - INFO : Loading asset: tree_19.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3163 ms][env_manager] - INFO : Creating ground plane in Isaac Gym Simulation. (env_manager.py:172)
[37m[3168 ms][env_manager] - INFO : [DONE] Creating ground plane in Isaac Gym Simulation (env_manager.py:174)
[37m[3168 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[3546 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[3546 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[3546 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[3577 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[3584 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[3584 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[3669 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[3669 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[3758 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 11 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[3955 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[3956 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
[37m[4613 ms][navigation_task_gate] - INFO : Setting up static camera for gate navigation... (navigation_task_gate.py:483)
[37m[4613 ms][navigation_task_gate] - INFO : Static camera properties: 480x270, FOV: 87.0° (navigation_task_gate.py:502)
[37m[4631 ms][navigation_task_gate] - INFO : ✓ Static camera setup complete (navigation_task_gate.py:519)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[36m[2025-07-03 12:00:46,253][47135] Env info: EnvInfo(obs_space=Dict('obs': Box(-inf, inf, (145,), float32)), action_space=Box(-1.0, 1.0, (3,), float32), num_agents=4, gpu_actions=True, gpu_observations=True, action_splits=None, all_discrete=None, frameskip=1, reward_shaping_scheme=None, env_info_protocol_version=1)
[AerialGymVecEnv] GIF saving DISABLED
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 4
[AerialGymVecEnv] Detected observation space: 145D
[AerialGymVecEnv] Using GATE NAVIGATION configuration (145D = 17D basic + 64D drone VAE + 64D static camera VAE)
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles_gate', '--experiment=gif_exp9', '--train_dir=./train_dir', '--num_workers=1', '--num_envs_per_worker=1', '--env_agents=4', '--obs_key=observations', '--batch_size=128', '--num_batches_to_accumulate=2', '--rollout=32', '--learning_rate=0.0003', '--use_rnn=true', '--rnn_size=128', '--rnn_num_layers=1', '--encoder_mlp_layers', '512', '256', '128', '--gamma=0.98', '--with_wandb=true', '--wandb_project=gate_navigation_dual_camera', '--wandb_user=ziya-ruso-ucl', '--wandb_group=gate_navigation_training', '--wandb_tags', 'aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized', '--save_every_sec=120', '--save_best_every_sec=5', '--train_for_env_steps=100000000']
[33m[2025-07-03 12:00:46,988][47005] In serial mode all components run on the same process. Only use async_rl and serial mode together for debugging.
[36m[2025-07-03 12:00:46,988][47005] Starting experiment with the following configuration:
[36mhelp=False
[36malgo=APPO
[36menv=quad_with_obstacles_gate
[36mexperiment=gif_exp9
[36mtrain_dir=./train_dir
[36mrestart_behavior=resume
[36mdevice=gpu
[36mseed=None
[36mnum_policies=1
[36masync_rl=True
[36mserial_mode=True
[36mbatched_sampling=True
[36mnum_batches_to_accumulate=2
[36mworker_num_splits=1
[36mpolicy_workers_per_policy=1
[36mmax_policy_lag=1000
[36mnum_workers=1
[36mnum_envs_per_worker=1
[36mbatch_size=128
[36mnum_batches_per_epoch=4
[36mnum_epochs=4
[36mrollout=32
[36mrecurrence=32
[36mshuffle_minibatches=False
[36mgamma=0.98
[36mreward_scale=0.1
[36mreward_clip=1000.0
[36mvalue_bootstrap=True
[36mnormalize_returns=True
[36mexploration_loss_coeff=0.001
[36mvalue_loss_coeff=2.0
[36mkl_loss_coeff=0.1
[36mexploration_loss=entropy
[36mgae_lambda=0.95
[36mppo_clip_ratio=0.2
[36mppo_clip_value=1.0
[36mwith_vtrace=False
[36mvtrace_rho=1.0
[36mvtrace_c=1.0
[36moptimizer=adam
[36madam_eps=1e-06
[36madam_beta1=0.9
[36madam_beta2=0.999
[36mmax_grad_norm=1.0
[36mlearning_rate=0.0003
[36mlr_schedule=kl_adaptive_epoch
[36mlr_schedule_kl_threshold=0.016
[36mlr_adaptive_min=1e-06
[36mlr_adaptive_max=0.01
[36mobs_subtract_mean=0.0
[36mobs_scale=1.0
[36mnormalize_input=True
[36mnormalize_input_keys=None
[36mdecorrelate_experience_max_seconds=0
[36mdecorrelate_envs_on_one_worker=True
[36mactor_worker_gpus=[0]
[36mset_workers_cpu_affinity=True
[36mforce_envs_single_thread=False
[36mdefault_niceness=0
[36mlog_to_file=True
[36mexperiment_summaries_interval=10
[36mflush_summaries_interval=30
[36mstats_avg=100
[36msummaries_use_frameskip=True
[36mheartbeat_interval=20
[36mheartbeat_reporting_interval=180
[36mtrain_for_env_steps=100000000
[36mtrain_for_seconds=10000000000
[36msave_every_sec=120
[36mkeep_checkpoints=5
[36mload_checkpoint_kind=latest
[36msave_milestones_sec=-1
[36msave_best_every_sec=5
[36msave_best_metric=reward
[36msave_best_after=100000
[36mbenchmark=False
[36mencoder_mlp_layers=[512, 256, 128]
[36mencoder_conv_architecture=convnet_simple
[36mencoder_conv_mlp_layers=[]
[36muse_rnn=True
[36mrnn_size=128
[36mrnn_type=gru
[36mrnn_num_layers=1
[36mdecoder_mlp_layers=[]
[36mnonlinearity=elu
[36mpolicy_initialization=torch_default
[36mpolicy_init_gain=1.0
[36mactor_critic_share_weights=True
[36madaptive_stddev=True
[36mcontinuous_tanh_scale=0.0
[36minitial_stddev=1.0
[36muse_env_info_cache=False
[36menv_gpu_actions=True
[36menv_gpu_observations=True
[36menv_frameskip=1
[36menv_framestack=1
[36mpixel_format=CHW
[36muse_record_episode_statistics=False
[36mwith_wandb=True
[36mwandb_user=ziya-ruso-ucl
[36mwandb_project=gate_navigation_dual_camera
[36mwandb_group=gate_navigation_training
[36mwandb_job_type=SF
[36mwandb_tags=['aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized']
[36mwith_pbt=False
[36mpbt_mix_policies_in_one_env=True
[36mpbt_period_env_steps=5000000
[36mpbt_start_mutation=20000000
[36mpbt_replace_fraction=0.3
[36mpbt_mutation_rate=0.15
[36mpbt_replace_reward_gap=0.1
[36mpbt_replace_reward_gap_absolute=1e-06
[36mpbt_optimize_gamma=False
[36mpbt_target_objective=true_objective
[36mpbt_perturb_min=1.1
[36mpbt_perturb_max=1.5
[36menv_agents=4
[36mheadless=False
[36msave_gifs=False
[36mobs_key=observations
[36msubtask=None
[36mige_api_version=preview4
[36meval_stats=False
[36maction_space_dim=3
[36mcommand_line=--env=quad_with_obstacles_gate --experiment=gif_exp9 --train_dir=./train_dir --num_workers=1 --num_envs_per_worker=1 --env_agents=4 --obs_key=observations --batch_size=128 --num_batches_to_accumulate=2 --rollout=32 --learning_rate=0.0003 --use_rnn=true --rnn_size=128 --rnn_num_layers=1 --encoder_mlp_layers 512 256 128 --gamma=0.98 --with_wandb=true --wandb_project=gate_navigation_dual_camera --wandb_user=ziya-ruso-ucl --wandb_group=gate_navigation_training --wandb_tags aerial_gym gate_navigation dual_camera x500 sample_factory memory_optimized --save_every_sec=120 --save_best_every_sec=5 --train_for_env_steps=100000000 --headless=false
[36mcli_args={'env': 'quad_with_obstacles_gate', 'experiment': 'gif_exp9', 'train_dir': './train_dir', 'num_batches_to_accumulate': 2, 'num_workers': 1, 'num_envs_per_worker': 1, 'batch_size': 128, 'rollout': 32, 'gamma': 0.98, 'learning_rate': 0.0003, 'train_for_env_steps': 100000000, 'save_every_sec': 120, 'save_best_every_sec': 5, 'encoder_mlp_layers': [512, 256, 128], 'use_rnn': True, 'rnn_size': 128, 'rnn_num_layers': 1, 'with_wandb': True, 'wandb_user': 'ziya-ruso-ucl', 'wandb_project': 'gate_navigation_dual_camera', 'wandb_group': 'gate_navigation_training', 'wandb_tags': ['aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized'], 'env_agents': 4, 'headless': False, 'obs_key': 'observations'}
[36mgit_hash=a54f99d681da80aa6215176cae93d2948a30ac42
[36mgit_repo_name=git@github.com:rusoziya/aerial_gym_simulator.git
[36mwandb_unique_id=gif_exp9_20250703_120038_132269
[36m[2025-07-03 12:00:46,989][47005] Saving configuration to ./train_dir/gif_exp9/config.json...
[36m[2025-07-03 12:00:47,024][47005] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-03 12:00:47,025][47005] Rollout worker 0 uses device cuda:0
[36m[2025-07-03 12:00:47,028][47005] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 12:00:47,028][47005] InferenceWorker_p0-w0: min num requests: 1
[36m[2025-07-03 12:00:47,029][47005] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 12:00:47,029][47005] Starting seed is not provided
[36m[2025-07-03 12:00:47,029][47005] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-03 12:00:47,029][47005] Initializing actor-critic model on device cuda:0
[36m[2025-07-03 12:00:47,030][47005] RunningMeanStd input shape: (145,)
[36m[2025-07-03 12:00:47,030][47005] RunningMeanStd input shape: (1,)
[36m[2025-07-03 12:00:47,058][47005] Created Actor Critic model with architecture:
[36m[2025-07-03 12:00:47,058][47005] ActorCriticSharedWeights(
[36m  (obs_normalizer): ObservationNormalizer(
[36m    (running_mean_std): RunningMeanStdDictInPlace(
[36m      (running_mean_std): ModuleDict(
[36m        (obs): RunningMeanStdInPlace()
[36m      )
[36m    )
[36m  )
[36m  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
[36m  (encoder): MultiInputEncoder(
[36m    (encoders): ModuleDict(
[36m      (obs): MlpEncoder(
[36m        (mlp_head): RecursiveScriptModule(
[36m          original_name=Sequential
[36m          (0): RecursiveScriptModule(original_name=Linear)
[36m          (1): RecursiveScriptModule(original_name=ELU)
[36m          (2): RecursiveScriptModule(original_name=Linear)
[36m          (3): RecursiveScriptModule(original_name=ELU)
[36m          (4): RecursiveScriptModule(original_name=Linear)
[36m          (5): RecursiveScriptModule(original_name=ELU)
[36m        )
[36m      )
[36m    )
[36m  )
[36m  (core): ModelCoreRNN(
[36m    (core): GRU(128, 128)
[36m  )
[36m  (decoder): MlpDecoder(
[36m    (mlp): Identity()
[36m  )
[36m  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
[36m  (action_parameterization): ActionParameterizationDefault(
[36m    (distribution_linear): Linear(in_features=128, out_features=6, bias=True)
[36m  )
[36m)
[36m[2025-07-03 12:00:47,484][47005] Using optimizer <class 'torch.optim.adam.Adam'>
[33m[2025-07-03 12:00:47,485][47005] No checkpoints found
[36m[2025-07-03 12:00:47,485][47005] Did not load from checkpoint, starting from scratch!
[36m[2025-07-03 12:00:47,485][47005] Initialized policy 0 weights for model version 0
[36m[2025-07-03 12:00:47,485][47005] LearnerWorker_p0 finished initialization!
[36m[2025-07-03 12:00:47,485][47005] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 12:00:47,488][47005] Inference worker 0-0 is ready!
[37m[1m[2025-07-03 12:00:47,488][47005] All inference workers are ready! Signal rollout workers to start!
[36m[2025-07-03 12:00:47,488][47005] EnvRunner 0-0 uses policy 0
[37m[11323 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task_gate.py:22)
[37m[11323 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Final headless mode: False (dce_navigation_task_gate.py:29)
[37m[11323 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Found SF_ENV_AGENTS environment variable: 4 (dce_navigation_task_gate.py:39)
[37m[11323 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Detected env_agents=4 from environment - setting environment count. (dce_navigation_task_gate.py:45)
[37m[11324 ms][base_task] - INFO : Setting seed: 3326819470 (base_task.py:38)
[37m[11324 ms][navigation_task_gate] - INFO : Building environment for gate navigation task. (navigation_task_gate.py:48)
[37m[11324 ms][navigation_task_gate] - INFO : Sim Name: base_sim, Env Name: gate_env, Robot Name: lmf2, Controller Name: lmf2_position_control (navigation_task_gate.py:49)
[37m[11324 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[11324 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[11324 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[11324 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[11324 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[11324 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[11325 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.64 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 7.80 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 11.27 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.68 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] GIF saving DISABLED
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 4
[AerialGymVecEnv] Detected observation space: 145D
[AerialGymVecEnv] Using GATE NAVIGATION configuration (145D = 17D basic + 64D drone VAE + 64D static camera VAE)
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[DEBUG] Set robot spawn positions: tensor([[ 0.4834, -5.1524,  3.3281],
        [ 4.2192, -2.5558,  3.2335],
        [ 4.7097, -5.2352,  1.3604],
        [ 0.9410, -3.7480,  2.8500]], device='cuda:0')
[37m[11325 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[11325 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[11325 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[11325 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[11325 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[11325 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[37m[12319 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[12319 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[12521 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[12521 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[12521 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[12521 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[12521 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[12521 ms][BaseRobot] - INFO : Initializing controller lmf2_position_control (base_robot.py:29)
[33m[12521 ms][base_multirotor] - WARNING : Creating 4 multirotors. (base_multirotor.py:32)
[37m[12522 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[12522 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[12522 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12522 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12526 ms][asset_loader] - INFO : Loading asset: tree_84.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12536 ms][asset_loader] - INFO : Loading asset: tree_68.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12544 ms][asset_loader] - INFO : Loading asset: tree_19.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12554 ms][asset_loader] - INFO : Loading asset: tree_12.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12563 ms][asset_loader] - INFO : Loading asset: tree_17.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12572 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12573 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12574 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12575 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12576 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12577 ms][asset_loader] - INFO : Loading asset: tree_82.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12588 ms][asset_loader] - INFO : Loading asset: tree_41.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12597 ms][asset_loader] - INFO : Loading asset: tree_76.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12623 ms][asset_loader] - INFO : Loading asset: tree_40.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12635 ms][asset_loader] - INFO : Loading asset: tree_77.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12644 ms][asset_loader] - INFO : Loading asset: tree_95.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12653 ms][asset_loader] - INFO : Loading asset: tree_20.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12662 ms][asset_loader] - INFO : Loading asset: tree_73.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12670 ms][asset_loader] - INFO : Loading asset: tree_5.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12679 ms][asset_loader] - INFO : Loading asset: tree_13.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12688 ms][asset_loader] - INFO : Loading asset: tree_54.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12697 ms][asset_loader] - INFO : Loading asset: tree_93.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12706 ms][env_manager] - INFO : Creating ground plane in Isaac Gym Simulation. (env_manager.py:172)
[37m[12712 ms][env_manager] - INFO : [DONE] Creating ground plane in Isaac Gym Simulation (env_manager.py:174)
[37m[12712 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[12728 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[12728 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[12728 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[12758 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[12766 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[12766 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[12863 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[12870 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[12968 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 11 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[13165 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[13166 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
[37m[13782 ms][navigation_task_gate] - INFO : Setting up static camera for gate navigation... (navigation_task_gate.py:483)
[37m[13782 ms][navigation_task_gate] - INFO : Static camera properties: 480x270, FOV: 87.0° (navigation_task_gate.py:502)
[37m[13799 ms][navigation_task_gate] - INFO : ✓ Static camera setup complete (navigation_task_gate.py:519)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[DEBUG] Set robot spawn positions: tensor([[ 3.8410, -5.0364,  2.1285],
        [-4.7938, -3.4227,  1.4814],
        [ 4.2267, -2.8755,  3.4742],
        [ 3.0828, -3.7723,  1.9844]], device='cuda:0')
[37m[14977 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-3.0000, -4.9311,  1.3615]], device='cuda:0')
[36m[2025-07-03 12:00:52,590][47005] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 12:00:52,590][47005] Avg episode reward: [(0, '-50.000')]
[37m[17402 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:00:55,764][47005] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 3.8. Samples: 12. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 12:00:55,764][47005] Avg episode reward: [(0, '-50.000')]
[DEBUG] Set robot spawn positions: tensor([[ 2.7591, -5.0511,  1.4048]], device='cuda:0')
[37m[20943 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.0914, -4.2160,  2.7124]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-0.0330, -3.5343,  3.3388]], device='cuda:0')
[37m[22474 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/nn/modules/module.py:1194: UserWarning: operator() profile_node %104 : int[] = prim::profile_ivalue(%102)
 does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)
  return forward_call(*input, **kwargs)
[37m[23352 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 4.7639, -5.0482,  2.7534]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-1.1195, -5.1816,  2.8359]], device='cuda:0')
[37m[24517 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:01:00,771][47005] Fps is (10 sec: 62.6, 60 sec: 62.6, 300 sec: 62.6). Total num frames: 512. Throughput: 0: 63.6. Samples: 520. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 12:01:00,771][47005] Avg episode reward: [(0, '-112.441')]
[37m[24622 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.4936, -4.7912,  2.6090]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 2.1848, -4.6847,  3.2389]], device='cuda:0')
[37m[26549 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[27856 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-3.7709, -2.8451,  3.1092]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 1.9947, -5.1168,  3.3345]], device='cuda:0')
[37m[29015 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:01:05,771][47005] Fps is (10 sec: 102.3, 60 sec: 77.7, 300 sec: 77.7). Total num frames: 1024. Throughput: 0: 82.2. Samples: 1084. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 12:01:05,771][47005] Avg episode reward: [(0, '-140.811')]
[37m[29770 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.9679, -4.8958,  2.9571]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.7610, -4.3843,  3.4792]], device='cuda:0')
[37m[30867 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[1m[2025-07-03 12:01:07,114][47005] Heartbeat connected on Batcher_0
[37m[1m[2025-07-03 12:01:07,115][47005] Heartbeat connected on LearnerWorker_p0
[37m[1m[2025-07-03 12:01:07,115][47005] Heartbeat connected on InferenceWorker_p0-w0
[37m[1m[2025-07-03 12:01:07,115][47005] Heartbeat connected on RolloutWorker_w0
[37m[31394 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 1.1027, -3.6976,  2.7404]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 2.3104, -3.5556,  1.6377]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 4.6226, -4.3990,  2.1025]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.6464, -3.4472,  2.0334]], device='cuda:0')
[36m[2025-07-03 12:01:10,778][47005] Fps is (10 sec: 102.3, 60 sec: 84.5, 300 sec: 84.5). Total num frames: 1536. Throughput: 0: 76.8. Samples: 1396. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:01:10,778][47005] Avg episode reward: [(0, '-146.258')]
[37m[34889 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[35090 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[35597 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[35832 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-2.1887, -4.3143,  1.4088],
        [-0.5409, -2.8813,  2.1082]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 2.4466, -4.0053,  3.5167]], device='cuda:0')
[37m[38944 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:01:15,775][47005] Fps is (10 sec: 102.4, 60 sec: 88.3, 300 sec: 88.3). Total num frames: 2048. Throughput: 0: 87.0. Samples: 2016. Policy #0 lag: (min: 4.0, avg: 4.5, max: 20.0)
[36m[2025-07-03 12:01:15,775][47005] Avg episode reward: [(0, '-163.719')]
[37m[39739 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 4.3054, -3.7024,  1.2447]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-0.6990, -3.8942,  2.3770]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.6588, -4.0039,  1.3623]], device='cuda:0')
[37m[41872 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[41922 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[42152 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.1829, -3.5737,  2.1072]], device='cuda:0')
[37m[43720 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.6429, -5.1100,  3.2694]], device='cuda:0')
[36m[2025-07-03 12:01:20,768][47005] Fps is (10 sec: 102.5, 60 sec: 90.9, 300 sec: 90.9). Total num frames: 2560. Throughput: 0: 92.6. Samples: 2608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:01:20,768][47005] Avg episode reward: [(0, '-170.053')]
[37m[45357 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 2.9896, -5.1991,  2.3028]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-1.7232, -2.8768,  1.6443]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.8216, -3.6497,  2.5143]], device='cuda:0')
[37m[46599 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[47087 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[48370 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:01:25,778][47005] Fps is (10 sec: 102.4, 60 sec: 92.6, 300 sec: 92.6). Total num frames: 3072. Throughput: 0: 88.1. Samples: 2924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:01:25,779][47005] Avg episode reward: [(0, '-175.240')]
[DEBUG] Set robot spawn positions: tensor([[ 0.3676, -5.3611,  2.2584]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 2.1647, -2.8156,  2.6273]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 1.5357, -4.8045,  2.7416]], device='cuda:0')
[37m[50639 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[51810 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[52081 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.1342, -3.3885,  3.0180]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.6935, -3.8824,  3.2947]], device='cuda:0')
[37m[53561 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[54113 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.3333, -3.0411,  3.5308]], device='cuda:0')
[36m[2025-07-03 12:01:30,781][47005] Fps is (10 sec: 102.3, 60 sec: 93.8, 300 sec: 93.8). Total num frames: 3584. Throughput: 0: 92.6. Samples: 3536. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:01:30,781][47005] Avg episode reward: [(0, '-182.186')]
[37m[55585 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.6688, -4.2141,  2.5058]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.7636, -4.2948,  1.2173]], device='cuda:0')
[37m[56648 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[56809 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 1.3348, -4.3997,  1.2803]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 3.8590, -5.2225,  2.4279]], device='cuda:0')
[37m[59089 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[59491 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:01:35,762][47005] Fps is (10 sec: 102.6, 60 sec: 94.9, 300 sec: 94.9). Total num frames: 4096. Throughput: 0: 96.0. Samples: 4144. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 12:01:35,762][47005] Avg episode reward: [(0, '-183.420')]
[DEBUG] Set robot spawn positions: tensor([[-2.4781, -3.0525,  2.0351]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 3.0139, -4.1096,  2.2071]], device='cuda:0')
[37m[61392 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[61749 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.9132, -4.4753,  1.7632]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 4.2520, -3.1922,  3.5604]], device='cuda:0')
[37m[64022 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[64190 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:01:40,786][47005] Fps is (10 sec: 102.3, 60 sec: 95.6, 300 sec: 95.6). Total num frames: 4608. Throughput: 0: 98.7. Samples: 4456. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:01:40,786][47005] Avg episode reward: [(0, '-188.462')]
[DEBUG] Set robot spawn positions: tensor([[-0.0638, -4.4487,  1.3781]], device='cuda:0')
[37m[66537 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-0.6413, -2.9352,  3.1884]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.9105, -4.7959,  1.2025]], device='cuda:0')
[37m[67632 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[68145 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-2.4433, -2.9392,  1.9560]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-3.6914, -4.3111,  3.3273]], device='cuda:0')
[36m[2025-07-03 12:01:45,781][47005] Fps is (10 sec: 102.2, 60 sec: 96.3, 300 sec: 96.3). Total num frames: 5120. Throughput: 0: 101.1. Samples: 5072. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-03 12:01:45,782][47005] Avg episode reward: [(0, '-188.706')]
[37m[70080 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[70129 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.1517, -3.5546,  1.6745]], device='cuda:0')
[37m[70761 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[72239 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[72529 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.3779, -3.7112,  1.8865]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-1.3130, -4.5371,  2.7946]], device='cuda:0')
[37m[74385 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:01:50,782][47005] Fps is (10 sec: 102.4, 60 sec: 96.8, 300 sec: 96.8). Total num frames: 5632. Throughput: 0: 102.3. Samples: 5688. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 12:01:50,782][47005] Avg episode reward: [(0, '-187.142')]
[DEBUG] Set robot spawn positions: tensor([[-1.3543, -3.4472,  3.5343]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.6304, -3.0230,  2.9550]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 1.1400, -5.3544,  3.5379]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-3.2333, -4.0256,  1.9984]], device='cuda:0')
[37m[76827 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[77129 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[77874 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[78525 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 4.4682, -4.5645,  3.5870]], device='cuda:0')
[36m[2025-07-03 12:01:55,748][47005] Fps is (10 sec: 102.7, 60 sec: 102.4, 300 sec: 97.3). Total num frames: 6144. Throughput: 0: 102.4. Samples: 6000. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 12:01:55,748][47005] Avg episode reward: [(0, '-188.298')]
[DEBUG] Set robot spawn positions: tensor([[ 4.0521, -3.6028,  1.9291]], device='cuda:0')
[37m[81276 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[82277 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 2.9994, -4.1140,  2.8701]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.7957, -4.1308,  2.3110]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.8305, -5.1556,  3.4003]], device='cuda:0')
[37m[82846 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[82895 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:02:00,754][47005] Fps is (10 sec: 102.7, 60 sec: 102.4, 300 sec: 97.6). Total num frames: 6656. Throughput: 0: 102.2. Samples: 6612. Policy #0 lag: (min: 4.0, avg: 4.5, max: 20.0)
[36m[2025-07-03 12:02:00,754][47005] Avg episode reward: [(0, '-189.031')]
[DEBUG] Set robot spawn positions: tensor([[-2.6247, -4.7602,  3.0844]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.6549, -3.6296,  2.5446]], device='cuda:0')
[37m[85893 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[86129 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.7353, -3.2585,  3.2846]], device='cuda:0')
[37m[87857 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.7789, -3.6741,  3.4674]], device='cuda:0')
[37m[89153 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:02:05,774][47005] Fps is (10 sec: 102.1, 60 sec: 102.4, 300 sec: 97.9). Total num frames: 7168. Throughput: 0: 102.5. Samples: 7220. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:02:05,775][47005] Avg episode reward: [(0, '-186.168')]
[DEBUG] Set robot spawn positions: tensor([[ 4.4997, -4.4060,  3.5496]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.7106, -3.7618,  2.0390]], device='cuda:0')
[37m[90945 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[91149 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.8373, -3.2771,  2.3467]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.3206, -4.9919,  3.1589]], device='cuda:0')
[37m[93658 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[94148 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[94476 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:02:10,751][47005] Fps is (10 sec: 102.4, 60 sec: 102.4, 300 sec: 98.3). Total num frames: 7680. Throughput: 0: 102.5. Samples: 7532. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:02:10,751][47005] Avg episode reward: [(0, '-187.475')]
[DEBUG] Set robot spawn positions: tensor([[ 2.2690, -5.1009,  2.9396]], device='cuda:0')
[37m[96751 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.3823, -3.9877,  3.4978]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-1.5133, -4.5701,  1.3472]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.1358, -4.0483,  2.1966]], device='cuda:0')
[37m[98101 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[98152 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.3067, -4.2038,  3.2369]], device='cuda:0')
[37m[98841 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:02:15,769][47005] Fps is (10 sec: 102.4, 60 sec: 102.4, 300 sec: 98.5). Total num frames: 8192. Throughput: 0: 102.2. Samples: 8136. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 12:02:15,770][47005] Avg episode reward: [(0, '-185.844')]
[DEBUG] Set robot spawn positions: tensor([[-1.4967, -2.8611,  3.2320]], device='cuda:0')
[37m[100721 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.2089, -3.7695,  3.5523]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.3519, -3.5801,  1.3483]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 2.0850, -3.1994,  3.4254]], device='cuda:0')
[37m[102391 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[102440 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[102980 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.6690, -3.9461,  2.1685]], device='cuda:0')
[36m[2025-07-03 12:02:20,752][47005] Fps is (10 sec: 102.4, 60 sec: 102.4, 300 sec: 98.7). Total num frames: 8704. Throughput: 0: 102.2. Samples: 8744. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:02:20,752][47005] Avg episode reward: [(0, '-184.386')]
[37m[105504 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-0.6435, -5.1240,  2.2303]], device='cuda:0')
[37m[106605 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.2062, -2.4254,  2.7970]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.2197, -4.7866,  1.8690]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-0.9486, -2.4536,  2.5030]], device='cuda:0')
[37m[108789 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[108876 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[109475 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:02:25,754][47005] Fps is (10 sec: 102.6, 60 sec: 102.4, 300 sec: 98.9). Total num frames: 9216. Throughput: 0: 102.2. Samples: 9052. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:02:25,754][47005] Avg episode reward: [(0, '-185.929')]
[DEBUG] Set robot spawn positions: tensor([[ 3.1373, -3.4670,  2.7899]], device='cuda:0')
[37m[111764 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.2246, -5.0525,  2.5989]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 4.2634, -4.9842,  3.1955]], device='cuda:0')
[37m[112831 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[113381 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.0773, -4.1072,  3.1478]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 1.7922, -5.1405,  1.7521]], device='cuda:0')
[37m[114504 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:02:30,780][47005] Fps is (10 sec: 102.1, 60 sec: 102.4, 300 sec: 99.1). Total num frames: 9728. Throughput: 0: 102.4. Samples: 9680. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-03 12:02:30,780][47005] Avg episode reward: [(0, '-185.989')]
[37m[115940 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-3.8862, -2.9344,  2.7705]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 1.6797, -3.3536,  1.8873]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 2.7221, -4.8632,  1.8650]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-3.2044, -5.0280,  2.3716]], device='cuda:0')
[37m[116543 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[116705 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[116756 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[118036 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.3596, -4.6548,  3.0681]], device='cuda:0')
[36m[2025-07-03 12:02:35,751][47005] Fps is (10 sec: 102.4, 60 sec: 102.4, 300 sec: 99.3). Total num frames: 10240. Throughput: 0: 102.4. Samples: 10292. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 12:02:35,751][47005] Avg episode reward: [(0, '-182.553')]
[37m[119755 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.0062, -3.3922,  1.6960]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.9905, -2.5368,  2.4919]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 2.2753, -2.4194,  2.3156]], device='cuda:0')
[37m[121514 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[122152 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[122203 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-2.2176, -2.6677,  1.9967]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-0.4080, -4.6124,  1.5687]], device='cuda:0')
[37m[123301 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[123650 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 1.6294, -3.2198,  1.6169]], device='cuda:0')
[36m[2025-07-03 12:02:40,766][47005] Fps is (10 sec: 102.5, 60 sec: 102.4, 300 sec: 99.4). Total num frames: 10752. Throughput: 0: 102.3. Samples: 10604. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:02:40,766][47005] Avg episode reward: [(0, '-180.380')]
[37m[1m[2025-07-03 12:02:40,804][47005] Saving ./train_dir/gif_exp9/checkpoint_p0/checkpoint_000000336_10752.pth...
[37m[126080 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 4.1026, -5.1365,  2.2142]], device='cuda:0')
[37m[127364 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.4418, -3.8809,  1.3973]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 4.2620, -3.5971,  2.0233]], device='cuda:0')
[37m[129206 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:02:45,751][47005] Fps is (10 sec: 102.4, 60 sec: 102.5, 300 sec: 99.5). Total num frames: 11264. Throughput: 0: 102.5. Samples: 11224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:02:45,751][47005] Avg episode reward: [(0, '-182.464')]
[37m[130407 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.3575, -4.5514,  1.7714]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-3.6260, -2.9063,  1.9360]], device='cuda:0')
[37m[131026 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[132219 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 1.0265, -4.7773,  2.8986]], device='cuda:0')
[37m[133797 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.8265, -5.2583,  3.3854]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 1.3087, -3.6820,  2.4056]], device='cuda:0')
[36m[2025-07-03 12:02:50,771][47005] Fps is (10 sec: 102.3, 60 sec: 102.4, 300 sec: 99.6). Total num frames: 11776. Throughput: 0: 102.5. Samples: 11832. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 12:02:50,771][47005] Avg episode reward: [(0, '-184.849')]
[37m[135066 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[135559 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.0610, -3.9628,  1.2612]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.6932, -5.3793,  2.0094]], device='cuda:0')
[37m[136902 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[136989 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 1.2265, -4.8445,  2.1142]], device='cuda:0')
[37m[139593 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:02:55,792][47005] Fps is (10 sec: 102.0, 60 sec: 102.3, 300 sec: 99.7). Total num frames: 12288. Throughput: 0: 102.5. Samples: 12148. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:02:55,792][47005] Avg episode reward: [(0, '-181.811')]
[DEBUG] Set robot spawn positions: tensor([[-4.2817, -2.9167,  2.8044]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-0.4388, -4.6090,  2.5911]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-0.2857, -5.3481,  1.3911]], device='cuda:0')
[37m[142037 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[142127 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[142333 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.7600, -4.0734,  2.3085]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.1842, -4.5751,  3.4276]], device='cuda:0')
[37m[144284 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[144480 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.3923, -4.6639,  1.8931]], device='cuda:0')
[36m[2025-07-03 12:03:00,755][47005] Fps is (10 sec: 102.6, 60 sec: 102.4, 300 sec: 99.9). Total num frames: 12800. Throughput: 0: 102.8. Samples: 12760. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-03 12:03:00,755][47005] Avg episode reward: [(0, '-181.937')]
[37m[144606 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-0.0762, -4.5791,  2.6551]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-3.9433, -3.3049,  2.6041]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.9344, -3.3480,  3.4212]], device='cuda:0')
[37m[147029 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[147637 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[147885 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.0507, -5.2751,  3.1936]], device='cuda:0')
[36m[2025-07-03 12:03:05,761][47005] Fps is (10 sec: 102.7, 60 sec: 102.4, 300 sec: 100.0). Total num frames: 13312. Throughput: 0: 102.7. Samples: 13368. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[36m[2025-07-03 12:03:05,761][47005] Avg episode reward: [(0, '-178.473')]
[37m[150294 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.2426, -4.2340,  1.7558]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 4.5902, -4.0370,  3.1580]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 4.7037, -4.5493,  2.5972]], device='cuda:0')
[37m[152671 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[153072 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[153158 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 1.1707, -4.0827,  1.3626]], device='cuda:0')
[36m[2025-07-03 12:03:10,768][47005] Fps is (10 sec: 102.3, 60 sec: 102.4, 300 sec: 100.0). Total num frames: 13824. Throughput: 0: 102.8. Samples: 13680. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 12:03:10,768][47005] Avg episode reward: [(0, '-177.889')]
[37m[155691 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 4.4614, -3.6130,  2.3341]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 1.9261, -4.9885,  1.8776]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 3.6653, -4.1592,  3.0945]], device='cuda:0')
[37m[157330 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[157934 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[158218 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 4.0897, -3.0587,  2.0361]], device='cuda:0')
[36m[2025-07-03 12:03:15,779][47005] Fps is (10 sec: 102.2, 60 sec: 102.4, 300 sec: 100.1). Total num frames: 14336. Throughput: 0: 102.4. Samples: 14288. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 12:03:15,780][47005] Avg episode reward: [(0, '-177.731')]
[37m[159862 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.7888, -3.5613,  3.3938]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 4.5516, -5.3652,  1.6336]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.3530, -3.3710,  2.8861]], device='cuda:0')
[37m[162978 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[163064 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[164100 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:03:20,765][47005] Fps is (10 sec: 102.4, 60 sec: 102.4, 300 sec: 100.2). Total num frames: 14848. Throughput: 0: 102.1. Samples: 14888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:03:20,765][47005] Avg episode reward: [(0, '-177.036')]
[DEBUG] Set robot spawn positions: tensor([[-2.4697, -3.9422,  2.4202]], device='cuda:0')
[37m[165313 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.0275, -5.3955,  2.8233]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 4.4348, -4.6100,  1.8624]], device='cuda:0')
[37m[166985 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[167674 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.7976, -5.1541,  3.2059]], device='cuda:0')
[37m[169550 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:03:25,751][47005] Fps is (10 sec: 102.7, 60 sec: 102.4, 300 sec: 100.3). Total num frames: 15360. Throughput: 0: 102.0. Samples: 15192. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 12:03:25,751][47005] Avg episode reward: [(0, '-175.413')]
[DEBUG] Set robot spawn positions: tensor([[-2.6390, -3.6262,  1.3089]], device='cuda:0')
[37m[172253 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.5364, -2.9446,  1.4670]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.4626, -5.1142,  2.6144]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.2000, -3.6391,  2.9274]], device='cuda:0')
[37m[173212 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[173381 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[174379 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:03:30,769][47005] Fps is (10 sec: 102.4, 60 sec: 102.4, 300 sec: 100.3). Total num frames: 15872. Throughput: 0: 101.8. Samples: 15808. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 12:03:30,769][47005] Avg episode reward: [(0, '-172.045')]
[DEBUG] Set robot spawn positions: tensor([[ 1.3539, -2.7167,  3.5290]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-0.5225, -4.3583,  2.6604]], device='cuda:0')
[37m[177644 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[178248 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-3.7556, -3.6183,  2.5574]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-0.7785, -4.7662,  2.6194]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.3526, -3.8556,  2.6908]], device='cuda:0')
[37m[179376 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:03:35,763][47005] Fps is (10 sec: 102.3, 60 sec: 102.4, 300 sec: 100.4). Total num frames: 16384. Throughput: 0: 101.9. Samples: 16416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:03:35,763][47005] Avg episode reward: [(0, '-168.901')]
[37m[179886 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[180086 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.7672, -5.3273,  2.3503]], device='cuda:0')
[37m[182375 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-2.1947, -3.8609,  1.9448]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 3.7547, -5.0768,  2.6863]], device='cuda:0')
[37m[183007 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[184003 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:03:40,785][47005] Fps is (10 sec: 102.2, 60 sec: 102.4, 300 sec: 100.5). Total num frames: 16896. Throughput: 0: 101.8. Samples: 16728. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 12:03:40,786][47005] Avg episode reward: [(0, '-165.675')]
[DEBUG] Set robot spawn positions: tensor([[ 3.7224, -4.0390,  1.8946]], device='cuda:0')
[37m[186133 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 1.9051, -4.8339,  2.4941]], device='cuda:0')
[37m[187660 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.2858, -5.3642,  2.4410]], device='cuda:0')
[37m[188767 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:03:45,746][47005] Fps is (10 sec: 102.6, 60 sec: 102.4, 300 sec: 100.5). Total num frames: 17408. Throughput: 0: 101.8. Samples: 17340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:03:45,747][47005] Avg episode reward: [(0, '-166.684')]
[DEBUG] Set robot spawn positions: tensor([[ 1.2795, -2.7721,  1.5349],
        [ 0.8900, -2.6574,  2.0784]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.5108, -2.5961,  1.3039]], device='cuda:0')
[37m[191119 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[192485 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.7207, -4.6862,  3.2063]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.3326, -5.3984,  2.6362]], device='cuda:0')
[37m[194400 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[194564 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:03:50,765][47005] Fps is (10 sec: 102.6, 60 sec: 102.4, 300 sec: 100.6). Total num frames: 17920. Throughput: 0: 101.9. Samples: 17956. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 12:03:50,765][47005] Avg episode reward: [(0, '-166.999')]
[DEBUG] Set robot spawn positions: tensor([[-4.0374, -4.8283,  1.4304]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.6517, -5.3311,  1.3338]], device='cuda:0')
[37m[195834 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[196237 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 2.7168, -5.1265,  2.0830]], device='cuda:0')
[37m[198270 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:03:55,766][47005] Fps is (10 sec: 102.2, 60 sec: 102.4, 300 sec: 100.6). Total num frames: 18432. Throughput: 0: 102.0. Samples: 18268. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:03:55,766][47005] Avg episode reward: [(0, '-164.856')]
[DEBUG] Set robot spawn positions: tensor([[ 3.8854, -4.9048,  3.3978]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.2627, -5.2247,  2.5526]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.1106, -2.7491,  2.2680]], device='cuda:0')
[37m[201686 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[201995 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[202235 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.4310, -4.1209,  2.9360]], device='cuda:0')
[37m[204122 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:04:00,768][47005] Fps is (10 sec: 102.4, 60 sec: 102.4, 300 sec: 100.7). Total num frames: 18944. Throughput: 0: 102.2. Samples: 18884. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:04:00,768][47005] Avg episode reward: [(0, '-158.905')]
[DEBUG] Set robot spawn positions: tensor([[ 0.3465, -4.9236,  1.5541]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-1.6588, -3.7250,  1.4361]], device='cuda:0')
[37m[205749 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[206229 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 4.6264, -3.6663,  2.3111]], device='cuda:0')
[37m[208637 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:04:05,775][47005] Fps is (10 sec: 102.3, 60 sec: 102.4, 300 sec: 100.7). Total num frames: 19456. Throughput: 0: 102.0. Samples: 19480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:04:05,775][47005] Avg episode reward: [(0, '-156.155')]
[DEBUG] Set robot spawn positions: tensor([[ 4.0611, -3.1842,  3.4872]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.6769, -2.7367,  2.9854]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 3.8927, -3.9197,  3.1910]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-0.4381, -5.2554,  2.7119]], device='cuda:0')
[37m[211009 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[211133 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[211297 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[211797 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.1868, -3.1074,  3.0633]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.5048, -5.1223,  1.7378]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.2536, -2.4489,  1.7956]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.1198, -4.0848,  1.9844]], device='cuda:0')
[37m[213291 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[213612 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[213663 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[213712 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:04:10,753][47005] Fps is (10 sec: 102.6, 60 sec: 102.4, 300 sec: 100.8). Total num frames: 19968. Throughput: 0: 102.2. Samples: 19792. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:04:10,754][47005] Avg episode reward: [(0, '-147.289')]
[DEBUG] Set robot spawn positions: tensor([[ 1.6020, -5.0242,  2.3106]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 1.2045, -4.1482,  2.1224]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-3.1588, -4.6802,  1.4136]], device='cuda:0')
[37m[216056 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[216297 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[216538 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 3.7456, -4.9571,  1.6991]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 1.0223, -2.9163,  2.6397]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 2.2993, -3.3959,  1.5668]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-0.9803, -3.9007,  2.5966]], device='cuda:0')
[37m[219287 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[219410 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:04:15,759][47005] Fps is (10 sec: 102.6, 60 sec: 102.4, 300 sec: 100.8). Total num frames: 20480. Throughput: 0: 102.2. Samples: 20404. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 12:04:15,760][47005] Avg episode reward: [(0, '-145.445')]
[37m[219681 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[220245 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-1.5521, -3.7232,  3.0816]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.9616, -4.2471,  3.5953]], device='cuda:0')
[37m[222536 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[222842 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.4557, -3.0230,  3.3043]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 3.5969, -3.5081,  3.2418]], device='cuda:0')
[37m[223223 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:04:20,765][47005] Fps is (10 sec: 102.3, 60 sec: 102.4, 300 sec: 100.8). Total num frames: 20992. Throughput: 0: 102.3. Samples: 21020. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:04:20,765][47005] Avg episode reward: [(0, '-139.728')]
[37m[224742 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.8816, -4.9179,  1.5804]], device='cuda:0')
[37m[227769 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 1.0808, -4.5889,  1.3041]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.0867, -2.4632,  2.8016]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-3.3452, -5.3526,  2.3913]], device='cuda:0')
[36m[2025-07-03 12:04:25,755][47005] Fps is (10 sec: 102.4, 60 sec: 102.4, 300 sec: 100.9). Total num frames: 21504. Throughput: 0: 102.3. Samples: 21328. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 12:04:25,755][47005] Avg episode reward: [(0, '-138.574')]
[37m[229621 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[230012 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[230402 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.4423, -3.6622,  2.0255]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 2.5394, -3.7658,  1.7464]], device='cuda:0')
[37m[232466 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[232817 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 2.1316, -5.1181,  2.0877]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[ 0.1914, -3.1072,  1.9401]], device='cuda:0')
[37m[234301 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[234465 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:04:30,779][47005] Fps is (10 sec: 102.3, 60 sec: 102.4, 300 sec: 100.9). Total num frames: 22016. Throughput: 0: 102.2. Samples: 21944. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-03 12:04:30,779][47005] Avg episode reward: [(0, '-139.262')]
[DEBUG] Set robot spawn positions: tensor([[ 0.6129, -2.4015,  1.8134]], device='cuda:0')
[37m[236672 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[ 0.1568, -3.8532,  3.0557]], device='cuda:0')
[36m[2025-07-03 12:04:35,781][47005] Fps is (10 sec: 102.1, 60 sec: 102.4, 300 sec: 100.9). Total num frames: 22528. Throughput: 0: 101.8. Samples: 22540. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-03 12:04:35,782][47005] Avg episode reward: [(0, '-138.614')]
[37m[239822 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-4.7048, -4.7783,  3.4548]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-4.5882, -2.6715,  2.5423]], device='cuda:0')
[DEBUG] Set robot spawn positions: tensor([[-2.8306, -2.4074,  1.4912]], device='cuda:0')
[37m[241036 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[241330 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[242676 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[DEBUG] Set robot spawn positions: tensor([[-2.4299, -3.5919,  2.1134]], device='cuda:0')
[37m[244414 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 12:04:40,802][47005] Fps is (10 sec: 102.2, 60 sec: 102.4, 300 sec: 101.0). Total num frames: 23040. Throughput: 0: 101.3. Samples: 22832. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 12:04:40,803][47005] Avg episode reward: [(0, '-136.236')]
[37m[1m[2025-07-03 12:04:40,853][47005] Saving ./train_dir/gif_exp9/checkpoint_p0/checkpoint_000000720_23040.pth...
[37m[1m[2025-07-03 12:04:41,228][47005] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 47005], exiting...
[37m[1m[2025-07-03 12:04:41,228][47005] Runner profile tree view:
[37m[1mmain_loop: 234.1992
[37m[1m[2025-07-03 12:04:41,228][47005] Collected {0: 23040}, FPS: 98.4