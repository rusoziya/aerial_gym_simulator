Importing module 'gym_38' (/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
[36m[2025-07-04 07:31:13,595][06649] Queried available GPUs: 0
[37m[1m[2025-07-04 07:31:13,596][06649] Environment var CUDA_VISIBLE_DEVICES is 0
PyTorch version 1.13.1
Device count 1
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
Warp 1.0.0-beta.5 initialized:
   CUDA Toolkit: 11.5, Driver: 12.4
   Devices:
     "cpu"    | x86_64
     "cuda:0" | NVIDIA GeForce RTX 4080 Laptop GPU (sm_89)
   Kernel cache: /home/ziyar/.cache/warp/1.0.0-beta.5
[SUBPROCESS] FORCED headless mode for all Sample Factory training: headless=True
[SUBPROCESS] This prevents Isaac Gym viewer conflicts across all processes
[SUBPROCESS] Task action_space_dim: 4
[SUBPROCESS] Target Sample Factory action space: 4D
[SUBPROCESS] Setting num_envs to 16 based on env_agents=16
[SUBPROCESS] Set SF_ENV_AGENTS=16 environment variable
[SUBPROCESS] Config batch_size: 2048
[SUBPROCESS] Using STANDARD CONFIG (16 environments)
Registered quad_with_obstacles_gate and dce_navigation_task_gate in subprocess
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles_gate', '--experiment=gate_config_3_static_cam_fixed_1', '--train_dir=./train_dir', '--num_workers=1', '--num_envs_per_worker=1', '--env_agents=16', '--obs_key=observations', '--batch_size=2048', '--num_batches_to_accumulate=2', '--num_batches_per_epoch=8', '--num_epochs=4', '--rollout=32', '--learning_rate=0.0003', '--use_rnn=true', '--rnn_size=64', '--rnn_num_layers=1', '--encoder_mlp_layers', '512', '256', '64', '--gamma=0.98', '--reward_scale=0.1', '--max_grad_norm=1.0', '--async_rl=true', '--normalize_input=true', '--use_env_info_cache=false', '--with_wandb=true', '--wandb_project=gate_navigation_dual_camera', '--wandb_user=ziya-ruso-ucl', '--wandb_group=gate_navigation_training', '--wandb_tags', 'aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized', '--save_every_sec=120', '--save_best_every_sec=5', '--train_for_env_steps=100000000', '--save_gifs=true']
Not connected to PVD
+++ Using GPU PhysX
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/utils/cpp_extension.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging  # type: ignore[attr-defined]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Using /home/ziyar/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
Emitting ninja build file /home/ziyar/.cache/torch_extensions/py38_cu117/gymtorch/build.ninja...
Building extension module gymtorch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module gymtorch...
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/graph.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping, Set, Iterable
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/readwrite/graphml.py:346: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  (np.int, "int"), (np.int8, "int"),
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/torch_utils.py:135: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  def get_axis_params(value, axis_idx, x_value=0., dtype=np.float, n_dims=3):
[37m[1837 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task_gate.py:22)
[37m[1837 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Final headless mode: False (dce_navigation_task_gate.py:29)
[37m[1837 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Found SF_ENV_AGENTS environment variable: 16 (dce_navigation_task_gate.py:39)
[37m[1837 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Detected env_agents=16 from environment - setting environment count. (dce_navigation_task_gate.py:45)
[37m[1837 ms][base_task] - INFO : Setting seed: 147005692 (base_task.py:38)
[37m[1848 ms][navigation_task_gate] - INFO : Building environment for gate navigation task. (navigation_task_gate.py:48)
[37m[1848 ms][navigation_task_gate] - INFO : Sim Name: base_sim, Env Name: gate_env, Robot Name: lmf2, Controller Name: lmf2_position_control (navigation_task_gate.py:49)
[37m[1848 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[1848 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[1848 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[1848 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[1848 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[1848 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[1850 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[1850 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[1850 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[1850 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[1850 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[1850 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[1850 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
[37m[2934 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[2934 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[3181 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[3181 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[3181 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[3181 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[3181 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[3181 ms][BaseRobot] - INFO : Initializing controller lmf2_position_control (base_robot.py:29)
[33m[3181 ms][base_multirotor] - WARNING : Creating 16 multirotors. (base_multirotor.py:32)
[37m[3181 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[3181 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[3181 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3182 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3188 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3189 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3189 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3190 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3191 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3192 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3193 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3194 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3195 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3196 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3198 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[3741 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[3741 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[3741 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[3768 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[3777 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[3777 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[3856 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[3857 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[3897 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 10 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[4293 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[4294 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
creating render graph
Module warp.utils load on device 'cuda:0' took 2.46 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 8.43 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 12.54 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 6.46 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] GIF saving ENABLED for dual cameras (drone + static)
[AerialGymVecEnv] Forced action space shape: (4,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 16
[AerialGymVecEnv] Detected observation space: 145D
[AerialGymVecEnv] Using GATE NAVIGATION configuration (145D = 17D basic + 64D drone VAE + 64D static camera VAE)
[make_aerialgym_env] Final action space shape: (4,)
[make_aerialgym_env] Expected 4D action space: Box(-1.0, 1.0, (4,), float32)
[37m[4939 ms][navigation_task_gate] - INFO : Setting up static camera for gate navigation... (navigation_task_gate.py:522)
[37m[4939 ms][navigation_task_gate] - INFO : Static camera properties (D455 specs): 480x270, FOV: 87.0° (navigation_task_gate.py:541)
[37m[4939 ms][navigation_task_gate] - INFO : Static camera depth range: 0.4000000059604645m - 20.0m (navigation_task_gate.py:542)
[37m[4944 ms][navigation_task_gate] - INFO : Created static camera sensor 0 in environment 0 (navigation_task_gate.py:550)
[37m[4948 ms][navigation_task_gate] - INFO : Created static camera sensor 1 in environment 1 (navigation_task_gate.py:550)
[37m[4952 ms][navigation_task_gate] - INFO : Created static camera sensor 2 in environment 2 (navigation_task_gate.py:550)
[37m[4956 ms][navigation_task_gate] - INFO : Created static camera sensor 3 in environment 3 (navigation_task_gate.py:550)
[37m[4959 ms][navigation_task_gate] - INFO : Created static camera sensor 4 in environment 4 (navigation_task_gate.py:550)
[37m[4963 ms][navigation_task_gate] - INFO : Created static camera sensor 5 in environment 5 (navigation_task_gate.py:550)
[37m[4967 ms][navigation_task_gate] - INFO : Created static camera sensor 6 in environment 6 (navigation_task_gate.py:550)
[37m[4971 ms][navigation_task_gate] - INFO : Created static camera sensor 7 in environment 7 (navigation_task_gate.py:550)
[37m[4974 ms][navigation_task_gate] - INFO : Created static camera sensor 8 in environment 8 (navigation_task_gate.py:550)
[37m[4978 ms][navigation_task_gate] - INFO : Created static camera sensor 9 in environment 9 (navigation_task_gate.py:550)
[37m[4982 ms][navigation_task_gate] - INFO : Created static camera sensor 10 in environment 10 (navigation_task_gate.py:550)
[37m[4986 ms][navigation_task_gate] - INFO : Created static camera sensor 11 in environment 11 (navigation_task_gate.py:550)
[37m[4989 ms][navigation_task_gate] - INFO : Created static camera sensor 12 in environment 12 (navigation_task_gate.py:550)
[37m[4993 ms][navigation_task_gate] - INFO : Created static camera sensor 13 in environment 13 (navigation_task_gate.py:550)
[37m[4997 ms][navigation_task_gate] - INFO : Created static camera sensor 14 in environment 14 (navigation_task_gate.py:550)
[37m[5001 ms][navigation_task_gate] - INFO : Created static camera sensor 15 in environment 15 (navigation_task_gate.py:550)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 0 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 1 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 2 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 3 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 4 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 5 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 6 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 7 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 8 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 9 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 10 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 11 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 12 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 13 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 14 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : Set static camera 15 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[5001 ms][navigation_task_gate] - INFO : ✓ Static camera setup complete with fixed positioning (navigation_task_gate.py:568)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[36m[2025-07-04 07:31:18,778][06765] Env info: EnvInfo(obs_space=Dict('obs': Box(-inf, inf, (145,), float32)), action_space=Box(-1.0, 1.0, (4,), float32), num_agents=16, gpu_actions=True, gpu_observations=True, action_splits=None, all_discrete=None, frameskip=1, reward_shaping_scheme=None, env_info_protocol_version=1)
[33m[2025-07-04 07:31:19,587][06649] In serial mode all components run on the same process. Only use async_rl and serial mode together for debugging.
[36m[2025-07-04 07:31:19,588][06649] Starting experiment with the following configuration:
[36mhelp=False
[36malgo=APPO
[36menv=quad_with_obstacles_gate
[36mexperiment=gate_config_3_static_cam_fixed_1
[36mtrain_dir=./train_dir
[36mrestart_behavior=resume
[36mdevice=gpu
[36mseed=None
[36mnum_policies=1
[36masync_rl=True
[36mserial_mode=True
[36mbatched_sampling=True
[36mnum_batches_to_accumulate=2
[36mworker_num_splits=1
[36mpolicy_workers_per_policy=1
[36mmax_policy_lag=1000
[36mnum_workers=1
[36mnum_envs_per_worker=1
[36mbatch_size=2048
[36mnum_batches_per_epoch=8
[36mnum_epochs=4
[36mrollout=32
[36mrecurrence=32
[36mshuffle_minibatches=False
[36mgamma=0.98
[36mreward_scale=0.1
[36mreward_clip=1000.0
[36mvalue_bootstrap=True
[36mnormalize_returns=True
[36mexploration_loss_coeff=0.001
[36mvalue_loss_coeff=2.0
[36mkl_loss_coeff=0.1
[36mexploration_loss=entropy
[36mgae_lambda=0.95
[36mppo_clip_ratio=0.2
[36mppo_clip_value=1.0
[36mwith_vtrace=False
[36mvtrace_rho=1.0
[36mvtrace_c=1.0
[36moptimizer=adam
[36madam_eps=1e-06
[36madam_beta1=0.9
[36madam_beta2=0.999
[36mmax_grad_norm=1.0
[36mlearning_rate=0.0003
[36mlr_schedule=kl_adaptive_epoch
[36mlr_schedule_kl_threshold=0.016
[36mlr_adaptive_min=1e-06
[36mlr_adaptive_max=0.01
[36mobs_subtract_mean=0.0
[36mobs_scale=1.0
[36mnormalize_input=True
[36mnormalize_input_keys=None
[36mdecorrelate_experience_max_seconds=0
[36mdecorrelate_envs_on_one_worker=True
[36mactor_worker_gpus=[0]
[36mset_workers_cpu_affinity=True
[36mforce_envs_single_thread=False
[36mdefault_niceness=0
[36mlog_to_file=True
[36mexperiment_summaries_interval=10
[36mflush_summaries_interval=30
[36mstats_avg=100
[36msummaries_use_frameskip=True
[36mheartbeat_interval=20
[36mheartbeat_reporting_interval=180
[36mtrain_for_env_steps=100000000
[36mtrain_for_seconds=10000000000
[36msave_every_sec=120
[36mkeep_checkpoints=5
[36mload_checkpoint_kind=latest
[36msave_milestones_sec=-1
[36msave_best_every_sec=5
[36msave_best_metric=reward
[36msave_best_after=100000
[36mbenchmark=False
[36mencoder_mlp_layers=[512, 256, 64]
[36mencoder_conv_architecture=convnet_simple
[36mencoder_conv_mlp_layers=[]
[36muse_rnn=True
[36mrnn_size=64
[36mrnn_type=gru
[36mrnn_num_layers=1
[36mdecoder_mlp_layers=[]
[36mnonlinearity=elu
[36mpolicy_initialization=torch_default
[36mpolicy_init_gain=1.0
[36mactor_critic_share_weights=True
[36madaptive_stddev=True
[36mcontinuous_tanh_scale=0.0
[36minitial_stddev=1.0
[36muse_env_info_cache=False
[36menv_gpu_actions=True
[36menv_gpu_observations=True
[36menv_frameskip=1
[36menv_framestack=1
[36mpixel_format=CHW
[36muse_record_episode_statistics=False
[36mwith_wandb=True
[36mwandb_user=ziya-ruso-ucl
[36mwandb_project=gate_navigation_dual_camera
[36mwandb_group=gate_navigation_training
[36mwandb_job_type=SF
[36mwandb_tags=['aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized']
[36mwith_pbt=False
[36mpbt_mix_policies_in_one_env=True
[36mpbt_period_env_steps=5000000
[36mpbt_start_mutation=20000000
[36mpbt_replace_fraction=0.3
[36mpbt_mutation_rate=0.15
[36mpbt_replace_reward_gap=0.1
[36mpbt_replace_reward_gap_absolute=1e-06
[36mpbt_optimize_gamma=False
[36mpbt_target_objective=true_objective
[36mpbt_perturb_min=1.1
[36mpbt_perturb_max=1.5
[36menv_agents=16
[36mheadless=False
[36msave_gifs=True
[36mobs_key=observations
[36msubtask=None
[36mige_api_version=preview4
[36meval_stats=False
[36maction_space_dim=3
[36mcommand_line=--env=quad_with_obstacles_gate --experiment=gate_config_3_static_cam_fixed_1 --train_dir=./train_dir --num_workers=1 --num_envs_per_worker=1 --env_agents=16 --obs_key=observations --batch_size=2048 --num_batches_to_accumulate=2 --num_batches_per_epoch=8 --num_epochs=4 --rollout=32 --learning_rate=0.0003 --use_rnn=true --rnn_size=64 --rnn_num_layers=1 --encoder_mlp_layers 512 256 64 --gamma=0.98 --reward_scale=0.1 --max_grad_norm=1.0 --async_rl=true --normalize_input=true --use_env_info_cache=false --with_wandb=true --wandb_project=gate_navigation_dual_camera --wandb_user=ziya-ruso-ucl --wandb_group=gate_navigation_training --wandb_tags aerial_gym gate_navigation dual_camera x500 sample_factory memory_optimized --save_every_sec=120 --save_best_every_sec=5 --train_for_env_steps=100000000 --headless=false --save_gifs=true
[36mcli_args={'env': 'quad_with_obstacles_gate', 'experiment': 'gate_config_3_static_cam_fixed_1', 'train_dir': './train_dir', 'async_rl': True, 'num_batches_to_accumulate': 2, 'num_workers': 1, 'num_envs_per_worker': 1, 'batch_size': 2048, 'num_batches_per_epoch': 8, 'num_epochs': 4, 'rollout': 32, 'gamma': 0.98, 'reward_scale': 0.1, 'max_grad_norm': 1.0, 'learning_rate': 0.0003, 'normalize_input': True, 'train_for_env_steps': 100000000, 'save_every_sec': 120, 'save_best_every_sec': 5, 'encoder_mlp_layers': [512, 256, 64], 'use_rnn': True, 'rnn_size': 64, 'rnn_num_layers': 1, 'use_env_info_cache': False, 'with_wandb': True, 'wandb_user': 'ziya-ruso-ucl', 'wandb_project': 'gate_navigation_dual_camera', 'wandb_group': 'gate_navigation_training', 'wandb_tags': ['aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized'], 'env_agents': 16, 'headless': False, 'save_gifs': True, 'obs_key': 'observations'}
[36mgit_hash=0cfb8043f86f71fecc5b96bf9393310f6c956cd6
[36mgit_repo_name=git@github.com:rusoziya/aerial_gym_simulator.git
[36mwandb_unique_id=gate_config_3_static_cam_fixed_1_20250704_073110_526971
[36m[2025-07-04 07:31:19,588][06649] Saving configuration to ./train_dir/gate_config_3_static_cam_fixed_1/config.json...
[36m[2025-07-04 07:31:19,771][06649] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-04 07:31:19,772][06649] Rollout worker 0 uses device cuda:0
[36m[2025-07-04 07:31:19,788][06649] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-04 07:31:19,788][06649] InferenceWorker_p0-w0: min num requests: 1
[36m[2025-07-04 07:31:19,789][06649] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-04 07:31:19,790][06649] Starting seed is not provided
[36m[2025-07-04 07:31:19,790][06649] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-04 07:31:19,790][06649] Initializing actor-critic model on device cuda:0
[36m[2025-07-04 07:31:19,790][06649] RunningMeanStd input shape: (145,)
[36m[2025-07-04 07:31:19,791][06649] RunningMeanStd input shape: (1,)
[36m[2025-07-04 07:31:19,820][06649] Created Actor Critic model with architecture:
[36m[2025-07-04 07:31:19,820][06649] ActorCriticSharedWeights(
[36m  (obs_normalizer): ObservationNormalizer(
[36m    (running_mean_std): RunningMeanStdDictInPlace(
[36m      (running_mean_std): ModuleDict(
[36m        (obs): RunningMeanStdInPlace()
[36m      )
[36m    )
[36m  )
[36m  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
[36m  (encoder): MultiInputEncoder(
[36m    (encoders): ModuleDict(
[36m      (obs): MlpEncoder(
[36m        (mlp_head): RecursiveScriptModule(
[36m          original_name=Sequential
[36m          (0): RecursiveScriptModule(original_name=Linear)
[36m          (1): RecursiveScriptModule(original_name=ELU)
[36m          (2): RecursiveScriptModule(original_name=Linear)
[36m          (3): RecursiveScriptModule(original_name=ELU)
[36m          (4): RecursiveScriptModule(original_name=Linear)
[36m          (5): RecursiveScriptModule(original_name=ELU)
[36m        )
[36m      )
[36m    )
[36m  )
[36m  (core): ModelCoreRNN(
[36m    (core): GRU(64, 64)
[36m  )
[36m  (decoder): MlpDecoder(
[36m    (mlp): Identity()
[36m  )
[36m  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
[36m  (action_parameterization): ActionParameterizationDefault(
[36m    (distribution_linear): Linear(in_features=64, out_features=8, bias=True)
[36m  )
[36m)
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles_gate', '--experiment=gate_config_3_static_cam_fixed_1', '--train_dir=./train_dir', '--num_workers=1', '--num_envs_per_worker=1', '--env_agents=16', '--obs_key=observations', '--batch_size=2048', '--num_batches_to_accumulate=2', '--num_batches_per_epoch=8', '--num_epochs=4', '--rollout=32', '--learning_rate=0.0003', '--use_rnn=true', '--rnn_size=64', '--rnn_num_layers=1', '--encoder_mlp_layers', '512', '256', '64', '--gamma=0.98', '--reward_scale=0.1', '--max_grad_norm=1.0', '--async_rl=true', '--normalize_input=true', '--use_env_info_cache=false', '--with_wandb=true', '--wandb_project=gate_navigation_dual_camera', '--wandb_user=ziya-ruso-ucl', '--wandb_group=gate_navigation_training', '--wandb_tags', 'aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized', '--save_every_sec=120', '--save_best_every_sec=5', '--train_for_env_steps=100000000', '--save_gifs=true']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.69 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 7.86 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 11.60 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.75 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] GIF saving ENABLED for dual cameras (drone + static)
[AerialGymVecEnv] Forced action space shape: (4,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 16
[AerialGymVecEnv] Detected observation space: 145D
[AerialGymVecEnv] Using GATE NAVIGATION configuration (145D = 17D basic + 64D drone VAE + 64D static camera VAE)
[make_aerialgym_env] Final action space shape: (4,)
[make_aerialgym_env] Expected 4D action space: Box(-1.0, 1.0, (4,), float32)
[37m[12169 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[12169 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[12169 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[12169 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[12169 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[12169 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[37m[13184 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[13195 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[13400 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[13400 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[13400 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[13400 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[13400 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[13400 ms][BaseRobot] - INFO : Initializing controller lmf2_position_control (base_robot.py:29)
[33m[13400 ms][base_multirotor] - WARNING : Creating 16 multirotors. (base_multirotor.py:32)
[37m[13400 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[13400 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[13400 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13401 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13404 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13405 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13406 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13407 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13408 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13409 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13410 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13411 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13412 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13413 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13415 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[13431 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[13431 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[13431 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[13451 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[13460 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[13460 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[13534 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[13534 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[13565 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 10 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[13760 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[13761 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
[37m[14375 ms][navigation_task_gate] - INFO : Setting up static camera for gate navigation... (navigation_task_gate.py:522)
[37m[14375 ms][navigation_task_gate] - INFO : Static camera properties (D455 specs): 480x270, FOV: 87.0° (navigation_task_gate.py:541)
[37m[14375 ms][navigation_task_gate] - INFO : Static camera depth range: 0.4000000059604645m - 20.0m (navigation_task_gate.py:542)
[37m[14379 ms][navigation_task_gate] - INFO : Created static camera sensor 0 in environment 0 (navigation_task_gate.py:550)
[37m[14384 ms][navigation_task_gate] - INFO : Created static camera sensor 1 in environment 1 (navigation_task_gate.py:550)
[37m[14388 ms][navigation_task_gate] - INFO : Created static camera sensor 2 in environment 2 (navigation_task_gate.py:550)
[37m[14392 ms][navigation_task_gate] - INFO : Created static camera sensor 3 in environment 3 (navigation_task_gate.py:550)
[37m[14396 ms][navigation_task_gate] - INFO : Created static camera sensor 4 in environment 4 (navigation_task_gate.py:550)
[37m[14400 ms][navigation_task_gate] - INFO : Created static camera sensor 5 in environment 5 (navigation_task_gate.py:550)
[37m[14404 ms][navigation_task_gate] - INFO : Created static camera sensor 6 in environment 6 (navigation_task_gate.py:550)
[37m[14409 ms][navigation_task_gate] - INFO : Created static camera sensor 7 in environment 7 (navigation_task_gate.py:550)
[37m[14413 ms][navigation_task_gate] - INFO : Created static camera sensor 8 in environment 8 (navigation_task_gate.py:550)
[37m[14417 ms][navigation_task_gate] - INFO : Created static camera sensor 9 in environment 9 (navigation_task_gate.py:550)
[37m[14421 ms][navigation_task_gate] - INFO : Created static camera sensor 10 in environment 10 (navigation_task_gate.py:550)
[37m[14426 ms][navigation_task_gate] - INFO : Created static camera sensor 11 in environment 11 (navigation_task_gate.py:550)
[37m[14430 ms][navigation_task_gate] - INFO : Created static camera sensor 12 in environment 12 (navigation_task_gate.py:550)
[37m[14434 ms][navigation_task_gate] - INFO : Created static camera sensor 13 in environment 13 (navigation_task_gate.py:550)
[37m[14438 ms][navigation_task_gate] - INFO : Created static camera sensor 14 in environment 14 (navigation_task_gate.py:550)
[37m[14443 ms][navigation_task_gate] - INFO : Created static camera sensor 15 in environment 15 (navigation_task_gate.py:550)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 0 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 1 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 2 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 3 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 4 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 5 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 6 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 7 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 8 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 9 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 10 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 11 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 12 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 13 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 14 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : Set static camera 15 to look from (0.0, -3.0, 1.5) toward (0.0, 0.0, 1.5) (navigation_task_gate.py:566)
[37m[14443 ms][navigation_task_gate] - INFO : ✓ Static camera setup complete with fixed positioning (navigation_task_gate.py:568)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[GIF] Episode 0 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0000_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0000_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0000_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0000_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0000_merged_dual_camera.gif
[36m[2025-07-04 07:31:25,680][06649] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:31:25,680][06649] Avg episode reward: [(0, '-100.000')]
[33m[18934 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[33m[19143 ms][IGE_viewer_control] - WARNING : Camera follow: False (IGE_viewer_control.py:217)
[36m[2025-07-04 07:31:28,089][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 19.9. Samples: 48. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:31:28,089][06649] Avg episode reward: [(0, '-98.502')]
[33m[21671 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[36m[2025-07-04 07:31:32,932][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 134.6. Samples: 976. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:31:32,932][06649] Avg episode reward: [(0, '-34.800')]
[36m[2025-07-04 07:31:37,938][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 134.4. Samples: 1648. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:31:37,938][06649] Avg episode reward: [(0, '-24.291')]
[37m[1m[2025-07-04 07:31:39,892][06649] Heartbeat connected on Batcher_0
[37m[1m[2025-07-04 07:31:39,892][06649] Heartbeat connected on LearnerWorker_p0
[37m[1m[2025-07-04 07:31:39,892][06649] Heartbeat connected on InferenceWorker_p0-w0
[37m[1m[2025-07-04 07:31:39,892][06649] Heartbeat connected on RolloutWorker_w0
[36m[2025-07-04 07:31:42,939][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 171.5. Samples: 2960. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:31:42,939][06649] Avg episode reward: [(0, '-23.049')]
[36m[2025-07-04 07:31:47,940][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 195.5. Samples: 4352. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:31:47,940][06649] Avg episode reward: [(0, '-24.304')]
[36m[2025-07-04 07:31:53,014][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 183.8. Samples: 5024. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:31:53,014][06649] Avg episode reward: [(0, '-23.818')]
[36m[2025-07-04 07:31:57,978][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 197.2. Samples: 6368. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:31:57,979][06649] Avg episode reward: [(0, '-26.531')]
[36m[2025-07-04 07:32:02,923][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 207.9. Samples: 7744. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:32:02,923][06649] Avg episode reward: [(0, '-23.039')]
[36m[2025-07-04 07:32:08,011][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 199.2. Samples: 8432. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:32:08,011][06649] Avg episode reward: [(0, '-22.929')]
[36m[2025-07-04 07:32:12,923][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 215.5. Samples: 9712. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:32:12,923][06649] Avg episode reward: [(0, '-25.425')]
[33m[69574 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[69575 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:472)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task_gate/navigation_task_gate.py:479: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/success_rate"] = torch.tensor(success_rate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task_gate/navigation_task_gate.py:480: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/crash_rate"] = torch.tensor(crash_rate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task_gate/navigation_task_gate.py:481: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/timeout_rate"] = torch.tensor(timeout_rate, dtype=torch.float32)
[36m[2025-07-04 07:32:17,990][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 225.1. Samples: 11120. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:32:17,990][06649] Avg episode reward: [(0, '-23.535')]
[36m[2025-07-04 07:32:22,938][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 225.1. Samples: 11776. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:32:22,939][06649] Avg episode reward: [(0, '-23.468')]
[36m[2025-07-04 07:32:27,974][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 224.5. Samples: 13072. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:32:27,974][06649] Avg episode reward: [(0, '-23.897')]
[36m[2025-07-04 07:32:32,978][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 224.5. Samples: 14464. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:32:32,978][06649] Avg episode reward: [(0, '-23.823')]
[36m[2025-07-04 07:32:37,980][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 225.9. Samples: 15184. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-04 07:32:37,980][06649] Avg episode reward: [(0, '-22.250')]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/nn/modules/module.py:1194: UserWarning: operator() profile_node %104 : int[] = prim::profile_ivalue(%102)
 does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)
  return forward_call(*input, **kwargs)
[36m[2025-07-04 07:32:42,961][06649] Fps is (10 sec: 1641.1, 60 sec: 273.0, 300 sec: 212.0). Total num frames: 16384. Throughput: 0: 223.4. Samples: 16416. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:32:42,961][06649] Avg episode reward: [(0, '-23.746')]
[GIF] Episode 100 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0001_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0001_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0001_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0001_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0001_merged_dual_camera.gif
[36m[2025-07-04 07:32:47,950][06649] Fps is (10 sec: 1643.3, 60 sec: 273.0, 300 sec: 199.1). Total num frames: 16384. Throughput: 0: 220.3. Samples: 17664. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:32:47,951][06649] Avg episode reward: [(0, '-24.072')]
[36m[2025-07-04 07:32:52,949][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 187.7). Total num frames: 16384. Throughput: 0: 220.8. Samples: 18352. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:32:52,949][06649] Avg episode reward: [(0, '-21.892')]
[36m[2025-07-04 07:32:57,996][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 177.5). Total num frames: 16384. Throughput: 0: 222.6. Samples: 19744. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:32:57,997][06649] Avg episode reward: [(0, '-20.249')]
[36m[2025-07-04 07:33:02,924][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 168.5). Total num frames: 16384. Throughput: 0: 222.9. Samples: 21136. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:02,924][06649] Avg episode reward: [(0, '-22.583')]
[36m[2025-07-04 07:33:07,972][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 160.2). Total num frames: 16384. Throughput: 0: 222.1. Samples: 21776. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:07,972][06649] Avg episode reward: [(0, '-20.654')]
[33m[121411 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[121411 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:472)
[36m[2025-07-04 07:33:12,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 152.8). Total num frames: 16384. Throughput: 0: 223.5. Samples: 23120. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:12,928][06649] Avg episode reward: [(0, '-20.947')]
[37m[1m[2025-07-04 07:33:13,015][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000032_16384.pth...
[36m[2025-07-04 07:33:17,962][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 145.9). Total num frames: 16384. Throughput: 0: 223.4. Samples: 24512. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:17,962][06649] Avg episode reward: [(0, '-19.439')]
[36m[2025-07-04 07:33:22,971][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 139.7). Total num frames: 16384. Throughput: 0: 221.6. Samples: 25152. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:22,971][06649] Avg episode reward: [(0, '-23.396')]
[36m[2025-07-04 07:33:27,951][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 134.0). Total num frames: 16384. Throughput: 0: 225.1. Samples: 26544. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:27,952][06649] Avg episode reward: [(0, '-22.851')]
[36m[2025-07-04 07:33:32,967][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 128.7). Total num frames: 16384. Throughput: 0: 226.4. Samples: 27856. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:32,967][06649] Avg episode reward: [(0, '-19.649')]
[36m[2025-07-04 07:33:37,963][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 123.9). Total num frames: 16384. Throughput: 0: 226.1. Samples: 28528. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:37,963][06649] Avg episode reward: [(0, '-21.882')]
[36m[2025-07-04 07:33:42,956][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 119.4). Total num frames: 16384. Throughput: 0: 225.3. Samples: 29872. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:42,956][06649] Avg episode reward: [(0, '-21.549')]
[36m[2025-07-04 07:33:47,984][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 115.1). Total num frames: 16384. Throughput: 0: 224.1. Samples: 31232. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:47,984][06649] Avg episode reward: [(0, '-22.004')]
[36m[2025-07-04 07:33:52,977][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 111.2). Total num frames: 16384. Throughput: 0: 224.0. Samples: 31856. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:52,977][06649] Avg episode reward: [(0, '-19.510')]
[36m[2025-07-04 07:33:57,970][06649] Fps is (10 sec: 1640.6, 60 sec: 273.2, 300 sec: 215.2). Total num frames: 32768. Throughput: 0: 221.7. Samples: 33104. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:33:57,971][06649] Avg episode reward: [(0, '-20.016')]
[36m[2025-07-04 07:34:02,928][06649] Fps is (10 sec: 1646.5, 60 sec: 273.0, 300 sec: 208.4). Total num frames: 32768. Throughput: 0: 220.6. Samples: 34432. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:02,928][06649] Avg episode reward: [(0, '-16.123')]
[33m[175231 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[175231 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:472)
[36m[2025-07-04 07:34:07,926][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 202.0). Total num frames: 32768. Throughput: 0: 222.1. Samples: 35136. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:07,926][06649] Avg episode reward: [(0, '-15.590')]
[36m[2025-07-04 07:34:12,954][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 195.9). Total num frames: 32768. Throughput: 0: 219.7. Samples: 36432. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:12,963][06649] Avg episode reward: [(0, '-17.229')]
[GIF] Episode 200 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0002_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0002_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0002_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0002_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0002_merged_dual_camera.gif
[36m[2025-07-04 07:34:17,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 190.2). Total num frames: 32768. Throughput: 0: 222.4. Samples: 37856. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:17,927][06649] Avg episode reward: [(0, '-14.834')]
[36m[2025-07-04 07:34:22,962][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 184.8). Total num frames: 32768. Throughput: 0: 222.6. Samples: 38544. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:22,962][06649] Avg episode reward: [(0, '-16.939')]
[36m[2025-07-04 07:34:27,963][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 179.8). Total num frames: 32768. Throughput: 0: 221.8. Samples: 39856. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:27,963][06649] Avg episode reward: [(0, '-17.981')]
[36m[2025-07-04 07:34:32,947][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 175.0). Total num frames: 32768. Throughput: 0: 221.7. Samples: 41200. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:32,947][06649] Avg episode reward: [(0, '-15.934')]
[36m[2025-07-04 07:34:37,979][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 170.4). Total num frames: 32768. Throughput: 0: 221.9. Samples: 41840. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:37,979][06649] Avg episode reward: [(0, '-16.838')]
[36m[2025-07-04 07:34:42,936][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.1). Total num frames: 32768. Throughput: 0: 223.5. Samples: 43152. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:42,936][06649] Avg episode reward: [(0, '-13.679')]
[36m[2025-07-04 07:34:47,967][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 162.0). Total num frames: 32768. Throughput: 0: 225.2. Samples: 44576. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:47,968][06649] Avg episode reward: [(0, '-14.671')]
[36m[2025-07-04 07:34:52,960][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 158.1). Total num frames: 32768. Throughput: 0: 226.0. Samples: 45312. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:52,961][06649] Avg episode reward: [(0, '-16.940')]
[36m[2025-07-04 07:34:57,964][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 154.4). Total num frames: 32768. Throughput: 0: 227.5. Samples: 46672. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:34:57,964][06649] Avg episode reward: [(0, '-19.274')]
[33m[230859 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[230859 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:472)
[36m[2025-07-04 07:35:02,943][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 150.8). Total num frames: 32768. Throughput: 0: 225.3. Samples: 48000. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-04 07:35:02,943][06649] Avg episode reward: [(0, '-15.667')]
[36m[2025-07-04 07:35:07,949][06649] Fps is (10 sec: 1640.7, 60 sec: 273.0, 300 sec: 221.1). Total num frames: 49152. Throughput: 0: 226.2. Samples: 48720. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:07,950][06649] Avg episode reward: [(0, '-18.227')]
[36m[2025-07-04 07:35:12,945][06649] Fps is (10 sec: 1638.1, 60 sec: 273.1, 300 sec: 216.3). Total num frames: 49152. Throughput: 0: 225.9. Samples: 50016. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:12,945][06649] Avg episode reward: [(0, '-5.800')]
[37m[1m[2025-07-04 07:35:13,049][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000096_49152.pth...
[36m[2025-07-04 07:35:17,956][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 211.6). Total num frames: 49152. Throughput: 0: 225.7. Samples: 51360. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:17,956][06649] Avg episode reward: [(0, '-3.793')]
[36m[2025-07-04 07:35:22,944][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 207.2). Total num frames: 49152. Throughput: 0: 225.6. Samples: 51984. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:22,945][06649] Avg episode reward: [(0, '-8.894')]
[36m[2025-07-04 07:35:27,947][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 202.9). Total num frames: 49152. Throughput: 0: 226.4. Samples: 53344. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:27,948][06649] Avg episode reward: [(0, '-6.888')]
[36m[2025-07-04 07:35:32,977][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 198.8). Total num frames: 49152. Throughput: 0: 225.0. Samples: 54704. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:32,977][06649] Avg episode reward: [(0, '-11.801')]
[36m[2025-07-04 07:35:37,964][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 194.8). Total num frames: 49152. Throughput: 0: 223.3. Samples: 55360. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:37,964][06649] Avg episode reward: [(0, '-8.927')]
[36m[2025-07-04 07:35:42,950][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 191.1). Total num frames: 49152. Throughput: 0: 223.4. Samples: 56720. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:42,950][06649] Avg episode reward: [(0, '-8.530')]
[GIF] Episode 300 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0003_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0003_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0003_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0003_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0003_merged_dual_camera.gif
[36m[2025-07-04 07:35:47,947][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 187.4). Total num frames: 49152. Throughput: 0: 222.9. Samples: 58032. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:47,947][06649] Avg episode reward: [(0, '-7.598')]
[36m[2025-07-04 07:35:52,972][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 183.9). Total num frames: 49152. Throughput: 0: 221.8. Samples: 58704. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:52,973][06649] Avg episode reward: [(0, '-7.484')]
[36m[2025-07-04 07:35:57,956][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 180.5). Total num frames: 49152. Throughput: 0: 223.2. Samples: 60064. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:35:57,956][06649] Avg episode reward: [(0, '-8.078')]
[33m[292003 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[292004 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:472)
[36m[2025-07-04 07:36:02,935][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 177.3). Total num frames: 49152. Throughput: 0: 224.8. Samples: 61472. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:36:02,935][06649] Avg episode reward: [(0, '-5.259')]
[36m[2025-07-04 07:36:07,942][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 174.1). Total num frames: 49152. Throughput: 0: 226.1. Samples: 62160. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:36:07,942][06649] Avg episode reward: [(0, '-3.479')]
[36m[2025-07-04 07:36:12,997][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 171.1). Total num frames: 49152. Throughput: 0: 225.5. Samples: 63504. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:36:12,997][06649] Avg episode reward: [(0, '-7.318')]
[36m[2025-07-04 07:36:17,992][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 168.1). Total num frames: 49152. Throughput: 0: 226.1. Samples: 64880. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-04 07:36:17,992][06649] Avg episode reward: [(0, '-6.306')]
[36m[2025-07-04 07:36:22,926][06649] Fps is (10 sec: 1650.1, 60 sec: 273.2, 300 sec: 222.3). Total num frames: 65536. Throughput: 0: 227.0. Samples: 65568. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:36:22,926][06649] Avg episode reward: [(0, '-5.613')]
[36m[2025-07-04 07:36:27,931][06649] Fps is (10 sec: 1648.5, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 226.2. Samples: 66896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:36:27,931][06649] Avg episode reward: [(0, '7.538')]
[36m[2025-07-04 07:36:32,950][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 65536. Throughput: 0: 226.8. Samples: 68240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:36:32,950][06649] Avg episode reward: [(0, '2.364')]
[36m[2025-07-04 07:36:37,977][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 65536. Throughput: 0: 226.1. Samples: 68880. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:36:37,978][06649] Avg episode reward: [(0, '4.989')]
[36m[2025-07-04 07:36:42,952][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 65536. Throughput: 0: 226.2. Samples: 70240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:36:42,952][06649] Avg episode reward: [(0, '12.691')]
[36m[2025-07-04 07:36:47,931][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 225.4. Samples: 71616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:36:47,932][06649] Avg episode reward: [(0, '8.345')]
[36m[2025-07-04 07:36:52,950][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 226.4. Samples: 72352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:36:52,950][06649] Avg episode reward: [(0, '8.371')]
[36m[2025-07-04 07:36:58,012][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 65536. Throughput: 0: 227.5. Samples: 73744. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:36:58,012][06649] Avg episode reward: [(0, '8.886')]
[36m[2025-07-04 07:37:02,931][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 228.2. Samples: 75136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:02,932][06649] Avg episode reward: [(0, '6.074')]
[33m[358553 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[358553 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:472)
[36m[2025-07-04 07:37:07,980][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 65536. Throughput: 0: 227.3. Samples: 75808. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:07,981][06649] Avg episode reward: [(0, '3.965')]
[36m[2025-07-04 07:37:12,936][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 226.8. Samples: 77104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:12,937][06649] Avg episode reward: [(0, '2.085')]
[37m[1m[2025-07-04 07:37:13,010][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000128_65536.pth...
[36m[2025-07-04 07:37:17,967][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 65536. Throughput: 0: 229.2. Samples: 78560. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:17,967][06649] Avg episode reward: [(0, '10.606')]
[36m[2025-07-04 07:37:22,943][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 230.2. Samples: 79232. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:22,943][06649] Avg episode reward: [(0, '14.003')]
[36m[2025-07-04 07:37:27,953][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 230.7. Samples: 80624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:27,953][06649] Avg episode reward: [(0, '10.504')]
[36m[2025-07-04 07:37:32,954][06649] Fps is (10 sec: 1636.6, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 81920. Throughput: 0: 229.6. Samples: 81952. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:32,955][06649] Avg episode reward: [(0, '3.929')]
[GIF] Episode 400 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0004_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0004_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0004_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0004_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0004_merged_dual_camera.gif
[36m[2025-07-04 07:37:37,992][06649] Fps is (10 sec: 1632.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 81920. Throughput: 0: 227.3. Samples: 82592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:37,993][06649] Avg episode reward: [(0, '22.767')]
[36m[2025-07-04 07:37:42,940][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 226.5. Samples: 83920. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:42,940][06649] Avg episode reward: [(0, '27.338')]
[36m[2025-07-04 07:37:47,945][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 226.8. Samples: 85344. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:47,946][06649] Avg episode reward: [(0, '25.704')]
[36m[2025-07-04 07:37:52,924][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 227.5. Samples: 86032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:52,924][06649] Avg episode reward: [(0, '23.779')]
[36m[2025-07-04 07:37:57,924][06649] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 229.8. Samples: 87440. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:37:57,924][06649] Avg episode reward: [(0, '20.920')]
[36m[2025-07-04 07:38:02,926][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 226.3. Samples: 88736. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:02,926][06649] Avg episode reward: [(0, '21.337')]
[36m[2025-07-04 07:38:07,965][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 81920. Throughput: 0: 225.7. Samples: 89392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:07,965][06649] Avg episode reward: [(0, '22.772')]
[36m[2025-07-04 07:38:12,956][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 226.5. Samples: 90816. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:12,957][06649] Avg episode reward: [(0, '30.845')]
[36m[2025-07-04 07:38:17,922][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 228.1. Samples: 92208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:17,923][06649] Avg episode reward: [(0, '35.547')]
[33m[433872 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[433872 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:472)
[36m[2025-07-04 07:38:22,920][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 229.3. Samples: 92896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:22,920][06649] Avg episode reward: [(0, '22.309')]
[36m[2025-07-04 07:38:27,949][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 230.0. Samples: 94272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:27,949][06649] Avg episode reward: [(0, '19.638')]
[36m[2025-07-04 07:38:32,954][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 227.9. Samples: 95600. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:32,955][06649] Avg episode reward: [(0, '29.623')]
[36m[2025-07-04 07:38:37,989][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 81920. Throughput: 0: 228.3. Samples: 96320. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:37,989][06649] Avg episode reward: [(0, '34.789')]
[36m[2025-07-04 07:38:42,974][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 227.7. Samples: 97696. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:42,974][06649] Avg episode reward: [(0, '25.793')]
[36m[2025-07-04 07:38:47,980][06649] Fps is (10 sec: 1639.9, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 98304. Throughput: 0: 230.5. Samples: 99120. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:47,980][06649] Avg episode reward: [(0, '32.495')]
[36m[2025-07-04 07:38:53,001][06649] Fps is (10 sec: 1634.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 98304. Throughput: 0: 230.2. Samples: 99760. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:53,001][06649] Avg episode reward: [(0, '44.787')]
[36m[2025-07-04 07:38:57,918][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 229.2. Samples: 101120. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:38:57,919][06649] Avg episode reward: [(0, '51.986')]
[36m[2025-07-04 07:39:02,935][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 98304. Throughput: 0: 227.5. Samples: 102448. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:02,935][06649] Avg episode reward: [(0, '57.819')]
[36m[2025-07-04 07:39:07,954][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 226.7. Samples: 103104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:07,954][06649] Avg episode reward: [(0, '54.672')]
[36m[2025-07-04 07:39:12,937][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 98304. Throughput: 0: 229.4. Samples: 104592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:12,938][06649] Avg episode reward: [(0, '51.801')]
[37m[1m[2025-07-04 07:39:13,005][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000192_98304.pth...
[36m[2025-07-04 07:39:17,944][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 229.7. Samples: 105936. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:17,944][06649] Avg episode reward: [(0, '51.286')]
[36m[2025-07-04 07:39:22,965][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 228.4. Samples: 106592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:22,965][06649] Avg episode reward: [(0, '56.247')]
[36m[2025-07-04 07:39:27,971][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 98304. Throughput: 0: 227.2. Samples: 107920. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:27,972][06649] Avg episode reward: [(0, '54.937')]
[36m[2025-07-04 07:39:32,951][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 228.1. Samples: 109376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:32,951][06649] Avg episode reward: [(0, '60.954')]
[36m[2025-07-04 07:39:37,951][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 98304. Throughput: 0: 228.9. Samples: 110048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:37,951][06649] Avg episode reward: [(0, '54.095')]
[36m[2025-07-04 07:39:42,973][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 228.0. Samples: 111392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:42,973][06649] Avg episode reward: [(0, '39.829')]
[36m[2025-07-04 07:39:47,935][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 229.3. Samples: 112768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:47,935][06649] Avg episode reward: [(0, '54.743')]
[GIF] Episode 500 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0005_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0005_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0005_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0005_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0005_merged_dual_camera.gif
[33m[522268 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[522268 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:472)
[36m[2025-07-04 07:39:52,960][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 230.4. Samples: 113472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:39:52,961][06649] Avg episode reward: [(0, '56.271')]
[36m[2025-07-04 07:39:57,922][06649] Fps is (10 sec: 1640.5, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 114688. Throughput: 0: 225.5. Samples: 114736. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:39:57,922][06649] Avg episode reward: [(0, '66.497')]
[37m[1m[2025-07-04 07:39:57,986][06649] Saving new best policy, reward=66.497!
[36m[2025-07-04 07:40:02,943][06649] Fps is (10 sec: 1641.2, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 225.4. Samples: 116080. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:02,944][06649] Avg episode reward: [(0, '92.723')]
[37m[1m[2025-07-04 07:40:03,038][06649] Saving new best policy, reward=92.723!
[36m[2025-07-04 07:40:07,934][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 227.0. Samples: 116800. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:07,934][06649] Avg episode reward: [(0, '105.269')]
[37m[1m[2025-07-04 07:40:07,998][06649] Saving new best policy, reward=105.269!
[36m[2025-07-04 07:40:12,951][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 230.1. Samples: 118272. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:12,951][06649] Avg episode reward: [(0, '105.026')]
[36m[2025-07-04 07:40:17,964][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 114688. Throughput: 0: 228.9. Samples: 119680. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:17,964][06649] Avg episode reward: [(0, '91.535')]
[36m[2025-07-04 07:40:22,962][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 114688. Throughput: 0: 229.6. Samples: 120384. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:22,963][06649] Avg episode reward: [(0, '78.857')]
[36m[2025-07-04 07:40:27,947][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 229.5. Samples: 121712. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:27,948][06649] Avg episode reward: [(0, '96.663')]
[36m[2025-07-04 07:40:32,955][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 229.2. Samples: 123088. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:32,956][06649] Avg episode reward: [(0, '116.170')]
[37m[1m[2025-07-04 07:40:33,036][06649] Saving new best policy, reward=116.170!
[36m[2025-07-04 07:40:37,935][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 229.1. Samples: 123776. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:37,935][06649] Avg episode reward: [(0, '109.692')]
[36m[2025-07-04 07:40:42,938][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 232.4. Samples: 125200. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:42,938][06649] Avg episode reward: [(0, '99.776')]
[36m[2025-07-04 07:40:47,959][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 232.5. Samples: 126544. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:47,959][06649] Avg episode reward: [(0, '108.668')]
[36m[2025-07-04 07:40:52,919][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 231.2. Samples: 127200. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:52,920][06649] Avg episode reward: [(0, '104.049')]
[36m[2025-07-04 07:40:57,961][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 114688. Throughput: 0: 228.2. Samples: 128544. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:40:57,961][06649] Avg episode reward: [(0, '108.572')]
[36m[2025-07-04 07:41:02,961][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 114688. Throughput: 0: 228.3. Samples: 129952. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:41:02,961][06649] Avg episode reward: [(0, '96.889')]
[36m[2025-07-04 07:41:07,934][06649] Fps is (10 sec: 1642.7, 60 sec: 273.1, 300 sec: 277.8). Total num frames: 131072. Throughput: 0: 228.1. Samples: 130640. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:07,935][06649] Avg episode reward: [(0, '98.481')]
[36m[2025-07-04 07:41:12,920][06649] Fps is (10 sec: 1645.2, 60 sec: 273.2, 300 sec: 277.8). Total num frames: 131072. Throughput: 0: 228.4. Samples: 131984. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:12,920][06649] Avg episode reward: [(0, '127.088')]
[37m[1m[2025-07-04 07:41:12,985][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000256_131072.pth...
[37m[1m[2025-07-04 07:41:12,989][06649] Saving new best policy, reward=127.088!
[36m[2025-07-04 07:41:17,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 228.8. Samples: 133376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:17,927][06649] Avg episode reward: [(0, '180.949')]
[37m[1m[2025-07-04 07:41:17,991][06649] Saving new best policy, reward=180.949!
[33m[611720 ms][IGE_viewer_control] - WARNING : Camera follow: False (IGE_viewer_control.py:217)
[33m[612607 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[33m[613415 ms][IGE_viewer_control] - WARNING : Camera follow: False (IGE_viewer_control.py:217)
[36m[2025-07-04 07:41:22,921][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 228.7. Samples: 134064. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:22,921][06649] Avg episode reward: [(0, '197.730')]
[37m[1m[2025-07-04 07:41:22,983][06649] Saving new best policy, reward=197.730!
[36m[2025-07-04 07:41:27,929][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 227.2. Samples: 135424. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:27,930][06649] Avg episode reward: [(0, '179.129')]
[36m[2025-07-04 07:41:32,939][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 225.9. Samples: 136704. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:32,940][06649] Avg episode reward: [(0, '225.409')]
[37m[1m[2025-07-04 07:41:33,019][06649] Saving new best policy, reward=225.409!
[36m[2025-07-04 07:41:37,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 226.8. Samples: 137408. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:37,932][06649] Avg episode reward: [(0, '282.305')]
[37m[1m[2025-07-04 07:41:37,993][06649] Saving new best policy, reward=282.305!
[36m[2025-07-04 07:41:42,975][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 131072. Throughput: 0: 227.8. Samples: 138800. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:42,975][06649] Avg episode reward: [(0, '276.758')]
[36m[2025-07-04 07:41:47,970][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 131072. Throughput: 0: 226.8. Samples: 140160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:47,971][06649] Avg episode reward: [(0, '222.609')]
[36m[2025-07-04 07:41:52,964][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 226.7. Samples: 140848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:52,964][06649] Avg episode reward: [(0, '203.528')]
[33m[645532 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[645532 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.9990234375
[33mTimeout Rate: 0.0009765625 (navigation_task_gate.py:472)
[36m[2025-07-04 07:41:57,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 228.6. Samples: 142272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:41:57,927][06649] Avg episode reward: [(0, '176.631')]
[36m[2025-07-04 07:42:02,981][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 228.7. Samples: 143680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:42:02,982][06649] Avg episode reward: [(0, '193.586')]
[36m[2025-07-04 07:42:07,972][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 131072. Throughput: 0: 228.0. Samples: 144336. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:42:07,972][06649] Avg episode reward: [(0, '188.265')]
[36m[2025-07-04 07:42:12,973][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 227.3. Samples: 145664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:42:12,973][06649] Avg episode reward: [(0, '194.396')]
[36m[2025-07-04 07:42:17,996][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 131072. Throughput: 0: 229.0. Samples: 147024. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:42:17,996][06649] Avg episode reward: [(0, '215.764')]
[36m[2025-07-04 07:42:22,945][06649] Fps is (10 sec: 1642.9, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 147456. Throughput: 0: 228.6. Samples: 147696. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:42:22,946][06649] Avg episode reward: [(0, '244.588')]
[36m[2025-07-04 07:42:27,982][06649] Fps is (10 sec: 1640.8, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 228.6. Samples: 149088. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:42:27,982][06649] Avg episode reward: [(0, '321.443')]
[37m[1m[2025-07-04 07:42:28,045][06649] Saving new best policy, reward=321.443!
[36m[2025-07-04 07:42:32,974][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 228.2. Samples: 150432. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:42:32,974][06649] Avg episode reward: [(0, '398.445')]
[37m[1m[2025-07-04 07:42:33,045][06649] Saving new best policy, reward=398.445!
[36m[2025-07-04 07:42:37,921][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 227.8. Samples: 151088. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:42:37,921][06649] Avg episode reward: [(0, '433.860')]
[37m[1m[2025-07-04 07:42:37,999][06649] Saving new best policy, reward=433.860!
[36m[2025-07-04 07:42:42,941][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 225.4. Samples: 152416. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:42:42,941][06649] Avg episode reward: [(0, '492.005')]
[37m[1m[2025-07-04 07:42:43,010][06649] Saving new best policy, reward=492.005!
[36m[2025-07-04 07:42:47,972][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 224.8. Samples: 153792. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:42:47,972][06649] Avg episode reward: [(0, '438.496')]
[36m[2025-07-04 07:42:52,982][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 225.0. Samples: 154464. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:42:52,983][06649] Avg episode reward: [(0, '450.110')]
[36m[2025-07-04 07:42:57,919][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 226.4. Samples: 155840. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:42:57,920][06649] Avg episode reward: [(0, '447.602')]
[36m[2025-07-04 07:43:02,924][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 226.1. Samples: 157184. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:43:02,924][06649] Avg episode reward: [(0, '423.729')]
[36m[2025-07-04 07:43:07,933][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 227.6. Samples: 157936. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:43:07,934][06649] Avg episode reward: [(0, '430.968')]
[36m[2025-07-04 07:43:12,950][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 227.0. Samples: 159296. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:43:12,951][06649] Avg episode reward: [(0, '449.666')]
[37m[1m[2025-07-04 07:43:13,028][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000288_147456.pth...
[36m[2025-07-04 07:43:13,032][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000032_16384.pth
[36m[2025-07-04 07:43:17,937][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 227.7. Samples: 160672. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:43:17,937][06649] Avg episode reward: [(0, '412.206')]
[36m[2025-07-04 07:43:22,918][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 229.3. Samples: 161408. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:43:22,918][06649] Avg episode reward: [(0, '353.959')]
[36m[2025-07-04 07:43:27,981][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 229.8. Samples: 162768. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-04 07:43:27,981][06649] Avg episode reward: [(0, '365.895')]
[GIF] Episode 600 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0006_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0006_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0006_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0006_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0006_merged_dual_camera.gif
[36m[2025-07-04 07:43:32,939][06649] Fps is (10 sec: 1635.0, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 163840. Throughput: 0: 229.5. Samples: 164112. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:43:32,940][06649] Avg episode reward: [(0, '393.285')]
[36m[2025-07-04 07:43:37,975][06649] Fps is (10 sec: 1639.3, 60 sec: 272.8, 300 sec: 277.7). Total num frames: 163840. Throughput: 0: 229.7. Samples: 164800. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:43:37,975][06649] Avg episode reward: [(0, '468.555')]
[36m[2025-07-04 07:43:42,964][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 229.1. Samples: 166160. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:43:42,964][06649] Avg episode reward: [(0, '668.443')]
[37m[1m[2025-07-04 07:43:43,040][06649] Saving new best policy, reward=668.443!
[36m[2025-07-04 07:43:47,943][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 231.0. Samples: 167584. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:43:47,944][06649] Avg episode reward: [(0, '864.573')]
[37m[1m[2025-07-04 07:43:48,009][06649] Saving new best policy, reward=864.573!
[36m[2025-07-04 07:43:52,954][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 229.9. Samples: 168288. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:43:52,954][06649] Avg episode reward: [(0, '961.415')]
[37m[1m[2025-07-04 07:43:53,020][06649] Saving new best policy, reward=961.415!
[36m[2025-07-04 07:43:57,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 231.6. Samples: 169712. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:43:57,932][06649] Avg episode reward: [(0, '1035.298')]
[37m[1m[2025-07-04 07:43:57,994][06649] Saving new best policy, reward=1035.298!
[36m[2025-07-04 07:44:02,975][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 231.6. Samples: 171104. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:44:02,975][06649] Avg episode reward: [(0, '938.073')]
[36m[2025-07-04 07:44:07,941][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 231.3. Samples: 171824. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:44:07,941][06649] Avg episode reward: [(0, '1007.048')]
[36m[2025-07-04 07:44:12,969][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 232.2. Samples: 173216. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:44:12,970][06649] Avg episode reward: [(0, '878.339')]
[36m[2025-07-04 07:44:17,952][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 231.4. Samples: 174528. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:44:17,952][06649] Avg episode reward: [(0, '774.913')]
[36m[2025-07-04 07:44:22,980][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 231.1. Samples: 175200. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:44:22,980][06649] Avg episode reward: [(0, '770.878')]
[36m[2025-07-04 07:44:27,981][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 231.0. Samples: 176560. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:44:27,981][06649] Avg episode reward: [(0, '821.647')]
[36m[2025-07-04 07:44:33,004][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 228.0. Samples: 177856. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:44:33,004][06649] Avg episode reward: [(0, '734.147')]
[36m[2025-07-04 07:44:37,928][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 227.0. Samples: 178496. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:44:37,928][06649] Avg episode reward: [(0, '779.753')]
[36m[2025-07-04 07:44:42,939][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 224.3. Samples: 179808. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:44:42,939][06649] Avg episode reward: [(0, '829.975')]
[36m[2025-07-04 07:44:47,954][06649] Fps is (10 sec: 1634.2, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 180224. Throughput: 0: 222.0. Samples: 181088. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:44:47,954][06649] Avg episode reward: [(0, '835.034')]
[36m[2025-07-04 07:44:52,966][06649] Fps is (10 sec: 1633.9, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 220.7. Samples: 181760. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:44:52,966][06649] Avg episode reward: [(0, '996.042')]
[36m[2025-07-04 07:44:57,977][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 217.2. Samples: 182992. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:44:57,977][06649] Avg episode reward: [(0, '1115.352')]
[37m[1m[2025-07-04 07:44:58,040][06649] Saving new best policy, reward=1115.352!
[36m[2025-07-04 07:45:02,974][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 217.1. Samples: 184304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:02,975][06649] Avg episode reward: [(0, '1333.892')]
[37m[1m[2025-07-04 07:45:03,069][06649] Saving new best policy, reward=1333.892!
[36m[2025-07-04 07:45:07,976][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 217.6. Samples: 184992. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:07,976][06649] Avg episode reward: [(0, '1500.898')]
[37m[1m[2025-07-04 07:45:08,045][06649] Saving new best policy, reward=1500.898!
[36m[2025-07-04 07:45:12,967][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 180224. Throughput: 0: 215.9. Samples: 186272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:12,967][06649] Avg episode reward: [(0, '1618.153')]
[37m[1m[2025-07-04 07:45:13,070][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000352_180224.pth...
[36m[2025-07-04 07:45:13,077][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000096_49152.pth
[37m[1m[2025-07-04 07:45:13,078][06649] Saving new best policy, reward=1618.153!
[36m[2025-07-04 07:45:17,963][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 180224. Throughput: 0: 216.4. Samples: 187584. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:17,964][06649] Avg episode reward: [(0, '1675.400')]
[37m[1m[2025-07-04 07:45:18,060][06649] Saving new best policy, reward=1675.400!
[36m[2025-07-04 07:45:22,971][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 216.7. Samples: 188256. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:22,971][06649] Avg episode reward: [(0, '1815.009')]
[37m[1m[2025-07-04 07:45:23,044][06649] Saving new best policy, reward=1815.009!
[36m[2025-07-04 07:45:27,944][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 180224. Throughput: 0: 215.8. Samples: 189520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:27,944][06649] Avg episode reward: [(0, '1809.978')]
[36m[2025-07-04 07:45:32,953][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 218.3. Samples: 190912. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:32,953][06649] Avg episode reward: [(0, '1829.977')]
[37m[1m[2025-07-04 07:45:33,022][06649] Saving new best policy, reward=1829.977!
[36m[2025-07-04 07:45:37,955][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 218.4. Samples: 191584. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:37,955][06649] Avg episode reward: [(0, '1783.523')]
[36m[2025-07-04 07:45:42,949][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 180224. Throughput: 0: 223.4. Samples: 193040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:42,949][06649] Avg episode reward: [(0, '1679.167')]
[36m[2025-07-04 07:45:47,964][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 224.4. Samples: 194400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:47,964][06649] Avg episode reward: [(0, '1694.671')]
[33m[883060 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[883061 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.8544921875
[33mTimeout Rate: 0.1455078125 (navigation_task_gate.py:472)
[36m[2025-07-04 07:45:53,038][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 223.7. Samples: 195072. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:53,038][06649] Avg episode reward: [(0, '1833.303')]
[37m[1m[2025-07-04 07:45:53,140][06649] Saving new best policy, reward=1833.303!
[36m[2025-07-04 07:45:57,935][06649] Fps is (10 sec: 1643.2, 60 sec: 273.3, 300 sec: 277.7). Total num frames: 196608. Throughput: 0: 225.2. Samples: 196400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:45:57,935][06649] Avg episode reward: [(0, '1613.595')]
[36m[2025-07-04 07:46:02,961][06649] Fps is (10 sec: 1651.1, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 196608. Throughput: 0: 225.4. Samples: 197728. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:02,961][06649] Avg episode reward: [(0, '1665.955')]
[36m[2025-07-04 07:46:07,964][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 196608. Throughput: 0: 226.5. Samples: 198448. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:07,964][06649] Avg episode reward: [(0, '1893.201')]
[37m[1m[2025-07-04 07:46:08,051][06649] Saving new best policy, reward=1893.201!
[36m[2025-07-04 07:46:12,973][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 196608. Throughput: 0: 229.2. Samples: 199840. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:12,973][06649] Avg episode reward: [(0, '2071.057')]
[37m[1m[2025-07-04 07:46:13,036][06649] Saving new best policy, reward=2071.057!
[36m[2025-07-04 07:46:17,945][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 196608. Throughput: 0: 229.4. Samples: 201232. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:17,945][06649] Avg episode reward: [(0, '2321.217')]
[37m[1m[2025-07-04 07:46:18,021][06649] Saving new best policy, reward=2321.217!
[36m[2025-07-04 07:46:22,966][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 196608. Throughput: 0: 229.6. Samples: 201920. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:22,966][06649] Avg episode reward: [(0, '2509.978')]
[37m[1m[2025-07-04 07:46:23,111][06649] Saving new best policy, reward=2509.978!
[36m[2025-07-04 07:46:27,965][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 196608. Throughput: 0: 227.1. Samples: 203264. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:27,965][06649] Avg episode reward: [(0, '2585.460')]
[37m[1m[2025-07-04 07:46:28,034][06649] Saving new best policy, reward=2585.460!
[36m[2025-07-04 07:46:32,937][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 228.4. Samples: 204672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:32,937][06649] Avg episode reward: [(0, '2719.886')]
[37m[1m[2025-07-04 07:46:33,016][06649] Saving new best policy, reward=2719.886!
[36m[2025-07-04 07:46:37,941][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 229.5. Samples: 205376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:37,942][06649] Avg episode reward: [(0, '3042.600')]
[37m[1m[2025-07-04 07:46:38,013][06649] Saving new best policy, reward=3042.600!
[36m[2025-07-04 07:46:42,920][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 233.0. Samples: 206880. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:42,921][06649] Avg episode reward: [(0, '3185.674')]
[37m[1m[2025-07-04 07:46:42,984][06649] Saving new best policy, reward=3185.674!
[36m[2025-07-04 07:46:47,964][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 235.7. Samples: 208336. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:47,964][06649] Avg episode reward: [(0, '3217.329')]
[37m[1m[2025-07-04 07:46:48,024][06649] Saving new best policy, reward=3217.329!
[36m[2025-07-04 07:46:52,926][06649] Fps is (10 sec: 0.0, 60 sec: 273.6, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 235.9. Samples: 209056. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:52,926][06649] Avg episode reward: [(0, '3243.652')]
[37m[1m[2025-07-04 07:46:52,993][06649] Saving new best policy, reward=3243.652!
[36m[2025-07-04 07:46:57,964][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 235.8. Samples: 210448. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:46:57,964][06649] Avg episode reward: [(0, '3211.730')]
[36m[2025-07-04 07:47:02,987][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 196608. Throughput: 0: 234.1. Samples: 211776. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:47:02,987][06649] Avg episode reward: [(0, '3227.624')]
[36m[2025-07-04 07:47:08,062][06649] Fps is (10 sec: 1622.6, 60 sec: 272.6, 300 sec: 277.6). Total num frames: 212992. Throughput: 0: 233.5. Samples: 212448. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:08,062][06649] Avg episode reward: [(0, '3277.809')]
[37m[1m[2025-07-04 07:47:08,128][06649] Saving new best policy, reward=3277.809!
[36m[2025-07-04 07:47:12,921][06649] Fps is (10 sec: 1649.3, 60 sec: 273.3, 300 sec: 277.8). Total num frames: 212992. Throughput: 0: 233.5. Samples: 213760. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:12,921][06649] Avg episode reward: [(0, '3321.420')]
[37m[1m[2025-07-04 07:47:13,014][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000416_212992.pth...
[36m[2025-07-04 07:47:13,018][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000128_65536.pth
[37m[1m[2025-07-04 07:47:13,019][06649] Saving new best policy, reward=3321.420!
[36m[2025-07-04 07:47:17,919][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 232.6. Samples: 215136. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:17,919][06649] Avg episode reward: [(0, '3408.584')]
[37m[1m[2025-07-04 07:47:18,009][06649] Saving new best policy, reward=3408.584!
[36m[2025-07-04 07:47:22,987][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 231.2. Samples: 215792. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:22,988][06649] Avg episode reward: [(0, '3529.773')]
[37m[1m[2025-07-04 07:47:23,070][06649] Saving new best policy, reward=3529.773!
[36m[2025-07-04 07:47:27,935][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 228.2. Samples: 217152. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:27,935][06649] Avg episode reward: [(0, '3650.214')]
[37m[1m[2025-07-04 07:47:28,022][06649] Saving new best policy, reward=3650.214!
[36m[2025-07-04 07:47:32,954][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 226.2. Samples: 218512. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:32,954][06649] Avg episode reward: [(0, '3831.621')]
[37m[1m[2025-07-04 07:47:33,029][06649] Saving new best policy, reward=3831.621!
[36m[2025-07-04 07:47:37,965][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 224.9. Samples: 219184. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:37,966][06649] Avg episode reward: [(0, '3948.694')]
[37m[1m[2025-07-04 07:47:38,077][06649] Saving new best policy, reward=3948.694!
[36m[2025-07-04 07:47:42,962][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 225.1. Samples: 220576. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:42,962][06649] Avg episode reward: [(0, '4161.519')]
[37m[1m[2025-07-04 07:47:43,030][06649] Saving new best policy, reward=4161.519!
[36m[2025-07-04 07:47:47,970][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 226.9. Samples: 221984. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:47,971][06649] Avg episode reward: [(0, '4276.986')]
[37m[1m[2025-07-04 07:47:48,038][06649] Saving new best policy, reward=4276.986!
[36m[2025-07-04 07:47:52,946][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 227.4. Samples: 222656. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:52,946][06649] Avg episode reward: [(0, '4546.444')]
[37m[1m[2025-07-04 07:47:53,009][06649] Saving new best policy, reward=4546.444!
[36m[2025-07-04 07:47:57,973][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 227.6. Samples: 224016. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:47:57,974][06649] Avg episode reward: [(0, '4713.031')]
[37m[1m[2025-07-04 07:47:58,054][06649] Saving new best policy, reward=4713.031!
[36m[2025-07-04 07:48:02,923][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 228.6. Samples: 225424. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:48:02,923][06649] Avg episode reward: [(0, '4712.440')]
[36m[2025-07-04 07:48:07,987][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 229.7. Samples: 226128. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:48:07,987][06649] Avg episode reward: [(0, '4642.944')]
[36m[2025-07-04 07:48:12,970][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 229.5. Samples: 227488. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:48:12,970][06649] Avg episode reward: [(0, '4606.939')]
[36m[2025-07-04 07:48:17,946][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 229.4. Samples: 228832. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 07:48:17,946][06649] Avg episode reward: [(0, '4535.034')]
[36m[2025-07-04 07:48:22,953][06649] Fps is (10 sec: 1641.1, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 229376. Throughput: 0: 229.7. Samples: 229520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:48:22,954][06649] Avg episode reward: [(0, '4430.911')]
[36m[2025-07-04 07:48:27,978][06649] Fps is (10 sec: 1633.1, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 229376. Throughput: 0: 230.7. Samples: 230960. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:48:27,978][06649] Avg episode reward: [(0, '4381.036')]
[36m[2025-07-04 07:48:32,963][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 231.5. Samples: 232400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:48:32,964][06649] Avg episode reward: [(0, '4405.748')]
[36m[2025-07-04 07:48:37,946][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 232.2. Samples: 233104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:48:37,946][06649] Avg episode reward: [(0, '4435.394')]
[36m[2025-07-04 07:48:42,938][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 235.6. Samples: 234608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:48:42,938][06649] Avg episode reward: [(0, '4407.160')]
[36m[2025-07-04 07:48:47,944][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 234.2. Samples: 235968. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:48:47,945][06649] Avg episode reward: [(0, '4618.564')]
[36m[2025-07-04 07:48:52,956][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 229376. Throughput: 0: 232.7. Samples: 236592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:48:52,956][06649] Avg episode reward: [(0, '4731.342')]
[37m[1m[2025-07-04 07:48:53,020][06649] Saving new best policy, reward=4731.342!
[36m[2025-07-04 07:48:57,993][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 229376. Throughput: 0: 235.6. Samples: 238096. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:48:57,993][06649] Avg episode reward: [(0, '4799.646')]
[37m[1m[2025-07-04 07:48:58,102][06649] Saving new best policy, reward=4799.646!
[36m[2025-07-04 07:49:02,961][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 229376. Throughput: 0: 236.7. Samples: 239488. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:49:02,961][06649] Avg episode reward: [(0, '4866.006')]
[37m[1m[2025-07-04 07:49:03,033][06649] Saving new best policy, reward=4866.006!
[36m[2025-07-04 07:49:07,943][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 237.6. Samples: 240208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:49:07,943][06649] Avg episode reward: [(0, '5037.004')]
[37m[1m[2025-07-04 07:49:08,015][06649] Saving new best policy, reward=5037.004!
[36m[2025-07-04 07:49:12,931][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 235.6. Samples: 241552. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:49:12,931][06649] Avg episode reward: [(0, '5012.271')]
[37m[1m[2025-07-04 07:49:13,017][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000448_229376.pth...
[36m[2025-07-04 07:49:13,034][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000192_98304.pth
[36m[2025-07-04 07:49:17,920][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 233.8. Samples: 242912. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:49:17,920][06649] Avg episode reward: [(0, '5005.886')]
[36m[2025-07-04 07:49:22,970][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 233.1. Samples: 243600. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:49:22,970][06649] Avg episode reward: [(0, '5058.361')]
[37m[1m[2025-07-04 07:49:23,068][06649] Saving new best policy, reward=5058.361!
[36m[2025-07-04 07:49:27,927][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 231.9. Samples: 245040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:49:27,927][06649] Avg episode reward: [(0, '5019.636')]
[36m[2025-07-04 07:49:32,959][06649] Fps is (10 sec: 1640.2, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 245760. Throughput: 0: 230.7. Samples: 246352. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:49:32,959][06649] Avg episode reward: [(0, '4957.719')]
[36m[2025-07-04 07:49:38,001][06649] Fps is (10 sec: 1626.4, 60 sec: 272.8, 300 sec: 277.6). Total num frames: 245760. Throughput: 0: 231.9. Samples: 247040. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:49:38,001][06649] Avg episode reward: [(0, '4980.999')]
[36m[2025-07-04 07:49:42,961][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 229.5. Samples: 248416. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:49:42,961][06649] Avg episode reward: [(0, '5030.077')]
[36m[2025-07-04 07:49:47,971][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 230.7. Samples: 249872. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:49:47,972][06649] Avg episode reward: [(0, '4999.681')]
[36m[2025-07-04 07:49:52,926][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 230.1. Samples: 250560. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:49:52,926][06649] Avg episode reward: [(0, '5044.855')]
[36m[2025-07-04 07:49:57,954][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 228.9. Samples: 251856. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:49:57,954][06649] Avg episode reward: [(0, '4980.219')]
[36m[2025-07-04 07:50:02,964][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 228.0. Samples: 253184. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:50:02,964][06649] Avg episode reward: [(0, '4954.681')]
[36m[2025-07-04 07:50:07,965][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 228.3. Samples: 253872. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:50:07,965][06649] Avg episode reward: [(0, '4933.290')]
[36m[2025-07-04 07:50:12,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 227.2. Samples: 255264. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:50:12,928][06649] Avg episode reward: [(0, '4937.847')]
[36m[2025-07-04 07:50:17,974][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 227.5. Samples: 256592. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:50:17,974][06649] Avg episode reward: [(0, '4978.612')]
[36m[2025-07-04 07:50:22,917][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 228.0. Samples: 257280. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:50:22,918][06649] Avg episode reward: [(0, '4927.572')]
[36m[2025-07-04 07:50:27,961][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 245760. Throughput: 0: 230.8. Samples: 258800. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:50:27,962][06649] Avg episode reward: [(0, '4885.204')]
[36m[2025-07-04 07:50:32,930][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 229.5. Samples: 260192. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:50:32,931][06649] Avg episode reward: [(0, '4896.418')]
[36m[2025-07-04 07:50:37,958][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 245760. Throughput: 0: 228.8. Samples: 260864. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-04 07:50:37,959][06649] Avg episode reward: [(0, '4968.295')]
[36m[2025-07-04 07:50:42,949][06649] Fps is (10 sec: 1635.4, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 262144. Throughput: 0: 230.1. Samples: 262208. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:50:42,949][06649] Avg episode reward: [(0, '5050.605')]
[36m[2025-07-04 07:50:47,938][06649] Fps is (10 sec: 1641.8, 60 sec: 273.2, 300 sec: 277.8). Total num frames: 262144. Throughput: 0: 228.0. Samples: 263440. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:50:47,938][06649] Avg episode reward: [(0, '5068.065')]
[37m[1m[2025-07-04 07:50:48,006][06649] Saving new best policy, reward=5068.065!
[36m[2025-07-04 07:50:52,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 228.8. Samples: 264160. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:50:52,928][06649] Avg episode reward: [(0, '5041.037')]
[36m[2025-07-04 07:50:57,963][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 232.3. Samples: 265728. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:50:57,963][06649] Avg episode reward: [(0, '5047.227')]
[36m[2025-07-04 07:51:02,954][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 234.1. Samples: 267120. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:02,954][06649] Avg episode reward: [(0, '5002.103')]
[36m[2025-07-04 07:51:07,951][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 234.1. Samples: 267824. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:07,951][06649] Avg episode reward: [(0, '5060.778')]
[36m[2025-07-04 07:51:12,929][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 232.3. Samples: 269248. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:12,929][06649] Avg episode reward: [(0, '5114.398')]
[37m[1m[2025-07-04 07:51:13,002][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000512_262144.pth...
[36m[2025-07-04 07:51:13,007][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000256_131072.pth
[37m[1m[2025-07-04 07:51:13,008][06649] Saving new best policy, reward=5114.398!
[36m[2025-07-04 07:51:17,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 231.1. Samples: 270592. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:17,932][06649] Avg episode reward: [(0, '5049.927')]
[36m[2025-07-04 07:51:22,937][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 229.1. Samples: 271168. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:22,938][06649] Avg episode reward: [(0, '5026.723')]
[36m[2025-07-04 07:51:27,920][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 227.7. Samples: 272448. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:27,920][06649] Avg episode reward: [(0, '5025.204')]
[36m[2025-07-04 07:51:32,925][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 231.9. Samples: 273872. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:32,925][06649] Avg episode reward: [(0, '5000.688')]
[36m[2025-07-04 07:51:37,929][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 262144. Throughput: 0: 229.7. Samples: 274496. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:37,929][06649] Avg episode reward: [(0, '4968.968')]
[36m[2025-07-04 07:51:42,958][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 225.8. Samples: 275888. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:42,959][06649] Avg episode reward: [(0, '4999.399')]
[36m[2025-07-04 07:51:47,928][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 223.8. Samples: 277184. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:47,928][06649] Avg episode reward: [(0, '4989.651')]
[36m[2025-07-04 07:51:52,977][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 262144. Throughput: 0: 223.2. Samples: 277872. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-04 07:51:52,977][06649] Avg episode reward: [(0, '4987.630')]
[36m[2025-07-04 07:51:57,940][06649] Fps is (10 sec: 1636.4, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 278528. Throughput: 0: 220.4. Samples: 279168. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:51:57,940][06649] Avg episode reward: [(0, '4925.749')]
[36m[2025-07-04 07:52:02,966][06649] Fps is (10 sec: 1640.2, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 221.0. Samples: 280544. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:02,966][06649] Avg episode reward: [(0, '4975.826')]
[36m[2025-07-04 07:52:07,925][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 223.4. Samples: 281216. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:07,925][06649] Avg episode reward: [(0, '4990.107')]
[36m[2025-07-04 07:52:12,969][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 225.9. Samples: 282624. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:12,970][06649] Avg episode reward: [(0, '4962.074')]
[36m[2025-07-04 07:52:17,963][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 225.2. Samples: 284016. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:17,963][06649] Avg episode reward: [(0, '4924.554')]
[36m[2025-07-04 07:52:22,929][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 227.2. Samples: 284720. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:22,929][06649] Avg episode reward: [(0, '4949.136')]
[36m[2025-07-04 07:52:27,966][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 227.2. Samples: 286112. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:27,966][06649] Avg episode reward: [(0, '4917.380')]
[36m[2025-07-04 07:52:33,036][06649] Fps is (10 sec: 0.0, 60 sec: 272.6, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 228.8. Samples: 287504. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:33,036][06649] Avg episode reward: [(0, '4904.018')]
[36m[2025-07-04 07:52:37,991][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 223.2. Samples: 287920. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:37,991][06649] Avg episode reward: [(0, '4978.531')]
[36m[2025-07-04 07:52:42,948][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 215.4. Samples: 288864. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:42,949][06649] Avg episode reward: [(0, '5007.188')]
[36m[2025-07-04 07:52:48,011][06649] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 203.5. Samples: 289712. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:48,011][06649] Avg episode reward: [(0, '4987.767')]
[36m[2025-07-04 07:52:52,933][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 200.1. Samples: 290224. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:52,934][06649] Avg episode reward: [(0, '4988.055')]
[36m[2025-07-04 07:52:57,929][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 191.5. Samples: 291232. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:52:57,930][06649] Avg episode reward: [(0, '5000.272')]
[36m[2025-07-04 07:53:02,932][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 188.6. Samples: 292496. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:53:02,932][06649] Avg episode reward: [(0, '4976.116')]
[36m[2025-07-04 07:53:08,012][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 187.7. Samples: 293184. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:53:08,012][06649] Avg episode reward: [(0, '4990.272')]
[33m[1319938 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[1319939 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.0986328125
[33mTimeout Rate: 0.9013671875 (navigation_task_gate.py:472)
[GIF] Episode 700 truncated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0007_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0007_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0007_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0007_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0007_merged_dual_camera.gif
[36m[2025-07-04 07:53:12,949][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 181.8. Samples: 294288. Policy #0 lag: (min: 26.0, avg: 26.0, max: 26.0)
[36m[2025-07-04 07:53:12,949][06649] Avg episode reward: [(0, '5045.662')]
[37m[1m[2025-07-04 07:53:13,027][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000544_278528.pth...
[36m[2025-07-04 07:53:13,031][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000288_147456.pth
[36m[2025-07-04 07:53:17,971][06649] Fps is (10 sec: 1645.1, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 177.7. Samples: 295488. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:53:17,972][06649] Avg episode reward: [(0, '5084.314')]
[36m[2025-07-04 07:53:22,946][06649] Fps is (10 sec: 1638.9, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 182.6. Samples: 296128. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:53:22,947][06649] Avg episode reward: [(0, '5119.114')]
[37m[1m[2025-07-04 07:53:23,032][06649] Saving new best policy, reward=5119.114!
[36m[2025-07-04 07:53:27,984][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 191.8. Samples: 297504. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:53:27,984][06649] Avg episode reward: [(0, '5071.447')]
[36m[2025-07-04 07:53:32,942][06649] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 203.0. Samples: 298832. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:53:32,943][06649] Avg episode reward: [(0, '5000.441')]
[36m[2025-07-04 07:53:37,931][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 206.2. Samples: 299504. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:53:37,931][06649] Avg episode reward: [(0, '5031.951')]
[36m[2025-07-04 07:53:42,959][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 210.0. Samples: 300688. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:53:42,960][06649] Avg episode reward: [(0, '5003.607')]
[36m[2025-07-04 07:53:47,954][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 211.5. Samples: 302016. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:53:47,954][06649] Avg episode reward: [(0, '5023.335')]
[36m[2025-07-04 07:53:52,973][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 211.4. Samples: 302688. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:53:52,973][06649] Avg episode reward: [(0, '5149.870')]
[37m[1m[2025-07-04 07:53:53,058][06649] Saving new best policy, reward=5149.870!
[36m[2025-07-04 07:53:57,992][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 216.3. Samples: 304032. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:53:57,993][06649] Avg episode reward: [(0, '5112.593')]
[36m[2025-07-04 07:54:02,966][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 218.3. Samples: 305312. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:54:02,966][06649] Avg episode reward: [(0, '5024.349')]
[36m[2025-07-04 07:54:07,970][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 220.0. Samples: 306032. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:54:07,971][06649] Avg episode reward: [(0, '5024.769')]
[36m[2025-07-04 07:54:12,978][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 220.1. Samples: 307408. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:54:12,978][06649] Avg episode reward: [(0, '4969.728')]
[36m[2025-07-04 07:54:17,948][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 221.1. Samples: 308784. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:54:17,948][06649] Avg episode reward: [(0, '4877.756')]
[36m[2025-07-04 07:54:22,978][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 221.3. Samples: 309472. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:54:22,978][06649] Avg episode reward: [(0, '4899.876')]
[36m[2025-07-04 07:54:27,975][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 294912. Throughput: 0: 224.6. Samples: 310800. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-04 07:54:27,975][06649] Avg episode reward: [(0, '4887.670')]
[36m[2025-07-04 07:54:32,971][06649] Fps is (10 sec: 1639.6, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 221.1. Samples: 311968. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:54:32,971][06649] Avg episode reward: [(0, '4831.266')]
[36m[2025-07-04 07:54:37,985][06649] Fps is (10 sec: 1636.7, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 219.3. Samples: 312560. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:54:37,986][06649] Avg episode reward: [(0, '4839.937')]
[36m[2025-07-04 07:54:42,950][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 216.0. Samples: 313744. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:54:42,950][06649] Avg episode reward: [(0, '4874.132')]
[36m[2025-07-04 07:54:47,936][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 217.7. Samples: 315104. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:54:47,936][06649] Avg episode reward: [(0, '4927.519')]
[36m[2025-07-04 07:54:52,979][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 213.3. Samples: 315632. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:54:52,979][06649] Avg episode reward: [(0, '4970.647')]
[36m[2025-07-04 07:54:57,941][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 211.7. Samples: 316928. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:54:57,941][06649] Avg episode reward: [(0, '5066.196')]
[36m[2025-07-04 07:55:02,923][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 209.2. Samples: 318192. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:55:02,923][06649] Avg episode reward: [(0, '5247.440')]
[37m[1m[2025-07-04 07:55:03,006][06649] Saving new best policy, reward=5247.440!
[36m[2025-07-04 07:55:07,926][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 209.0. Samples: 318864. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:55:07,926][06649] Avg episode reward: [(0, '5236.507')]
[36m[2025-07-04 07:55:12,924][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 208.2. Samples: 320160. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:55:12,925][06649] Avg episode reward: [(0, '5201.562')]
[37m[1m[2025-07-04 07:55:13,001][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000608_311296.pth...
[36m[2025-07-04 07:55:13,008][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000352_180224.pth
[36m[2025-07-04 07:55:17,946][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 211.0. Samples: 321456. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:55:17,947][06649] Avg episode reward: [(0, '5275.222')]
[37m[1m[2025-07-04 07:55:18,041][06649] Saving new best policy, reward=5275.222!
[36m[2025-07-04 07:55:23,009][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 212.5. Samples: 322128. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:55:23,009][06649] Avg episode reward: [(0, '5290.325')]
[37m[1m[2025-07-04 07:55:23,095][06649] Saving new best policy, reward=5290.325!
[36m[2025-07-04 07:55:27,947][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 215.1. Samples: 323424. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:55:27,947][06649] Avg episode reward: [(0, '5239.457')]
[36m[2025-07-04 07:55:32,975][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 214.9. Samples: 324784. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:55:32,975][06649] Avg episode reward: [(0, '5227.451')]
[36m[2025-07-04 07:55:37,980][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 311296. Throughput: 0: 217.6. Samples: 325424. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:55:37,980][06649] Avg episode reward: [(0, '5128.958')]
[36m[2025-07-04 07:55:42,953][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 311296. Throughput: 0: 218.6. Samples: 326768. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-04 07:55:42,953][06649] Avg episode reward: [(0, '5169.350')]
[36m[2025-07-04 07:55:47,922][06649] Fps is (10 sec: 1647.8, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 218.7. Samples: 328032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:55:47,923][06649] Avg episode reward: [(0, '5114.690')]
[36m[2025-07-04 07:55:52,989][06649] Fps is (10 sec: 1632.5, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 217.3. Samples: 328656. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:55:52,990][06649] Avg episode reward: [(0, '5154.364')]
[36m[2025-07-04 07:55:57,974][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 218.8. Samples: 330016. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:55:57,974][06649] Avg episode reward: [(0, '5167.576')]
[36m[2025-07-04 07:56:02,958][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 220.4. Samples: 331376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:02,958][06649] Avg episode reward: [(0, '5191.435')]
[36m[2025-07-04 07:56:07,946][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 221.5. Samples: 332080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:07,946][06649] Avg episode reward: [(0, '5144.748')]
[36m[2025-07-04 07:56:12,974][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 222.1. Samples: 333424. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:12,974][06649] Avg episode reward: [(0, '5242.474')]
[36m[2025-07-04 07:56:17,925][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 222.5. Samples: 334784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:17,925][06649] Avg episode reward: [(0, '5191.108')]
[36m[2025-07-04 07:56:22,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 221.0. Samples: 335360. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:22,932][06649] Avg episode reward: [(0, '5161.825')]
[36m[2025-07-04 07:56:27,971][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 217.5. Samples: 336560. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:27,971][06649] Avg episode reward: [(0, '5108.854')]
[36m[2025-07-04 07:56:32,938][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 218.6. Samples: 337872. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:32,939][06649] Avg episode reward: [(0, '5033.029')]
[36m[2025-07-04 07:56:37,978][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 219.4. Samples: 338528. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:37,978][06649] Avg episode reward: [(0, '5066.500')]
[36m[2025-07-04 07:56:42,917][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 221.1. Samples: 339952. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:42,917][06649] Avg episode reward: [(0, '4987.480')]
[36m[2025-07-04 07:56:47,972][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 217.2. Samples: 341152. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:47,972][06649] Avg episode reward: [(0, '4985.607')]
[36m[2025-07-04 07:56:52,922][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 327680. Throughput: 0: 215.6. Samples: 341776. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:52,922][06649] Avg episode reward: [(0, '4929.187')]
[36m[2025-07-04 07:56:57,944][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 327680. Throughput: 0: 216.7. Samples: 343168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:56:57,944][06649] Avg episode reward: [(0, '4967.220')]
[36m[2025-07-04 07:57:02,971][06649] Fps is (10 sec: 1630.3, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 344064. Throughput: 0: 215.6. Samples: 344496. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:02,972][06649] Avg episode reward: [(0, '4966.208')]
[36m[2025-07-04 07:57:07,957][06649] Fps is (10 sec: 1636.3, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 218.2. Samples: 345184. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:07,957][06649] Avg episode reward: [(0, '5011.396')]
[36m[2025-07-04 07:57:12,985][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 344064. Throughput: 0: 222.9. Samples: 346592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:12,985][06649] Avg episode reward: [(0, '5071.926')]
[37m[1m[2025-07-04 07:57:12,989][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000672_344064.pth...
[36m[2025-07-04 07:57:12,996][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000416_212992.pth
[36m[2025-07-04 07:57:17,966][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 344064. Throughput: 0: 222.8. Samples: 347904. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:17,967][06649] Avg episode reward: [(0, '5080.776')]
[36m[2025-07-04 07:57:22,930][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 222.8. Samples: 348544. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:22,930][06649] Avg episode reward: [(0, '5013.698')]
[36m[2025-07-04 07:57:27,955][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 215.6. Samples: 349664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:27,956][06649] Avg episode reward: [(0, '5073.113')]
[36m[2025-07-04 07:57:32,957][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 211.3. Samples: 350656. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:32,957][06649] Avg episode reward: [(0, '5028.934')]
[36m[2025-07-04 07:57:37,928][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 208.3. Samples: 351152. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:37,929][06649] Avg episode reward: [(0, '5136.962')]
[36m[2025-07-04 07:57:42,978][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 199.7. Samples: 352160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:42,978][06649] Avg episode reward: [(0, '5136.466')]
[36m[2025-07-04 07:57:47,956][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 344064. Throughput: 0: 192.1. Samples: 353136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:47,956][06649] Avg episode reward: [(0, '5156.286')]
[36m[2025-07-04 07:57:52,926][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 187.5. Samples: 353616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:52,927][06649] Avg episode reward: [(0, '5176.355')]
[36m[2025-07-04 07:57:58,106][06649] Fps is (10 sec: 0.0, 60 sec: 272.3, 300 sec: 222.0). Total num frames: 344064. Throughput: 0: 175.9. Samples: 354528. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:57:58,107][06649] Avg episode reward: [(0, '5158.700')]
[36m[2025-07-04 07:58:02,955][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 168.6. Samples: 355488. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:02,955][06649] Avg episode reward: [(0, '5150.385')]
[36m[2025-07-04 07:58:07,936][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 166.4. Samples: 356032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:07,936][06649] Avg episode reward: [(0, '5144.310')]
[36m[2025-07-04 07:58:12,922][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 344064. Throughput: 0: 166.2. Samples: 357136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:12,922][06649] Avg episode reward: [(0, '5115.652')]
[36m[2025-07-04 07:58:17,945][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 344064. Throughput: 0: 169.3. Samples: 358272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:17,945][06649] Avg episode reward: [(0, '5174.534')]
[36m[2025-07-04 07:58:22,997][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 344064. Throughput: 0: 167.9. Samples: 358720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:22,998][06649] Avg episode reward: [(0, '5163.838')]
[36m[2025-07-04 07:58:27,984][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 344064. Throughput: 0: 168.5. Samples: 359744. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:27,984][06649] Avg episode reward: [(0, '5206.303')]
[36m[2025-07-04 07:58:32,988][06649] Fps is (10 sec: 1639.9, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 167.3. Samples: 360672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:32,988][06649] Avg episode reward: [(0, '5172.083')]
[36m[2025-07-04 07:58:37,966][06649] Fps is (10 sec: 1641.3, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 168.0. Samples: 361184. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:37,966][06649] Avg episode reward: [(0, '5181.065')]
[36m[2025-07-04 07:58:42,975][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 172.6. Samples: 362272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:42,975][06649] Avg episode reward: [(0, '5030.124')]
[36m[2025-07-04 07:58:47,981][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 174.5. Samples: 363344. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:47,981][06649] Avg episode reward: [(0, '5047.491')]
[36m[2025-07-04 07:58:52,921][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 174.6. Samples: 363888. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:52,921][06649] Avg episode reward: [(0, '5008.298')]
[36m[2025-07-04 07:58:57,973][06649] Fps is (10 sec: 0.0, 60 sec: 273.7, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 171.9. Samples: 364880. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:58:57,973][06649] Avg episode reward: [(0, '4936.580')]
[36m[2025-07-04 07:59:02,926][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 169.0. Samples: 365872. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:02,926][06649] Avg episode reward: [(0, '4948.647')]
[36m[2025-07-04 07:59:07,998][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 171.4. Samples: 366432. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:07,998][06649] Avg episode reward: [(0, '5009.599')]
[36m[2025-07-04 07:59:12,949][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 172.9. Samples: 367520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:12,950][06649] Avg episode reward: [(0, '4962.412')]
[37m[1m[2025-07-04 07:59:13,032][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000704_360448.pth...
[36m[2025-07-04 07:59:13,039][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000448_229376.pth
[36m[2025-07-04 07:59:17,978][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 178.5. Samples: 368704. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:17,979][06649] Avg episode reward: [(0, '4967.056')]
[36m[2025-07-04 07:59:22,983][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 179.1. Samples: 369248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:22,983][06649] Avg episode reward: [(0, '5005.924')]
[36m[2025-07-04 07:59:27,989][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 360448. Throughput: 0: 179.5. Samples: 370352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:27,989][06649] Avg episode reward: [(0, '5013.170')]
[36m[2025-07-04 07:59:32,968][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 360448. Throughput: 0: 180.3. Samples: 371456. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:32,968][06649] Avg episode reward: [(0, '5004.566')]
[36m[2025-07-04 07:59:38,048][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 360448. Throughput: 0: 179.8. Samples: 372000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:38,049][06649] Avg episode reward: [(0, '5181.474')]
[36m[2025-07-04 07:59:42,959][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 360448. Throughput: 0: 181.7. Samples: 373056. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:42,959][06649] Avg episode reward: [(0, '5217.806')]
[36m[2025-07-04 07:59:48,108][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.5). Total num frames: 360448. Throughput: 0: 179.9. Samples: 374000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:48,108][06649] Avg episode reward: [(0, '5239.507')]
[36m[2025-07-04 07:59:52,951][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 360448. Throughput: 0: 176.5. Samples: 374368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:52,951][06649] Avg episode reward: [(0, '5208.296')]
[36m[2025-07-04 07:59:57,977][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 360448. Throughput: 0: 173.4. Samples: 375328. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 07:59:57,977][06649] Avg episode reward: [(0, '5213.660')]
[36m[2025-07-04 08:00:02,957][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 360448. Throughput: 0: 175.7. Samples: 376608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:00:02,957][06649] Avg episode reward: [(0, '5217.775')]
[36m[2025-07-04 08:00:08,119][06649] Fps is (10 sec: 1615.5, 60 sec: 272.5, 300 sec: 222.0). Total num frames: 376832. Throughput: 0: 174.4. Samples: 377120. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:08,119][06649] Avg episode reward: [(0, '5203.884')]
[36m[2025-07-04 08:00:12,960][06649] Fps is (10 sec: 1637.9, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 162.6. Samples: 377664. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:12,960][06649] Avg episode reward: [(0, '5151.972')]
[36m[2025-07-04 08:00:17,944][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 376832. Throughput: 0: 154.7. Samples: 378416. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:17,944][06649] Avg episode reward: [(0, '5142.242')]
[36m[2025-07-04 08:00:23,003][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 154.5. Samples: 378944. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:23,003][06649] Avg episode reward: [(0, '4999.511')]
[36m[2025-07-04 08:00:27,977][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 376832. Throughput: 0: 160.3. Samples: 380272. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:27,977][06649] Avg episode reward: [(0, '4941.033')]
[36m[2025-07-04 08:00:32,919][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 376832. Throughput: 0: 170.3. Samples: 381632. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:32,920][06649] Avg episode reward: [(0, '4854.106')]
[36m[2025-07-04 08:00:37,974][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 174.8. Samples: 382240. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:37,974][06649] Avg episode reward: [(0, '4793.279')]
[36m[2025-07-04 08:00:42,946][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 376832. Throughput: 0: 180.7. Samples: 383456. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:42,946][06649] Avg episode reward: [(0, '4756.460')]
[36m[2025-07-04 08:00:47,972][06649] Fps is (10 sec: 0.0, 60 sec: 273.7, 300 sec: 166.6). Total num frames: 376832. Throughput: 0: 179.5. Samples: 384688. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:47,972][06649] Avg episode reward: [(0, '4710.902')]
[36m[2025-07-04 08:00:52,978][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 376832. Throughput: 0: 183.0. Samples: 385328. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:52,978][06649] Avg episode reward: [(0, '4599.726')]
[36m[2025-07-04 08:00:57,982][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 376832. Throughput: 0: 197.9. Samples: 386576. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:00:57,983][06649] Avg episode reward: [(0, '4511.507')]
[36m[2025-07-04 08:01:02,935][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 376832. Throughput: 0: 205.6. Samples: 387664. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:01:02,935][06649] Avg episode reward: [(0, '4508.888')]
[36m[2025-07-04 08:01:07,956][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 376832. Throughput: 0: 204.3. Samples: 388128. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:01:07,957][06649] Avg episode reward: [(0, '4549.291')]
[36m[2025-07-04 08:01:12,962][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 376832. Throughput: 0: 198.1. Samples: 389184. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:01:12,963][06649] Avg episode reward: [(0, '4578.273')]
[37m[1m[2025-07-04 08:01:13,045][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000736_376832.pth...
[36m[2025-07-04 08:01:13,049][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000512_262144.pth
[36m[2025-07-04 08:01:17,926][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 376832. Throughput: 0: 195.9. Samples: 390448. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:01:17,926][06649] Avg episode reward: [(0, '4549.705')]
[36m[2025-07-04 08:01:22,999][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 376832. Throughput: 0: 195.4. Samples: 391040. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:01:23,000][06649] Avg episode reward: [(0, '4572.884')]
[36m[2025-07-04 08:01:27,921][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 376832. Throughput: 0: 195.7. Samples: 392256. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:01:27,922][06649] Avg episode reward: [(0, '4506.330')]
[33m[1821297 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[1821297 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.0791015625
[33mTimeout Rate: 0.9208984375 (navigation_task_gate.py:472)
[36m[2025-07-04 08:01:32,931][06649] Fps is (10 sec: 1649.7, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 393216. Throughput: 0: 189.7. Samples: 393216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:01:32,931][06649] Avg episode reward: [(0, '4445.171')]
[36m[2025-07-04 08:01:38,095][06649] Fps is (10 sec: 1610.4, 60 sec: 272.5, 300 sec: 222.0). Total num frames: 393216. Throughput: 0: 184.4. Samples: 393648. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:01:38,096][06649] Avg episode reward: [(0, '4446.920')]
[36m[2025-07-04 08:01:42,961][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 393216. Throughput: 0: 177.9. Samples: 394576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:01:42,961][06649] Avg episode reward: [(0, '4511.912')]
[36m[2025-07-04 08:01:47,993][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 393216. Throughput: 0: 175.8. Samples: 395584. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:01:47,994][06649] Avg episode reward: [(0, '4564.847')]
[36m[2025-07-04 08:01:52,971][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 393216. Throughput: 0: 178.1. Samples: 396144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:01:52,972][06649] Avg episode reward: [(0, '4479.285')]
[36m[2025-07-04 08:01:57,947][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 176.1. Samples: 397104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:01:57,948][06649] Avg episode reward: [(0, '4519.392')]
[36m[2025-07-04 08:02:02,924][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 169.6. Samples: 398080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:02,924][06649] Avg episode reward: [(0, '4495.763')]
[36m[2025-07-04 08:02:07,999][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 168.2. Samples: 398608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:07,999][06649] Avg episode reward: [(0, '4529.468')]
[36m[2025-07-04 08:02:12,982][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 163.3. Samples: 399616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:12,982][06649] Avg episode reward: [(0, '4610.289')]
[36m[2025-07-04 08:02:17,918][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 164.3. Samples: 400608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:17,918][06649] Avg episode reward: [(0, '4426.798')]
[36m[2025-07-04 08:02:23,008][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 167.1. Samples: 401152. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:23,008][06649] Avg episode reward: [(0, '4425.761')]
[36m[2025-07-04 08:02:27,942][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 166.8. Samples: 402080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:27,942][06649] Avg episode reward: [(0, '4379.308')]
[36m[2025-07-04 08:02:33,021][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 165.9. Samples: 403056. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:33,021][06649] Avg episode reward: [(0, '4304.538')]
[36m[2025-07-04 08:02:37,937][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 163.3. Samples: 403488. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:37,937][06649] Avg episode reward: [(0, '4351.090')]
[36m[2025-07-04 08:02:43,003][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 164.4. Samples: 404512. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:43,003][06649] Avg episode reward: [(0, '4333.760')]
[36m[2025-07-04 08:02:47,930][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 165.7. Samples: 405536. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:47,931][06649] Avg episode reward: [(0, '4412.173')]
[36m[2025-07-04 08:02:52,964][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 393216. Throughput: 0: 164.0. Samples: 405984. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:52,964][06649] Avg episode reward: [(0, '4325.548')]
[36m[2025-07-04 08:02:58,000][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 163.8. Samples: 406992. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:02:58,001][06649] Avg episode reward: [(0, '4214.367')]
[36m[2025-07-04 08:03:02,922][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 165.3. Samples: 408048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:03:02,922][06649] Avg episode reward: [(0, '4124.561')]
[36m[2025-07-04 08:03:07,917][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 393216. Throughput: 0: 165.3. Samples: 408576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:03:07,918][06649] Avg episode reward: [(0, '4163.058')]
[36m[2025-07-04 08:03:12,994][06649] Fps is (10 sec: 1626.7, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 409600. Throughput: 0: 167.6. Samples: 409632. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:03:12,994][06649] Avg episode reward: [(0, '4163.741')]
[37m[1m[2025-07-04 08:03:13,085][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000800_409600.pth...
[36m[2025-07-04 08:03:13,090][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000544_278528.pth
[36m[2025-07-04 08:03:17,974][06649] Fps is (10 sec: 1629.2, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 170.1. Samples: 410704. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:03:17,974][06649] Avg episode reward: [(0, '4158.563')]
[36m[2025-07-04 08:03:22,984][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 173.3. Samples: 411296. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:03:22,985][06649] Avg episode reward: [(0, '4212.766')]
[36m[2025-07-04 08:03:27,968][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 175.4. Samples: 412400. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:03:27,969][06649] Avg episode reward: [(0, '4185.957')]
[36m[2025-07-04 08:03:32,987][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 176.5. Samples: 413488. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:03:32,987][06649] Avg episode reward: [(0, '4141.589')]
[36m[2025-07-04 08:03:37,939][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 179.7. Samples: 414064. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:03:37,940][06649] Avg episode reward: [(0, '4070.437')]
[36m[2025-07-04 08:03:42,980][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 185.3. Samples: 415328. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:03:42,980][06649] Avg episode reward: [(0, '4081.381')]
[36m[2025-07-04 08:03:47,976][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 188.9. Samples: 416560. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:03:47,977][06649] Avg episode reward: [(0, '4089.576')]
[36m[2025-07-04 08:03:53,018][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 190.5. Samples: 417168. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:03:53,019][06649] Avg episode reward: [(0, '4093.610')]
[36m[2025-07-04 08:03:58,061][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.5). Total num frames: 409600. Throughput: 0: 192.4. Samples: 418304. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:03:58,062][06649] Avg episode reward: [(0, '4117.431')]
[36m[2025-07-04 08:04:03,012][06649] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 188.6. Samples: 419200. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:04:03,012][06649] Avg episode reward: [(0, '4036.251')]
[36m[2025-07-04 08:04:07,918][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 187.3. Samples: 419712. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:04:07,918][06649] Avg episode reward: [(0, '3998.952')]
[36m[2025-07-04 08:04:12,975][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 184.5. Samples: 420704. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:04:12,975][06649] Avg episode reward: [(0, '4023.600')]
[36m[2025-07-04 08:04:17,931][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 181.2. Samples: 421632. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:04:17,931][06649] Avg episode reward: [(0, '3983.614')]
[36m[2025-07-04 08:04:22,920][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 409600. Throughput: 0: 178.9. Samples: 422112. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:04:22,921][06649] Avg episode reward: [(0, '4032.688')]
[36m[2025-07-04 08:04:27,996][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 174.5. Samples: 423184. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:04:27,996][06649] Avg episode reward: [(0, '4076.640')]
[36m[2025-07-04 08:04:33,032][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 170.8. Samples: 424256. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:04:33,032][06649] Avg episode reward: [(0, '4035.979')]
[36m[2025-07-04 08:04:37,973][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 409600. Throughput: 0: 168.7. Samples: 424752. Policy #0 lag: (min: 30.0, avg: 30.0, max: 30.0)
[36m[2025-07-04 08:04:37,974][06649] Avg episode reward: [(0, '4229.678')]
[36m[2025-07-04 08:04:42,950][06649] Fps is (10 sec: 1652.0, 60 sec: 273.2, 300 sec: 222.3). Total num frames: 425984. Throughput: 0: 167.5. Samples: 425824. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:04:42,950][06649] Avg episode reward: [(0, '4025.872')]
[36m[2025-07-04 08:04:47,943][06649] Fps is (10 sec: 1643.3, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 425984. Throughput: 0: 171.6. Samples: 426912. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:04:47,944][06649] Avg episode reward: [(0, '4028.359')]
[36m[2025-07-04 08:04:52,945][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 425984. Throughput: 0: 173.8. Samples: 427536. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:04:52,946][06649] Avg episode reward: [(0, '4157.708')]
[36m[2025-07-04 08:04:57,968][06649] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 222.1). Total num frames: 425984. Throughput: 0: 175.3. Samples: 428592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:04:57,968][06649] Avg episode reward: [(0, '4192.572')]
[36m[2025-07-04 08:05:03,015][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.7). Total num frames: 425984. Throughput: 0: 174.6. Samples: 429504. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:03,016][06649] Avg episode reward: [(0, '4192.742')]
[36m[2025-07-04 08:05:08,013][06649] Fps is (10 sec: 0.0, 60 sec: 272.6, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 174.6. Samples: 429984. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:08,013][06649] Avg episode reward: [(0, '4212.363')]
[36m[2025-07-04 08:05:12,931][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 169.1. Samples: 430784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:12,931][06649] Avg episode reward: [(0, '4293.749')]
[37m[1m[2025-07-04 08:05:13,050][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000832_425984.pth...
[36m[2025-07-04 08:05:13,055][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000608_311296.pth
[36m[2025-07-04 08:05:17,999][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 164.4. Samples: 431648. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:17,999][06649] Avg episode reward: [(0, '4199.516')]
[36m[2025-07-04 08:05:22,976][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 164.6. Samples: 432160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:22,976][06649] Avg episode reward: [(0, '4172.541')]
[36m[2025-07-04 08:05:28,014][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 161.2. Samples: 433088. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:28,015][06649] Avg episode reward: [(0, '4076.113')]
[36m[2025-07-04 08:05:33,005][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 159.1. Samples: 434080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:33,006][06649] Avg episode reward: [(0, '4080.618')]
[36m[2025-07-04 08:05:37,962][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 155.3. Samples: 434528. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:37,963][06649] Avg episode reward: [(0, '4252.111')]
[36m[2025-07-04 08:05:42,983][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 153.2. Samples: 435488. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:42,983][06649] Avg episode reward: [(0, '4271.332')]
[36m[2025-07-04 08:05:47,930][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 156.7. Samples: 436544. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:47,930][06649] Avg episode reward: [(0, '4380.113')]
[36m[2025-07-04 08:05:52,930][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 158.2. Samples: 437088. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:52,930][06649] Avg episode reward: [(0, '4293.935')]
[36m[2025-07-04 08:05:58,004][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 164.7. Samples: 438208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:05:58,004][06649] Avg episode reward: [(0, '4299.298')]
[36m[2025-07-04 08:06:02,937][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 168.4. Samples: 439216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:02,938][06649] Avg episode reward: [(0, '4397.005')]
[36m[2025-07-04 08:06:07,918][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 169.1. Samples: 439760. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:07,922][06649] Avg episode reward: [(0, '4357.760')]
[36m[2025-07-04 08:06:12,986][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 425984. Throughput: 0: 171.8. Samples: 440816. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:12,986][06649] Avg episode reward: [(0, '4479.580')]
[36m[2025-07-04 08:06:17,921][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 425984. Throughput: 0: 173.8. Samples: 441888. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:17,922][06649] Avg episode reward: [(0, '4498.345')]
[36m[2025-07-04 08:06:23,001][06649] Fps is (10 sec: 1635.9, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 442368. Throughput: 0: 173.7. Samples: 442352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:23,002][06649] Avg episode reward: [(0, '4540.254')]
[36m[2025-07-04 08:06:27,926][06649] Fps is (10 sec: 1637.7, 60 sec: 273.5, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 176.2. Samples: 443408. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:27,926][06649] Avg episode reward: [(0, '4576.379')]
[36m[2025-07-04 08:06:32,922][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 166.7). Total num frames: 442368. Throughput: 0: 173.9. Samples: 444368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:32,922][06649] Avg episode reward: [(0, '4604.833')]
[36m[2025-07-04 08:06:37,952][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 173.1. Samples: 444880. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:37,952][06649] Avg episode reward: [(0, '4598.250')]
[36m[2025-07-04 08:06:42,995][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 172.1. Samples: 445952. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:42,995][06649] Avg episode reward: [(0, '4567.400')]
[36m[2025-07-04 08:06:48,027][06649] Fps is (10 sec: 0.0, 60 sec: 272.6, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 172.5. Samples: 446992. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:48,028][06649] Avg episode reward: [(0, '4677.625')]
[GIF] Episode 800 truncated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0008_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0008_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0008_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0008_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0008_merged_dual_camera.gif
[36m[2025-07-04 08:06:53,406][06649] Fps is (10 sec: 0.0, 60 sec: 270.9, 300 sec: 166.4). Total num frames: 442368. Throughput: 0: 170.6. Samples: 447520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:53,406][06649] Avg episode reward: [(0, '4659.578')]
[36m[2025-07-04 08:06:57,951][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 170.4. Samples: 448480. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:06:57,951][06649] Avg episode reward: [(0, '4683.459')]
[36m[2025-07-04 08:07:02,926][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.7). Total num frames: 442368. Throughput: 0: 170.6. Samples: 449568. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:02,926][06649] Avg episode reward: [(0, '4744.920')]
[36m[2025-07-04 08:07:07,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 172.4. Samples: 450096. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:07,932][06649] Avg episode reward: [(0, '4833.651')]
[36m[2025-07-04 08:07:13,006][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 173.2. Samples: 451216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:13,006][06649] Avg episode reward: [(0, '4868.264')]
[37m[1m[2025-07-04 08:07:13,132][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000864_442368.pth...
[36m[2025-07-04 08:07:13,137][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000672_344064.pth
[36m[2025-07-04 08:07:17,918][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.7). Total num frames: 442368. Throughput: 0: 173.9. Samples: 452192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:17,918][06649] Avg episode reward: [(0, '4751.698')]
[36m[2025-07-04 08:07:22,921][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 175.4. Samples: 452768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:22,921][06649] Avg episode reward: [(0, '4701.916')]
[36m[2025-07-04 08:07:27,993][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 175.3. Samples: 453840. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:27,993][06649] Avg episode reward: [(0, '4737.531')]
[36m[2025-07-04 08:07:32,929][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 174.2. Samples: 454816. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:32,929][06649] Avg episode reward: [(0, '4661.243')]
[36m[2025-07-04 08:07:37,963][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 176.3. Samples: 455376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:37,963][06649] Avg episode reward: [(0, '4618.759')]
[36m[2025-07-04 08:07:42,935][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 174.6. Samples: 456336. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:42,936][06649] Avg episode reward: [(0, '4546.898')]
[36m[2025-07-04 08:07:47,933][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 173.8. Samples: 457392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:47,933][06649] Avg episode reward: [(0, '4537.547')]
[36m[2025-07-04 08:07:53,006][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 442368. Throughput: 0: 172.9. Samples: 457888. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:53,007][06649] Avg episode reward: [(0, '4533.433')]
[36m[2025-07-04 08:07:57,932][06649] Fps is (10 sec: 1638.5, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 458752. Throughput: 0: 170.2. Samples: 458864. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:07:57,932][06649] Avg episode reward: [(0, '4501.074')]
[36m[2025-07-04 08:08:02,971][06649] Fps is (10 sec: 1644.1, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 458752. Throughput: 0: 174.4. Samples: 460048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:02,972][06649] Avg episode reward: [(0, '4528.953')]
[36m[2025-07-04 08:08:08,010][06649] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 175.3. Samples: 460672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:08,010][06649] Avg episode reward: [(0, '4700.252')]
[36m[2025-07-04 08:08:12,945][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 175.1. Samples: 461712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:12,945][06649] Avg episode reward: [(0, '4529.334')]
[36m[2025-07-04 08:08:17,962][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 176.2. Samples: 462752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:17,962][06649] Avg episode reward: [(0, '4545.087')]
[36m[2025-07-04 08:08:22,942][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 175.7. Samples: 463280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:22,942][06649] Avg episode reward: [(0, '4599.132')]
[36m[2025-07-04 08:08:28,011][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 178.2. Samples: 464368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:28,011][06649] Avg episode reward: [(0, '4661.025')]
[36m[2025-07-04 08:08:32,995][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 180.7. Samples: 465536. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:32,995][06649] Avg episode reward: [(0, '4860.988')]
[36m[2025-07-04 08:08:37,946][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 181.6. Samples: 466048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:37,946][06649] Avg episode reward: [(0, '4844.317')]
[36m[2025-07-04 08:08:42,951][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 181.6. Samples: 467040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:42,952][06649] Avg episode reward: [(0, '4923.349')]
[36m[2025-07-04 08:08:47,960][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 178.5. Samples: 468080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:47,961][06649] Avg episode reward: [(0, '4897.111')]
[36m[2025-07-04 08:08:52,951][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.7). Total num frames: 458752. Throughput: 0: 176.9. Samples: 468624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:52,951][06649] Avg episode reward: [(0, '4812.227')]
[36m[2025-07-04 08:08:57,952][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 458752. Throughput: 0: 176.0. Samples: 469632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:08:57,952][06649] Avg episode reward: [(0, '4929.912')]
[36m[2025-07-04 08:09:02,929][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 177.6. Samples: 470736. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:09:02,929][06649] Avg episode reward: [(0, '4958.578')]
[36m[2025-07-04 08:09:07,961][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 176.6. Samples: 471232. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:09:07,961][06649] Avg episode reward: [(0, '4935.106')]
[36m[2025-07-04 08:09:12,943][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 177.0. Samples: 472320. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:09:12,943][06649] Avg episode reward: [(0, '4873.627')]
[37m[1m[2025-07-04 08:09:13,082][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000896_458752.pth...
[36m[2025-07-04 08:09:13,087][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000704_360448.pth
[36m[2025-07-04 08:09:17,966][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 176.5. Samples: 473472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:09:17,966][06649] Avg episode reward: [(0, '4919.194')]
[36m[2025-07-04 08:09:22,994][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 177.6. Samples: 474048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:09:22,994][06649] Avg episode reward: [(0, '4814.465')]
[36m[2025-07-04 08:09:27,976][06649] Fps is (10 sec: 1636.7, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 475136. Throughput: 0: 180.5. Samples: 475168. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:09:27,976][06649] Avg episode reward: [(0, '4880.139')]
[36m[2025-07-04 08:09:32,926][06649] Fps is (10 sec: 1649.6, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 475136. Throughput: 0: 182.5. Samples: 476288. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:09:32,926][06649] Avg episode reward: [(0, '4876.745')]
[36m[2025-07-04 08:09:38,030][06649] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 182.1. Samples: 476832. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:09:38,030][06649] Avg episode reward: [(0, '4980.028')]
[36m[2025-07-04 08:09:42,963][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 182.7. Samples: 477856. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:09:42,963][06649] Avg episode reward: [(0, '5044.328')]
[36m[2025-07-04 08:09:48,027][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 179.5. Samples: 478832. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:09:48,027][06649] Avg episode reward: [(0, '5114.978')]
[36m[2025-07-04 08:09:52,941][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 181.8. Samples: 479408. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:09:52,941][06649] Avg episode reward: [(0, '5147.051')]
[36m[2025-07-04 08:09:57,973][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 183.7. Samples: 480592. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:09:57,973][06649] Avg episode reward: [(0, '5257.441')]
[36m[2025-07-04 08:10:03,052][06649] Fps is (10 sec: 0.0, 60 sec: 272.5, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 180.6. Samples: 481616. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:03,053][06649] Avg episode reward: [(0, '5294.886')]
[37m[1m[2025-07-04 08:10:03,218][06649] Saving new best policy, reward=5294.886!
[36m[2025-07-04 08:10:07,979][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 180.0. Samples: 482144. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:07,980][06649] Avg episode reward: [(0, '5372.096')]
[37m[1m[2025-07-04 08:10:08,058][06649] Saving new best policy, reward=5372.096!
[36m[2025-07-04 08:10:12,984][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 177.7. Samples: 483168. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:12,985][06649] Avg episode reward: [(0, '5406.750')]
[37m[1m[2025-07-04 08:10:13,057][06649] Saving new best policy, reward=5406.750!
[36m[2025-07-04 08:10:17,962][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 175.9. Samples: 484208. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:17,962][06649] Avg episode reward: [(0, '5426.192')]
[37m[1m[2025-07-04 08:10:18,036][06649] Saving new best policy, reward=5426.192!
[36m[2025-07-04 08:10:23,006][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 176.4. Samples: 484768. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:23,007][06649] Avg episode reward: [(0, '5410.879')]
[36m[2025-07-04 08:10:27,948][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 176.1. Samples: 485776. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:27,949][06649] Avg episode reward: [(0, '5324.133')]
[33m[2361349 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[2361349 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.177734375
[33mTimeout Rate: 0.822265625 (navigation_task_gate.py:472)
[36m[2025-07-04 08:10:32,971][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 178.4. Samples: 486848. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:32,972][06649] Avg episode reward: [(0, '5261.277')]
[36m[2025-07-04 08:10:37,929][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 177.5. Samples: 487392. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:37,929][06649] Avg episode reward: [(0, '5208.023')]
[36m[2025-07-04 08:10:42,971][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 177.1. Samples: 488560. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:42,972][06649] Avg episode reward: [(0, '5249.609')]
[36m[2025-07-04 08:10:47,935][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 177.9. Samples: 489600. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:47,935][06649] Avg episode reward: [(0, '5219.071')]
[36m[2025-07-04 08:10:52,971][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 178.5. Samples: 490176. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:52,971][06649] Avg episode reward: [(0, '5124.163')]
[36m[2025-07-04 08:10:57,986][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 178.8. Samples: 491216. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-04 08:10:57,987][06649] Avg episode reward: [(0, '5080.102')]
[36m[2025-07-04 08:11:02,965][06649] Fps is (10 sec: 1639.4, 60 sec: 273.5, 300 sec: 222.1). Total num frames: 491520. Throughput: 0: 177.4. Samples: 492192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:02,965][06649] Avg episode reward: [(0, '5075.990')]
[36m[2025-07-04 08:11:07,926][06649] Fps is (10 sec: 1648.3, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 177.7. Samples: 492752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:07,926][06649] Avg episode reward: [(0, '5041.548')]
[36m[2025-07-04 08:11:13,003][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 491520. Throughput: 0: 180.8. Samples: 493920. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:13,003][06649] Avg episode reward: [(0, '5103.084')]
[37m[1m[2025-07-04 08:11:13,082][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000960_491520.pth...
[36m[2025-07-04 08:11:13,088][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000736_376832.pth
[36m[2025-07-04 08:11:18,005][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 184.8. Samples: 495168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:18,005][06649] Avg episode reward: [(0, '5154.520')]
[36m[2025-07-04 08:11:22,919][06649] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 185.3. Samples: 495728. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:22,919][06649] Avg episode reward: [(0, '5236.960')]
[36m[2025-07-04 08:11:27,972][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 182.8. Samples: 496784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:27,972][06649] Avg episode reward: [(0, '5261.540')]
[36m[2025-07-04 08:11:33,013][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 183.1. Samples: 497856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:33,013][06649] Avg episode reward: [(0, '5215.227')]
[36m[2025-07-04 08:11:38,019][06649] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 180.4. Samples: 498304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:38,019][06649] Avg episode reward: [(0, '5219.338')]
[36m[2025-07-04 08:11:43,004][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 181.6. Samples: 499392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:43,004][06649] Avg episode reward: [(0, '5176.157')]
[36m[2025-07-04 08:11:47,946][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.9). Total num frames: 491520. Throughput: 0: 184.6. Samples: 500496. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:47,946][06649] Avg episode reward: [(0, '5198.867')]
[36m[2025-07-04 08:11:53,024][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 185.2. Samples: 501104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:53,024][06649] Avg episode reward: [(0, '5089.330')]
[36m[2025-07-04 08:11:57,937][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 183.0. Samples: 502144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:11:57,937][06649] Avg episode reward: [(0, '5145.261')]
[36m[2025-07-04 08:12:02,960][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 178.0. Samples: 503168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:12:02,960][06649] Avg episode reward: [(0, '5137.947')]
[36m[2025-07-04 08:12:07,995][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 175.3. Samples: 503632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:12:07,996][06649] Avg episode reward: [(0, '5109.321')]
[36m[2025-07-04 08:12:12,932][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 177.6. Samples: 504768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:12:12,932][06649] Avg episode reward: [(0, '5022.574')]
[36m[2025-07-04 08:12:17,923][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 178.5. Samples: 505872. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:12:17,923][06649] Avg episode reward: [(0, '5012.239')]
[36m[2025-07-04 08:12:22,996][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 182.1. Samples: 506496. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:12:22,996][06649] Avg episode reward: [(0, '4995.061')]
[36m[2025-07-04 08:12:27,966][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 181.5. Samples: 507552. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:12:27,966][06649] Avg episode reward: [(0, '4981.069')]
[36m[2025-07-04 08:12:32,948][06649] Fps is (10 sec: 1646.2, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 176.7. Samples: 508448. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:12:32,949][06649] Avg episode reward: [(0, '4994.061')]
[36m[2025-07-04 08:12:37,973][06649] Fps is (10 sec: 1637.2, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 507904. Throughput: 0: 175.8. Samples: 509008. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:12:37,973][06649] Avg episode reward: [(0, '5071.967')]
[36m[2025-07-04 08:12:42,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 178.2. Samples: 510160. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:12:42,932][06649] Avg episode reward: [(0, '5089.073')]
[36m[2025-07-04 08:12:47,982][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 178.8. Samples: 511216. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:12:47,982][06649] Avg episode reward: [(0, '5183.244')]
[36m[2025-07-04 08:12:52,941][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 180.1. Samples: 511728. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:12:52,941][06649] Avg episode reward: [(0, '5159.348')]
[36m[2025-07-04 08:12:57,948][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 177.7. Samples: 512768. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:12:57,948][06649] Avg episode reward: [(0, '5246.390')]
[36m[2025-07-04 08:13:02,989][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 177.2. Samples: 513856. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:02,989][06649] Avg episode reward: [(0, '5134.201')]
[36m[2025-07-04 08:13:07,973][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 174.7. Samples: 514352. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:07,974][06649] Avg episode reward: [(0, '5139.901')]
[36m[2025-07-04 08:13:12,969][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 174.2. Samples: 515392. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:12,970][06649] Avg episode reward: [(0, '5132.732')]
[37m[1m[2025-07-04 08:13:13,072][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000992_507904.pth...
[36m[2025-07-04 08:13:13,079][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000800_409600.pth
[36m[2025-07-04 08:13:17,937][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 174.6. Samples: 516304. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:17,938][06649] Avg episode reward: [(0, '5131.284')]
[36m[2025-07-04 08:13:22,931][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 166.7). Total num frames: 507904. Throughput: 0: 174.0. Samples: 516832. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:22,931][06649] Avg episode reward: [(0, '5042.382')]
[36m[2025-07-04 08:13:27,929][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.7). Total num frames: 507904. Throughput: 0: 172.1. Samples: 517904. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:27,929][06649] Avg episode reward: [(0, '5024.211')]
[36m[2025-07-04 08:13:32,918][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 172.3. Samples: 518960. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:32,918][06649] Avg episode reward: [(0, '4933.835')]
[36m[2025-07-04 08:13:37,989][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 174.4. Samples: 519584. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:37,989][06649] Avg episode reward: [(0, '4873.697')]
[36m[2025-07-04 08:13:42,927][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 176.1. Samples: 520688. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:42,928][06649] Avg episode reward: [(0, '4864.298')]
[36m[2025-07-04 08:13:47,955][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 175.8. Samples: 521760. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:47,956][06649] Avg episode reward: [(0, '4889.101')]
[36m[2025-07-04 08:13:52,988][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 177.0. Samples: 522320. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:52,988][06649] Avg episode reward: [(0, '4845.110')]
[36m[2025-07-04 08:13:57,949][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 507904. Throughput: 0: 175.7. Samples: 523296. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:13:57,949][06649] Avg episode reward: [(0, '4893.508')]
[36m[2025-07-04 08:14:02,951][06649] Fps is (10 sec: 1644.5, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 178.4. Samples: 524336. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:02,951][06649] Avg episode reward: [(0, '4945.837')]
[36m[2025-07-04 08:14:07,943][06649] Fps is (10 sec: 1639.4, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 179.5. Samples: 524912. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:07,944][06649] Avg episode reward: [(0, '4910.933')]
[36m[2025-07-04 08:14:12,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 179.6. Samples: 525984. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:12,927][06649] Avg episode reward: [(0, '4939.523')]
[36m[2025-07-04 08:14:17,926][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 178.5. Samples: 526992. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:17,926][06649] Avg episode reward: [(0, '5027.359')]
[36m[2025-07-04 08:14:22,959][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 177.5. Samples: 527568. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:22,960][06649] Avg episode reward: [(0, '5068.807')]
[36m[2025-07-04 08:14:27,991][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 176.8. Samples: 528656. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:27,991][06649] Avg episode reward: [(0, '5073.127')]
[36m[2025-07-04 08:14:32,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.7). Total num frames: 524288. Throughput: 0: 180.4. Samples: 529872. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:32,928][06649] Avg episode reward: [(0, '5047.591')]
[36m[2025-07-04 08:14:37,924][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 180.9. Samples: 530448. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:37,924][06649] Avg episode reward: [(0, '5020.301')]
[36m[2025-07-04 08:14:42,933][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.7). Total num frames: 524288. Throughput: 0: 183.5. Samples: 531552. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:42,933][06649] Avg episode reward: [(0, '5005.226')]
[36m[2025-07-04 08:14:47,975][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 185.9. Samples: 532704. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:47,976][06649] Avg episode reward: [(0, '5023.503')]
[36m[2025-07-04 08:14:52,990][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 185.4. Samples: 533264. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:52,990][06649] Avg episode reward: [(0, '5023.207')]
[36m[2025-07-04 08:14:58,004][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 185.3. Samples: 534336. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:14:58,004][06649] Avg episode reward: [(0, '4979.261')]
[36m[2025-07-04 08:15:02,939][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 187.7. Samples: 535440. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:15:02,939][06649] Avg episode reward: [(0, '5004.340')]
[36m[2025-07-04 08:15:08,023][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 188.5. Samples: 536064. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:15:08,024][06649] Avg episode reward: [(0, '5079.391')]
[36m[2025-07-04 08:15:13,010][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 189.1. Samples: 537168. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:15:13,011][06649] Avg episode reward: [(0, '5036.961')]
[37m[1m[2025-07-04 08:15:13,107][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001024_524288.pth...
[36m[2025-07-04 08:15:13,114][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000832_425984.pth
[36m[2025-07-04 08:15:17,954][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 188.3. Samples: 538352. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:15:17,954][06649] Avg episode reward: [(0, '5108.085')]
[36m[2025-07-04 08:15:22,977][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 187.2. Samples: 538880. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:15:22,977][06649] Avg episode reward: [(0, '5175.667')]
[36m[2025-07-04 08:15:28,005][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 524288. Throughput: 0: 187.4. Samples: 540000. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:15:28,006][06649] Avg episode reward: [(0, '5183.996')]
[36m[2025-07-04 08:15:32,943][06649] Fps is (10 sec: 1643.9, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 540672. Throughput: 0: 185.4. Samples: 541040. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:15:32,943][06649] Avg episode reward: [(0, '5199.786')]
[36m[2025-07-04 08:15:38,004][06649] Fps is (10 sec: 1638.6, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 540672. Throughput: 0: 185.2. Samples: 541600. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:15:38,005][06649] Avg episode reward: [(0, '5109.492')]
[36m[2025-07-04 08:15:43,030][06649] Fps is (10 sec: 0.0, 60 sec: 272.6, 300 sec: 222.1). Total num frames: 540672. Throughput: 0: 185.1. Samples: 542672. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:15:43,031][06649] Avg episode reward: [(0, '5116.585')]
[36m[2025-07-04 08:15:47,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 540672. Throughput: 0: 181.7. Samples: 543616. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:15:47,928][06649] Avg episode reward: [(0, '5067.156')]
[36m[2025-07-04 08:15:52,939][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 540672. Throughput: 0: 181.0. Samples: 544192. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:15:52,940][06649] Avg episode reward: [(0, '5058.183')]
[36m[2025-07-04 08:15:57,993][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 540672. Throughput: 0: 180.0. Samples: 545264. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:15:57,993][06649] Avg episode reward: [(0, '5033.175')]
[36m[2025-07-04 08:16:02,993][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 540672. Throughput: 0: 178.7. Samples: 546400. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:02,994][06649] Avg episode reward: [(0, '5054.545')]
[36m[2025-07-04 08:16:07,929][06649] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 166.7). Total num frames: 540672. Throughput: 0: 178.7. Samples: 546912. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:07,930][06649] Avg episode reward: [(0, '5000.651')]
[36m[2025-07-04 08:16:12,918][06649] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 166.7). Total num frames: 540672. Throughput: 0: 178.5. Samples: 548016. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:12,918][06649] Avg episode reward: [(0, '4947.392')]
[36m[2025-07-04 08:16:17,993][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 540672. Throughput: 0: 176.5. Samples: 548992. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:17,993][06649] Avg episode reward: [(0, '4830.168')]
[36m[2025-07-04 08:16:22,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 540672. Throughput: 0: 178.1. Samples: 549600. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:22,932][06649] Avg episode reward: [(0, '4781.896')]
[36m[2025-07-04 08:16:27,985][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 540672. Throughput: 0: 177.6. Samples: 550656. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:27,986][06649] Avg episode reward: [(0, '4814.597')]
[36m[2025-07-04 08:16:32,942][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 540672. Throughput: 0: 183.0. Samples: 551856. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:32,943][06649] Avg episode reward: [(0, '4857.434')]
[36m[2025-07-04 08:16:37,979][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 540672. Throughput: 0: 181.9. Samples: 552384. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:37,979][06649] Avg episode reward: [(0, '4892.335')]
[36m[2025-07-04 08:16:42,981][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 540672. Throughput: 0: 184.2. Samples: 553552. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:42,981][06649] Avg episode reward: [(0, '5002.360')]
[36m[2025-07-04 08:16:47,922][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 540672. Throughput: 0: 185.2. Samples: 554720. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:47,922][06649] Avg episode reward: [(0, '4983.878')]
[36m[2025-07-04 08:16:52,929][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 540672. Throughput: 0: 185.2. Samples: 555248. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:52,929][06649] Avg episode reward: [(0, '4925.725')]
[36m[2025-07-04 08:16:57,944][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 540672. Throughput: 0: 183.4. Samples: 556272. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-04 08:16:57,944][06649] Avg episode reward: [(0, '4943.699')]
[36m[2025-07-04 08:17:02,972][06649] Fps is (10 sec: 1631.3, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 557056. Throughput: 0: 186.0. Samples: 557360. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:02,972][06649] Avg episode reward: [(0, '4836.617')]
[36m[2025-07-04 08:17:07,952][06649] Fps is (10 sec: 1637.1, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 557056. Throughput: 0: 186.9. Samples: 558016. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:07,952][06649] Avg episode reward: [(0, '4745.146')]
[36m[2025-07-04 08:17:12,979][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 557056. Throughput: 0: 195.2. Samples: 559440. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:12,979][06649] Avg episode reward: [(0, '4662.298')]
[37m[1m[2025-07-04 08:17:13,058][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001088_557056.pth...
[36m[2025-07-04 08:17:13,062][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000864_442368.pth
[36m[2025-07-04 08:17:17,978][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 557056. Throughput: 0: 201.8. Samples: 560944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:17,978][06649] Avg episode reward: [(0, '4685.908')]
[36m[2025-07-04 08:17:22,989][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 557056. Throughput: 0: 205.5. Samples: 561632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:22,990][06649] Avg episode reward: [(0, '4683.257')]
[36m[2025-07-04 08:17:27,991][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 557056. Throughput: 0: 205.5. Samples: 562800. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:27,992][06649] Avg episode reward: [(0, '4634.146')]
[36m[2025-07-04 08:17:32,937][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 557056. Throughput: 0: 211.5. Samples: 564240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:32,937][06649] Avg episode reward: [(0, '4647.926')]
[36m[2025-07-04 08:17:38,005][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 557056. Throughput: 0: 216.2. Samples: 564992. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:38,006][06649] Avg episode reward: [(0, '4609.786')]
[36m[2025-07-04 08:17:42,919][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.7). Total num frames: 557056. Throughput: 0: 212.4. Samples: 565824. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:42,919][06649] Avg episode reward: [(0, '4724.187')]
[36m[2025-07-04 08:17:47,956][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 557056. Throughput: 0: 215.2. Samples: 567040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:47,956][06649] Avg episode reward: [(0, '4861.299')]
[36m[2025-07-04 08:17:52,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 557056. Throughput: 0: 211.7. Samples: 567536. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:52,927][06649] Avg episode reward: [(0, '4902.793')]
[36m[2025-07-04 08:17:57,948][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 557056. Throughput: 0: 196.8. Samples: 568288. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:17:57,949][06649] Avg episode reward: [(0, '4934.891')]
[36m[2025-07-04 08:18:02,943][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 557056. Throughput: 0: 190.7. Samples: 569520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:02,943][06649] Avg episode reward: [(0, '5042.137')]
[36m[2025-07-04 08:18:07,969][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 557056. Throughput: 0: 190.0. Samples: 570176. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:07,970][06649] Avg episode reward: [(0, '5003.747')]
[36m[2025-07-04 08:18:12,985][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 557056. Throughput: 0: 192.4. Samples: 571456. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:12,986][06649] Avg episode reward: [(0, '4981.554')]
[36m[2025-07-04 08:18:18,019][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 557056. Throughput: 0: 186.0. Samples: 572624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:18,019][06649] Avg episode reward: [(0, '4974.889')]
[36m[2025-07-04 08:18:23,021][06649] Fps is (10 sec: 1632.5, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 179.8. Samples: 573088. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:23,022][06649] Avg episode reward: [(0, '5036.272')]
[36m[2025-07-04 08:18:28,016][06649] Fps is (10 sec: 1638.8, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 182.0. Samples: 574032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:28,017][06649] Avg episode reward: [(0, '5108.618')]
[36m[2025-07-04 08:18:33,013][06649] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 177.6. Samples: 575040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:33,013][06649] Avg episode reward: [(0, '5122.700')]
[36m[2025-07-04 08:18:37,969][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 176.9. Samples: 575504. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:37,969][06649] Avg episode reward: [(0, '5123.503')]
[36m[2025-07-04 08:18:42,985][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 184.0. Samples: 576576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:42,985][06649] Avg episode reward: [(0, '5129.089')]
[36m[2025-07-04 08:18:47,950][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 573440. Throughput: 0: 177.7. Samples: 577520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:47,951][06649] Avg episode reward: [(0, '5117.236')]
[36m[2025-07-04 08:18:53,004][06649] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 173.7. Samples: 578000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:53,004][06649] Avg episode reward: [(0, '5063.638')]
[36m[2025-07-04 08:18:57,956][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 166.2. Samples: 578928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:18:57,956][06649] Avg episode reward: [(0, '5050.430')]
[36m[2025-07-04 08:19:02,936][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 165.6. Samples: 580064. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:02,937][06649] Avg episode reward: [(0, '5018.929')]
[36m[2025-07-04 08:19:07,964][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 169.8. Samples: 580720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:07,964][06649] Avg episode reward: [(0, '4964.252')]
[36m[2025-07-04 08:19:12,963][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 176.6. Samples: 581968. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:12,963][06649] Avg episode reward: [(0, '4996.981')]
[37m[1m[2025-07-04 08:19:13,038][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001120_573440.pth...
[36m[2025-07-04 08:19:13,046][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000896_458752.pth
[33m[2889054 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[33m[2889155 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[2889155 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.1005859375
[33mTimeout Rate: 0.8994140625 (navigation_task_gate.py:472)
[36m[2025-07-04 08:19:17,992][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 182.5. Samples: 583248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:17,992][06649] Avg episode reward: [(0, '4986.975')]
[36m[2025-07-04 08:19:22,921][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 573440. Throughput: 0: 185.4. Samples: 583840. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:22,921][06649] Avg episode reward: [(0, '4988.059')]
[36m[2025-07-04 08:19:27,958][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 190.3. Samples: 585136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:27,958][06649] Avg episode reward: [(0, '5016.794')]
[36m[2025-07-04 08:19:32,934][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 197.4. Samples: 586400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:32,934][06649] Avg episode reward: [(0, '5013.659')]
[33m[2905992 ms][IGE_viewer_control] - WARNING : Camera follow: False (IGE_viewer_control.py:217)
[36m[2025-07-04 08:19:37,947][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 201.1. Samples: 587040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:37,947][06649] Avg episode reward: [(0, '5013.780')]
[36m[2025-07-04 08:19:42,956][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 206.6. Samples: 588224. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:42,956][06649] Avg episode reward: [(0, '5030.384')]
[36m[2025-07-04 08:19:47,969][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 208.2. Samples: 589440. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:47,969][06649] Avg episode reward: [(0, '5161.846')]
[36m[2025-07-04 08:19:52,944][06649] Fps is (10 sec: 1640.3, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 204.5. Samples: 589920. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:52,945][06649] Avg episode reward: [(0, '5156.417')]
[36m[2025-07-04 08:19:57,935][06649] Fps is (10 sec: 1644.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 208.5. Samples: 591344. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:19:57,935][06649] Avg episode reward: [(0, '5217.760')]
[36m[2025-07-04 08:20:02,928][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 206.5. Samples: 592528. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:02,929][06649] Avg episode reward: [(0, '5048.497')]
[36m[2025-07-04 08:20:07,941][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 207.2. Samples: 593168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:07,941][06649] Avg episode reward: [(0, '5141.938')]
[36m[2025-07-04 08:20:12,980][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 589824. Throughput: 0: 207.9. Samples: 594496. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:12,980][06649] Avg episode reward: [(0, '5131.945')]
[36m[2025-07-04 08:20:17,970][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 205.0. Samples: 595632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:17,970][06649] Avg episode reward: [(0, '5201.315')]
[36m[2025-07-04 08:20:23,017][06649] Fps is (10 sec: 0.0, 60 sec: 272.6, 300 sec: 222.1). Total num frames: 589824. Throughput: 0: 206.6. Samples: 596352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:23,017][06649] Avg episode reward: [(0, '5229.180')]
[36m[2025-07-04 08:20:27,960][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 198.4. Samples: 597152. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:27,960][06649] Avg episode reward: [(0, '5280.623')]
[GIF] Episode 900 truncated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0009_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0009_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0009_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0009_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0009_merged_dual_camera.gif
[36m[2025-07-04 08:20:32,998][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 185.5. Samples: 597792. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:32,998][06649] Avg episode reward: [(0, '5335.326')]
[36m[2025-07-04 08:20:38,031][06649] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 183.8. Samples: 598208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:38,031][06649] Avg episode reward: [(0, '5214.258')]
[36m[2025-07-04 08:20:42,955][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 168.8. Samples: 598944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:42,955][06649] Avg episode reward: [(0, '5204.884')]
[36m[2025-07-04 08:20:48,012][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 158.3. Samples: 599664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:48,012][06649] Avg episode reward: [(0, '5210.900')]
[36m[2025-07-04 08:20:52,924][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 589824. Throughput: 0: 152.2. Samples: 600016. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:52,924][06649] Avg episode reward: [(0, '5237.936')]
[36m[2025-07-04 08:20:57,935][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 138.4. Samples: 600720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:20:57,935][06649] Avg episode reward: [(0, '5269.571')]
[36m[2025-07-04 08:21:02,936][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 139.8. Samples: 601920. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:21:02,936][06649] Avg episode reward: [(0, '5324.702')]
[36m[2025-07-04 08:21:07,917][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 137.2. Samples: 602512. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:21:07,918][06649] Avg episode reward: [(0, '5363.027')]
[36m[2025-07-04 08:21:12,997][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 146.7. Samples: 603760. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:21:12,997][06649] Avg episode reward: [(0, '5365.493')]
[37m[1m[2025-07-04 08:21:13,076][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001152_589824.pth...
[36m[2025-07-04 08:21:13,083][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000960_491520.pth
[36m[2025-07-04 08:21:17,970][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 159.4. Samples: 604960. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:21:17,971][06649] Avg episode reward: [(0, '5231.006')]
[36m[2025-07-04 08:21:23,057][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 163.8. Samples: 605584. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:21:23,057][06649] Avg episode reward: [(0, '5256.046')]
[36m[2025-07-04 08:21:27,982][06649] Fps is (10 sec: 1636.6, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 173.1. Samples: 606736. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:21:27,982][06649] Avg episode reward: [(0, '5296.755')]
[36m[2025-07-04 08:21:32,974][06649] Fps is (10 sec: 1652.1, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 606208. Throughput: 0: 184.0. Samples: 607936. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:21:32,974][06649] Avg episode reward: [(0, '5343.076')]
[36m[2025-07-04 08:21:37,958][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 606208. Throughput: 0: 191.1. Samples: 608624. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:21:37,959][06649] Avg episode reward: [(0, '5295.091')]
[36m[2025-07-04 08:21:42,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 203.0. Samples: 609856. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:21:42,933][06649] Avg episode reward: [(0, '5277.572')]
[36m[2025-07-04 08:21:47,943][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 206.2. Samples: 611200. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:21:47,943][06649] Avg episode reward: [(0, '5243.282')]
[36m[2025-07-04 08:21:52,917][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 606208. Throughput: 0: 207.6. Samples: 611856. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:21:52,918][06649] Avg episode reward: [(0, '5210.222')]
[36m[2025-07-04 08:21:57,934][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 209.7. Samples: 613184. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:21:57,934][06649] Avg episode reward: [(0, '5212.412')]
[36m[2025-07-04 08:22:02,922][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 212.9. Samples: 614528. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:22:02,922][06649] Avg episode reward: [(0, '5199.187')]
[36m[2025-07-04 08:22:07,930][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 215.0. Samples: 615232. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:22:07,930][06649] Avg episode reward: [(0, '5208.994')]
[36m[2025-07-04 08:22:12,936][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 220.0. Samples: 616624. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:22:12,936][06649] Avg episode reward: [(0, '5155.839')]
[36m[2025-07-04 08:22:17,949][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 224.5. Samples: 618032. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:22:17,949][06649] Avg episode reward: [(0, '5106.068')]
[36m[2025-07-04 08:22:22,968][06649] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 223.9. Samples: 618704. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:22:22,969][06649] Avg episode reward: [(0, '5164.874')]
[36m[2025-07-04 08:22:27,942][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 225.7. Samples: 620016. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:22:27,942][06649] Avg episode reward: [(0, '5089.069')]
[36m[2025-07-04 08:22:32,923][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 606208. Throughput: 0: 226.6. Samples: 621392. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-04 08:22:32,923][06649] Avg episode reward: [(0, '5208.885')]
[36m[2025-07-04 08:22:37,919][06649] Fps is (10 sec: 1642.2, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 622592. Throughput: 0: 226.1. Samples: 622032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:22:37,920][06649] Avg episode reward: [(0, '5217.389')]
[36m[2025-07-04 08:22:42,969][06649] Fps is (10 sec: 1630.8, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 622592. Throughput: 0: 228.1. Samples: 623456. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:22:42,969][06649] Avg episode reward: [(0, '5249.460')]
[36m[2025-07-04 08:22:47,935][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 622592. Throughput: 0: 230.7. Samples: 624912. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:22:47,935][06649] Avg episode reward: [(0, '5326.565')]
[36m[2025-07-04 08:22:52,946][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 622592. Throughput: 0: 228.9. Samples: 625536. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:22:52,946][06649] Avg episode reward: [(0, '5302.309')]
[36m[2025-07-04 08:22:57,964][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 622592. Throughput: 0: 227.4. Samples: 626864. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:22:57,965][06649] Avg episode reward: [(0, '5414.897')]
[36m[2025-07-04 08:23:02,975][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 622592. Throughput: 0: 225.6. Samples: 628192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:02,976][06649] Avg episode reward: [(0, '5428.333')]
[37m[1m[2025-07-04 08:23:03,043][06649] Saving new best policy, reward=5428.333!
[36m[2025-07-04 08:23:07,925][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 622592. Throughput: 0: 225.6. Samples: 628848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:07,925][06649] Avg episode reward: [(0, '5483.477')]
[37m[1m[2025-07-04 08:23:07,990][06649] Saving new best policy, reward=5483.477!
[36m[2025-07-04 08:23:12,939][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 622592. Throughput: 0: 227.2. Samples: 630240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:12,939][06649] Avg episode reward: [(0, '5546.583')]
[37m[1m[2025-07-04 08:23:13,018][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001216_622592.pth...
[36m[2025-07-04 08:23:13,023][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000000992_507904.pth
[37m[1m[2025-07-04 08:23:13,024][06649] Saving new best policy, reward=5546.583!
[36m[2025-07-04 08:23:17,923][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.7). Total num frames: 622592. Throughput: 0: 221.5. Samples: 631360. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:17,923][06649] Avg episode reward: [(0, '5516.730')]
[36m[2025-07-04 08:23:22,959][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 221.7. Samples: 632016. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:22,959][06649] Avg episode reward: [(0, '5520.066')]
[36m[2025-07-04 08:23:27,989][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 217.5. Samples: 633248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:27,990][06649] Avg episode reward: [(0, '5584.057')]
[37m[1m[2025-07-04 08:23:28,099][06649] Saving new best policy, reward=5584.057!
[36m[2025-07-04 08:23:32,990][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 212.0. Samples: 634464. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:32,991][06649] Avg episode reward: [(0, '5450.076')]
[36m[2025-07-04 08:23:37,974][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 212.1. Samples: 635088. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:37,974][06649] Avg episode reward: [(0, '5458.326')]
[36m[2025-07-04 08:23:42,966][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 208.0. Samples: 636224. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:42,967][06649] Avg episode reward: [(0, '5414.212')]
[36m[2025-07-04 08:23:47,973][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 208.0. Samples: 637552. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:47,974][06649] Avg episode reward: [(0, '5431.560')]
[36m[2025-07-04 08:23:52,920][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 206.6. Samples: 638144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:52,920][06649] Avg episode reward: [(0, '5399.276')]
[36m[2025-07-04 08:23:57,950][06649] Fps is (10 sec: 1642.2, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 638976. Throughput: 0: 201.6. Samples: 639312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:23:57,950][06649] Avg episode reward: [(0, '5411.486')]
[36m[2025-07-04 08:24:02,972][06649] Fps is (10 sec: 1629.9, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 638976. Throughput: 0: 205.3. Samples: 640608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:02,972][06649] Avg episode reward: [(0, '5445.245')]
[36m[2025-07-04 08:24:07,958][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 638976. Throughput: 0: 204.8. Samples: 641232. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:07,959][06649] Avg episode reward: [(0, '5358.053')]
[36m[2025-07-04 08:24:12,948][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 638976. Throughput: 0: 208.9. Samples: 642640. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:12,948][06649] Avg episode reward: [(0, '5271.177')]
[36m[2025-07-04 08:24:17,920][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 638976. Throughput: 0: 206.9. Samples: 643760. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:17,920][06649] Avg episode reward: [(0, '5221.214')]
[36m[2025-07-04 08:24:22,949][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 638976. Throughput: 0: 204.9. Samples: 644304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:22,950][06649] Avg episode reward: [(0, '5262.367')]
[36m[2025-07-04 08:24:27,962][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 638976. Throughput: 0: 200.9. Samples: 645264. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:27,962][06649] Avg episode reward: [(0, '5320.881')]
[36m[2025-07-04 08:24:32,972][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 638976. Throughput: 0: 193.8. Samples: 646272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:32,972][06649] Avg episode reward: [(0, '5261.221')]
[36m[2025-07-04 08:24:37,923][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 638976. Throughput: 0: 192.7. Samples: 646816. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:37,923][06649] Avg episode reward: [(0, '5240.759')]
[36m[2025-07-04 08:24:43,014][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 638976. Throughput: 0: 188.2. Samples: 647792. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:43,015][06649] Avg episode reward: [(0, '5210.283')]
[36m[2025-07-04 08:24:47,940][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 180.4. Samples: 648720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:47,940][06649] Avg episode reward: [(0, '5122.888')]
[36m[2025-07-04 08:24:52,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 179.0. Samples: 649280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:52,927][06649] Avg episode reward: [(0, '5055.195')]
[36m[2025-07-04 08:24:57,922][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 173.3. Samples: 650432. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:24:57,922][06649] Avg episode reward: [(0, '5032.204')]
[36m[2025-07-04 08:25:02,949][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 175.9. Samples: 651680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:02,949][06649] Avg episode reward: [(0, '5165.548')]
[36m[2025-07-04 08:25:07,987][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 175.5. Samples: 652208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:07,988][06649] Avg episode reward: [(0, '5225.624')]
[36m[2025-07-04 08:25:13,020][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 181.5. Samples: 653440. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:13,020][06649] Avg episode reward: [(0, '5278.772')]
[37m[1m[2025-07-04 08:25:13,097][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001248_638976.pth...
[36m[2025-07-04 08:25:13,104][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001024_524288.pth
[36m[2025-07-04 08:25:17,943][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 638976. Throughput: 0: 186.1. Samples: 654640. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:17,944][06649] Avg episode reward: [(0, '5322.023')]
[36m[2025-07-04 08:25:22,930][06649] Fps is (10 sec: 1653.2, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 655360. Throughput: 0: 186.6. Samples: 655216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:22,930][06649] Avg episode reward: [(0, '5379.702')]
[36m[2025-07-04 08:25:27,988][06649] Fps is (10 sec: 1631.2, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 655360. Throughput: 0: 191.4. Samples: 656400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:27,988][06649] Avg episode reward: [(0, '5390.835')]
[36m[2025-07-04 08:25:32,934][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 655360. Throughput: 0: 198.4. Samples: 657648. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:32,935][06649] Avg episode reward: [(0, '5451.949')]
[36m[2025-07-04 08:25:37,928][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 655360. Throughput: 0: 200.2. Samples: 658288. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:37,928][06649] Avg episode reward: [(0, '5527.962')]
[36m[2025-07-04 08:25:42,924][06649] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 222.2). Total num frames: 655360. Throughput: 0: 200.2. Samples: 659440. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:42,924][06649] Avg episode reward: [(0, '5625.774')]
[37m[1m[2025-07-04 08:25:43,026][06649] Saving new best policy, reward=5625.774!
[36m[2025-07-04 08:25:47,971][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 655360. Throughput: 0: 197.2. Samples: 660560. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:47,971][06649] Avg episode reward: [(0, '5726.565')]
[37m[1m[2025-07-04 08:25:48,059][06649] Saving new best policy, reward=5726.565!
[36m[2025-07-04 08:25:52,947][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 655360. Throughput: 0: 197.9. Samples: 661104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:52,948][06649] Avg episode reward: [(0, '5568.248')]
[36m[2025-07-04 08:25:57,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 655360. Throughput: 0: 198.4. Samples: 662352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:25:57,932][06649] Avg episode reward: [(0, '5443.923')]
[36m[2025-07-04 08:26:02,949][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 655360. Throughput: 0: 199.8. Samples: 663632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:26:02,949][06649] Avg episode reward: [(0, '5461.826')]
[36m[2025-07-04 08:26:07,972][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 655360. Throughput: 0: 200.7. Samples: 664256. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:26:07,972][06649] Avg episode reward: [(0, '5414.174')]
[36m[2025-07-04 08:26:13,009][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 655360. Throughput: 0: 199.4. Samples: 665376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:26:13,009][06649] Avg episode reward: [(0, '5413.488')]
[36m[2025-07-04 08:26:17,962][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 655360. Throughput: 0: 196.9. Samples: 666512. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:26:17,962][06649] Avg episode reward: [(0, '5346.431')]
[36m[2025-07-04 08:26:22,971][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 196.8. Samples: 667152. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:26:22,971][06649] Avg episode reward: [(0, '5266.127')]
[36m[2025-07-04 08:26:27,988][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 198.5. Samples: 668384. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:26:27,989][06649] Avg episode reward: [(0, '5204.812')]
[36m[2025-07-04 08:26:32,929][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 201.8. Samples: 669632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:26:32,929][06649] Avg episode reward: [(0, '5088.294')]
[36m[2025-07-04 08:26:37,984][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 204.3. Samples: 670304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:26:37,984][06649] Avg episode reward: [(0, '5270.432')]
[36m[2025-07-04 08:26:42,938][06649] Fps is (10 sec: 1636.9, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 671744. Throughput: 0: 204.8. Samples: 671568. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:26:42,938][06649] Avg episode reward: [(0, '5278.331')]
[36m[2025-07-04 08:26:48,010][06649] Fps is (10 sec: 1634.1, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 671744. Throughput: 0: 202.7. Samples: 672768. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:26:48,010][06649] Avg episode reward: [(0, '5108.269')]
[36m[2025-07-04 08:26:52,989][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 671744. Throughput: 0: 202.6. Samples: 673376. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:26:52,990][06649] Avg episode reward: [(0, '5166.466')]
[36m[2025-07-04 08:26:57,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 671744. Throughput: 0: 208.0. Samples: 674720. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:26:57,927][06649] Avg episode reward: [(0, '5197.465')]
[36m[2025-07-04 08:27:02,966][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 671744. Throughput: 0: 210.1. Samples: 675968. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:02,966][06649] Avg episode reward: [(0, '5096.528')]
[36m[2025-07-04 08:27:07,918][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 671744. Throughput: 0: 208.6. Samples: 676528. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:07,918][06649] Avg episode reward: [(0, '5153.363')]
[36m[2025-07-04 08:27:12,937][06649] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 671744. Throughput: 0: 209.3. Samples: 677792. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:12,937][06649] Avg episode reward: [(0, '5221.560')]
[37m[1m[2025-07-04 08:27:13,012][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001312_671744.pth...
[36m[2025-07-04 08:27:13,017][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001088_557056.pth
[36m[2025-07-04 08:27:17,988][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 671744. Throughput: 0: 209.9. Samples: 679088. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:17,989][06649] Avg episode reward: [(0, '5266.056')]
[36m[2025-07-04 08:27:22,923][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 671744. Throughput: 0: 209.0. Samples: 679696. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:22,923][06649] Avg episode reward: [(0, '5215.540')]
[33m[3379790 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[3379790 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.0830078125
[33mTimeout Rate: 0.9169921875 (navigation_task_gate.py:472)
[36m[2025-07-04 08:27:27,946][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 671744. Throughput: 0: 210.5. Samples: 681040. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:27,946][06649] Avg episode reward: [(0, '5180.693')]
[36m[2025-07-04 08:27:32,931][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 213.0. Samples: 682336. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:32,931][06649] Avg episode reward: [(0, '5306.770')]
[36m[2025-07-04 08:27:37,934][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 214.3. Samples: 683008. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:37,934][06649] Avg episode reward: [(0, '5191.172')]
[36m[2025-07-04 08:27:42,968][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 211.4. Samples: 684240. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:42,968][06649] Avg episode reward: [(0, '5208.769')]
[36m[2025-07-04 08:27:47,931][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 213.1. Samples: 685552. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:47,931][06649] Avg episode reward: [(0, '5136.040')]
[36m[2025-07-04 08:27:52,930][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 215.8. Samples: 686240. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:52,930][06649] Avg episode reward: [(0, '5069.554')]
[36m[2025-07-04 08:27:57,928][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 215.5. Samples: 687488. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-04 08:27:57,928][06649] Avg episode reward: [(0, '5022.643')]
[36m[2025-07-04 08:28:02,926][06649] Fps is (10 sec: 1639.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 688128. Throughput: 0: 215.1. Samples: 688752. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:02,927][06649] Avg episode reward: [(0, '5021.460')]
[36m[2025-07-04 08:28:07,985][06649] Fps is (10 sec: 1629.2, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 688128. Throughput: 0: 215.2. Samples: 689392. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:07,985][06649] Avg episode reward: [(0, '5059.439')]
[36m[2025-07-04 08:28:12,977][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 688128. Throughput: 0: 214.6. Samples: 690704. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:12,977][06649] Avg episode reward: [(0, '5024.461')]
[36m[2025-07-04 08:28:17,958][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 688128. Throughput: 0: 214.3. Samples: 691984. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:17,958][06649] Avg episode reward: [(0, '5121.807')]
[36m[2025-07-04 08:28:22,986][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 688128. Throughput: 0: 213.1. Samples: 692608. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:22,987][06649] Avg episode reward: [(0, '5003.452')]
[36m[2025-07-04 08:28:27,925][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 688128. Throughput: 0: 214.6. Samples: 693888. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:27,925][06649] Avg episode reward: [(0, '5178.010')]
[36m[2025-07-04 08:28:32,937][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 688128. Throughput: 0: 215.1. Samples: 695232. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:32,937][06649] Avg episode reward: [(0, '5184.444')]
[36m[2025-07-04 08:28:37,928][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 688128. Throughput: 0: 214.1. Samples: 695872. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:37,928][06649] Avg episode reward: [(0, '5183.211')]
[36m[2025-07-04 08:28:42,971][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 688128. Throughput: 0: 217.0. Samples: 697264. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:42,971][06649] Avg episode reward: [(0, '5327.336')]
[36m[2025-07-04 08:28:47,954][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 688128. Throughput: 0: 220.7. Samples: 698688. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:47,954][06649] Avg episode reward: [(0, '5368.449')]
[36m[2025-07-04 08:28:52,952][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 222.4. Samples: 699392. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:52,952][06649] Avg episode reward: [(0, '5391.942')]
[36m[2025-07-04 08:28:57,922][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 220.7. Samples: 700624. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:28:57,923][06649] Avg episode reward: [(0, '5428.424')]
[36m[2025-07-04 08:29:02,970][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 222.5. Samples: 702000. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:29:02,971][06649] Avg episode reward: [(0, '5460.445')]
[36m[2025-07-04 08:29:07,922][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 224.3. Samples: 702688. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:29:07,922][06649] Avg episode reward: [(0, '5487.692')]
[36m[2025-07-04 08:29:12,928][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 226.5. Samples: 704080. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-04 08:29:12,929][06649] Avg episode reward: [(0, '5450.725')]
[37m[1m[2025-07-04 08:29:13,014][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001344_688128.pth...
[36m[2025-07-04 08:29:13,018][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001120_573440.pth
[36m[2025-07-04 08:29:17,980][06649] Fps is (10 sec: 1628.9, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 704512. Throughput: 0: 222.0. Samples: 705232. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:29:17,980][06649] Avg episode reward: [(0, '5361.325')]
[36m[2025-07-04 08:29:22,945][06649] Fps is (10 sec: 1635.6, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 222.5. Samples: 705888. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:29:22,946][06649] Avg episode reward: [(0, '5316.831')]
[36m[2025-07-04 08:29:27,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 219.9. Samples: 707152. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:29:27,932][06649] Avg episode reward: [(0, '5322.489')]
[36m[2025-07-04 08:29:32,975][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 704512. Throughput: 0: 217.1. Samples: 708464. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:29:32,975][06649] Avg episode reward: [(0, '5303.875')]
[36m[2025-07-04 08:29:37,919][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 216.3. Samples: 709120. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:29:37,919][06649] Avg episode reward: [(0, '5324.844')]
[36m[2025-07-04 08:29:42,946][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 216.4. Samples: 710368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:29:42,946][06649] Avg episode reward: [(0, '5310.030')]
[36m[2025-07-04 08:29:47,969][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 704512. Throughput: 0: 215.1. Samples: 711680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:29:47,969][06649] Avg episode reward: [(0, '5363.726')]
[36m[2025-07-04 08:29:52,980][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 704512. Throughput: 0: 213.4. Samples: 712304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:29:52,980][06649] Avg episode reward: [(0, '5424.986')]
[36m[2025-07-04 08:29:57,955][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 212.9. Samples: 713664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:29:57,955][06649] Avg episode reward: [(0, '5425.614')]
[36m[2025-07-04 08:30:02,966][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 216.6. Samples: 714976. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:02,967][06649] Avg episode reward: [(0, '5465.564')]
[36m[2025-07-04 08:30:07,938][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 216.9. Samples: 715648. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:07,938][06649] Avg episode reward: [(0, '5491.609')]
[36m[2025-07-04 08:30:12,982][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 704512. Throughput: 0: 216.3. Samples: 716896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:12,982][06649] Avg episode reward: [(0, '5432.305')]
[36m[2025-07-04 08:30:17,978][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 704512. Throughput: 0: 217.2. Samples: 718240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:17,978][06649] Avg episode reward: [(0, '5423.422')]
[36m[2025-07-04 08:30:22,936][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 704512. Throughput: 0: 218.2. Samples: 718944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:22,936][06649] Avg episode reward: [(0, '5383.008')]
[36m[2025-07-04 08:30:27,917][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 704512. Throughput: 0: 222.0. Samples: 720352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:27,917][06649] Avg episode reward: [(0, '5246.893')]
[36m[2025-07-04 08:30:32,960][06649] Fps is (10 sec: 1634.5, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 720896. Throughput: 0: 222.6. Samples: 721696. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:32,960][06649] Avg episode reward: [(0, '5233.983')]
[36m[2025-07-04 08:30:37,964][06649] Fps is (10 sec: 1630.7, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 720896. Throughput: 0: 223.0. Samples: 722336. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:37,965][06649] Avg episode reward: [(0, '5242.025')]
[36m[2025-07-04 08:30:42,945][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 223.0. Samples: 723696. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:42,945][06649] Avg episode reward: [(0, '5187.393')]
[36m[2025-07-04 08:30:47,919][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 223.9. Samples: 725040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:47,919][06649] Avg episode reward: [(0, '5183.844')]
[36m[2025-07-04 08:30:52,921][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 222.7. Samples: 725664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:52,921][06649] Avg episode reward: [(0, '5217.872')]
[36m[2025-07-04 08:30:57,950][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 224.5. Samples: 726992. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:30:57,950][06649] Avg episode reward: [(0, '5318.339')]
[36m[2025-07-04 08:31:02,970][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 223.0. Samples: 728272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:02,970][06649] Avg episode reward: [(0, '5458.831')]
[36m[2025-07-04 08:31:07,944][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 222.2. Samples: 728944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:07,944][06649] Avg episode reward: [(0, '5494.480')]
[36m[2025-07-04 08:31:12,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 220.4. Samples: 730272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:12,927][06649] Avg episode reward: [(0, '5568.676')]
[37m[1m[2025-07-04 08:31:12,992][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001408_720896.pth...
[36m[2025-07-04 08:31:12,996][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001152_589824.pth
[36m[2025-07-04 08:31:17,952][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 221.6. Samples: 731664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:17,952][06649] Avg episode reward: [(0, '5562.643')]
[36m[2025-07-04 08:31:22,996][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 221.0. Samples: 732288. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:22,996][06649] Avg episode reward: [(0, '5580.923')]
[36m[2025-07-04 08:31:27,932][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 220.5. Samples: 733616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:27,932][06649] Avg episode reward: [(0, '5578.720')]
[36m[2025-07-04 08:31:32,970][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 217.7. Samples: 734848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:32,971][06649] Avg episode reward: [(0, '5629.183')]
[36m[2025-07-04 08:31:37,960][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 720896. Throughput: 0: 217.8. Samples: 735472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:37,960][06649] Avg episode reward: [(0, '5448.314')]
[36m[2025-07-04 08:31:42,955][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 720896. Throughput: 0: 217.2. Samples: 736768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:42,955][06649] Avg episode reward: [(0, '5352.562')]
[36m[2025-07-04 08:31:47,919][06649] Fps is (10 sec: 1645.2, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 216.1. Samples: 737984. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:47,919][06649] Avg episode reward: [(0, '5299.641')]
[36m[2025-07-04 08:31:52,923][06649] Fps is (10 sec: 1643.6, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 216.6. Samples: 738688. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:52,924][06649] Avg episode reward: [(0, '5237.211')]
[36m[2025-07-04 08:31:57,922][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 214.8. Samples: 739936. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:31:57,922][06649] Avg episode reward: [(0, '5204.476')]
[36m[2025-07-04 08:32:02,957][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 737280. Throughput: 0: 215.1. Samples: 741344. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:02,958][06649] Avg episode reward: [(0, '5235.783')]
[36m[2025-07-04 08:32:08,010][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 737280. Throughput: 0: 215.8. Samples: 742000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:08,010][06649] Avg episode reward: [(0, '5277.368')]
[36m[2025-07-04 08:32:12,934][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 215.5. Samples: 743312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:12,934][06649] Avg episode reward: [(0, '5355.679')]
[36m[2025-07-04 08:32:17,952][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 737280. Throughput: 0: 217.0. Samples: 744608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:17,953][06649] Avg episode reward: [(0, '5435.320')]
[36m[2025-07-04 08:32:22,970][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 737280. Throughput: 0: 217.9. Samples: 745280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:22,970][06649] Avg episode reward: [(0, '5486.455')]
[36m[2025-07-04 08:32:27,966][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 737280. Throughput: 0: 219.0. Samples: 746624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:27,966][06649] Avg episode reward: [(0, '5584.939')]
[36m[2025-07-04 08:32:32,940][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 222.5. Samples: 748000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:32,940][06649] Avg episode reward: [(0, '5674.053')]
[GIF] Episode 1000 truncated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0010_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0010_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0010_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0010_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0010_merged_dual_camera.gif
[36m[2025-07-04 08:32:37,965][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 219.5. Samples: 748576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:37,965][06649] Avg episode reward: [(0, '5678.254')]
[36m[2025-07-04 08:32:42,964][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 737280. Throughput: 0: 219.9. Samples: 749840. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:42,964][06649] Avg episode reward: [(0, '5656.737')]
[36m[2025-07-04 08:32:47,964][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 737280. Throughput: 0: 219.3. Samples: 751216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:47,964][06649] Avg episode reward: [(0, '5607.018')]
[36m[2025-07-04 08:32:52,925][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 219.1. Samples: 751840. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:52,925][06649] Avg episode reward: [(0, '5513.747')]
[36m[2025-07-04 08:32:57,972][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 737280. Throughput: 0: 218.5. Samples: 753152. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-04 08:32:57,972][06649] Avg episode reward: [(0, '5556.003')]
[36m[2025-07-04 08:33:02,963][06649] Fps is (10 sec: 1632.1, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 219.3. Samples: 754480. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:02,964][06649] Avg episode reward: [(0, '5561.268')]
[36m[2025-07-04 08:33:07,964][06649] Fps is (10 sec: 1639.7, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 219.4. Samples: 755152. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:07,964][06649] Avg episode reward: [(0, '5586.042')]
[36m[2025-07-04 08:33:12,957][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 218.0. Samples: 756432. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:12,957][06649] Avg episode reward: [(0, '5587.727')]
[37m[1m[2025-07-04 08:33:13,047][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001472_753664.pth...
[36m[2025-07-04 08:33:13,052][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001216_622592.pth
[36m[2025-07-04 08:33:17,942][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 216.2. Samples: 757728. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:17,942][06649] Avg episode reward: [(0, '5586.732')]
[36m[2025-07-04 08:33:22,951][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 218.4. Samples: 758400. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:22,951][06649] Avg episode reward: [(0, '5615.471')]
[36m[2025-07-04 08:33:28,017][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 220.2. Samples: 759760. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:28,017][06649] Avg episode reward: [(0, '5625.617')]
[36m[2025-07-04 08:33:32,927][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 218.1. Samples: 761024. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:32,927][06649] Avg episode reward: [(0, '5609.744')]
[36m[2025-07-04 08:33:37,933][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 219.3. Samples: 761712. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:37,933][06649] Avg episode reward: [(0, '5631.000')]
[36m[2025-07-04 08:33:42,981][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 221.5. Samples: 763120. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:42,981][06649] Avg episode reward: [(0, '5578.240')]
[36m[2025-07-04 08:33:47,940][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 223.0. Samples: 764512. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:47,940][06649] Avg episode reward: [(0, '5429.048')]
[36m[2025-07-04 08:33:52,944][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 223.0. Samples: 765184. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:52,945][06649] Avg episode reward: [(0, '5365.844')]
[36m[2025-07-04 08:33:57,931][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 225.6. Samples: 766576. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:33:57,931][06649] Avg episode reward: [(0, '5324.783')]
[36m[2025-07-04 08:34:02,925][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 224.8. Samples: 767840. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:34:02,926][06649] Avg episode reward: [(0, '5262.335')]
[36m[2025-07-04 08:34:07,951][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 224.0. Samples: 768480. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-04 08:34:07,951][06649] Avg episode reward: [(0, '5222.472')]
[36m[2025-07-04 08:34:12,947][06649] Fps is (10 sec: 1634.9, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 222.2. Samples: 769744. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:34:12,947][06649] Avg episode reward: [(0, '5225.490')]
[36m[2025-07-04 08:34:17,921][06649] Fps is (10 sec: 1643.2, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 221.9. Samples: 771008. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:34:17,922][06649] Avg episode reward: [(0, '5370.478')]
[36m[2025-07-04 08:34:22,925][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 221.5. Samples: 771680. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:34:22,925][06649] Avg episode reward: [(0, '5406.228')]
[36m[2025-07-04 08:34:27,975][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 223.0. Samples: 773152. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:34:27,975][06649] Avg episode reward: [(0, '5529.861')]
[36m[2025-07-04 08:34:32,973][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 222.1. Samples: 774512. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:34:32,973][06649] Avg episode reward: [(0, '5558.967')]
[36m[2025-07-04 08:34:37,920][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 221.6. Samples: 775152. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:34:37,920][06649] Avg episode reward: [(0, '5612.330')]
[36m[2025-07-04 08:34:42,980][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 220.2. Samples: 776496. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:34:42,981][06649] Avg episode reward: [(0, '5586.754')]
[36m[2025-07-04 08:34:47,987][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 219.8. Samples: 777744. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:34:47,987][06649] Avg episode reward: [(0, '5626.866')]
[33m[3824319 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:469)
[33m[3824319 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 0.08984375
[33mTimeout Rate: 0.91015625 (navigation_task_gate.py:472)
[36m[2025-07-04 08:34:52,974][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 219.6. Samples: 778368. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:34:52,974][06649] Avg episode reward: [(0, '5680.476')]
[36m[2025-07-04 08:34:57,980][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 221.3. Samples: 779712. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:34:57,980][06649] Avg episode reward: [(0, '5730.317')]
[37m[1m[2025-07-04 08:34:58,044][06649] Saving new best policy, reward=5730.317!
[36m[2025-07-04 08:35:02,980][06649] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 224.1. Samples: 781104. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:35:02,981][06649] Avg episode reward: [(0, '5600.192')]
[36m[2025-07-04 08:35:07,975][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 223.8. Samples: 781760. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:35:07,975][06649] Avg episode reward: [(0, '5579.069')]
[36m[2025-07-04 08:35:12,934][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 220.6. Samples: 783072. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:35:12,934][06649] Avg episode reward: [(0, '5664.468')]
[37m[1m[2025-07-04 08:35:13,010][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001504_770048.pth...
[36m[2025-07-04 08:35:13,018][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001248_638976.pth
[36m[2025-07-04 08:35:17,942][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 220.6. Samples: 784432. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:35:17,942][06649] Avg episode reward: [(0, '5676.605')]
[36m[2025-07-04 08:35:22,974][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 221.2. Samples: 785120. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-04 08:35:22,974][06649] Avg episode reward: [(0, '5688.574')]
[36m[2025-07-04 08:35:27,918][06649] Fps is (10 sec: 1642.4, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 221.8. Samples: 786464. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:35:27,918][06649] Avg episode reward: [(0, '5790.961')]
[37m[1m[2025-07-04 08:35:27,984][06649] Saving new best policy, reward=5790.961!
[36m[2025-07-04 08:35:32,931][06649] Fps is (10 sec: 1645.4, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 223.2. Samples: 787776. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:35:32,932][06649] Avg episode reward: [(0, '5729.779')]
[36m[2025-07-04 08:35:37,947][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 223.4. Samples: 788416. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:35:37,947][06649] Avg episode reward: [(0, '5651.673')]
[36m[2025-07-04 08:35:42,943][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 786432. Throughput: 0: 222.1. Samples: 789696. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:35:42,943][06649] Avg episode reward: [(0, '5718.973')]
[36m[2025-07-04 08:35:47,974][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 786432. Throughput: 0: 218.3. Samples: 790928. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:35:47,975][06649] Avg episode reward: [(0, '5840.496')]
[37m[1m[2025-07-04 08:35:48,046][06649] Saving new best policy, reward=5840.496!
[36m[2025-07-04 08:35:52,957][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 217.7. Samples: 791552. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:35:52,958][06649] Avg episode reward: [(0, '5852.036')]
[37m[1m[2025-07-04 08:35:53,064][06649] Saving new best policy, reward=5852.036!
[36m[2025-07-04 08:35:57,919][06649] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 217.7. Samples: 792864. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:35:57,919][06649] Avg episode reward: [(0, '5850.456')]
[36m[2025-07-04 08:36:02,977][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 786432. Throughput: 0: 216.7. Samples: 794192. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:36:02,977][06649] Avg episode reward: [(0, '5808.772')]
[36m[2025-07-04 08:36:07,959][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 786432. Throughput: 0: 217.3. Samples: 794896. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:36:07,959][06649] Avg episode reward: [(0, '5841.227')]
[36m[2025-07-04 08:36:12,956][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 218.5. Samples: 796304. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:36:12,956][06649] Avg episode reward: [(0, '5867.875')]
[37m[1m[2025-07-04 08:36:13,078][06649] Saving new best policy, reward=5867.875!
[36m[2025-07-04 08:36:17,921][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 218.4. Samples: 797600. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:36:17,921][06649] Avg episode reward: [(0, '5880.594')]
[37m[1m[2025-07-04 08:36:17,986][06649] Saving new best policy, reward=5880.594!
[36m[2025-07-04 08:36:22,966][06649] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 786432. Throughput: 0: 219.3. Samples: 798288. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:36:22,966][06649] Avg episode reward: [(0, '5979.094')]
[37m[1m[2025-07-04 08:36:23,033][06649] Saving new best policy, reward=5979.094!
[36m[2025-07-04 08:36:27,975][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 221.7. Samples: 799680. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:36:27,975][06649] Avg episode reward: [(0, '5842.361')]
[36m[2025-07-04 08:36:32,929][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 222.4. Samples: 800928. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:36:32,929][06649] Avg episode reward: [(0, '5816.984')]
[36m[2025-07-04 08:36:38,005][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 786432. Throughput: 0: 222.0. Samples: 801552. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:36:38,006][06649] Avg episode reward: [(0, '5743.928')]
[36m[2025-07-04 08:36:42,984][06649] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 786432. Throughput: 0: 215.5. Samples: 802576. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-04 08:36:42,985][06649] Avg episode reward: [(0, '5688.553')]
[36m[2025-07-04 08:36:47,964][06649] Fps is (10 sec: 1645.2, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 209.8. Samples: 803632. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-04 08:36:47,964][06649] Avg episode reward: [(0, '5670.692')]
[36m[2025-07-04 08:36:52,964][06649] Fps is (10 sec: 1641.8, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 205.8. Samples: 804160. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-04 08:36:52,964][06649] Avg episode reward: [(0, '5717.455')]
[36m[2025-07-04 08:36:57,928][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 802816. Throughput: 0: 196.7. Samples: 805152. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-04 08:36:57,928][06649] Avg episode reward: [(0, '5594.195')]
[36m[2025-07-04 08:37:02,957][06649] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 802816. Throughput: 0: 192.9. Samples: 806288. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-04 08:37:02,957][06649] Avg episode reward: [(0, '5593.292')]
[36m[2025-07-04 08:37:07,967][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 191.6. Samples: 806912. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-04 08:37:07,967][06649] Avg episode reward: [(0, '5636.534')]
[36m[2025-07-04 08:37:13,000][06649] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 186.9. Samples: 808096. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-04 08:37:13,000][06649] Avg episode reward: [(0, '5645.980')]
[37m[1m[2025-07-04 08:37:13,125][06649] Saving ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001568_802816.pth...
[36m[2025-07-04 08:37:13,131][06649] Removing ./train_dir/gate_config_3_static_cam_fixed_1/checkpoint_p0/checkpoint_000001312_671744.pth
[36m[2025-07-04 08:37:17,938][06649] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 802816. Throughput: 0: 187.0. Samples: 809344. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-04 08:37:17,938][06649] Avg episode reward: [(0, '5665.803')]
[37m[1m[2025-07-04 08:37:19,241][06649] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 6649], exiting...
[37m[1m[2025-07-04 08:37:19,241][06649] Runner profile tree view:
[37m[1mmain_loop: 3959.4513
[37m[1m[2025-07-04 08:37:19,241][06649] Collected {0: 802816}, FPS: 202.8