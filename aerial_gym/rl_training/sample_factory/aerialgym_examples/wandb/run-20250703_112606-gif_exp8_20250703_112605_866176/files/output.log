Importing module 'gym_38' (/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
[36m[2025-07-03 11:26:09,194][33729] Queried available GPUs: 0
[37m[1m[2025-07-03 11:26:09,195][33729] Environment var CUDA_VISIBLE_DEVICES is 0
PyTorch version 1.13.1
Device count 1
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
Warp 1.0.0-beta.5 initialized:
   CUDA Toolkit: 11.5, Driver: 12.4
   Devices:
     "cpu"    | x86_64
     "cuda:0" | NVIDIA GeForce RTX 4080 Laptop GPU (sm_89)
   Kernel cache: /home/ziyar/.cache/warp/1.0.0-beta.5
[SUBPROCESS] FORCED headless mode for all Sample Factory training: headless=True
[SUBPROCESS] This prevents Isaac Gym viewer conflicts across all processes
[SUBPROCESS] Task action_space_dim: 3
[SUBPROCESS] Target Sample Factory action space: 3D
[SUBPROCESS] Setting num_envs to 4 based on env_agents=4
[SUBPROCESS] Set SF_ENV_AGENTS=4 environment variable
[SUBPROCESS] Config batch_size: 128
[SUBPROCESS] Using MEDIUM CONFIG (4 environments)
Registered quad_with_obstacles_gate and dce_navigation_task_gate in subprocess
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles_gate', '--experiment=gif_exp8', '--train_dir=./train_dir', '--num_workers=1', '--num_envs_per_worker=1', '--env_agents=4', '--obs_key=observations', '--batch_size=128', '--num_batches_to_accumulate=2', '--rollout=32', '--learning_rate=0.0003', '--use_rnn=true', '--rnn_size=128', '--rnn_num_layers=1', '--encoder_mlp_layers', '512', '256', '128', '--gamma=0.98', '--with_wandb=true', '--wandb_project=gate_navigation_dual_camera', '--wandb_user=ziya-ruso-ucl', '--wandb_group=gate_navigation_training', '--wandb_tags', 'aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized', '--save_every_sec=120', '--save_best_every_sec=5', '--train_for_env_steps=100000000']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/utils/cpp_extension.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging  # type: ignore[attr-defined]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Using /home/ziyar/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
Emitting ninja build file /home/ziyar/.cache/torch_extensions/py38_cu117/gymtorch/build.ninja...
Building extension module gymtorch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module gymtorch...
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/graph.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping, Set, Iterable
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/readwrite/graphml.py:346: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  (np.int, "int"), (np.int8, "int"),
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/torch_utils.py:135: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  def get_axis_params(value, axis_idx, x_value=0., dtype=np.float, n_dims=3):
[37m[1792 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task_gate.py:22)
[37m[1792 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Final headless mode: False (dce_navigation_task_gate.py:29)
[37m[1792 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Found SF_ENV_AGENTS environment variable: 4 (dce_navigation_task_gate.py:39)
[37m[1792 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Detected env_agents=4 from environment - setting environment count. (dce_navigation_task_gate.py:45)
[37m[1792 ms][base_task] - INFO : Setting seed: 1476393382 (base_task.py:38)
[37m[1793 ms][navigation_task_gate] - INFO : Building environment for gate navigation task. (navigation_task_gate.py:48)
[37m[1793 ms][navigation_task_gate] - INFO : Sim Name: base_sim, Env Name: gate_env, Robot Name: lmf2, Controller Name: lmf2_position_control (navigation_task_gate.py:49)
[37m[1793 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[1793 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[1793 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[1793 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[1793 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[1793 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[1794 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[1794 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[1794 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[1794 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[1794 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[1794 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[1794 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.45 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 7.54 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 11.37 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.51 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] GIF saving DISABLED
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 4
[AerialGymVecEnv] Detected observation space: 145D
[AerialGymVecEnv] Using GATE NAVIGATION configuration (145D = 17D basic + 64D drone VAE + 64D static camera VAE)
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[37m[2774 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[2774 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[2978 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[2978 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[2978 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[2978 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[2978 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[2978 ms][BaseRobot] - INFO : Initializing controller lmf2_position_control (base_robot.py:29)
[33m[2978 ms][base_multirotor] - WARNING : Creating 4 multirotors. (base_multirotor.py:32)
[37m[2978 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[2978 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[2978 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2979 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2982 ms][asset_loader] - INFO : Loading asset: tree_33.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2991 ms][asset_loader] - INFO : Loading asset: tree_49.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[2999 ms][asset_loader] - INFO : Loading asset: tree_41.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3008 ms][asset_loader] - INFO : Loading asset: tree_40.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3017 ms][asset_loader] - INFO : Loading asset: tree_3.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3026 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3027 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3028 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3028 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3029 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3030 ms][asset_loader] - INFO : Loading asset: tree_51.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3039 ms][asset_loader] - INFO : Loading asset: tree_99.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3048 ms][asset_loader] - INFO : Loading asset: tree_10.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3057 ms][asset_loader] - INFO : Loading asset: tree_24.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3065 ms][asset_loader] - INFO : Loading asset: tree_38.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3074 ms][asset_loader] - INFO : Loading asset: tree_21.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3083 ms][asset_loader] - INFO : Loading asset: tree_86.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3091 ms][asset_loader] - INFO : Loading asset: tree_17.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3100 ms][asset_loader] - INFO : Loading asset: tree_97.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3109 ms][asset_loader] - INFO : Loading asset: tree_67.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3117 ms][asset_loader] - INFO : Loading asset: tree_87.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3126 ms][asset_loader] - INFO : Loading asset: tree_30.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3135 ms][asset_loader] - INFO : Loading asset: tree_77.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3144 ms][env_manager] - INFO : Creating ground plane in Isaac Gym Simulation. (env_manager.py:172)
[37m[3149 ms][env_manager] - INFO : [DONE] Creating ground plane in Isaac Gym Simulation (env_manager.py:174)
[37m[3149 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[3524 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[3524 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[3524 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[3554 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[3562 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[3562 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[3635 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[3635 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[3734 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 11 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[3930 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[3930 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
[37m[4545 ms][navigation_task_gate] - INFO : Setting up static camera for gate navigation... (navigation_task_gate.py:474)
[37m[4545 ms][navigation_task_gate] - INFO : Static camera properties: 480x270, FOV: 87.0° (navigation_task_gate.py:493)
[37m[4562 ms][navigation_task_gate] - INFO : ✓ Static camera setup complete (navigation_task_gate.py:510)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[36m[2025-07-03 11:26:13,940][33853] Env info: EnvInfo(obs_space=Dict('obs': Box(-inf, inf, (145,), float32)), action_space=Box(-1.0, 1.0, (3,), float32), num_agents=4, gpu_actions=True, gpu_observations=True, action_splits=None, all_discrete=None, frameskip=1, reward_shaping_scheme=None, env_info_protocol_version=1)
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles_gate', '--experiment=gif_exp8', '--train_dir=./train_dir', '--num_workers=1', '--num_envs_per_worker=1', '--env_agents=4', '--obs_key=observations', '--batch_size=128', '--num_batches_to_accumulate=2', '--rollout=32', '--learning_rate=0.0003', '--use_rnn=true', '--rnn_size=128', '--rnn_num_layers=1', '--encoder_mlp_layers', '512', '256', '128', '--gamma=0.98', '--with_wandb=true', '--wandb_project=gate_navigation_dual_camera', '--wandb_user=ziya-ruso-ucl', '--wandb_group=gate_navigation_training', '--wandb_tags', 'aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized', '--save_every_sec=120', '--save_best_every_sec=5', '--train_for_env_steps=100000000']
[33m[2025-07-03 11:26:14,680][33729] In serial mode all components run on the same process. Only use async_rl and serial mode together for debugging.
[36m[2025-07-03 11:26:14,680][33729] Starting experiment with the following configuration:
[36mhelp=False
[36malgo=APPO
[36menv=quad_with_obstacles_gate
[36mexperiment=gif_exp8
[36mtrain_dir=./train_dir
[36mrestart_behavior=resume
[36mdevice=gpu
[36mseed=None
[36mnum_policies=1
[36masync_rl=True
[36mserial_mode=True
[36mbatched_sampling=True
[36mnum_batches_to_accumulate=2
[36mworker_num_splits=1
[36mpolicy_workers_per_policy=1
[36mmax_policy_lag=1000
[36mnum_workers=1
[36mnum_envs_per_worker=1
[36mbatch_size=128
[36mnum_batches_per_epoch=4
[36mnum_epochs=4
[36mrollout=32
[36mrecurrence=32
[36mshuffle_minibatches=False
[36mgamma=0.98
[36mreward_scale=0.1
[36mreward_clip=1000.0
[36mvalue_bootstrap=True
[36mnormalize_returns=True
[36mexploration_loss_coeff=0.001
[36mvalue_loss_coeff=2.0
[36mkl_loss_coeff=0.1
[36mexploration_loss=entropy
[36mgae_lambda=0.95
[36mppo_clip_ratio=0.2
[36mppo_clip_value=1.0
[36mwith_vtrace=False
[36mvtrace_rho=1.0
[36mvtrace_c=1.0
[36moptimizer=adam
[36madam_eps=1e-06
[36madam_beta1=0.9
[36madam_beta2=0.999
[36mmax_grad_norm=1.0
[36mlearning_rate=0.0003
[36mlr_schedule=kl_adaptive_epoch
[36mlr_schedule_kl_threshold=0.016
[36mlr_adaptive_min=1e-06
[36mlr_adaptive_max=0.01
[36mobs_subtract_mean=0.0
[36mobs_scale=1.0
[36mnormalize_input=True
[36mnormalize_input_keys=None
[36mdecorrelate_experience_max_seconds=0
[36mdecorrelate_envs_on_one_worker=True
[36mactor_worker_gpus=[0]
[36mset_workers_cpu_affinity=True
[36mforce_envs_single_thread=False
[36mdefault_niceness=0
[36mlog_to_file=True
[36mexperiment_summaries_interval=10
[36mflush_summaries_interval=30
[36mstats_avg=100
[36msummaries_use_frameskip=True
[36mheartbeat_interval=20
[36mheartbeat_reporting_interval=180
[36mtrain_for_env_steps=100000000
[36mtrain_for_seconds=10000000000
[36msave_every_sec=120
[36mkeep_checkpoints=5
[36mload_checkpoint_kind=latest
[36msave_milestones_sec=-1
[36msave_best_every_sec=5
[36msave_best_metric=reward
[36msave_best_after=100000
[36mbenchmark=False
[36mencoder_mlp_layers=[512, 256, 128]
[36mencoder_conv_architecture=convnet_simple
[36mencoder_conv_mlp_layers=[]
[36muse_rnn=True
[36mrnn_size=128
[36mrnn_type=gru
[36mrnn_num_layers=1
[36mdecoder_mlp_layers=[]
[36mnonlinearity=elu
[36mpolicy_initialization=torch_default
[36mpolicy_init_gain=1.0
[36mactor_critic_share_weights=True
[36madaptive_stddev=True
[36mcontinuous_tanh_scale=0.0
[36minitial_stddev=1.0
[36muse_env_info_cache=False
[36menv_gpu_actions=True
[36menv_gpu_observations=True
[36menv_frameskip=1
[36menv_framestack=1
[36mpixel_format=CHW
[36muse_record_episode_statistics=False
[36mwith_wandb=True
[36mwandb_user=ziya-ruso-ucl
[36mwandb_project=gate_navigation_dual_camera
[36mwandb_group=gate_navigation_training
[36mwandb_job_type=SF
[36mwandb_tags=['aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized']
[36mwith_pbt=False
[36mpbt_mix_policies_in_one_env=True
[36mpbt_period_env_steps=5000000
[36mpbt_start_mutation=20000000
[36mpbt_replace_fraction=0.3
[36mpbt_mutation_rate=0.15
[36mpbt_replace_reward_gap=0.1
[36mpbt_replace_reward_gap_absolute=1e-06
[36mpbt_optimize_gamma=False
[36mpbt_target_objective=true_objective
[36mpbt_perturb_min=1.1
[36mpbt_perturb_max=1.5
[36menv_agents=4
[36mheadless=False
[36msave_gifs=False
[36mobs_key=observations
[36msubtask=None
[36mige_api_version=preview4
[36meval_stats=False
[36maction_space_dim=3
[36mcommand_line=--env=quad_with_obstacles_gate --experiment=gif_exp8 --train_dir=./train_dir --num_workers=1 --num_envs_per_worker=1 --env_agents=4 --obs_key=observations --batch_size=128 --num_batches_to_accumulate=2 --rollout=32 --learning_rate=0.0003 --use_rnn=true --rnn_size=128 --rnn_num_layers=1 --encoder_mlp_layers 512 256 128 --gamma=0.98 --with_wandb=true --wandb_project=gate_navigation_dual_camera --wandb_user=ziya-ruso-ucl --wandb_group=gate_navigation_training --wandb_tags aerial_gym gate_navigation dual_camera x500 sample_factory memory_optimized --save_every_sec=120 --save_best_every_sec=5 --train_for_env_steps=100000000 --headless=false
[36mcli_args={'env': 'quad_with_obstacles_gate', 'experiment': 'gif_exp8', 'train_dir': './train_dir', 'num_batches_to_accumulate': 2, 'num_workers': 1, 'num_envs_per_worker': 1, 'batch_size': 128, 'rollout': 32, 'gamma': 0.98, 'learning_rate': 0.0003, 'train_for_env_steps': 100000000, 'save_every_sec': 120, 'save_best_every_sec': 5, 'encoder_mlp_layers': [512, 256, 128], 'use_rnn': True, 'rnn_size': 128, 'rnn_num_layers': 1, 'with_wandb': True, 'wandb_user': 'ziya-ruso-ucl', 'wandb_project': 'gate_navigation_dual_camera', 'wandb_group': 'gate_navigation_training', 'wandb_tags': ['aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized'], 'env_agents': 4, 'headless': False, 'obs_key': 'observations'}
[36mgit_hash=a54f99d681da80aa6215176cae93d2948a30ac42
[36mgit_repo_name=git@github.com:rusoziya/aerial_gym_simulator.git
[36mwandb_unique_id=gif_exp8_20250703_112605_866176
[36m[2025-07-03 11:26:14,680][33729] Saving configuration to ./train_dir/gif_exp8/config.json...
[36m[2025-07-03 11:26:14,715][33729] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-03 11:26:14,715][33729] Rollout worker 0 uses device cuda:0
[36m[2025-07-03 11:26:14,721][33729] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 11:26:14,721][33729] InferenceWorker_p0-w0: min num requests: 1
[36m[2025-07-03 11:26:14,722][33729] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 11:26:14,723][33729] Starting seed is not provided
[36m[2025-07-03 11:26:14,723][33729] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-03 11:26:14,723][33729] Initializing actor-critic model on device cuda:0
[36m[2025-07-03 11:26:14,724][33729] RunningMeanStd input shape: (145,)
[36m[2025-07-03 11:26:14,724][33729] RunningMeanStd input shape: (1,)
[36m[2025-07-03 11:26:14,749][33729] Created Actor Critic model with architecture:
[36m[2025-07-03 11:26:14,750][33729] ActorCriticSharedWeights(
[36m  (obs_normalizer): ObservationNormalizer(
[36m    (running_mean_std): RunningMeanStdDictInPlace(
[36m      (running_mean_std): ModuleDict(
[36m        (obs): RunningMeanStdInPlace()
[36m      )
[36m    )
[36m  )
[36m  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
[36m  (encoder): MultiInputEncoder(
[36m    (encoders): ModuleDict(
[36m      (obs): MlpEncoder(
[36m        (mlp_head): RecursiveScriptModule(
[36m          original_name=Sequential
[36m          (0): RecursiveScriptModule(original_name=Linear)
[36m          (1): RecursiveScriptModule(original_name=ELU)
[36m          (2): RecursiveScriptModule(original_name=Linear)
[36m          (3): RecursiveScriptModule(original_name=ELU)
[36m          (4): RecursiveScriptModule(original_name=Linear)
[36m          (5): RecursiveScriptModule(original_name=ELU)
[36m        )
[36m      )
[36m    )
[36m  )
[36m  (core): ModelCoreRNN(
[36m    (core): GRU(128, 128)
[36m  )
[36m  (decoder): MlpDecoder(
[36m    (mlp): Identity()
[36m  )
[36m  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
[36m  (action_parameterization): ActionParameterizationDefault(
[36m    (distribution_linear): Linear(in_features=128, out_features=6, bias=True)
[36m  )
[36m)
[36m[2025-07-03 11:26:15,173][33729] Using optimizer <class 'torch.optim.adam.Adam'>
[33m[2025-07-03 11:26:15,173][33729] No checkpoints found
[36m[2025-07-03 11:26:15,173][33729] Did not load from checkpoint, starting from scratch!
[36m[2025-07-03 11:26:15,173][33729] Initialized policy 0 weights for model version 0
[36m[2025-07-03 11:26:15,174][33729] LearnerWorker_p0 finished initialization!
[36m[2025-07-03 11:26:15,174][33729] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 11:26:15,176][33729] Inference worker 0-0 is ready!
[37m[1m[2025-07-03 11:26:15,176][33729] All inference workers are ready! Signal rollout workers to start!
[36m[2025-07-03 11:26:15,176][33729] EnvRunner 0-0 uses policy 0
[37m[11216 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task_gate.py:22)
[37m[11216 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Final headless mode: False (dce_navigation_task_gate.py:29)
[37m[11216 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Found SF_ENV_AGENTS environment variable: 4 (dce_navigation_task_gate.py:39)
[37m[11216 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Detected env_agents=4 from environment - setting environment count. (dce_navigation_task_gate.py:45)
[37m[11216 ms][base_task] - INFO : Setting seed: 1189509433 (base_task.py:38)
[37m[11216 ms][navigation_task_gate] - INFO : Building environment for gate navigation task. (navigation_task_gate.py:48)
[37m[11216 ms][navigation_task_gate] - INFO : Sim Name: base_sim, Env Name: gate_env, Robot Name: lmf2, Controller Name: lmf2_position_control (navigation_task_gate.py:49)
[37m[11216 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[11216 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[11216 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[11216 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[11216 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[11216 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[11218 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[11218 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[11218 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[11218 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[11218 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[11218 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.56 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 7.82 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 11.50 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.70 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] GIF saving DISABLED
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 4
[AerialGymVecEnv] Detected observation space: 145D
[AerialGymVecEnv] Using GATE NAVIGATION configuration (145D = 17D basic + 64D drone VAE + 64D static camera VAE)
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[33m[11218 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[37m[12204 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[12204 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[12407 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[12407 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[12407 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[12407 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[12407 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[12407 ms][BaseRobot] - INFO : Initializing controller lmf2_position_control (base_robot.py:29)
[33m[12407 ms][base_multirotor] - WARNING : Creating 4 multirotors. (base_multirotor.py:32)
[37m[12408 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[12408 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[12408 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12408 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12412 ms][asset_loader] - INFO : Loading asset: tree_79.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12421 ms][asset_loader] - INFO : Loading asset: tree_35.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12430 ms][asset_loader] - INFO : Loading asset: tree_27.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12439 ms][asset_loader] - INFO : Loading asset: tree_14.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12448 ms][asset_loader] - INFO : Loading asset: tree_24.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12457 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12458 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12459 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12460 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12461 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12462 ms][asset_loader] - INFO : Loading asset: tree_59.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12470 ms][asset_loader] - INFO : Loading asset: tree_31.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12479 ms][asset_loader] - INFO : Loading asset: tree_51.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12488 ms][asset_loader] - INFO : Loading asset: tree_9.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12497 ms][asset_loader] - INFO : Loading asset: tree_19.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12506 ms][asset_loader] - INFO : Loading asset: tree_29.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12514 ms][asset_loader] - INFO : Loading asset: tree_61.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12523 ms][asset_loader] - INFO : Loading asset: tree_8.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12532 ms][asset_loader] - INFO : Loading asset: tree_92.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12541 ms][asset_loader] - INFO : Loading asset: tree_37.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12550 ms][asset_loader] - INFO : Loading asset: tree_36.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12558 ms][asset_loader] - INFO : Loading asset: tree_97.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12567 ms][asset_loader] - INFO : Loading asset: tree_63.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12578 ms][asset_loader] - INFO : Loading asset: tree_1.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[12592 ms][env_manager] - INFO : Creating ground plane in Isaac Gym Simulation. (env_manager.py:172)
[37m[12604 ms][env_manager] - INFO : [DONE] Creating ground plane in Isaac Gym Simulation (env_manager.py:174)
[37m[12604 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[12621 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[12621 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[12621 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[12650 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[12658 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[12659 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[12745 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[12751 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[12845 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 11 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[13040 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[13041 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
[37m[13655 ms][navigation_task_gate] - INFO : Setting up static camera for gate navigation... (navigation_task_gate.py:474)
[37m[13656 ms][navigation_task_gate] - INFO : Static camera properties: 480x270, FOV: 87.0° (navigation_task_gate.py:493)
[37m[13673 ms][navigation_task_gate] - INFO : ✓ Static camera setup complete (navigation_task_gate.py:510)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[37m[14681 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:26:20,053][33729] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 11:26:20,053][33729] Avg episode reward: [(0, '-50.000')]
[37m[17065 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[33m[17434 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[36m[2025-07-03 11:26:23,543][33729] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 3.4. Samples: 12. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 11:26:23,543][33729] Avg episode reward: [(0, '-50.000')]
[33m[20168 ms][IGE_viewer_control] - WARNING : Camera follow: False (IGE_viewer_control.py:217)
[37m[20363 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[21589 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[21975 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/nn/modules/module.py:1194: UserWarning: operator() profile_node %104 : int[] = prim::profile_ivalue(%102)
 does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)
  return forward_call(*input, **kwargs)
[36m[2025-07-03 11:26:28,559][33729] Fps is (10 sec: 60.2, 60 sec: 60.2, 300 sec: 60.2). Total num frames: 512. Throughput: 0: 61.1. Samples: 520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:26:28,560][33729] Avg episode reward: [(0, '-113.090')]
[37m[25075 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[27736 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[27794 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[28977 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[29336 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:26:33,531][33729] Fps is (10 sec: 102.5, 60 sec: 76.0, 300 sec: 76.0). Total num frames: 1024. Throughput: 0: 79.5. Samples: 1072. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-03 11:26:33,531][33729] Avg episode reward: [(0, '-122.265')]
[37m[1m[2025-07-03 11:26:34,781][33729] Heartbeat connected on Batcher_0
[37m[1m[2025-07-03 11:26:34,781][33729] Heartbeat connected on LearnerWorker_p0
[37m[1m[2025-07-03 11:26:34,781][33729] Heartbeat connected on InferenceWorker_p0-w0
[37m[1m[2025-07-03 11:26:34,781][33729] Heartbeat connected on RolloutWorker_w0
[37m[32016 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[33343 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[33964 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:26:38,548][33729] Fps is (10 sec: 102.5, 60 sec: 83.0, 300 sec: 83.0). Total num frames: 1536. Throughput: 0: 74.6. Samples: 1380. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:26:38,549][33729] Avg episode reward: [(0, '-141.233')]
[37m[35409 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[37268 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[38739 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:26:43,560][33729] Fps is (10 sec: 102.1, 60 sec: 87.1, 300 sec: 87.1). Total num frames: 2048. Throughput: 0: 84.7. Samples: 1992. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[36m[2025-07-03 11:26:43,560][33729] Avg episode reward: [(0, '-157.626')]
[37m[40639 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[41509 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[43366 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:26:48,546][33729] Fps is (10 sec: 102.4, 60 sec: 89.8, 300 sec: 89.8). Total num frames: 2560. Throughput: 0: 91.5. Samples: 2608. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:26:48,546][33729] Avg episode reward: [(0, '-170.703')]
[37m[44718 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[44767 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[45214 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[46789 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[48013 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[48436 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[49543 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:26:53,541][33729] Fps is (10 sec: 102.6, 60 sec: 91.7, 300 sec: 91.7). Total num frames: 3072. Throughput: 0: 87.3. Samples: 2924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:26:53,541][33729] Avg episode reward: [(0, '-177.888')]
[37m[50177 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[52197 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[52526 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[53011 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:26:58,539][33729] Fps is (10 sec: 102.5, 60 sec: 93.1, 300 sec: 93.1). Total num frames: 3584. Throughput: 0: 92.0. Samples: 3540. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 11:26:58,539][33729] Avg episode reward: [(0, '-177.177')]
[37m[57202 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[57327 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[57674 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[59283 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[59330 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:03,550][33729] Fps is (10 sec: 102.3, 60 sec: 94.2, 300 sec: 94.2). Total num frames: 4096. Throughput: 0: 95.1. Samples: 4136. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-03 11:27:03,550][33729] Avg episode reward: [(0, '-181.299')]
[37m[61155 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[61866 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[63223 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[63443 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[64481 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:08,549][33729] Fps is (10 sec: 102.3, 60 sec: 95.0, 300 sec: 95.0). Total num frames: 4608. Throughput: 0: 98.5. Samples: 4444. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:27:08,549][33729] Avg episode reward: [(0, '-181.664')]
[37m[65920 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[66132 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[68074 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[68659 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[69237 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:13,531][33729] Fps is (10 sec: 102.6, 60 sec: 95.7, 300 sec: 95.7). Total num frames: 5120. Throughput: 0: 100.4. Samples: 5036. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 11:27:13,532][33729] Avg episode reward: [(0, '-183.286')]
[37m[70248 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[71803 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[73150 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[74243 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:18,541][33729] Fps is (10 sec: 102.5, 60 sec: 96.3, 300 sec: 96.3). Total num frames: 5632. Throughput: 0: 101.3. Samples: 5632. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-03 11:27:18,542][33729] Avg episode reward: [(0, '-183.494')]
[37m[74807 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[76712 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[77028 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:23,532][33729] Fps is (10 sec: 102.4, 60 sec: 102.4, 300 sec: 96.8). Total num frames: 6144. Throughput: 0: 101.1. Samples: 5928. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 11:27:23,533][33729] Avg episode reward: [(0, '-184.761')]
[37m[81046 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[81831 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[82234 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[83304 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[84103 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:28,549][33729] Fps is (10 sec: 51.2, 60 sec: 93.9, 300 sec: 89.7). Total num frames: 6144. Throughput: 0: 100.8. Samples: 6528. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 11:27:28,550][33729] Avg episode reward: [(0, '-177.305')]
[37m[87137 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[87439 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[87616 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[87896 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:33,540][33729] Fps is (10 sec: 51.2, 60 sec: 93.9, 300 sec: 90.6). Total num frames: 6656. Throughput: 0: 100.2. Samples: 7116. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 11:27:33,540][33729] Avg episode reward: [(0, '-177.291')]
[37m[92567 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[93051 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[93101 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[94323 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:38,543][33729] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 91.3). Total num frames: 7168. Throughput: 0: 99.9. Samples: 7420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:27:38,544][33729] Avg episode reward: [(0, '-177.218')]
[37m[98324 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[98977 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[99214 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:43,534][33729] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 92.0). Total num frames: 7680. Throughput: 0: 99.7. Samples: 8024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:27:43,534][33729] Avg episode reward: [(0, '-180.901')]
[37m[99851 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[103456 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:48,559][33729] Fps is (10 sec: 102.2, 60 sec: 93.8, 300 sec: 92.6). Total num frames: 8192. Throughput: 0: 99.4. Samples: 8608. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:27:48,560][33729] Avg episode reward: [(0, '-181.168')]
[37m[104796 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[104896 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[105866 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[108866 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[109311 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:53,533][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 93.1). Total num frames: 8704. Throughput: 0: 98.2. Samples: 8860. Policy #0 lag: (min: 4.0, avg: 4.5, max: 20.0)
[36m[2025-07-03 11:27:53,533][33729] Avg episode reward: [(0, '-179.736')]
[37m[110257 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[110602 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[113829 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:27:58,529][33729] Fps is (10 sec: 102.7, 60 sec: 93.9, 300 sec: 93.6). Total num frames: 9216. Throughput: 0: 96.4. Samples: 9372. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:27:58,529][33729] Avg episode reward: [(0, '-180.455')]
[37m[116401 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[116934 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[118323 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:03,538][33729] Fps is (10 sec: 102.3, 60 sec: 93.9, 300 sec: 94.0). Total num frames: 9728. Throughput: 0: 94.8. Samples: 9896. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:28:03,538][33729] Avg episode reward: [(0, '-177.147')]
[37m[120269 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[120412 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[121610 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[121838 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:08,555][33729] Fps is (10 sec: 102.1, 60 sec: 93.9, 300 sec: 94.4). Total num frames: 10240. Throughput: 0: 94.0. Samples: 10160. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:28:08,555][33729] Avg episode reward: [(0, '-174.874')]
[37m[1m[2025-07-03 11:28:08,600][33729] Saving ./train_dir/gif_exp8/checkpoint_p0/checkpoint_000000320_10240.pth...
[37m[124703 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[126588 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[126969 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[127428 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:13,540][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 94.7). Total num frames: 10752. Throughput: 0: 92.4. Samples: 10684. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:28:13,540][33729] Avg episode reward: [(0, '-174.856')]
[37m[129691 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[131109 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[131382 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[133670 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:18,553][33729] Fps is (10 sec: 51.2, 60 sec: 85.3, 300 sec: 90.7). Total num frames: 10752. Throughput: 0: 90.9. Samples: 11208. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:28:18,553][33729] Avg episode reward: [(0, '-173.420')]
[37m[136216 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[136812 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[138763 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[139041 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:23,539][33729] Fps is (10 sec: 51.2, 60 sec: 85.3, 300 sec: 91.2). Total num frames: 11264. Throughput: 0: 90.0. Samples: 11468. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:28:23,539][33729] Avg episode reward: [(0, '-175.933')]
[37m[142952 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[143790 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:28,569][33729] Fps is (10 sec: 102.2, 60 sec: 93.8, 300 sec: 91.6). Total num frames: 11776. Throughput: 0: 88.5. Samples: 12008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:28:28,569][33729] Avg episode reward: [(0, '-175.240')]
[37m[145024 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[145556 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[148491 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[148546 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:33,542][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 92.1). Total num frames: 12288. Throughput: 0: 87.4. Samples: 12540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:28:33,542][33729] Avg episode reward: [(0, '-177.301')]
[37m[149601 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[151191 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[154404 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[154459 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:38,547][33729] Fps is (10 sec: 102.6, 60 sec: 93.9, 300 sec: 92.4). Total num frames: 12800. Throughput: 0: 87.7. Samples: 12808. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:28:38,547][33729] Avg episode reward: [(0, '-175.932')]
[37m[155302 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[156187 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[157828 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:43,533][33729] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 92.8). Total num frames: 13312. Throughput: 0: 88.2. Samples: 13340. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-03 11:28:43,534][33729] Avg episode reward: [(0, '-174.782')]
[37m[161097 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[161887 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[162986 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[163844 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:48,535][33729] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 93.1). Total num frames: 13824. Throughput: 0: 88.5. Samples: 13876. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:28:48,535][33729] Avg episode reward: [(0, '-171.741')]
[37m[164730 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[167549 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[169293 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[169495 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:53,531][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 93.4). Total num frames: 14336. Throughput: 0: 88.8. Samples: 14152. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:28:53,532][33729] Avg episode reward: [(0, '-166.940')]
[37m[170269 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[173593 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[173788 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:28:58,533][33729] Fps is (10 sec: 51.2, 60 sec: 85.3, 300 sec: 90.5). Total num frames: 14336. Throughput: 0: 89.0. Samples: 14688. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:28:58,533][33729] Avg episode reward: [(0, '-164.892')]
[37m[174700 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[177527 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:03,572][33729] Fps is (10 sec: 51.0, 60 sec: 85.3, 300 sec: 90.8). Total num frames: 14848. Throughput: 0: 88.8. Samples: 15204. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:29:03,572][33729] Avg episode reward: [(0, '-163.807')]
[37m[179770 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[180993 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[181231 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:08,533][33729] Fps is (10 sec: 102.4, 60 sec: 85.4, 300 sec: 91.2). Total num frames: 15360. Throughput: 0: 88.6. Samples: 15456. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 11:29:08,533][33729] Avg episode reward: [(0, '-163.258')]
[37m[185069 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[185133 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[187575 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:13,537][33729] Fps is (10 sec: 102.8, 60 sec: 85.3, 300 sec: 91.5). Total num frames: 15872. Throughput: 0: 88.6. Samples: 15992. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-03 11:29:13,537][33729] Avg episode reward: [(0, '-162.415')]
[37m[190505 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[191357 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[191876 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[193143 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:18,562][33729] Fps is (10 sec: 102.1, 60 sec: 93.9, 300 sec: 91.8). Total num frames: 16384. Throughput: 0: 88.6. Samples: 16528. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-03 11:29:18,563][33729] Avg episode reward: [(0, '-157.167')]
[37m[194670 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[196110 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[197027 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[198737 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:23,540][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 92.1). Total num frames: 16896. Throughput: 0: 88.8. Samples: 16804. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 11:29:23,541][33729] Avg episode reward: [(0, '-155.960')]
[37m[200859 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[203915 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[204402 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:28,565][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 92.3). Total num frames: 17408. Throughput: 0: 89.4. Samples: 17364. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 11:29:28,566][33729] Avg episode reward: [(0, '-155.933')]
[37m[204699 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[204794 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[208369 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[209169 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:33,551][33729] Fps is (10 sec: 102.3, 60 sec: 93.9, 300 sec: 92.6). Total num frames: 17920. Throughput: 0: 90.4. Samples: 17944. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 11:29:33,551][33729] Avg episode reward: [(0, '-154.099')]
[37m[210586 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[211203 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:38,539][33729] Fps is (10 sec: 102.7, 60 sec: 93.9, 300 sec: 92.9). Total num frames: 18432. Throughput: 0: 91.1. Samples: 18252. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:29:38,540][33729] Avg episode reward: [(0, '-154.014')]
[37m[214594 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[214954 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[215346 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[215803 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[218481 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:43,544][33729] Fps is (10 sec: 102.5, 60 sec: 93.8, 300 sec: 93.1). Total num frames: 18944. Throughput: 0: 92.6. Samples: 18856. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:29:43,545][33729] Avg episode reward: [(0, '-151.140')]
[37m[220910 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[221653 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[221878 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[224269 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[224318 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:48,542][33729] Fps is (10 sec: 51.2, 60 sec: 85.3, 300 sec: 90.9). Total num frames: 18944. Throughput: 0: 93.8. Samples: 19424. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:29:48,542][33729] Avg episode reward: [(0, '-153.964')]
[37m[227629 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[228311 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[229265 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:53,532][33729] Fps is (10 sec: 51.3, 60 sec: 85.3, 300 sec: 91.1). Total num frames: 19456. Throughput: 0: 94.7. Samples: 19716. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 11:29:53,532][33729] Avg episode reward: [(0, '-153.950')]
[37m[230605 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[232434 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[234330 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:29:58,563][33729] Fps is (10 sec: 102.2, 60 sec: 93.8, 300 sec: 91.4). Total num frames: 19968. Throughput: 0: 94.9. Samples: 20264. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 11:29:58,563][33729] Avg episode reward: [(0, '-153.320')]
[37m[234779 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[236238 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[237460 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[239315 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:03,535][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 91.6). Total num frames: 20480. Throughput: 0: 96.1. Samples: 20848. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 11:30:03,535][33729] Avg episode reward: [(0, '-149.995')]
[37m[239963 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[241039 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[242333 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[243773 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:08,545][33729] Fps is (10 sec: 102.6, 60 sec: 93.8, 300 sec: 91.9). Total num frames: 20992. Throughput: 0: 96.3. Samples: 21136. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:30:08,545][33729] Avg episode reward: [(0, '-148.602')]
[37m[1m[2025-07-03 11:30:08,600][33729] Saving ./train_dir/gif_exp8/checkpoint_p0/checkpoint_000000656_20992.pth...
[37m[245439 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[246604 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[246729 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[247261 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:13,554][33729] Fps is (10 sec: 102.2, 60 sec: 93.8, 300 sec: 92.1). Total num frames: 21504. Throughput: 0: 96.6. Samples: 21712. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 11:30:13,555][33729] Avg episode reward: [(0, '-148.723')]
[37m[250784 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[252435 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[253009 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[253202 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:18,573][33729] Fps is (10 sec: 102.1, 60 sec: 93.8, 300 sec: 92.3). Total num frames: 22016. Throughput: 0: 95.4. Samples: 22240. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:30:18,574][33729] Avg episode reward: [(0, '-148.589')]
[37m[257623 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[257785 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[259551 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:23,551][33729] Fps is (10 sec: 102.4, 60 sec: 93.8, 300 sec: 92.5). Total num frames: 22528. Throughput: 0: 94.7. Samples: 22516. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[36m[2025-07-03 11:30:23,552][33729] Avg episode reward: [(0, '-153.067')]
[37m[259852 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[261490 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[261932 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[263129 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[263215 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[263727 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:28,530][33729] Fps is (10 sec: 102.8, 60 sec: 93.9, 300 sec: 92.7). Total num frames: 23040. Throughput: 0: 94.3. Samples: 23096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:30:28,530][33729] Avg episode reward: [(0, '-152.796')]
[37m[266305 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[267503 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[268171 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[268295 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[269458 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[269508 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:33,542][33729] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 92.9). Total num frames: 23552. Throughput: 0: 94.8. Samples: 23688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:30:33,542][33729] Avg episode reward: [(0, '-148.952')]
[37m[269595 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[273135 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[273537 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[273770 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:38,552][33729] Fps is (10 sec: 102.2, 60 sec: 93.8, 300 sec: 93.1). Total num frames: 24064. Throughput: 0: 94.8. Samples: 23984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:30:38,553][33729] Avg episode reward: [(0, '-146.339')]
[37m[275644 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[278331 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[278949 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[279399 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:43,538][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 93.3). Total num frames: 24576. Throughput: 0: 95.1. Samples: 24540. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:30:43,538][33729] Avg episode reward: [(0, '-145.567')]
[37m[281403 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[283268 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[284461 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:48,542][33729] Fps is (10 sec: 51.3, 60 sec: 93.9, 300 sec: 91.5). Total num frames: 24576. Throughput: 0: 93.7. Samples: 25064. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:30:48,542][33729] Avg episode reward: [(0, '-144.742')]
[37m[284614 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[285661 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[288567 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:53,536][33729] Fps is (10 sec: 51.2, 60 sec: 93.9, 300 sec: 91.7). Total num frames: 25088. Throughput: 0: 92.9. Samples: 25316. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:30:53,536][33729] Avg episode reward: [(0, '-146.714')]
[37m[290162 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[290631 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[292646 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[293310 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:30:58,551][33729] Fps is (10 sec: 102.3, 60 sec: 93.9, 300 sec: 91.9). Total num frames: 25600. Throughput: 0: 91.9. Samples: 25848. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:30:58,552][33729] Avg episode reward: [(0, '-147.614')]
[37m[295037 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[295488 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[297508 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[298458 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[299563 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:03,559][33729] Fps is (10 sec: 102.2, 60 sec: 93.8, 300 sec: 92.1). Total num frames: 26112. Throughput: 0: 93.2. Samples: 26432. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:31:03,559][33729] Avg episode reward: [(0, '-147.782')]
[37m[301311 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[302994 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:08,534][33729] Fps is (10 sec: 102.6, 60 sec: 93.9, 300 sec: 92.3). Total num frames: 26624. Throughput: 0: 93.6. Samples: 26728. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 11:31:08,534][33729] Avg episode reward: [(0, '-149.582')]
[37m[305302 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[305464 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[305748 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[308811 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:13,553][33729] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 92.5). Total num frames: 27136. Throughput: 0: 94.3. Samples: 27340. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:31:13,554][33729] Avg episode reward: [(0, '-146.998')]
[37m[311482 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[312256 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[312500 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:18,555][33729] Fps is (10 sec: 102.2, 60 sec: 93.9, 300 sec: 93.7). Total num frames: 27648. Throughput: 0: 92.8. Samples: 27864. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 11:31:18,555][33729] Avg episode reward: [(0, '-145.063')]
[37m[315493 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[318256 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[319179 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[319456 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:23,551][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 93.7). Total num frames: 28160. Throughput: 0: 92.1. Samples: 28128. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[36m[2025-07-03 11:31:23,552][33729] Avg episode reward: [(0, '-144.955')]
[37m[320437 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[323924 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[324201 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:28,540][33729] Fps is (10 sec: 102.6, 60 sec: 93.9, 300 sec: 93.7). Total num frames: 28672. Throughput: 0: 91.5. Samples: 28656. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:31:28,541][33729] Avg episode reward: [(0, '-144.927')]
[37m[324645 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[326010 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[329577 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:33,576][33729] Fps is (10 sec: 102.1, 60 sec: 93.8, 300 sec: 93.7). Total num frames: 29184. Throughput: 0: 91.5. Samples: 29184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:31:33,576][33729] Avg episode reward: [(0, '-144.648')]
[37m[331369 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[331428 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[332999 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:38,541][33729] Fps is (10 sec: 51.2, 60 sec: 85.4, 300 sec: 92.0). Total num frames: 29184. Throughput: 0: 91.5. Samples: 29432. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:31:38,541][33729] Avg episode reward: [(0, '-145.361')]
[37m[336005 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[336425 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[338954 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:43,544][33729] Fps is (10 sec: 51.4, 60 sec: 85.3, 300 sec: 92.0). Total num frames: 29696. Throughput: 0: 91.2. Samples: 29952. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-03 11:31:43,544][33729] Avg episode reward: [(0, '-142.158')]
[37m[340343 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[342318 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[342772 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[342831 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:48,554][33729] Fps is (10 sec: 102.3, 60 sec: 93.8, 300 sec: 92.0). Total num frames: 30208. Throughput: 0: 90.0. Samples: 30480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:31:48,554][33729] Avg episode reward: [(0, '-141.108')]
[37m[345065 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[345498 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[346889 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[347432 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[349004 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:53,541][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 92.0). Total num frames: 30720. Throughput: 0: 89.9. Samples: 30772. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 11:31:53,541][33729] Avg episode reward: [(0, '-139.057')]
[37m[349633 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[349684 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[352451 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[352965 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[354512 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:31:58,550][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 92.0). Total num frames: 31232. Throughput: 0: 89.0. Samples: 31344. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:31:58,550][33729] Avg episode reward: [(0, '-130.566')]
[37m[354736 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[357361 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[358637 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[359129 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:03,569][33729] Fps is (10 sec: 102.1, 60 sec: 93.9, 300 sec: 92.0). Total num frames: 31744. Throughput: 0: 89.0. Samples: 31872. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:32:03,569][33729] Avg episode reward: [(0, '-128.918')]
[37m[361082 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[363107 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[363161 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:08,548][33729] Fps is (10 sec: 102.4, 60 sec: 93.8, 300 sec: 92.0). Total num frames: 32256. Throughput: 0: 89.2. Samples: 32140. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:32:08,549][33729] Avg episode reward: [(0, '-128.835')]
[37m[1m[2025-07-03 11:32:08,594][33729] Saving ./train_dir/gif_exp8/checkpoint_p0/checkpoint_000001008_32256.pth...
[37m[365245 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[365428 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[367600 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[368907 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:13,547][33729] Fps is (10 sec: 102.6, 60 sec: 93.9, 300 sec: 92.0). Total num frames: 32768. Throughput: 0: 89.9. Samples: 32704. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:32:13,547][33729] Avg episode reward: [(0, '-130.242')]
[37m[370740 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[371154 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[371642 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:18,581][33729] Fps is (10 sec: 102.1, 60 sec: 93.8, 300 sec: 92.0). Total num frames: 33280. Throughput: 0: 90.9. Samples: 33276. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 11:32:18,582][33729] Avg episode reward: [(0, '-129.534')]
[37m[375114 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[375954 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[377092 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[378054 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[378956 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:23,531][33729] Fps is (10 sec: 51.3, 60 sec: 85.4, 300 sec: 92.0). Total num frames: 33280. Throughput: 0: 91.0. Samples: 33528. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 11:32:23,532][33729] Avg episode reward: [(0, '-126.684')]
[37m[382985 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[383556 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[383953 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:28,546][33729] Fps is (10 sec: 51.4, 60 sec: 85.3, 300 sec: 92.0). Total num frames: 33792. Throughput: 0: 90.8. Samples: 34040. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:32:28,546][33729] Avg episode reward: [(0, '-124.326')]
[37m[386745 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[387322 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[388573 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:33,554][33729] Fps is (10 sec: 102.2, 60 sec: 85.4, 300 sec: 92.0). Total num frames: 34304. Throughput: 0: 90.4. Samples: 34548. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 11:32:33,555][33729] Avg episode reward: [(0, '-120.730')]
[37m[390121 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[390651 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[393123 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[393946 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:38,550][33729] Fps is (10 sec: 102.4, 60 sec: 93.9, 300 sec: 92.0). Total num frames: 34816. Throughput: 0: 89.6. Samples: 34804. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 11:32:38,550][33729] Avg episode reward: [(0, '-117.979')]
[37m[394702 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[397223 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[399479 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[399540 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:43,545][33729] Fps is (10 sec: 102.5, 60 sec: 93.9, 300 sec: 92.0). Total num frames: 35328. Throughput: 0: 88.5. Samples: 35324. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:32:43,545][33729] Avg episode reward: [(0, '-118.301')]
[37m[399798 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[403500 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[404051 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[404247 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:48,560][33729] Fps is (10 sec: 102.3, 60 sec: 93.9, 300 sec: 92.0). Total num frames: 35840. Throughput: 0: 87.9. Samples: 35828. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:32:48,561][33729] Avg episode reward: [(0, '-120.446')]
[37m[406041 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[409186 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[409325 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:53,550][33729] Fps is (10 sec: 51.2, 60 sec: 85.3, 300 sec: 90.2). Total num frames: 35840. Throughput: 0: 87.5. Samples: 36076. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[36m[2025-07-03 11:32:53,551][33729] Avg episode reward: [(0, '-121.782')]
[37m[409750 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[410915 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[411696 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[412150 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:32:58,549][33729] Fps is (10 sec: 51.3, 60 sec: 85.3, 300 sec: 90.2). Total num frames: 36352. Throughput: 0: 86.5. Samples: 36596. Policy #0 lag: (min: 4.0, avg: 4.5, max: 20.0)
[36m[2025-07-03 11:32:58,549][33729] Avg episode reward: [(0, '-121.782')]
[37m[415037 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[415247 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[416895 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[419323 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:03,546][33729] Fps is (10 sec: 102.4, 60 sec: 85.4, 300 sec: 90.3). Total num frames: 36864. Throughput: 0: 85.3. Samples: 37112. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 11:33:03,546][33729] Avg episode reward: [(0, '-120.323')]
[37m[419649 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[420476 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[423418 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:08,560][33729] Fps is (10 sec: 102.3, 60 sec: 85.3, 300 sec: 90.2). Total num frames: 37376. Throughput: 0: 85.4. Samples: 37372. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[36m[2025-07-03 11:33:08,560][33729] Avg episode reward: [(0, '-118.545')]
[37m[424815 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[425858 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[426214 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[427092 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:13,557][33729] Fps is (10 sec: 102.3, 60 sec: 85.3, 300 sec: 92.0). Total num frames: 37888. Throughput: 0: 85.2. Samples: 37876. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 11:33:13,558][33729] Avg episode reward: [(0, '-116.628')]
[37m[430844 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[430943 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[431513 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[431653 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:18,685][33729] Fps is (10 sec: 101.1, 60 sec: 85.2, 300 sec: 91.9). Total num frames: 38400. Throughput: 0: 84.8. Samples: 38376. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 11:33:18,685][33729] Avg episode reward: [(0, '-117.957')]
[37m[434790 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[435666 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[436243 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[438895 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:23,560][33729] Fps is (10 sec: 51.2, 60 sec: 85.3, 300 sec: 90.3). Total num frames: 38400. Throughput: 0: 85.0. Samples: 38628. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 11:33:23,560][33729] Avg episode reward: [(0, '-113.668')]
[37m[441414 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[442305 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[442745 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[444536 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:28,536][33729] Fps is (10 sec: 52.0, 60 sec: 85.3, 300 sec: 90.3). Total num frames: 38912. Throughput: 0: 84.8. Samples: 39140. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:33:28,536][33729] Avg episode reward: [(0, '-115.667')]
[37m[447527 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[447631 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[448900 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:33,555][33729] Fps is (10 sec: 102.4, 60 sec: 85.3, 300 sec: 90.2). Total num frames: 39424. Throughput: 0: 84.9. Samples: 39648. Policy #0 lag: (min: 4.0, avg: 4.5, max: 20.0)
[36m[2025-07-03 11:33:33,556][33729] Avg episode reward: [(0, '-115.272')]
[37m[451098 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[451893 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[451954 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[452612 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:38,538][33729] Fps is (10 sec: 102.4, 60 sec: 85.4, 300 sec: 90.2). Total num frames: 39936. Throughput: 0: 85.0. Samples: 39900. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 11:33:38,538][33729] Avg episode reward: [(0, '-113.152')]
[37m[455467 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[455805 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[457834 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[459349 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[459403 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:43,569][33729] Fps is (10 sec: 102.3, 60 sec: 85.3, 300 sec: 90.2). Total num frames: 40448. Throughput: 0: 84.9. Samples: 40416. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:33:43,569][33729] Avg episode reward: [(0, '-111.726')]
[37m[461072 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[461845 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:48,567][33729] Fps is (10 sec: 51.0, 60 sec: 76.8, 300 sec: 88.5). Total num frames: 40448. Throughput: 0: 84.7. Samples: 40924. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:33:48,568][33729] Avg episode reward: [(0, '-112.229')]
[37m[464941 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[465703 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[467424 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[468123 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:53,549][33729] Fps is (10 sec: 51.3, 60 sec: 85.3, 300 sec: 90.2). Total num frames: 40960. Throughput: 0: 84.2. Samples: 41160. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[36m[2025-07-03 11:33:53,549][33729] Avg episode reward: [(0, '-107.410')]
[37m[472115 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[472171 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[472225 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[473678 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[474018 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:33:58,544][33729] Fps is (10 sec: 102.6, 60 sec: 85.3, 300 sec: 90.3). Total num frames: 41472. Throughput: 0: 84.4. Samples: 41672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:33:58,544][33729] Avg episode reward: [(0, '-108.372')]
[37m[477644 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:03,572][33729] Fps is (10 sec: 102.2, 60 sec: 85.3, 300 sec: 90.2). Total num frames: 41984. Throughput: 0: 84.9. Samples: 42188. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:34:03,573][33729] Avg episode reward: [(0, '-107.787')]
[37m[479632 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[480038 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[482326 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:08,563][33729] Fps is (10 sec: 102.2, 60 sec: 85.3, 300 sec: 90.2). Total num frames: 42496. Throughput: 0: 84.9. Samples: 42448. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:34:08,563][33729] Avg episode reward: [(0, '-108.387')]
[37m[1m[2025-07-03 11:34:08,610][33729] Saving ./train_dir/gif_exp8/checkpoint_p0/checkpoint_000001328_42496.pth...
[37m[485020 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[485380 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[485487 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[488195 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:13,530][33729] Fps is (10 sec: 102.8, 60 sec: 85.4, 300 sec: 90.3). Total num frames: 43008. Throughput: 0: 85.2. Samples: 42972. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[36m[2025-07-03 11:34:13,530][33729] Avg episode reward: [(0, '-115.156')]
[37m[490662 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[491826 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[492952 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:18,548][33729] Fps is (10 sec: 51.3, 60 sec: 77.0, 300 sec: 88.5). Total num frames: 43008. Throughput: 0: 85.2. Samples: 43480. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[36m[2025-07-03 11:34:18,548][33729] Avg episode reward: [(0, '-116.169')]
[37m[495814 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[498470 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[499034 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:23,539][33729] Fps is (10 sec: 51.2, 60 sec: 85.4, 300 sec: 88.5). Total num frames: 43520. Throughput: 0: 84.9. Samples: 43720. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 11:34:23,539][33729] Avg episode reward: [(0, '-116.689')]
[37m[499746 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[502565 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[502976 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[504313 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:28,564][33729] Fps is (10 sec: 102.2, 60 sec: 85.3, 300 sec: 88.5). Total num frames: 44032. Throughput: 0: 84.7. Samples: 44228. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:34:28,564][33729] Avg episode reward: [(0, '-112.290')]
[37m[506470 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[507935 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[509335 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:33,547][33729] Fps is (10 sec: 102.3, 60 sec: 85.3, 300 sec: 88.5). Total num frames: 44544. Throughput: 0: 84.9. Samples: 44744. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:34:33,548][33729] Avg episode reward: [(0, '-112.230')]
[37m[510433 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[510679 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[512486 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[512552 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:38,545][33729] Fps is (10 sec: 102.6, 60 sec: 85.3, 300 sec: 88.5). Total num frames: 45056. Throughput: 0: 85.5. Samples: 45008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:34:38,546][33729] Avg episode reward: [(0, '-109.585')]
[37m[515945 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[516130 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[517262 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:43,568][33729] Fps is (10 sec: 102.2, 60 sec: 85.3, 300 sec: 90.2). Total num frames: 45568. Throughput: 0: 85.3. Samples: 45512. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:34:43,569][33729] Avg episode reward: [(0, '-110.140')]
[37m[520551 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[520789 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[522758 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[524346 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:48,558][33729] Fps is (10 sec: 51.1, 60 sec: 85.3, 300 sec: 88.5). Total num frames: 45568. Throughput: 0: 85.3. Samples: 46024. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:34:48,558][33729] Avg episode reward: [(0, '-109.791')]
[37m[526015 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[526744 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[528171 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[529094 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:53,533][33729] Fps is (10 sec: 51.4, 60 sec: 85.4, 300 sec: 88.5). Total num frames: 46080. Throughput: 0: 85.0. Samples: 46272. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[36m[2025-07-03 11:34:53,533][33729] Avg episode reward: [(0, '-106.555')]
[37m[531201 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[531344 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[534539 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:34:58,546][33729] Fps is (10 sec: 102.5, 60 sec: 85.3, 300 sec: 88.5). Total num frames: 46592. Throughput: 0: 84.9. Samples: 46796. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[36m[2025-07-03 11:34:58,546][33729] Avg episode reward: [(0, '-106.042')]
[37m[535373 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[535433 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:03,573][33729] Fps is (10 sec: 102.0, 60 sec: 85.3, 300 sec: 88.5). Total num frames: 47104. Throughput: 0: 84.7. Samples: 47292. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:35:03,574][33729] Avg episode reward: [(0, '-105.251')]
[37m[540460 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[540782 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[541591 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[541905 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:08,541][33729] Fps is (10 sec: 102.5, 60 sec: 85.4, 300 sec: 88.5). Total num frames: 47616. Throughput: 0: 85.2. Samples: 47552. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:35:08,541][33729] Avg episode reward: [(0, '-103.512')]
[37m[545992 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[546707 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[547104 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[549560 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:13,558][33729] Fps is (10 sec: 102.5, 60 sec: 85.3, 300 sec: 88.5). Total num frames: 48128. Throughput: 0: 85.4. Samples: 48072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:35:13,558][33729] Avg episode reward: [(0, '-103.974')]
[37m[551832 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[551972 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[552027 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:18,543][33729] Fps is (10 sec: 51.2, 60 sec: 85.3, 300 sec: 86.8). Total num frames: 48128. Throughput: 0: 85.4. Samples: 48588. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:35:18,543][33729] Avg episode reward: [(0, '-103.275')]
[37m[555355 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[555577 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[557552 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:23,533][33729] Fps is (10 sec: 51.3, 60 sec: 85.3, 300 sec: 86.8). Total num frames: 48640. Throughput: 0: 85.2. Samples: 48840. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 11:35:23,533][33729] Avg episode reward: [(0, '-103.019')]
[37m[559589 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[560767 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[562320 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[562741 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:28,545][33729] Fps is (10 sec: 102.4, 60 sec: 85.4, 300 sec: 86.8). Total num frames: 49152. Throughput: 0: 85.6. Samples: 49360. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:35:28,545][33729] Avg episode reward: [(0, '-105.545')]
[37m[566477 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[567985 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[568431 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:33,531][33729] Fps is (10 sec: 102.4, 60 sec: 85.4, 300 sec: 86.8). Total num frames: 49664. Throughput: 0: 85.7. Samples: 49880. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:35:33,531][33729] Avg episode reward: [(0, '-102.796')]
[37m[570215 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[571915 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[573071 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[573342 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:38,543][33729] Fps is (10 sec: 102.4, 60 sec: 85.3, 300 sec: 86.8). Total num frames: 50176. Throughput: 0: 86.1. Samples: 50148. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:35:38,544][33729] Avg episode reward: [(0, '-98.852')]
[37m[575398 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[575457 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[577849 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[579253 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:43,567][33729] Fps is (10 sec: 102.0, 60 sec: 85.3, 300 sec: 88.5). Total num frames: 50688. Throughput: 0: 86.0. Samples: 50668. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:35:43,567][33729] Avg episode reward: [(0, '-99.850')]
[37m[580836 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[584369 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:48,580][33729] Fps is (10 sec: 51.0, 60 sec: 85.3, 300 sec: 86.8). Total num frames: 50688. Throughput: 0: 86.3. Samples: 51176. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:35:48,581][33729] Avg episode reward: [(0, '-99.050')]
[37m[584868 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[585326 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[586637 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:53,578][33729] Fps is (10 sec: 51.1, 60 sec: 85.3, 300 sec: 86.8). Total num frames: 51200. Throughput: 0: 85.9. Samples: 51420. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:35:53,578][33729] Avg episode reward: [(0, '-98.806')]
[37m[589686 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[590164 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[591823 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[591878 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:35:58,550][33729] Fps is (10 sec: 102.7, 60 sec: 85.3, 300 sec: 86.8). Total num frames: 51712. Throughput: 0: 85.8. Samples: 51932. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:35:58,551][33729] Avg episode reward: [(0, '-96.995')]
[37m[595723 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[595922 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[598871 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[599391 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:03,555][33729] Fps is (10 sec: 102.6, 60 sec: 85.4, 300 sec: 86.8). Total num frames: 52224. Throughput: 0: 85.7. Samples: 52444. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:36:03,555][33729] Avg episode reward: [(0, '-95.159')]
[37m[599694 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[599843 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:08,539][33729] Fps is (10 sec: 102.5, 60 sec: 85.3, 300 sec: 86.8). Total num frames: 52736. Throughput: 0: 85.8. Samples: 52700. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:36:08,540][33729] Avg episode reward: [(0, '-94.158')]
[37m[1m[2025-07-03 11:36:08,592][33729] Saving ./train_dir/gif_exp8/checkpoint_p0/checkpoint_000001648_52736.pth...
[37m[605115 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[605225 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[605284 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[607197 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[607397 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[609027 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:13,569][33729] Fps is (10 sec: 102.3, 60 sec: 85.3, 300 sec: 86.8). Total num frames: 53248. Throughput: 0: 85.3. Samples: 53200. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:36:13,569][33729] Avg episode reward: [(0, '-95.481')]
[37m[611931 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[612815 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[613334 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[614439 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:18,564][33729] Fps is (10 sec: 51.1, 60 sec: 85.3, 300 sec: 85.0). Total num frames: 53248. Throughput: 0: 84.9. Samples: 53704. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[36m[2025-07-03 11:36:18,564][33729] Avg episode reward: [(0, '-93.370')]
[37m[616445 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[617922 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[618116 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:23,537][33729] Fps is (10 sec: 51.4, 60 sec: 85.3, 300 sec: 85.0). Total num frames: 53760. Throughput: 0: 84.5. Samples: 53952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:36:23,537][33729] Avg episode reward: [(0, '-91.875')]
[37m[619837 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[619893 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[622574 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[622995 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:28,562][33729] Fps is (10 sec: 102.4, 60 sec: 85.3, 300 sec: 85.0). Total num frames: 54272. Throughput: 0: 84.2. Samples: 54456. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 11:36:28,563][33729] Avg episode reward: [(0, '-91.055')]
[37m[625366 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[625627 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[625681 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[628764 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[628906 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:33,576][33729] Fps is (10 sec: 102.0, 60 sec: 85.3, 300 sec: 86.8). Total num frames: 54784. Throughput: 0: 84.3. Samples: 54968. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[36m[2025-07-03 11:36:33,577][33729] Avg episode reward: [(0, '-88.623')]
[37m[632184 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[632527 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[634513 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:38,553][33729] Fps is (10 sec: 102.5, 60 sec: 85.3, 300 sec: 86.8). Total num frames: 55296. Throughput: 0: 84.6. Samples: 55224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:36:38,554][33729] Avg episode reward: [(0, '-85.323')]
[37m[635726 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[636737 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[637576 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:43,553][33729] Fps is (10 sec: 102.6, 60 sec: 85.4, 300 sec: 86.8). Total num frames: 55808. Throughput: 0: 84.4. Samples: 55728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:36:43,553][33729] Avg episode reward: [(0, '-87.144')]
[37m[640119 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[640925 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[644132 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:48,553][33729] Fps is (10 sec: 51.2, 60 sec: 85.4, 300 sec: 85.0). Total num frames: 55808. Throughput: 0: 84.0. Samples: 56224. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:36:48,553][33729] Avg episode reward: [(0, '-86.860')]
[37m[644615 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[648100 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[649439 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:53,541][33729] Fps is (10 sec: 51.3, 60 sec: 85.4, 300 sec: 85.0). Total num frames: 56320. Throughput: 0: 83.7. Samples: 56468. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 11:36:53,542][33729] Avg episode reward: [(0, '-81.256')]
[37m[650082 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[652040 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[654184 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[37m[654462 ms][asset_manager] - INFO : Number of obstacles required in the environment by the                   code is lesser than the minimum number of obstacles that the environment configuration specifies. (asset_manager.py:53)
[36m[2025-07-03 11:36:58,555][33729] Fps is (10 sec: 102.4, 60 sec: 85.3, 300 sec: 85.0). Total num frames: 56832. Throughput: 0: 83.9. Samples: 56976. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
