Importing module 'gym_38' (/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
[36m[2025-07-03 17:19:20,206][07522] Queried available GPUs: 0
[37m[1m[2025-07-03 17:19:20,206][07522] Environment var CUDA_VISIBLE_DEVICES is 0
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/utils/cpp_extension.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging  # type: ignore[attr-defined]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
Using /home/ziyar/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
Emitting ninja build file /home/ziyar/.cache/torch_extensions/py38_cu117/gymtorch/build.ninja...
Building extension module gymtorch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module gymtorch...
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/graph.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping
PyTorch version 1.13.1
Device count 1
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
Warp 1.0.0-beta.5 initialized:
   CUDA Toolkit: 11.5, Driver: 12.4
   Devices:
     "cpu"    | x86_64
     "cuda:0" | NVIDIA GeForce RTX 4080 Laptop GPU (sm_89)
   Kernel cache: /home/ziyar/.cache/warp/1.0.0-beta.5
[SUBPROCESS] FORCED headless mode for all Sample Factory training: headless=True
[SUBPROCESS] This prevents Isaac Gym viewer conflicts across all processes
[SUBPROCESS] Task action_space_dim: 3
[SUBPROCESS] Target Sample Factory action space: 3D
[SUBPROCESS] Setting num_envs to 16 based on env_agents=16
[SUBPROCESS] Set SF_ENV_AGENTS=16 environment variable
[SUBPROCESS] Config batch_size: 2048
[SUBPROCESS] Using STANDARD CONFIG (16 environments)
Registered quad_with_obstacles_gate and dce_navigation_task_gate in subprocess
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles_gate', '--experiment=base_gate_rewards_classic34', '--train_dir=./train_dir', '--num_workers=1', '--num_envs_per_worker=1', '--env_agents=16', '--obs_key=observations', '--batch_size=2048', '--num_batches_to_accumulate=2', '--num_batches_per_epoch=8', '--num_epochs=4', '--rollout=32', '--learning_rate=0.0003', '--use_rnn=true', '--rnn_size=64', '--rnn_num_layers=1', '--encoder_mlp_layers', '512', '256', '64', '--gamma=0.98', '--reward_scale=0.1', '--max_grad_norm=1.0', '--async_rl=true', '--normalize_input=true', '--use_env_info_cache=false', '--with_wandb=true', '--wandb_project=gate_navigation_dual_camera', '--wandb_user=ziya-ruso-ucl', '--wandb_group=gate_navigation_training', '--wandb_tags', 'aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized', '--save_every_sec=120', '--save_best_every_sec=5', '--train_for_env_steps=100000000', '--save_gifs=true']
Not connected to PVD
+++ Using GPU PhysX
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  from collections import Mapping, Set, Iterable
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/networkx/readwrite/graphml.py:346: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  (np.int, "int"), (np.int8, "int"),
/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python/isaacgym/torch_utils.py:135: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  def get_axis_params(value, axis_idx, x_value=0., dtype=np.float, n_dims=3):
[37m[1802 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task_gate.py:22)
[37m[1802 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Final headless mode: False (dce_navigation_task_gate.py:29)
[37m[1802 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Found SF_ENV_AGENTS environment variable: 16 (dce_navigation_task_gate.py:39)
[37m[1802 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Detected env_agents=16 from environment - setting environment count. (dce_navigation_task_gate.py:45)
[37m[1802 ms][base_task] - INFO : Setting seed: 1126485170 (base_task.py:38)
[37m[1813 ms][navigation_task_gate] - INFO : Building environment for gate navigation task. (navigation_task_gate.py:48)
[37m[1813 ms][navigation_task_gate] - INFO : Sim Name: base_sim, Env Name: gate_env, Robot Name: lmf2, Controller Name: lmf2_position_control (navigation_task_gate.py:49)
[37m[1814 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[1814 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[1814 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[1814 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[1814 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[1814 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[1815 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[1815 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[1815 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[1815 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[1815 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[1815 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[1815 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
[37m[2869 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[2869 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[3113 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[3113 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[3113 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[3113 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[3114 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[3114 ms][BaseRobot] - INFO : Initializing controller lmf2_position_control (base_robot.py:29)
[33m[3114 ms][base_multirotor] - WARNING : Creating 16 multirotors. (base_multirotor.py:32)
[37m[3114 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[3114 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[3114 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3115 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3120 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3121 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3122 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3123 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3124 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3125 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3126 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3127 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3128 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3128 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[3130 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[3702 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[3702 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[3702 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[3724 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[3732 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[3732 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[3814 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[3814 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[3855 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 10 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[4241 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[4242 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
[37m[4899 ms][navigation_task_gate] - INFO : Setting up static camera for gate navigation... (navigation_task_gate.py:487)
[37m[4899 ms][navigation_task_gate] - INFO : Static camera properties: 480x270, FOV: 87.0Â° (navigation_task_gate.py:506)
[37m[4959 ms][navigation_task_gate] - INFO : âœ“ Static camera setup complete (navigation_task_gate.py:523)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[36m[2025-07-03 17:19:25,346][07760] Env info: EnvInfo(obs_space=Dict('obs': Box(-inf, inf, (145,), float32)), action_space=Box(-1.0, 1.0, (3,), float32), num_agents=16, gpu_actions=True, gpu_observations=True, action_splits=None, all_discrete=None, frameskip=1, reward_shaping_scheme=None, env_info_protocol_version=1)
[33m[2025-07-03 17:19:26,118][07522] In serial mode all components run on the same process. Only use async_rl and serial mode together for debugging.
[36m[2025-07-03 17:19:26,118][07522] Starting experiment with the following configuration:
[36mhelp=False
[36malgo=APPO
[36menv=quad_with_obstacles_gate
[36mexperiment=base_gate_rewards_classic34
[36mtrain_dir=./train_dir
[36mrestart_behavior=resume
[36mdevice=gpu
[36mseed=None
[36mnum_policies=1
[36masync_rl=True
[36mserial_mode=True
[36mbatched_sampling=True
[36mnum_batches_to_accumulate=2
[36mworker_num_splits=1
[36mpolicy_workers_per_policy=1
[36mmax_policy_lag=1000
[36mnum_workers=1
[36mnum_envs_per_worker=1
[36mbatch_size=2048
[36mnum_batches_per_epoch=8
[36mnum_epochs=4
[36mrollout=32
[36mrecurrence=32
[36mshuffle_minibatches=False
[36mgamma=0.98
[36mreward_scale=0.1
[36mreward_clip=1000.0
[36mvalue_bootstrap=True
[36mnormalize_returns=True
[36mexploration_loss_coeff=0.001
[36mvalue_loss_coeff=2.0
[36mkl_loss_coeff=0.1
[36mexploration_loss=entropy
[36mgae_lambda=0.95
[36mppo_clip_ratio=0.2
[36mppo_clip_value=1.0
[36mwith_vtrace=False
[36mvtrace_rho=1.0
[36mvtrace_c=1.0
[36moptimizer=adam
[36madam_eps=1e-06
[36madam_beta1=0.9
[36madam_beta2=0.999
[36mmax_grad_norm=1.0
[36mlearning_rate=0.0003
[36mlr_schedule=kl_adaptive_epoch
[36mlr_schedule_kl_threshold=0.016
[36mlr_adaptive_min=1e-06
[36mlr_adaptive_max=0.01
[36mobs_subtract_mean=0.0
[36mobs_scale=1.0
[36mnormalize_input=True
[36mnormalize_input_keys=None
[36mdecorrelate_experience_max_seconds=0
[36mdecorrelate_envs_on_one_worker=True
[36mactor_worker_gpus=[0]
[36mset_workers_cpu_affinity=True
[36mforce_envs_single_thread=False
[36mdefault_niceness=0
[36mlog_to_file=True
[36mexperiment_summaries_interval=10
[36mflush_summaries_interval=30
[36mstats_avg=100
[36msummaries_use_frameskip=True
[36mheartbeat_interval=20
[36mheartbeat_reporting_interval=180
[36mtrain_for_env_steps=100000000
[36mtrain_for_seconds=10000000000
[36msave_every_sec=120
[36mkeep_checkpoints=5
[36mload_checkpoint_kind=latest
[36msave_milestones_sec=-1
[36msave_best_every_sec=5
[36msave_best_metric=reward
[36msave_best_after=100000
[36mbenchmark=False
[36mencoder_mlp_layers=[512, 256, 64]
[36mencoder_conv_architecture=convnet_simple
[36mencoder_conv_mlp_layers=[]
[36muse_rnn=True
[36mrnn_size=64
[36mrnn_type=gru
[36mrnn_num_layers=1
[36mdecoder_mlp_layers=[]
[36mnonlinearity=elu
[36mpolicy_initialization=torch_default
[36mpolicy_init_gain=1.0
[36mactor_critic_share_weights=True
[36madaptive_stddev=True
[36mcontinuous_tanh_scale=0.0
[36minitial_stddev=1.0
[36muse_env_info_cache=False
[36menv_gpu_actions=True
[36menv_gpu_observations=True
[36menv_frameskip=1
[36menv_framestack=1
[36mpixel_format=CHW
[36muse_record_episode_statistics=False
[36mwith_wandb=True
[36mwandb_user=ziya-ruso-ucl
[36mwandb_project=gate_navigation_dual_camera
[36mwandb_group=gate_navigation_training
[36mwandb_job_type=SF
[36mwandb_tags=['aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized']
[36mwith_pbt=False
[36mpbt_mix_policies_in_one_env=True
[36mpbt_period_env_steps=5000000
[36mpbt_start_mutation=20000000
[36mpbt_replace_fraction=0.3
[36mpbt_mutation_rate=0.15
[36mpbt_replace_reward_gap=0.1
[36mpbt_replace_reward_gap_absolute=1e-06
[36mpbt_optimize_gamma=False
[36mpbt_target_objective=true_objective
[36mpbt_perturb_min=1.1
[36mpbt_perturb_max=1.5
[36menv_agents=16
[36mheadless=False
[36msave_gifs=True
[36mobs_key=observations
[36msubtask=None
[36mige_api_version=preview4
[36meval_stats=False
[36maction_space_dim=3
[36mcommand_line=--env=quad_with_obstacles_gate --experiment=base_gate_rewards_classic34 --train_dir=./train_dir --num_workers=1 --num_envs_per_worker=1 --env_agents=16 --obs_key=observations --batch_size=2048 --num_batches_to_accumulate=2 --num_batches_per_epoch=8 --num_epochs=4 --rollout=32 --learning_rate=0.0003 --use_rnn=true --rnn_size=64 --rnn_num_layers=1 --encoder_mlp_layers 512 256 64 --gamma=0.98 --reward_scale=0.1 --max_grad_norm=1.0 --async_rl=true --normalize_input=true --use_env_info_cache=false --with_wandb=true --wandb_project=gate_navigation_dual_camera --wandb_user=ziya-ruso-ucl --wandb_group=gate_navigation_training --wandb_tags aerial_gym gate_navigation dual_camera x500 sample_factory memory_optimized --save_every_sec=120 --save_best_every_sec=5 --train_for_env_steps=100000000 --headless=false --save_gifs=true
[36mcli_args={'env': 'quad_with_obstacles_gate', 'experiment': 'base_gate_rewards_classic34', 'train_dir': './train_dir', 'async_rl': True, 'num_batches_to_accumulate': 2, 'num_workers': 1, 'num_envs_per_worker': 1, 'batch_size': 2048, 'num_batches_per_epoch': 8, 'num_epochs': 4, 'rollout': 32, 'gamma': 0.98, 'reward_scale': 0.1, 'max_grad_norm': 1.0, 'learning_rate': 0.0003, 'normalize_input': True, 'train_for_env_steps': 100000000, 'save_every_sec': 120, 'save_best_every_sec': 5, 'encoder_mlp_layers': [512, 256, 64], 'use_rnn': True, 'rnn_size': 64, 'rnn_num_layers': 1, 'use_env_info_cache': False, 'with_wandb': True, 'wandb_user': 'ziya-ruso-ucl', 'wandb_project': 'gate_navigation_dual_camera', 'wandb_group': 'gate_navigation_training', 'wandb_tags': ['aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized'], 'env_agents': 16, 'headless': False, 'save_gifs': True, 'obs_key': 'observations'}
[36mgit_hash=a54f99d681da80aa6215176cae93d2948a30ac42
[36mgit_repo_name=git@github.com:rusoziya/aerial_gym_simulator.git
[36mwandb_unique_id=base_gate_rewards_classic34_20250703_171916_897955
[36m[2025-07-03 17:19:26,118][07522] Saving configuration to ./train_dir/base_gate_rewards_classic34/config.json...
[36m[2025-07-03 17:19:26,172][07522] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-03 17:19:26,173][07522] Rollout worker 0 uses device cuda:0
[36m[2025-07-03 17:19:26,187][07522] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 17:19:26,187][07522] InferenceWorker_p0-w0: min num requests: 1
[36m[2025-07-03 17:19:26,188][07522] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 17:19:26,189][07522] Starting seed is not provided
[36m[2025-07-03 17:19:26,189][07522] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[36m[2025-07-03 17:19:26,189][07522] Initializing actor-critic model on device cuda:0
[36m[2025-07-03 17:19:26,190][07522] RunningMeanStd input shape: (145,)
[36m[2025-07-03 17:19:26,190][07522] RunningMeanStd input shape: (1,)
[36m[2025-07-03 17:19:26,218][07522] Created Actor Critic model with architecture:
[36m[2025-07-03 17:19:26,218][07522] ActorCriticSharedWeights(
[36m  (obs_normalizer): ObservationNormalizer(
[36m    (running_mean_std): RunningMeanStdDictInPlace(
[36m      (running_mean_std): ModuleDict(
[36m        (obs): RunningMeanStdInPlace()
[36m      )
[36m    )
[36m  )
[36m  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
[36m  (encoder): MultiInputEncoder(
[36m    (encoders): ModuleDict(
[36m      (obs): MlpEncoder(
[36m        (mlp_head): RecursiveScriptModule(
[36m          original_name=Sequential
[36m          (0): RecursiveScriptModule(original_name=Linear)
[36m          (1): RecursiveScriptModule(original_name=ELU)
[36m          (2): RecursiveScriptModule(original_name=Linear)
[36m          (3): RecursiveScriptModule(original_name=ELU)
[36m          (4): RecursiveScriptModule(original_name=Linear)
[36m          (5): RecursiveScriptModule(original_name=ELU)
[36m        )
[36m      )
[36m    )
[36m  )
[36m  (core): ModelCoreRNN(
[36m    (core): GRU(64, 64)
[36m  )
[36m  (decoder): MlpDecoder(
[36m    (mlp): Identity()
[36m  )
[36m  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
[36m  (action_parameterization): ActionParameterizationDefault(
[36m    (distribution_linear): Linear(in_features=64, out_features=6, bias=True)
[36m  )
[36m)
creating render graph
Module warp.utils load on device 'cuda:0' took 2.52 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 8.44 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 12.33 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 6.43 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] GIF saving ENABLED for dual cameras (drone + static)
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 16
[AerialGymVecEnv] Detected observation space: 145D
[AerialGymVecEnv] Using GATE NAVIGATION configuration (145D = 17D basic + 64D drone VAE + 64D static camera VAE)
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[isaacgym:gymutil.py] Unknown args:  ['--env=quad_with_obstacles_gate', '--experiment=base_gate_rewards_classic34', '--train_dir=./train_dir', '--num_workers=1', '--num_envs_per_worker=1', '--env_agents=16', '--obs_key=observations', '--batch_size=2048', '--num_batches_to_accumulate=2', '--num_batches_per_epoch=8', '--num_epochs=4', '--rollout=32', '--learning_rate=0.0003', '--use_rnn=true', '--rnn_size=64', '--rnn_num_layers=1', '--encoder_mlp_layers', '512', '256', '64', '--gamma=0.98', '--reward_scale=0.1', '--max_grad_norm=1.0', '--async_rl=true', '--normalize_input=true', '--use_env_info_cache=false', '--with_wandb=true', '--wandb_project=gate_navigation_dual_camera', '--wandb_user=ziya-ruso-ucl', '--wandb_group=gate_navigation_training', '--wandb_tags', 'aerial_gym', 'gate_navigation', 'dual_camera', 'x500', 'sample_factory', 'memory_optimized', '--save_every_sec=120', '--save_best_every_sec=5', '--train_for_env_steps=100000000', '--save_gifs=true']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.55 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 7.82 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 11.65 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 5.78 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
[AerialGymVecEnv] GIF saving ENABLED for dual cameras (drone + static)
[AerialGymVecEnv] Forced action space shape: (3,)
[AerialGymVecEnv] is_multiagent: True, num_agents: 16
[AerialGymVecEnv] Detected observation space: 145D
[AerialGymVecEnv] Using GATE NAVIGATION configuration (145D = 17D basic + 64D drone VAE + 64D static camera VAE)
[make_aerialgym_env] Final action space shape: (3,)
[make_aerialgym_env] Action space: Box(-1.0, 1.0, (3,), float32)
[36m[2025-07-03 17:19:26,672][07522] Using optimizer <class 'torch.optim.adam.Adam'>
[33m[2025-07-03 17:19:26,673][07522] No checkpoints found
[36m[2025-07-03 17:19:26,673][07522] Did not load from checkpoint, starting from scratch!
[36m[2025-07-03 17:19:26,673][07522] Initialized policy 0 weights for model version 0
[36m[2025-07-03 17:19:26,673][07522] LearnerWorker_p0 finished initialization!
[36m[2025-07-03 17:19:26,674][07522] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[37m[1m[2025-07-03 17:19:26,682][07522] Inference worker 0-0 is ready!
[37m[1m[2025-07-03 17:19:26,682][07522] All inference workers are ready! Signal rollout workers to start!
[36m[2025-07-03 17:19:26,682][07522] EnvRunner 0-0 uses policy 0
[37m[12084 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Using SF_HEADLESS environment variable: False (dce_navigation_task_gate.py:22)
[37m[12084 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : DCE Gate Navigation Task - Final headless mode: False (dce_navigation_task_gate.py:29)
[37m[12084 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Found SF_ENV_AGENTS environment variable: 16 (dce_navigation_task_gate.py:39)
[37m[12084 ms][aerial_gym.examples.dce_rl_navigation.dce_navigation_task_gate] - INFO : Detected env_agents=16 from environment - setting environment count. (dce_navigation_task_gate.py:45)
[37m[12084 ms][base_task] - INFO : Setting seed: 1327012459 (base_task.py:38)
[37m[12084 ms][navigation_task_gate] - INFO : Building environment for gate navigation task. (navigation_task_gate.py:48)
[37m[12084 ms][navigation_task_gate] - INFO : Sim Name: base_sim, Env Name: gate_env, Robot Name: lmf2, Controller Name: lmf2_position_control (navigation_task_gate.py:49)
[37m[12085 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[12085 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[12085 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[12085 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[12085 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[12085 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[12087 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[12087 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[12087 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[37m[12087 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: 0 (IGE_env_manager.py:119)
[37m[12087 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[12087 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[12087 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[37m[13068 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[13077 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[13282 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[13282 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[13282 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[13282 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[13283 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[13283 ms][BaseRobot] - INFO : Initializing controller lmf2_position_control (base_robot.py:29)
[33m[13283 ms][base_multirotor] - WARNING : Creating 16 multirotors. (base_multirotor.py:32)
[37m[13283 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[13283 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[13283 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13283 ms][asset_loader] - INFO : Loading asset: gate.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13287 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13288 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13289 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13290 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13291 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13292 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13293 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13294 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13295 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13296 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[13298 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[13315 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:437)
[33m[13315 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:440)
[31m[13315 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:443)
[37m[13335 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[13344 ms][IsaacGymEnvManager] - WARNING : Headless: False (IGE_env_manager.py:424)
[37m[13344 ms][IsaacGymEnvManager] - INFO : Creating viewer (IGE_env_manager.py:426)
[33m[13409 ms][IGE_viewer_control] - WARNING : Instructions for using the viewer with the keyboard:
[33mESC: Quit
[33mV: Toggle Viewer Sync
[33mS: Sync Frame Time
[33mF: Toggle Camera Follow
[33mP: Toggle Camera Follow Type
[33mR: Reset All Environments
[33mUP: Switch Target Environment Up
[33mDOWN: Switch Target Environment Down
[33mSPACE: Pause Simulation
[33m (IGE_viewer_control.py:153)
[37m[13409 ms][IsaacGymEnvManager] - INFO : Created viewer (IGE_env_manager.py:432)
[33m[13439 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 10 (asset_manager.py:32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[13632 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[13633 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
[37m[14246 ms][navigation_task_gate] - INFO : Setting up static camera for gate navigation... (navigation_task_gate.py:487)
[37m[14246 ms][navigation_task_gate] - INFO : Static camera properties: 480x270, FOV: 87.0Â° (navigation_task_gate.py:506)
[37m[14307 ms][navigation_task_gate] - INFO : âœ“ Static camera setup complete (navigation_task_gate.py:523)
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.num_agents to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_agents` for environment variables or `env.get_wrapper_attr('num_agents')` that will search the reminding wrappers.
  logger.warn(
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.is_multiagent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_multiagent` for environment variables or `env.get_wrapper_attr('is_multiagent')` that will search the reminding wrappers.
  logger.warn(
[36m[2025-07-03 17:19:31,983][07522] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:19:31,983][07522] Avg episode reward: [(0, '-100.000')]
[GIF] Episode 0 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0000_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0000_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0000_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0000_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0000_merged_dual_camera.gif
[33m[18679 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[36m[2025-07-03 17:19:34,605][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 18.3. Samples: 48. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:19:34,605][07522] Avg episode reward: [(0, '-110.556')]
[36m[2025-07-03 17:19:39,556][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 150.0. Samples: 1136. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:19:39,556][07522] Avg episode reward: [(0, '-81.276')]
[36m[2025-07-03 17:19:44,565][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 150.1. Samples: 1888. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:19:44,565][07522] Avg episode reward: [(0, '-80.160')]
[37m[1m[2025-07-03 17:19:46,254][07522] Heartbeat connected on Batcher_0
[37m[1m[2025-07-03 17:19:46,254][07522] Heartbeat connected on LearnerWorker_p0
[37m[1m[2025-07-03 17:19:46,254][07522] Heartbeat connected on InferenceWorker_p0-w0
[37m[1m[2025-07-03 17:19:46,254][07522] Heartbeat connected on RolloutWorker_w0
[36m[2025-07-03 17:19:49,584][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 190.0. Samples: 3344. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:19:49,584][07522] Avg episode reward: [(0, '-81.285')]
[36m[2025-07-03 17:19:54,570][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 211.8. Samples: 4784. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:19:54,571][07522] Avg episode reward: [(0, '-81.086')]
[36m[2025-07-03 17:19:59,547][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 202.0. Samples: 5568. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:19:59,548][07522] Avg episode reward: [(0, '-82.489')]
[36m[2025-07-03 17:20:04,564][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 213.1. Samples: 6944. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:20:04,564][07522] Avg episode reward: [(0, '-79.913')]
[36m[2025-07-03 17:20:09,577][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 226.4. Samples: 8512. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:20:09,577][07522] Avg episode reward: [(0, '-82.136')]
[36m[2025-07-03 17:20:14,559][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 218.0. Samples: 9280. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:20:14,559][07522] Avg episode reward: [(0, '-79.702')]
[33m[60080 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[60081 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task_gate/navigation_task_gate.py:444: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/success_rate"] = torch.tensor(success_rate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task_gate/navigation_task_gate.py:445: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/crash_rate"] = torch.tensor(crash_rate, dtype=torch.float32)
/home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task_gate/navigation_task_gate.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.infos["curriculum/timeout_rate"] = torch.tensor(timeout_rate, dtype=torch.float32)
[36m[2025-07-03 17:20:19,580][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 237.6. Samples: 10736. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:20:19,580][07522] Avg episode reward: [(0, '-80.673')]
[36m[2025-07-03 17:20:24,543][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 246.1. Samples: 12208. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:20:24,544][07522] Avg episode reward: [(0, '-81.267')]
[36m[2025-07-03 17:20:29,584][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 245.6. Samples: 12944. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:20:29,584][07522] Avg episode reward: [(0, '-81.933')]
[36m[2025-07-03 17:20:34,608][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 245.6. Samples: 14400. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:20:34,608][07522] Avg episode reward: [(0, '-80.661')]
[GIF] Episode 100 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0001_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0001_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0001_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0001_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0001_merged_dual_camera.gif
[36m[2025-07-03 17:20:39,562][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 244.7. Samples: 15792. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[36m[2025-07-03 17:20:39,562][07522] Avg episode reward: [(0, '-80.145')]
/home/ziyar/miniforge3/envs/aerialgym/lib/python3.8/site-packages/torch/nn/modules/module.py:1194: UserWarning: operator() profile_node %104 : int[] = prim::profile_ivalue(%102)
 does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)
  return forward_call(*input, **kwargs)
[36m[2025-07-03 17:20:44,543][07522] Fps is (10 sec: 1649.1, 60 sec: 273.2, 300 sec: 225.8). Total num frames: 16384. Throughput: 0: 241.1. Samples: 16416. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:20:44,543][07522] Avg episode reward: [(0, '-80.303')]
[36m[2025-07-03 17:20:49,581][07522] Fps is (10 sec: 1635.2, 60 sec: 273.1, 300 sec: 211.1). Total num frames: 16384. Throughput: 0: 240.6. Samples: 17776. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:20:49,581][07522] Avg episode reward: [(0, '-80.269')]
[36m[2025-07-03 17:20:54,592][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 198.3). Total num frames: 16384. Throughput: 0: 236.4. Samples: 19152. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:20:54,592][07522] Avg episode reward: [(0, '-81.753')]
[33m[102379 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[102379 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:20:59,582][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 187.0). Total num frames: 16384. Throughput: 0: 236.0. Samples: 19904. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:20:59,582][07522] Avg episode reward: [(0, '-80.224')]
[36m[2025-07-03 17:21:04,563][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 177.0). Total num frames: 16384. Throughput: 0: 234.4. Samples: 21280. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:21:04,563][07522] Avg episode reward: [(0, '-81.256')]
[36m[2025-07-03 17:21:09,585][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 167.9). Total num frames: 16384. Throughput: 0: 230.5. Samples: 22592. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:21:09,585][07522] Avg episode reward: [(0, '-81.152')]
[36m[2025-07-03 17:21:14,575][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 159.7). Total num frames: 16384. Throughput: 0: 231.2. Samples: 23344. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:21:14,575][07522] Avg episode reward: [(0, '-81.006')]
[36m[2025-07-03 17:21:19,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 152.3). Total num frames: 16384. Throughput: 0: 228.9. Samples: 24688. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:21:19,551][07522] Avg episode reward: [(0, '-79.912')]
[37m[1m[2025-07-03 17:21:19,617][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000032_16384.pth...
[36m[2025-07-03 17:21:24,538][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 145.6). Total num frames: 16384. Throughput: 0: 228.7. Samples: 26080. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:21:24,538][07522] Avg episode reward: [(0, '-81.486')]
[36m[2025-07-03 17:21:29,589][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 139.3). Total num frames: 16384. Throughput: 0: 230.9. Samples: 26816. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:21:29,589][07522] Avg episode reward: [(0, '-80.987')]
[36m[2025-07-03 17:21:34,562][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 133.7). Total num frames: 16384. Throughput: 0: 231.9. Samples: 28208. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:21:34,562][07522] Avg episode reward: [(0, '-80.273')]
[36m[2025-07-03 17:21:39,575][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 128.4). Total num frames: 16384. Throughput: 0: 232.3. Samples: 29600. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:21:39,575][07522] Avg episode reward: [(0, '-80.789')]
[33m[145820 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[145820 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:21:44,545][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 123.6). Total num frames: 16384. Throughput: 0: 232.7. Samples: 30368. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:21:44,545][07522] Avg episode reward: [(0, '-80.430')]
[GIF] Episode 200 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0002_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0002_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0002_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0002_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0002_merged_dual_camera.gif
[36m[2025-07-03 17:21:49,558][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 119.1). Total num frames: 16384. Throughput: 0: 234.0. Samples: 31808. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[36m[2025-07-03 17:21:49,558][07522] Avg episode reward: [(0, '-81.483')]
[36m[2025-07-03 17:21:54,552][07522] Fps is (10 sec: 1637.2, 60 sec: 273.2, 300 sec: 229.8). Total num frames: 32768. Throughput: 0: 233.1. Samples: 33072. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:21:54,552][07522] Avg episode reward: [(0, '-81.973')]
[36m[2025-07-03 17:21:59,597][07522] Fps is (10 sec: 1632.1, 60 sec: 273.0, 300 sec: 222.0). Total num frames: 32768. Throughput: 0: 232.8. Samples: 33824. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:21:59,597][07522] Avg episode reward: [(0, '-80.028')]
[36m[2025-07-03 17:22:04,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 214.8). Total num frames: 32768. Throughput: 0: 233.9. Samples: 35216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:04,569][07522] Avg episode reward: [(0, '-80.875')]
[36m[2025-07-03 17:22:09,583][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 207.9). Total num frames: 32768. Throughput: 0: 236.2. Samples: 36720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:09,583][07522] Avg episode reward: [(0, '-78.998')]
[36m[2025-07-03 17:22:14,566][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 201.5). Total num frames: 32768. Throughput: 0: 235.5. Samples: 37408. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:14,566][07522] Avg episode reward: [(0, '-79.197')]
[36m[2025-07-03 17:22:19,585][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 195.5). Total num frames: 32768. Throughput: 0: 234.9. Samples: 38784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:19,585][07522] Avg episode reward: [(0, '-80.471')]
[33m[189640 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[189641 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:22:24,573][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 189.9). Total num frames: 32768. Throughput: 0: 234.3. Samples: 40144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:24,573][07522] Avg episode reward: [(0, '-80.577')]
[36m[2025-07-03 17:22:29,591][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 184.5). Total num frames: 32768. Throughput: 0: 233.4. Samples: 40880. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:29,591][07522] Avg episode reward: [(0, '-80.986')]
[36m[2025-07-03 17:22:34,586][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 179.4). Total num frames: 32768. Throughput: 0: 233.8. Samples: 42336. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:34,586][07522] Avg episode reward: [(0, '-80.465')]
[36m[2025-07-03 17:22:39,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 174.7). Total num frames: 32768. Throughput: 0: 235.8. Samples: 43680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:39,540][07522] Avg episode reward: [(0, '-80.185')]
[36m[2025-07-03 17:22:44,565][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 170.2). Total num frames: 32768. Throughput: 0: 234.5. Samples: 44368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:44,565][07522] Avg episode reward: [(0, '-80.372')]
[36m[2025-07-03 17:22:49,583][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 165.8). Total num frames: 32768. Throughput: 0: 233.2. Samples: 45712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:49,583][07522] Avg episode reward: [(0, '-80.789')]
[36m[2025-07-03 17:22:54,578][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 161.7). Total num frames: 32768. Throughput: 0: 232.2. Samples: 47168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:54,578][07522] Avg episode reward: [(0, '-81.167')]
[GIF] Episode 300 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0003_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0003_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0003_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0003_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0003_merged_dual_camera.gif
[36m[2025-07-03 17:22:59,610][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 157.8). Total num frames: 32768. Throughput: 0: 233.0. Samples: 47904. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:22:59,610][07522] Avg episode reward: [(0, '-80.581')]
[36m[2025-07-03 17:23:04,588][07522] Fps is (10 sec: 1636.8, 60 sec: 273.0, 300 sec: 231.2). Total num frames: 49152. Throughput: 0: 233.2. Samples: 49280. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:04,588][07522] Avg episode reward: [(0, '-79.975')]
[33m[233000 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[233001 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:23:09,591][07522] Fps is (10 sec: 1641.4, 60 sec: 273.0, 300 sec: 225.9). Total num frames: 49152. Throughput: 0: 235.3. Samples: 50736. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:09,592][07522] Avg episode reward: [(0, '-79.845')]
[36m[2025-07-03 17:23:14,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 220.8). Total num frames: 49152. Throughput: 0: 233.8. Samples: 51392. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:14,555][07522] Avg episode reward: [(0, '-77.055')]
[36m[2025-07-03 17:23:19,590][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 216.0). Total num frames: 49152. Throughput: 0: 232.9. Samples: 52816. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:19,591][07522] Avg episode reward: [(0, '-78.999')]
[37m[1m[2025-07-03 17:23:19,659][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000096_49152.pth...
[36m[2025-07-03 17:23:24,602][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 211.3). Total num frames: 49152. Throughput: 0: 233.6. Samples: 54208. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:24,603][07522] Avg episode reward: [(0, '-80.874')]
[36m[2025-07-03 17:23:29,575][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 206.9). Total num frames: 49152. Throughput: 0: 233.5. Samples: 54880. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:29,575][07522] Avg episode reward: [(0, '-79.267')]
[36m[2025-07-03 17:23:34,538][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 202.6). Total num frames: 49152. Throughput: 0: 234.9. Samples: 56272. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:34,538][07522] Avg episode reward: [(0, '-79.191')]
[36m[2025-07-03 17:23:39,589][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 198.5). Total num frames: 49152. Throughput: 0: 233.9. Samples: 57696. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:39,589][07522] Avg episode reward: [(0, '-80.676')]
[36m[2025-07-03 17:23:44,586][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 194.6). Total num frames: 49152. Throughput: 0: 233.7. Samples: 58416. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:44,586][07522] Avg episode reward: [(0, '-78.700')]
[36m[2025-07-03 17:23:49,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 190.8). Total num frames: 49152. Throughput: 0: 233.4. Samples: 59776. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:49,552][07522] Avg episode reward: [(0, '-79.878')]
[33m[278034 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[278035 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:23:54,549][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 187.2). Total num frames: 49152. Throughput: 0: 233.8. Samples: 61248. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:54,549][07522] Avg episode reward: [(0, '-78.535')]
[36m[2025-07-03 17:23:59,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 183.7). Total num frames: 49152. Throughput: 0: 234.9. Samples: 61968. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:23:59,573][07522] Avg episode reward: [(0, '-80.156')]
[GIF] Episode 400 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0004_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0004_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0004_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0004_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0004_merged_dual_camera.gif
[36m[2025-07-03 17:24:04,546][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 180.3). Total num frames: 49152. Throughput: 0: 237.0. Samples: 63472. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:24:04,546][07522] Avg episode reward: [(0, '-80.606')]
[36m[2025-07-03 17:24:09,560][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 177.1). Total num frames: 49152. Throughput: 0: 237.4. Samples: 64880. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:24:09,561][07522] Avg episode reward: [(0, '-80.808')]
[36m[2025-07-03 17:24:14,568][07522] Fps is (10 sec: 1634.7, 60 sec: 273.0, 300 sec: 231.9). Total num frames: 65536. Throughput: 0: 237.5. Samples: 65568. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:24:14,569][07522] Avg episode reward: [(0, '-78.349')]
[36m[2025-07-03 17:24:19,562][07522] Fps is (10 sec: 1638.1, 60 sec: 273.2, 300 sec: 227.9). Total num frames: 65536. Throughput: 0: 236.3. Samples: 66912. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:24:19,562][07522] Avg episode reward: [(0, '-79.514')]
[36m[2025-07-03 17:24:24,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 224.0). Total num frames: 65536. Throughput: 0: 236.7. Samples: 68336. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:24:24,546][07522] Avg episode reward: [(0, '-80.746')]
[36m[2025-07-03 17:24:29,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 235.6. Samples: 69008. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:24:29,546][07522] Avg episode reward: [(0, '-79.471')]
[36m[2025-07-03 17:24:34,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 237.5. Samples: 70464. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:24:34,560][07522] Avg episode reward: [(0, '-80.219')]
[33m[322304 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[322304 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:24:39,600][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 65536. Throughput: 0: 237.9. Samples: 71968. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:24:39,601][07522] Avg episode reward: [(0, '-79.625')]
[36m[2025-07-03 17:24:44,557][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 237.6. Samples: 72656. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:24:44,558][07522] Avg episode reward: [(0, '-78.357')]
[36m[2025-07-03 17:24:49,606][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 65536. Throughput: 0: 233.6. Samples: 74000. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:24:49,606][07522] Avg episode reward: [(0, '-79.393')]
[36m[2025-07-03 17:24:54,553][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 232.6. Samples: 75344. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:24:54,553][07522] Avg episode reward: [(0, '-80.353')]
[36m[2025-07-03 17:24:59,547][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 233.0. Samples: 76048. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:24:59,547][07522] Avg episode reward: [(0, '-79.947')]
[36m[2025-07-03 17:25:04,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 235.3. Samples: 77504. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:25:04,572][07522] Avg episode reward: [(0, '-78.239')]
[36m[2025-07-03 17:25:09,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 234.6. Samples: 78896. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:25:09,561][07522] Avg episode reward: [(0, '-79.424')]
[GIF] Episode 500 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0005_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0005_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0005_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0005_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0005_merged_dual_camera.gif
[36m[2025-07-03 17:25:14,561][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 65536. Throughput: 0: 235.3. Samples: 79600. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:25:14,562][07522] Avg episode reward: [(0, '-80.141')]
[36m[2025-07-03 17:25:19,564][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 65536. Throughput: 0: 233.6. Samples: 80976. Policy #0 lag: (min: 27.0, avg: 27.0, max: 27.0)
[36m[2025-07-03 17:25:19,565][07522] Avg episode reward: [(0, '-79.989')]
[37m[1m[2025-07-03 17:25:19,659][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000128_65536.pth...
[33m[368470 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[368470 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:25:24,572][07522] Fps is (10 sec: 1636.7, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 81920. Throughput: 0: 229.5. Samples: 82288. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:25:24,572][07522] Avg episode reward: [(0, '-79.313')]
[36m[2025-07-03 17:25:29,562][07522] Fps is (10 sec: 1638.8, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 81920. Throughput: 0: 230.0. Samples: 83008. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:25:29,562][07522] Avg episode reward: [(0, '-77.887')]
[36m[2025-07-03 17:25:34,629][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 277.6). Total num frames: 81920. Throughput: 0: 231.7. Samples: 84432. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:25:34,630][07522] Avg episode reward: [(0, '-79.142')]
[36m[2025-07-03 17:25:39,574][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 81920. Throughput: 0: 231.7. Samples: 85776. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:25:39,574][07522] Avg episode reward: [(0, '-79.279')]
[36m[2025-07-03 17:25:44,537][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 231.5. Samples: 86464. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:25:44,538][07522] Avg episode reward: [(0, '-78.436')]
[36m[2025-07-03 17:25:49,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 231.9. Samples: 87936. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:25:49,552][07522] Avg episode reward: [(0, '-78.540')]
[36m[2025-07-03 17:25:54,566][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 232.2. Samples: 89344. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:25:54,566][07522] Avg episode reward: [(0, '-77.183')]
[36m[2025-07-03 17:25:59,554][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 231.9. Samples: 90032. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:25:59,554][07522] Avg episode reward: [(0, '-77.654')]
[36m[2025-07-03 17:26:04,572][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 234.3. Samples: 91520. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:26:04,573][07522] Avg episode reward: [(0, '-78.504')]
[36m[2025-07-03 17:26:09,572][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 236.4. Samples: 92928. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:26:09,572][07522] Avg episode reward: [(0, '-76.431')]
[33m[415223 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[415223 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:26:14,562][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 81920. Throughput: 0: 236.4. Samples: 93648. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:26:14,562][07522] Avg episode reward: [(0, '-78.153')]
[36m[2025-07-03 17:26:19,595][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 81920. Throughput: 0: 234.8. Samples: 94992. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:26:19,595][07522] Avg episode reward: [(0, '-79.650')]
[36m[2025-07-03 17:26:24,613][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 81920. Throughput: 0: 235.5. Samples: 96384. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:26:24,613][07522] Avg episode reward: [(0, '-77.523')]
[GIF] Episode 600 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0006_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0006_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0006_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0006_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0006_merged_dual_camera.gif
[36m[2025-07-03 17:26:29,561][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 81920. Throughput: 0: 234.5. Samples: 97024. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:26:29,561][07522] Avg episode reward: [(0, '-78.401')]
[36m[2025-07-03 17:26:34,563][07522] Fps is (10 sec: 1646.7, 60 sec: 273.4, 300 sec: 277.7). Total num frames: 98304. Throughput: 0: 231.4. Samples: 98352. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:26:34,563][07522] Avg episode reward: [(0, '-76.713')]
[36m[2025-07-03 17:26:39,578][07522] Fps is (10 sec: 1635.6, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 98304. Throughput: 0: 231.4. Samples: 99760. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:26:39,578][07522] Avg episode reward: [(0, '-76.208')]
[36m[2025-07-03 17:26:44,604][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 277.7). Total num frames: 98304. Throughput: 0: 231.6. Samples: 100464. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:26:44,605][07522] Avg episode reward: [(0, '-76.266')]
[36m[2025-07-03 17:26:49,557][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 230.8. Samples: 101904. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:26:49,557][07522] Avg episode reward: [(0, '-77.226')]
[36m[2025-07-03 17:26:54,589][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 230.0. Samples: 103280. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:26:54,589][07522] Avg episode reward: [(0, '-76.586')]
[33m[463476 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[463476 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:26:59,623][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 98304. Throughput: 0: 229.4. Samples: 103984. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:26:59,624][07522] Avg episode reward: [(0, '-76.241')]
[36m[2025-07-03 17:27:04,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 232.0. Samples: 105424. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:27:04,555][07522] Avg episode reward: [(0, '-76.672')]
[36m[2025-07-03 17:27:09,584][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 98304. Throughput: 0: 232.3. Samples: 106832. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:27:09,584][07522] Avg episode reward: [(0, '-77.236')]
[36m[2025-07-03 17:27:14,584][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 233.5. Samples: 107536. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:27:14,584][07522] Avg episode reward: [(0, '-77.564')]
[36m[2025-07-03 17:27:19,572][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 236.8. Samples: 109008. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:27:19,572][07522] Avg episode reward: [(0, '-77.275')]
[37m[1m[2025-07-03 17:27:19,638][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000192_98304.pth...
[36m[2025-07-03 17:27:24,568][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 238.3. Samples: 110480. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:27:24,568][07522] Avg episode reward: [(0, '-75.960')]
[36m[2025-07-03 17:27:29,599][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 98304. Throughput: 0: 238.3. Samples: 111184. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:27:29,599][07522] Avg episode reward: [(0, '-77.158')]
[36m[2025-07-03 17:27:34,538][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 98304. Throughput: 0: 238.0. Samples: 112608. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:27:34,539][07522] Avg episode reward: [(0, '-77.099')]
[36m[2025-07-03 17:27:39,604][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 98304. Throughput: 0: 239.2. Samples: 114048. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:27:39,604][07522] Avg episode reward: [(0, '-79.011')]
[GIF] Episode 700 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0007_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0007_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0007_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0007_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0007_merged_dual_camera.gif
[36m[2025-07-03 17:27:44,568][07522] Fps is (10 sec: 1633.6, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 114688. Throughput: 0: 238.9. Samples: 114720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:27:44,568][07522] Avg episode reward: [(0, '-76.977')]
[37m[1m[2025-07-03 17:27:44,659][07522] Saving new best policy, reward=-76.977!
[33m[511628 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[511628 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:27:49,594][07522] Fps is (10 sec: 1640.0, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 114688. Throughput: 0: 236.2. Samples: 116064. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:27:49,594][07522] Avg episode reward: [(0, '-73.572')]
[37m[1m[2025-07-03 17:27:49,665][07522] Saving new best policy, reward=-73.572!
[36m[2025-07-03 17:27:54,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 277.8). Total num frames: 114688. Throughput: 0: 236.6. Samples: 117472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:27:54,546][07522] Avg episode reward: [(0, '-74.757')]
[36m[2025-07-03 17:27:59,603][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 114688. Throughput: 0: 237.1. Samples: 118208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:27:59,604][07522] Avg episode reward: [(0, '-75.613')]
[36m[2025-07-03 17:28:04,549][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 234.1. Samples: 119536. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:28:04,549][07522] Avg episode reward: [(0, '-74.437')]
[36m[2025-07-03 17:28:09,539][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 233.0. Samples: 120960. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:28:09,539][07522] Avg episode reward: [(0, '-74.926')]
[36m[2025-07-03 17:28:14,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 232.8. Samples: 121648. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:28:14,555][07522] Avg episode reward: [(0, '-74.637')]
[36m[2025-07-03 17:28:19,642][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 114688. Throughput: 0: 234.1. Samples: 123168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:28:19,642][07522] Avg episode reward: [(0, '-74.050')]
[36m[2025-07-03 17:28:24,592][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 114688. Throughput: 0: 234.7. Samples: 124608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:28:24,593][07522] Avg episode reward: [(0, '-74.880')]
[36m[2025-07-03 17:28:29,591][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 114688. Throughput: 0: 236.3. Samples: 125360. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:28:29,591][07522] Avg episode reward: [(0, '-74.393')]
[36m[2025-07-03 17:28:34,558][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 239.8. Samples: 126848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:28:34,558][07522] Avg episode reward: [(0, '-75.613')]
[33m[560929 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[560929 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:28:39,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 239.7. Samples: 128256. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:28:39,544][07522] Avg episode reward: [(0, '-77.550')]
[36m[2025-07-03 17:28:44,539][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 114688. Throughput: 0: 240.0. Samples: 128992. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:28:44,539][07522] Avg episode reward: [(0, '-74.926')]
[36m[2025-07-03 17:28:49,578][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 114688. Throughput: 0: 243.4. Samples: 130496. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:28:49,578][07522] Avg episode reward: [(0, '-75.875')]
[36m[2025-07-03 17:28:54,600][07522] Fps is (10 sec: 1628.5, 60 sec: 272.8, 300 sec: 277.7). Total num frames: 131072. Throughput: 0: 241.8. Samples: 131856. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:28:54,600][07522] Avg episode reward: [(0, '-74.620')]
[36m[2025-07-03 17:28:59,583][07522] Fps is (10 sec: 1637.6, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 131072. Throughput: 0: 243.4. Samples: 132608. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:28:59,583][07522] Avg episode reward: [(0, '-74.274')]
[GIF] Episode 800 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0008_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0008_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0008_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0008_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0008_merged_dual_camera.gif
[36m[2025-07-03 17:29:04,549][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 131072. Throughput: 0: 242.6. Samples: 134064. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:04,549][07522] Avg episode reward: [(0, '-73.713')]
[36m[2025-07-03 17:29:09,554][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 242.7. Samples: 135520. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:09,554][07522] Avg episode reward: [(0, '-74.344')]
[36m[2025-07-03 17:29:14,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 131072. Throughput: 0: 242.9. Samples: 136288. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:14,573][07522] Avg episode reward: [(0, '-72.938')]
[37m[1m[2025-07-03 17:29:14,638][07522] Saving new best policy, reward=-72.938!
[36m[2025-07-03 17:29:19,595][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 131072. Throughput: 0: 241.6. Samples: 137728. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:19,596][07522] Avg episode reward: [(0, '-74.214')]
[37m[1m[2025-07-03 17:29:19,686][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000256_131072.pth...
[36m[2025-07-03 17:29:24,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 131072. Throughput: 0: 242.0. Samples: 139152. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:24,569][07522] Avg episode reward: [(0, '-72.878')]
[37m[1m[2025-07-03 17:29:24,650][07522] Saving new best policy, reward=-72.878!
[33m[610700 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[610700 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:29:29,539][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 240.4. Samples: 139808. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:29,539][07522] Avg episode reward: [(0, '-74.550')]
[36m[2025-07-03 17:29:34,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 238.1. Samples: 141200. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:34,540][07522] Avg episode reward: [(0, '-74.471')]
[36m[2025-07-03 17:29:39,557][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 238.8. Samples: 142592. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:39,558][07522] Avg episode reward: [(0, '-73.088')]
[36m[2025-07-03 17:29:44,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 237.4. Samples: 143280. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:44,540][07522] Avg episode reward: [(0, '-73.180')]
[36m[2025-07-03 17:29:49,557][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 131072. Throughput: 0: 236.8. Samples: 144720. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:49,557][07522] Avg episode reward: [(0, '-75.070')]
[36m[2025-07-03 17:29:54,610][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 131072. Throughput: 0: 236.9. Samples: 146192. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[36m[2025-07-03 17:29:54,610][07522] Avg episode reward: [(0, '-73.651')]
[36m[2025-07-03 17:29:59,579][07522] Fps is (10 sec: 1634.7, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 147456. Throughput: 0: 236.4. Samples: 146928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:29:59,579][07522] Avg episode reward: [(0, '-74.088')]
[36m[2025-07-03 17:30:04,581][07522] Fps is (10 sec: 1643.2, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 147456. Throughput: 0: 235.1. Samples: 148304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:04,581][07522] Avg episode reward: [(0, '-70.913')]
[37m[1m[2025-07-03 17:30:04,645][07522] Saving new best policy, reward=-70.913!
[36m[2025-07-03 17:30:09,601][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 147456. Throughput: 0: 237.0. Samples: 149824. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:09,601][07522] Avg episode reward: [(0, '-72.022')]
[36m[2025-07-03 17:30:14,586][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 147456. Throughput: 0: 238.3. Samples: 150544. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:14,586][07522] Avg episode reward: [(0, '-71.498')]
[33m[661836 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[661836 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:30:19,554][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 241.3. Samples: 152064. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:19,554][07522] Avg episode reward: [(0, '-70.400')]
[37m[1m[2025-07-03 17:30:19,621][07522] Saving new best policy, reward=-70.400!
[GIF] Episode 900 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0009_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0009_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0009_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0009_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0009_merged_dual_camera.gif
[36m[2025-07-03 17:30:24,578][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 243.8. Samples: 153568. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:24,578][07522] Avg episode reward: [(0, '-75.922')]
[36m[2025-07-03 17:30:29,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 244.6. Samples: 154288. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:29,540][07522] Avg episode reward: [(0, '-70.853')]
[36m[2025-07-03 17:30:34,587][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 245.5. Samples: 155776. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:34,588][07522] Avg episode reward: [(0, '-73.473')]
[36m[2025-07-03 17:30:39,605][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 245.4. Samples: 157232. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:39,605][07522] Avg episode reward: [(0, '-70.637')]
[36m[2025-07-03 17:30:44,595][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 245.2. Samples: 157968. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:44,595][07522] Avg episode reward: [(0, '-74.369')]
[36m[2025-07-03 17:30:49,566][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 243.6. Samples: 159264. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:49,566][07522] Avg episode reward: [(0, '-71.204')]
[36m[2025-07-03 17:30:54,566][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 239.8. Samples: 160608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:54,566][07522] Avg episode reward: [(0, '-69.849')]
[37m[1m[2025-07-03 17:30:54,630][07522] Saving new best policy, reward=-69.849!
[36m[2025-07-03 17:30:59,585][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 147456. Throughput: 0: 239.7. Samples: 161328. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:30:59,585][07522] Avg episode reward: [(0, '-73.563')]
[36m[2025-07-03 17:31:04,539][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 147456. Throughput: 0: 236.2. Samples: 162688. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:04,539][07522] Avg episode reward: [(0, '-73.486')]
[36m[2025-07-03 17:31:09,592][07522] Fps is (10 sec: 1637.3, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 163840. Throughput: 0: 232.8. Samples: 164048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:09,592][07522] Avg episode reward: [(0, '-73.590')]
[33m[715290 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[715290 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:31:14,541][07522] Fps is (10 sec: 1638.0, 60 sec: 273.3, 300 sec: 277.7). Total num frames: 163840. Throughput: 0: 233.9. Samples: 164816. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:14,541][07522] Avg episode reward: [(0, '-70.000')]
[36m[2025-07-03 17:31:19,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 163840. Throughput: 0: 230.5. Samples: 166144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:19,572][07522] Avg episode reward: [(0, '-68.407')]
[37m[1m[2025-07-03 17:31:19,636][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000320_163840.pth...
[36m[2025-07-03 17:31:19,640][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000032_16384.pth
[37m[1m[2025-07-03 17:31:19,640][07522] Saving new best policy, reward=-68.407!
[36m[2025-07-03 17:31:24,575][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 163840. Throughput: 0: 230.6. Samples: 167600. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:24,575][07522] Avg episode reward: [(0, '-72.052')]
[36m[2025-07-03 17:31:29,583][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 230.5. Samples: 168336. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:29,583][07522] Avg episode reward: [(0, '-70.346')]
[36m[2025-07-03 17:31:34,599][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 233.1. Samples: 169760. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:34,599][07522] Avg episode reward: [(0, '-73.162')]
[36m[2025-07-03 17:31:39,550][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 234.4. Samples: 171152. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:39,550][07522] Avg episode reward: [(0, '-69.422')]
[GIF] Episode 1000 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0010_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0010_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0010_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0010_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0010_merged_dual_camera.gif
[36m[2025-07-03 17:31:44,600][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 233.9. Samples: 171856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:44,600][07522] Avg episode reward: [(0, '-71.746')]
[36m[2025-07-03 17:31:49,595][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 236.2. Samples: 173328. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:49,595][07522] Avg episode reward: [(0, '-71.810')]
[36m[2025-07-03 17:31:54,559][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 235.9. Samples: 174656. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:54,560][07522] Avg episode reward: [(0, '-69.922')]
[36m[2025-07-03 17:31:59,596][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 233.0. Samples: 175312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:31:59,597][07522] Avg episode reward: [(0, '-72.044')]
[36m[2025-07-03 17:32:04,565][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 233.3. Samples: 176640. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:04,566][07522] Avg episode reward: [(0, '-70.734')]
[33m[771466 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[771466 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:32:09,552][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 163840. Throughput: 0: 232.7. Samples: 178064. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:09,552][07522] Avg episode reward: [(0, '-69.864')]
[36m[2025-07-03 17:32:14,624][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 163840. Throughput: 0: 233.4. Samples: 178848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:14,624][07522] Avg episode reward: [(0, '-71.019')]
[36m[2025-07-03 17:32:19,578][07522] Fps is (10 sec: 1634.1, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 180224. Throughput: 0: 233.4. Samples: 180256. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:19,578][07522] Avg episode reward: [(0, '-71.249')]
[36m[2025-07-03 17:32:24,551][07522] Fps is (10 sec: 1650.5, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 180224. Throughput: 0: 234.7. Samples: 181712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:24,551][07522] Avg episode reward: [(0, '-67.572')]
[37m[1m[2025-07-03 17:32:24,641][07522] Saving new best policy, reward=-67.572!
[36m[2025-07-03 17:32:29,595][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 277.6). Total num frames: 180224. Throughput: 0: 233.6. Samples: 182368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:29,595][07522] Avg episode reward: [(0, '-66.571')]
[37m[1m[2025-07-03 17:32:29,685][07522] Saving new best policy, reward=-66.571!
[36m[2025-07-03 17:32:34,595][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 180224. Throughput: 0: 232.2. Samples: 183776. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:34,595][07522] Avg episode reward: [(0, '-68.293')]
[36m[2025-07-03 17:32:39,572][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 180224. Throughput: 0: 232.8. Samples: 185136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:39,572][07522] Avg episode reward: [(0, '-66.701')]
[36m[2025-07-03 17:32:44,599][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 180224. Throughput: 0: 233.2. Samples: 185808. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:44,599][07522] Avg episode reward: [(0, '-67.209')]
[36m[2025-07-03 17:32:49,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 235.1. Samples: 187216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:49,560][07522] Avg episode reward: [(0, '-68.105')]
[36m[2025-07-03 17:32:54,605][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 180224. Throughput: 0: 232.6. Samples: 188544. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:54,605][07522] Avg episode reward: [(0, '-67.645')]
[36m[2025-07-03 17:32:59,559][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 230.7. Samples: 189216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:32:59,559][07522] Avg episode reward: [(0, '-68.399')]
[36m[2025-07-03 17:33:04,619][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 231.3. Samples: 190672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:33:04,620][07522] Avg episode reward: [(0, '-66.992')]
[33m[831196 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[831196 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:33:09,588][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 229.1. Samples: 192032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:33:09,588][07522] Avg episode reward: [(0, '-69.297')]
[36m[2025-07-03 17:33:14,567][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 180224. Throughput: 0: 230.5. Samples: 192736. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:33:14,567][07522] Avg episode reward: [(0, '-68.203')]
[GIF] Episode 1100 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0011_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0011_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0011_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0011_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0011_merged_dual_camera.gif
[36m[2025-07-03 17:33:19,572][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 180224. Throughput: 0: 231.2. Samples: 194176. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:33:19,572][07522] Avg episode reward: [(0, '-70.382')]
[37m[1m[2025-07-03 17:33:19,635][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000352_180224.pth...
[36m[2025-07-03 17:33:19,639][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000096_49152.pth
[36m[2025-07-03 17:33:24,612][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 180224. Throughput: 0: 232.3. Samples: 195600. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:33:24,612][07522] Avg episode reward: [(0, '-67.504')]
[36m[2025-07-03 17:33:29,578][07522] Fps is (10 sec: 1637.5, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 196608. Throughput: 0: 233.4. Samples: 196304. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:33:29,578][07522] Avg episode reward: [(0, '-68.632')]
[36m[2025-07-03 17:33:34,600][07522] Fps is (10 sec: 1640.3, 60 sec: 273.0, 300 sec: 277.6). Total num frames: 196608. Throughput: 0: 230.5. Samples: 197600. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:33:34,600][07522] Avg episode reward: [(0, '-65.661')]
[37m[1m[2025-07-03 17:33:34,662][07522] Saving new best policy, reward=-65.661!
[36m[2025-07-03 17:33:39,574][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 196608. Throughput: 0: 232.0. Samples: 198976. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:33:39,574][07522] Avg episode reward: [(0, '-67.605')]
[36m[2025-07-03 17:33:44,553][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 277.7). Total num frames: 196608. Throughput: 0: 232.6. Samples: 199680. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:33:44,554][07522] Avg episode reward: [(0, '-67.135')]
[36m[2025-07-03 17:33:49,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 230.8. Samples: 201040. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:33:49,541][07522] Avg episode reward: [(0, '-66.710')]
[36m[2025-07-03 17:33:54,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 232.3. Samples: 202480. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:33:54,561][07522] Avg episode reward: [(0, '-64.798')]
[37m[1m[2025-07-03 17:33:54,626][07522] Saving new best policy, reward=-64.798!
[36m[2025-07-03 17:33:59,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 232.3. Samples: 203184. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:33:59,543][07522] Avg episode reward: [(0, '-63.045')]
[37m[1m[2025-07-03 17:33:59,620][07522] Saving new best policy, reward=-63.045!
[36m[2025-07-03 17:34:04,558][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 230.8. Samples: 204560. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:34:04,558][07522] Avg episode reward: [(0, '-61.856')]
[37m[1m[2025-07-03 17:34:04,620][07522] Saving new best policy, reward=-61.856!
[33m[894415 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[894415 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:34:09,589][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 196608. Throughput: 0: 230.5. Samples: 205968. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:34:09,590][07522] Avg episode reward: [(0, '-65.004')]
[36m[2025-07-03 17:34:14,547][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 230.6. Samples: 206672. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:34:14,547][07522] Avg episode reward: [(0, '-66.308')]
[36m[2025-07-03 17:34:19,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 232.1. Samples: 208032. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:34:19,545][07522] Avg episode reward: [(0, '-64.393')]
[36m[2025-07-03 17:34:24,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 196608. Throughput: 0: 232.3. Samples: 209424. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:34:24,556][07522] Avg episode reward: [(0, '-63.782')]
[36m[2025-07-03 17:34:29,597][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 196608. Throughput: 0: 232.7. Samples: 210160. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:34:29,597][07522] Avg episode reward: [(0, '-67.233')]
[36m[2025-07-03 17:34:34,555][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 196608. Throughput: 0: 232.8. Samples: 211520. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[36m[2025-07-03 17:34:34,555][07522] Avg episode reward: [(0, '-64.289')]
[36m[2025-07-03 17:34:39,572][07522] Fps is (10 sec: 1642.5, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 212992. Throughput: 0: 232.8. Samples: 212960. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:34:39,572][07522] Avg episode reward: [(0, '-66.505')]
[36m[2025-07-03 17:34:44,552][07522] Fps is (10 sec: 1638.8, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 212992. Throughput: 0: 232.1. Samples: 213632. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:34:44,552][07522] Avg episode reward: [(0, '-63.921')]
[36m[2025-07-03 17:34:49,569][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 212992. Throughput: 0: 232.1. Samples: 215008. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:34:49,569][07522] Avg episode reward: [(0, '-60.562')]
[37m[1m[2025-07-03 17:34:49,661][07522] Saving new best policy, reward=-60.562!
[36m[2025-07-03 17:34:54,596][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 231.1. Samples: 216368. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:34:54,596][07522] Avg episode reward: [(0, '-61.007')]
[GIF] Episode 1200 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0012_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0012_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0012_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0012_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0012_merged_dual_camera.gif
[36m[2025-07-03 17:34:59,627][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 231.1. Samples: 217088. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:34:59,628][07522] Avg episode reward: [(0, '-64.230')]
[36m[2025-07-03 17:35:04,599][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 232.3. Samples: 218496. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:35:04,599][07522] Avg episode reward: [(0, '-59.290')]
[37m[1m[2025-07-03 17:35:04,662][07522] Saving new best policy, reward=-59.290!
[36m[2025-07-03 17:35:09,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 233.2. Samples: 219920. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:35:09,570][07522] Avg episode reward: [(0, '-61.780')]
[36m[2025-07-03 17:35:14,578][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 233.3. Samples: 220656. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:35:14,578][07522] Avg episode reward: [(0, '-62.409')]
[33m[961591 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[961591 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:35:19,579][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 234.5. Samples: 222080. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:35:19,579][07522] Avg episode reward: [(0, '-62.840')]
[37m[1m[2025-07-03 17:35:19,652][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000416_212992.pth...
[36m[2025-07-03 17:35:19,656][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000128_65536.pth
[36m[2025-07-03 17:35:24,586][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 235.0. Samples: 223536. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:35:24,586][07522] Avg episode reward: [(0, '-59.588')]
[36m[2025-07-03 17:35:29,588][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 235.9. Samples: 224256. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:35:29,588][07522] Avg episode reward: [(0, '-62.194')]
[36m[2025-07-03 17:35:34,580][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 236.7. Samples: 225664. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:35:34,581][07522] Avg episode reward: [(0, '-61.671')]
[36m[2025-07-03 17:35:39,551][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 212992. Throughput: 0: 237.4. Samples: 227040. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:35:39,551][07522] Avg episode reward: [(0, '-61.323')]
[36m[2025-07-03 17:35:44,599][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 212992. Throughput: 0: 237.7. Samples: 227776. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[36m[2025-07-03 17:35:44,600][07522] Avg episode reward: [(0, '-61.576')]
[36m[2025-07-03 17:35:49,563][07522] Fps is (10 sec: 1636.5, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 229376. Throughput: 0: 237.7. Samples: 229184. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:35:49,563][07522] Avg episode reward: [(0, '-62.784')]
[36m[2025-07-03 17:35:54,546][07522] Fps is (10 sec: 1647.2, 60 sec: 273.3, 300 sec: 277.7). Total num frames: 229376. Throughput: 0: 235.5. Samples: 230512. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:35:54,546][07522] Avg episode reward: [(0, '-58.883')]
[37m[1m[2025-07-03 17:35:54,609][07522] Saving new best policy, reward=-58.883!
[36m[2025-07-03 17:35:59,581][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 277.7). Total num frames: 229376. Throughput: 0: 234.7. Samples: 231216. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:35:59,581][07522] Avg episode reward: [(0, '-57.948')]
[37m[1m[2025-07-03 17:35:59,651][07522] Saving new best policy, reward=-57.948!
[36m[2025-07-03 17:36:04,588][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 234.3. Samples: 232624. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:04,588][07522] Avg episode reward: [(0, '-58.778')]
[36m[2025-07-03 17:36:09,574][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 229376. Throughput: 0: 231.9. Samples: 233968. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:09,574][07522] Avg episode reward: [(0, '-56.813')]
[37m[1m[2025-07-03 17:36:09,641][07522] Saving new best policy, reward=-56.813!
[36m[2025-07-03 17:36:14,586][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 229376. Throughput: 0: 231.5. Samples: 234672. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:14,587][07522] Avg episode reward: [(0, '-57.223')]
[36m[2025-07-03 17:36:19,556][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 233.0. Samples: 236144. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:19,556][07522] Avg episode reward: [(0, '-56.562')]
[37m[1m[2025-07-03 17:36:19,632][07522] Saving new best policy, reward=-56.562!
[36m[2025-07-03 17:36:24,550][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 232.9. Samples: 237520. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:24,550][07522] Avg episode reward: [(0, '-57.433')]
[36m[2025-07-03 17:36:29,596][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 231.5. Samples: 238192. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:29,597][07522] Avg episode reward: [(0, '-58.547')]
[33m[1036143 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[1036143 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:36:34,598][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 229376. Throughput: 0: 231.3. Samples: 239600. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:34,598][07522] Avg episode reward: [(0, '-56.677')]
[36m[2025-07-03 17:36:39,547][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 233.2. Samples: 241008. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:39,548][07522] Avg episode reward: [(0, '-60.834')]
[36m[2025-07-03 17:36:44,621][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 229376. Throughput: 0: 231.3. Samples: 241632. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:44,621][07522] Avg episode reward: [(0, '-57.011')]
[36m[2025-07-03 17:36:49,572][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 229376. Throughput: 0: 230.5. Samples: 242992. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:49,572][07522] Avg episode reward: [(0, '-59.230')]
[36m[2025-07-03 17:36:54,567][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 229376. Throughput: 0: 231.9. Samples: 244400. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 17:36:54,567][07522] Avg episode reward: [(0, '-57.725')]
[GIF] Episode 1300 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0013_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0013_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0013_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0013_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0013_merged_dual_camera.gif
[36m[2025-07-03 17:36:59,574][07522] Fps is (10 sec: 1638.0, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 245760. Throughput: 0: 231.9. Samples: 245104. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:36:59,575][07522] Avg episode reward: [(0, '-56.491')]
[37m[1m[2025-07-03 17:36:59,638][07522] Saving new best policy, reward=-56.491!
[36m[2025-07-03 17:37:04,596][07522] Fps is (10 sec: 1633.7, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 245760. Throughput: 0: 230.6. Samples: 246528. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:04,596][07522] Avg episode reward: [(0, '-54.754')]
[37m[1m[2025-07-03 17:37:04,665][07522] Saving new best policy, reward=-54.754!
[36m[2025-07-03 17:37:09,553][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 277.8). Total num frames: 245760. Throughput: 0: 230.7. Samples: 247904. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:09,553][07522] Avg episode reward: [(0, '-50.386')]
[37m[1m[2025-07-03 17:37:09,644][07522] Saving new best policy, reward=-50.386!
[36m[2025-07-03 17:37:14,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 231.6. Samples: 248608. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:14,571][07522] Avg episode reward: [(0, '-53.946')]
[36m[2025-07-03 17:37:19,622][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 245760. Throughput: 0: 229.6. Samples: 249936. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:19,623][07522] Avg episode reward: [(0, '-52.886')]
[37m[1m[2025-07-03 17:37:19,693][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000480_245760.pth...
[36m[2025-07-03 17:37:19,697][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000192_98304.pth
[36m[2025-07-03 17:37:24,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 229.7. Samples: 251344. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:24,541][07522] Avg episode reward: [(0, '-52.686')]
[36m[2025-07-03 17:37:29,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 232.6. Samples: 252080. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:29,545][07522] Avg episode reward: [(0, '-53.041')]
[36m[2025-07-03 17:37:34,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 234.8. Samples: 253552. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:34,541][07522] Avg episode reward: [(0, '-51.222')]
[36m[2025-07-03 17:37:39,565][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 235.7. Samples: 255008. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:39,565][07522] Avg episode reward: [(0, '-53.311')]
[36m[2025-07-03 17:37:44,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 237.2. Samples: 255776. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:44,561][07522] Avg episode reward: [(0, '-54.561')]
[36m[2025-07-03 17:37:49,587][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 239.7. Samples: 257312. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:49,587][07522] Avg episode reward: [(0, '-55.698')]
[36m[2025-07-03 17:37:54,588][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 245760. Throughput: 0: 241.6. Samples: 258784. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:54,588][07522] Avg episode reward: [(0, '-52.095')]
[33m[1120335 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[1120336 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:37:59,545][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 245760. Throughput: 0: 241.6. Samples: 259472. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:37:59,545][07522] Avg episode reward: [(0, '-48.957')]
[37m[1m[2025-07-03 17:37:59,625][07522] Saving new best policy, reward=-48.957!
[36m[2025-07-03 17:38:04,598][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 245760. Throughput: 0: 243.0. Samples: 260864. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:04,598][07522] Avg episode reward: [(0, '-52.232')]
[36m[2025-07-03 17:38:09,552][07522] Fps is (10 sec: 1637.2, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 262144. Throughput: 0: 243.1. Samples: 262288. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:09,552][07522] Avg episode reward: [(0, '-53.689')]
[36m[2025-07-03 17:38:14,582][07522] Fps is (10 sec: 1641.1, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 262144. Throughput: 0: 240.9. Samples: 262928. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:14,582][07522] Avg episode reward: [(0, '-49.181')]
[36m[2025-07-03 17:38:19,598][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 262144. Throughput: 0: 240.4. Samples: 264384. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:19,598][07522] Avg episode reward: [(0, '-45.438')]
[37m[1m[2025-07-03 17:38:19,660][07522] Saving new best policy, reward=-45.438!
[36m[2025-07-03 17:38:24,609][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 262144. Throughput: 0: 240.8. Samples: 265856. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:24,610][07522] Avg episode reward: [(0, '-46.641')]
[36m[2025-07-03 17:38:29,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 239.2. Samples: 266544. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:29,569][07522] Avg episode reward: [(0, '-49.555')]
[36m[2025-07-03 17:38:34,573][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 236.5. Samples: 267952. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:34,574][07522] Avg episode reward: [(0, '-48.884')]
[36m[2025-07-03 17:38:39,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 237.0. Samples: 269440. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:39,553][07522] Avg episode reward: [(0, '-47.441')]
[36m[2025-07-03 17:38:44,594][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 262144. Throughput: 0: 237.3. Samples: 270160. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:44,594][07522] Avg episode reward: [(0, '-48.032')]
[36m[2025-07-03 17:38:49,585][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 262144. Throughput: 0: 239.0. Samples: 271616. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:49,585][07522] Avg episode reward: [(0, '-47.364')]
[36m[2025-07-03 17:38:54,607][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 262144. Throughput: 0: 237.9. Samples: 273008. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:54,608][07522] Avg episode reward: [(0, '-47.131')]
[36m[2025-07-03 17:38:59,577][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 262144. Throughput: 0: 239.3. Samples: 273696. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:38:59,577][07522] Avg episode reward: [(0, '-47.110')]
[36m[2025-07-03 17:39:04,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 239.2. Samples: 275136. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:39:04,552][07522] Avg episode reward: [(0, '-43.680')]
[37m[1m[2025-07-03 17:39:04,616][07522] Saving new best policy, reward=-43.680!
[36m[2025-07-03 17:39:09,583][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 262144. Throughput: 0: 240.1. Samples: 276656. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:39:09,583][07522] Avg episode reward: [(0, '-46.479')]
[36m[2025-07-03 17:39:14,543][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 262144. Throughput: 0: 241.6. Samples: 277408. Policy #0 lag: (min: 20.0, avg: 20.0, max: 20.0)
[36m[2025-07-03 17:39:14,543][07522] Avg episode reward: [(0, '-47.695')]
[36m[2025-07-03 17:39:19,582][07522] Fps is (10 sec: 1638.5, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 278528. Throughput: 0: 241.0. Samples: 278800. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:39:19,582][07522] Avg episode reward: [(0, '-46.441')]
[37m[1m[2025-07-03 17:39:19,653][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000544_278528.pth...
[36m[2025-07-03 17:39:19,657][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000256_131072.pth
[GIF] Episode 1400 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0014_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0014_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0014_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0014_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0014_merged_dual_camera.gif
[36m[2025-07-03 17:39:24,624][07522] Fps is (10 sec: 1625.2, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 278528. Throughput: 0: 239.6. Samples: 280240. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:39:24,624][07522] Avg episode reward: [(0, '-45.199')]
[36m[2025-07-03 17:39:29,587][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 278528. Throughput: 0: 238.3. Samples: 280880. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:39:29,587][07522] Avg episode reward: [(0, '-44.050')]
[36m[2025-07-03 17:39:34,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 237.0. Samples: 282272. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:39:34,540][07522] Avg episode reward: [(0, '-45.063')]
[33m[1220533 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[1220533 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:39:39,572][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 240.5. Samples: 283824. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:39:39,572][07522] Avg episode reward: [(0, '-42.008')]
[37m[1m[2025-07-03 17:39:39,637][07522] Saving new best policy, reward=-42.008!
[36m[2025-07-03 17:39:44,547][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 241.9. Samples: 284576. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:39:44,547][07522] Avg episode reward: [(0, '-39.428')]
[37m[1m[2025-07-03 17:39:44,609][07522] Saving new best policy, reward=-39.428!
[36m[2025-07-03 17:39:49,579][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 241.6. Samples: 286016. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:39:49,579][07522] Avg episode reward: [(0, '-44.072')]
[36m[2025-07-03 17:39:54,616][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 239.5. Samples: 287440. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:39:54,616][07522] Avg episode reward: [(0, '-44.242')]
[36m[2025-07-03 17:39:59,618][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 237.5. Samples: 288112. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:39:59,618][07522] Avg episode reward: [(0, '-43.225')]
[36m[2025-07-03 17:40:04,580][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 238.9. Samples: 289552. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:40:04,581][07522] Avg episode reward: [(0, '-44.387')]
[36m[2025-07-03 17:40:09,597][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 239.1. Samples: 290992. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:40:09,597][07522] Avg episode reward: [(0, '-44.277')]
[36m[2025-07-03 17:40:14,608][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 278528. Throughput: 0: 241.3. Samples: 291744. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:40:14,608][07522] Avg episode reward: [(0, '-43.415')]
[36m[2025-07-03 17:40:19,555][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 241.7. Samples: 293152. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:40:19,555][07522] Avg episode reward: [(0, '-42.521')]
[36m[2025-07-03 17:40:24,552][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 278528. Throughput: 0: 239.0. Samples: 294576. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 17:40:24,553][07522] Avg episode reward: [(0, '-41.570')]
[36m[2025-07-03 17:40:29,543][07522] Fps is (10 sec: 1640.4, 60 sec: 273.3, 300 sec: 277.7). Total num frames: 294912. Throughput: 0: 236.5. Samples: 295216. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:40:29,544][07522] Avg episode reward: [(0, '-43.257')]
[36m[2025-07-03 17:40:34,578][07522] Fps is (10 sec: 1634.2, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 294912. Throughput: 0: 236.8. Samples: 296672. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:40:34,578][07522] Avg episode reward: [(0, '-42.928')]
[36m[2025-07-03 17:40:39,575][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 294912. Throughput: 0: 237.4. Samples: 298112. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:40:39,576][07522] Avg episode reward: [(0, '-44.079')]
[36m[2025-07-03 17:40:44,564][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 238.1. Samples: 298816. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:40:44,565][07522] Avg episode reward: [(0, '-41.299')]
[36m[2025-07-03 17:40:49,557][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 238.0. Samples: 300256. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:40:49,558][07522] Avg episode reward: [(0, '-37.814')]
[37m[1m[2025-07-03 17:40:49,628][07522] Saving new best policy, reward=-37.814!
[36m[2025-07-03 17:40:54,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 236.2. Samples: 301616. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:40:54,571][07522] Avg episode reward: [(0, '-41.429')]
[36m[2025-07-03 17:40:59,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 236.1. Samples: 302352. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:40:59,540][07522] Avg episode reward: [(0, '-40.804')]
[36m[2025-07-03 17:41:04,566][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 236.7. Samples: 303808. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:41:04,566][07522] Avg episode reward: [(0, '-39.405')]
[36m[2025-07-03 17:41:09,578][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 235.6. Samples: 305184. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:41:09,578][07522] Avg episode reward: [(0, '-39.382')]
[36m[2025-07-03 17:41:14,548][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 236.8. Samples: 305872. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:41:14,549][07522] Avg episode reward: [(0, '-41.795')]
[36m[2025-07-03 17:41:19,589][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 236.7. Samples: 307328. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:41:19,589][07522] Avg episode reward: [(0, '-42.064')]
[37m[1m[2025-07-03 17:41:19,651][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000576_294912.pth...
[36m[2025-07-03 17:41:19,655][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000320_163840.pth
[36m[2025-07-03 17:41:24,594][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 237.8. Samples: 308816. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:41:24,594][07522] Avg episode reward: [(0, '-42.960')]
[33m[1332565 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[1332565 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:41:29,575][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 294912. Throughput: 0: 237.1. Samples: 309488. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:41:29,575][07522] Avg episode reward: [(0, '-43.549')]
[36m[2025-07-03 17:41:34,597][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 294912. Throughput: 0: 235.5. Samples: 310864. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 17:41:34,597][07522] Avg episode reward: [(0, '-40.981')]
[36m[2025-07-03 17:41:39,584][07522] Fps is (10 sec: 1636.9, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 311296. Throughput: 0: 236.4. Samples: 312256. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:41:39,584][07522] Avg episode reward: [(0, '-38.739')]
[36m[2025-07-03 17:41:44,544][07522] Fps is (10 sec: 1647.0, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 311296. Throughput: 0: 235.4. Samples: 312944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:41:44,545][07522] Avg episode reward: [(0, '-38.703')]
[36m[2025-07-03 17:41:49,570][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 311296. Throughput: 0: 233.2. Samples: 314304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:41:49,571][07522] Avg episode reward: [(0, '-38.406')]
[36m[2025-07-03 17:41:54,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 233.1. Samples: 315664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:41:54,540][07522] Avg episode reward: [(0, '-36.908')]
[37m[1m[2025-07-03 17:41:54,610][07522] Saving new best policy, reward=-36.908!
[36m[2025-07-03 17:41:59,580][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 232.0. Samples: 316320. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:41:59,580][07522] Avg episode reward: [(0, '-36.884')]
[37m[1m[2025-07-03 17:41:59,666][07522] Saving new best policy, reward=-36.884!
[36m[2025-07-03 17:42:04,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 230.8. Samples: 317712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:42:04,573][07522] Avg episode reward: [(0, '-37.232')]
[36m[2025-07-03 17:42:09,579][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 229.1. Samples: 319120. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:42:09,579][07522] Avg episode reward: [(0, '-38.780')]
[36m[2025-07-03 17:42:14,557][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 230.8. Samples: 319872. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:42:14,558][07522] Avg episode reward: [(0, '-40.880')]
[36m[2025-07-03 17:42:19,539][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 231.8. Samples: 321280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:42:19,539][07522] Avg episode reward: [(0, '-40.802')]
[36m[2025-07-03 17:42:24,553][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 232.0. Samples: 322688. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:42:24,553][07522] Avg episode reward: [(0, '-39.462')]
[GIF] Episode 1500 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0015_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0015_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0015_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0015_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0015_merged_dual_camera.gif
[36m[2025-07-03 17:42:29,586][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 230.9. Samples: 323344. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:42:29,586][07522] Avg episode reward: [(0, '-38.436')]
[36m[2025-07-03 17:42:34,568][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 232.9. Samples: 324784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:42:34,568][07522] Avg episode reward: [(0, '-36.595')]
[37m[1m[2025-07-03 17:42:34,637][07522] Saving new best policy, reward=-36.595!
[36m[2025-07-03 17:42:39,579][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 311296. Throughput: 0: 234.5. Samples: 326224. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:42:39,579][07522] Avg episode reward: [(0, '-37.704')]
[36m[2025-07-03 17:42:44,541][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 311296. Throughput: 0: 237.4. Samples: 326992. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:42:44,541][07522] Avg episode reward: [(0, '-36.768')]
[36m[2025-07-03 17:42:49,605][07522] Fps is (10 sec: 1634.1, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 327680. Throughput: 0: 237.0. Samples: 328384. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:42:49,606][07522] Avg episode reward: [(0, '-35.459')]
[37m[1m[2025-07-03 17:42:49,609][07522] Saving new best policy, reward=-35.459!
[36m[2025-07-03 17:42:54,627][07522] Fps is (10 sec: 1624.5, 60 sec: 272.7, 300 sec: 277.6). Total num frames: 327680. Throughput: 0: 233.4. Samples: 329632. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:42:54,627][07522] Avg episode reward: [(0, '-37.609')]
[36m[2025-07-03 17:42:59,562][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 327680. Throughput: 0: 231.4. Samples: 330288. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:42:59,562][07522] Avg episode reward: [(0, '-37.525')]
[36m[2025-07-03 17:43:04,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 227.7. Samples: 331536. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:04,571][07522] Avg episode reward: [(0, '-39.657')]
[36m[2025-07-03 17:43:09,583][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 217.5. Samples: 332480. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:09,584][07522] Avg episode reward: [(0, '-37.441')]
[36m[2025-07-03 17:43:14,603][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 213.3. Samples: 332944. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:14,603][07522] Avg episode reward: [(0, '-37.194')]
[36m[2025-07-03 17:43:19,578][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 207.2. Samples: 334112. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:19,578][07522] Avg episode reward: [(0, '-37.038')]
[37m[1m[2025-07-03 17:43:19,642][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000640_327680.pth...
[36m[2025-07-03 17:43:19,646][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000352_180224.pth
[36m[2025-07-03 17:43:24,587][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 206.2. Samples: 335504. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:24,588][07522] Avg episode reward: [(0, '-35.500')]
[36m[2025-07-03 17:43:29,556][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 205.1. Samples: 336224. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:29,557][07522] Avg episode reward: [(0, '-34.484')]
[37m[1m[2025-07-03 17:43:29,621][07522] Saving new best policy, reward=-34.484!
[36m[2025-07-03 17:43:34,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 206.4. Samples: 337664. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:34,569][07522] Avg episode reward: [(0, '-36.273')]
[33m[1462224 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[1462224 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:43:39,558][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 209.7. Samples: 339056. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:39,558][07522] Avg episode reward: [(0, '-38.547')]
[36m[2025-07-03 17:43:44,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 210.8. Samples: 339776. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:44,561][07522] Avg episode reward: [(0, '-35.971')]
[36m[2025-07-03 17:43:49,538][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 215.6. Samples: 341232. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:49,538][07522] Avg episode reward: [(0, '-37.270')]
[36m[2025-07-03 17:43:54,566][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 327680. Throughput: 0: 223.0. Samples: 342512. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:54,567][07522] Avg episode reward: [(0, '-37.993')]
[36m[2025-07-03 17:43:59,575][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 327680. Throughput: 0: 228.1. Samples: 343200. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 17:43:59,575][07522] Avg episode reward: [(0, '-34.099')]
[37m[1m[2025-07-03 17:43:59,640][07522] Saving new best policy, reward=-34.099!
[36m[2025-07-03 17:44:04,590][07522] Fps is (10 sec: 1634.5, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 344064. Throughput: 0: 231.4. Samples: 344528. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:04,591][07522] Avg episode reward: [(0, '-32.498')]
[37m[1m[2025-07-03 17:44:04,651][07522] Saving new best policy, reward=-32.498!
[36m[2025-07-03 17:44:09,553][07522] Fps is (10 sec: 1642.0, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 344064. Throughput: 0: 230.6. Samples: 345872. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:09,553][07522] Avg episode reward: [(0, '-31.887')]
[37m[1m[2025-07-03 17:44:09,617][07522] Saving new best policy, reward=-31.887!
[36m[2025-07-03 17:44:14,593][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 344064. Throughput: 0: 230.6. Samples: 346608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:14,593][07522] Avg episode reward: [(0, '-34.260')]
[36m[2025-07-03 17:44:19,606][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 227.4. Samples: 347904. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:19,607][07522] Avg episode reward: [(0, '-35.717')]
[36m[2025-07-03 17:44:24,564][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 226.1. Samples: 349232. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:24,564][07522] Avg episode reward: [(0, '-34.690')]
[36m[2025-07-03 17:44:29,585][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 344064. Throughput: 0: 224.6. Samples: 349888. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:29,586][07522] Avg episode reward: [(0, '-35.316')]
[36m[2025-07-03 17:44:34,545][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 220.8. Samples: 351168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:34,546][07522] Avg episode reward: [(0, '-32.441')]
[36m[2025-07-03 17:44:39,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 223.7. Samples: 352576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:39,552][07522] Avg episode reward: [(0, '-33.667')]
[36m[2025-07-03 17:44:44,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 224.8. Samples: 353312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:44,561][07522] Avg episode reward: [(0, '-33.006')]
[36m[2025-07-03 17:44:49,598][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 226.4. Samples: 354720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:49,598][07522] Avg episode reward: [(0, '-32.109')]
[36m[2025-07-03 17:44:54,602][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 229.1. Samples: 356192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:54,602][07522] Avg episode reward: [(0, '-33.059')]
[36m[2025-07-03 17:44:59,581][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 228.7. Samples: 356896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:44:59,581][07522] Avg episode reward: [(0, '-32.942')]
[36m[2025-07-03 17:45:04,539][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 231.1. Samples: 358288. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:45:04,539][07522] Avg episode reward: [(0, '-33.827')]
[36m[2025-07-03 17:45:09,544][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 344064. Throughput: 0: 232.3. Samples: 359680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:45:09,544][07522] Avg episode reward: [(0, '-30.646')]
[37m[1m[2025-07-03 17:45:09,639][07522] Saving new best policy, reward=-30.646!
[36m[2025-07-03 17:45:14,587][07522] Fps is (10 sec: 1630.5, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 360448. Throughput: 0: 232.9. Samples: 360368. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:45:14,588][07522] Avg episode reward: [(0, '-35.527')]
[36m[2025-07-03 17:45:19,582][07522] Fps is (10 sec: 1632.2, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 360448. Throughput: 0: 234.1. Samples: 361712. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:45:19,583][07522] Avg episode reward: [(0, '-36.611')]
[37m[1m[2025-07-03 17:45:19,647][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000704_360448.pth...
[36m[2025-07-03 17:45:19,651][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000416_212992.pth
[36m[2025-07-03 17:45:24,578][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 233.5. Samples: 363088. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:45:24,579][07522] Avg episode reward: [(0, '-35.505')]
[36m[2025-07-03 17:45:29,578][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 233.5. Samples: 363824. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:45:29,578][07522] Avg episode reward: [(0, '-33.532')]
[36m[2025-07-03 17:45:34,598][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 234.0. Samples: 365248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:45:34,599][07522] Avg episode reward: [(0, '-32.617')]
[36m[2025-07-03 17:45:39,576][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 234.8. Samples: 366752. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:45:39,576][07522] Avg episode reward: [(0, '-31.957')]
[36m[2025-07-03 17:45:44,539][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 236.0. Samples: 367504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:45:44,540][07522] Avg episode reward: [(0, '-30.288')]
[37m[1m[2025-07-03 17:45:44,629][07522] Saving new best policy, reward=-30.288!
[33m[1594338 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[1594338 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:45:49,597][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 233.3. Samples: 368800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:45:49,598][07522] Avg episode reward: [(0, '-33.367')]
[36m[2025-07-03 17:45:54,576][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 232.0. Samples: 370128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:45:54,577][07522] Avg episode reward: [(0, '-36.518')]
[GIF] Episode 1600 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0016_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0016_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0016_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0016_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0016_merged_dual_camera.gif
[36m[2025-07-03 17:45:59,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 232.1. Samples: 370800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:45:59,543][07522] Avg episode reward: [(0, '-37.182')]
[36m[2025-07-03 17:46:04,565][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 229.4. Samples: 372032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:46:04,565][07522] Avg episode reward: [(0, '-34.250')]
[36m[2025-07-03 17:46:09,574][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 360448. Throughput: 0: 227.2. Samples: 373312. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:46:09,574][07522] Avg episode reward: [(0, '-34.909')]
[36m[2025-07-03 17:46:14,567][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 225.1. Samples: 373952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:46:14,567][07522] Avg episode reward: [(0, '-34.178')]
[36m[2025-07-03 17:46:19,571][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 360448. Throughput: 0: 222.7. Samples: 375264. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[36m[2025-07-03 17:46:19,572][07522] Avg episode reward: [(0, '-34.631')]
[36m[2025-07-03 17:46:24,629][07522] Fps is (10 sec: 1628.3, 60 sec: 272.8, 300 sec: 277.6). Total num frames: 376832. Throughput: 0: 220.9. Samples: 376704. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:46:24,629][07522] Avg episode reward: [(0, '-32.754')]
[36m[2025-07-03 17:46:29,597][07522] Fps is (10 sec: 1634.3, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 376832. Throughput: 0: 217.0. Samples: 377280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:46:29,597][07522] Avg episode reward: [(0, '-31.926')]
[36m[2025-07-03 17:46:34,538][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 376832. Throughput: 0: 217.5. Samples: 378576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:46:34,539][07522] Avg episode reward: [(0, '-31.914')]
[36m[2025-07-03 17:46:39,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 376832. Throughput: 0: 218.5. Samples: 379952. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:46:39,544][07522] Avg episode reward: [(0, '-31.253')]
[36m[2025-07-03 17:46:44,594][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 217.7. Samples: 380608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:46:44,595][07522] Avg episode reward: [(0, '-30.371')]
[36m[2025-07-03 17:46:49,567][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 221.9. Samples: 382016. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:46:49,567][07522] Avg episode reward: [(0, '-29.164')]
[37m[1m[2025-07-03 17:46:49,638][07522] Saving new best policy, reward=-29.164!
[36m[2025-07-03 17:46:54,609][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 223.5. Samples: 383376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:46:54,609][07522] Avg episode reward: [(0, '-27.072')]
[37m[1m[2025-07-03 17:46:54,721][07522] Saving new best policy, reward=-27.072!
[36m[2025-07-03 17:46:59,585][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 223.9. Samples: 384032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:46:59,585][07522] Avg episode reward: [(0, '-26.375')]
[37m[1m[2025-07-03 17:46:59,647][07522] Saving new best policy, reward=-26.375!
[36m[2025-07-03 17:47:04,585][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 376832. Throughput: 0: 225.0. Samples: 385392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:04,585][07522] Avg episode reward: [(0, '-26.301')]
[37m[1m[2025-07-03 17:47:04,652][07522] Saving new best policy, reward=-26.301!
[36m[2025-07-03 17:47:09,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 225.3. Samples: 386832. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:09,573][07522] Avg episode reward: [(0, '-27.043')]
[36m[2025-07-03 17:47:14,586][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 227.3. Samples: 387504. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:14,586][07522] Avg episode reward: [(0, '-29.223')]
[36m[2025-07-03 17:47:19,572][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 227.4. Samples: 388816. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:19,572][07522] Avg episode reward: [(0, '-31.708')]
[37m[1m[2025-07-03 17:47:19,636][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000736_376832.pth...
[36m[2025-07-03 17:47:19,641][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000480_245760.pth
[36m[2025-07-03 17:47:24,581][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 376832. Throughput: 0: 227.4. Samples: 390192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:24,581][07522] Avg episode reward: [(0, '-33.198')]
[36m[2025-07-03 17:47:29,597][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 376832. Throughput: 0: 230.0. Samples: 390960. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:29,597][07522] Avg episode reward: [(0, '-31.810')]
[36m[2025-07-03 17:47:34,546][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 376832. Throughput: 0: 230.5. Samples: 392384. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:34,546][07522] Avg episode reward: [(0, '-31.293')]
[36m[2025-07-03 17:47:39,569][07522] Fps is (10 sec: 1643.0, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 393216. Throughput: 0: 228.8. Samples: 393664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:39,569][07522] Avg episode reward: [(0, '-29.632')]
[36m[2025-07-03 17:47:44,581][07522] Fps is (10 sec: 1632.7, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 393216. Throughput: 0: 228.6. Samples: 394320. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:44,581][07522] Avg episode reward: [(0, '-26.305')]
[36m[2025-07-03 17:47:49,600][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 393216. Throughput: 0: 227.5. Samples: 395632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:49,600][07522] Avg episode reward: [(0, '-25.673')]
[37m[1m[2025-07-03 17:47:49,663][07522] Saving new best policy, reward=-25.673!
[36m[2025-07-03 17:47:54,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 393216. Throughput: 0: 225.8. Samples: 396992. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:54,571][07522] Avg episode reward: [(0, '-25.050')]
[37m[1m[2025-07-03 17:47:54,641][07522] Saving new best policy, reward=-25.050!
[36m[2025-07-03 17:47:59,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 393216. Throughput: 0: 227.1. Samples: 397712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:47:59,541][07522] Avg episode reward: [(0, '-27.821')]
[36m[2025-07-03 17:48:04,594][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 393216. Throughput: 0: 228.2. Samples: 399088. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:48:04,595][07522] Avg episode reward: [(0, '-27.645')]
[33m[1733291 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[1733291 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:48:09,624][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 393216. Throughput: 0: 227.3. Samples: 400432. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:48:09,625][07522] Avg episode reward: [(0, '-28.670')]
[36m[2025-07-03 17:48:14,570][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 393216. Throughput: 0: 225.2. Samples: 401088. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:48:14,570][07522] Avg episode reward: [(0, '-28.628')]
[36m[2025-07-03 17:48:19,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 393216. Throughput: 0: 225.4. Samples: 402528. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:48:19,545][07522] Avg episode reward: [(0, '-28.352')]
[36m[2025-07-03 17:48:24,542][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 393216. Throughput: 0: 228.4. Samples: 403936. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:48:24,542][07522] Avg episode reward: [(0, '-27.862')]
[36m[2025-07-03 17:48:29,584][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 393216. Throughput: 0: 229.7. Samples: 404656. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:48:29,584][07522] Avg episode reward: [(0, '-26.465')]
[36m[2025-07-03 17:48:34,577][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 393216. Throughput: 0: 230.9. Samples: 406016. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:48:34,577][07522] Avg episode reward: [(0, '-30.223')]
[36m[2025-07-03 17:48:39,561][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 393216. Throughput: 0: 229.0. Samples: 407296. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:48:39,562][07522] Avg episode reward: [(0, '-27.890')]
[36m[2025-07-03 17:48:44,583][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 393216. Throughput: 0: 228.1. Samples: 407984. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:48:44,583][07522] Avg episode reward: [(0, '-28.029')]
[36m[2025-07-03 17:48:49,539][07522] Fps is (10 sec: 1642.1, 60 sec: 273.3, 300 sec: 277.7). Total num frames: 409600. Throughput: 0: 227.1. Samples: 409296. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:48:49,539][07522] Avg episode reward: [(0, '-26.671')]
[36m[2025-07-03 17:48:54,576][07522] Fps is (10 sec: 1639.6, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 409600. Throughput: 0: 223.9. Samples: 410496. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:48:54,576][07522] Avg episode reward: [(0, '-28.273')]
[36m[2025-07-03 17:48:59,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 222.7. Samples: 411104. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:48:59,552][07522] Avg episode reward: [(0, '-25.948')]
[36m[2025-07-03 17:49:04,578][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 409600. Throughput: 0: 219.2. Samples: 412400. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:04,578][07522] Avg episode reward: [(0, '-25.149')]
[36m[2025-07-03 17:49:09,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 217.6. Samples: 413728. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:09,544][07522] Avg episode reward: [(0, '-24.223')]
[37m[1m[2025-07-03 17:49:09,610][07522] Saving new best policy, reward=-24.223!
[36m[2025-07-03 17:49:14,598][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 217.5. Samples: 414448. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:14,598][07522] Avg episode reward: [(0, '-22.833')]
[37m[1m[2025-07-03 17:49:14,711][07522] Saving new best policy, reward=-22.833!
[36m[2025-07-03 17:49:19,590][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 409600. Throughput: 0: 214.3. Samples: 415664. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:19,591][07522] Avg episode reward: [(0, '-25.254')]
[37m[1m[2025-07-03 17:49:19,684][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000800_409600.pth...
[36m[2025-07-03 17:49:19,691][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000544_278528.pth
[36m[2025-07-03 17:49:24,588][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 213.2. Samples: 416896. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:24,588][07522] Avg episode reward: [(0, '-25.904')]
[36m[2025-07-03 17:49:29,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 213.8. Samples: 417600. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:29,553][07522] Avg episode reward: [(0, '-27.158')]
[36m[2025-07-03 17:49:34,548][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 216.8. Samples: 419056. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:34,548][07522] Avg episode reward: [(0, '-26.895')]
[GIF] Episode 1700 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0017_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0017_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0017_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0017_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0017_merged_dual_camera.gif
[36m[2025-07-03 17:49:39,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 220.2. Samples: 420400. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:39,545][07522] Avg episode reward: [(0, '-26.408')]
[36m[2025-07-03 17:49:44,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 222.8. Samples: 421136. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:44,570][07522] Avg episode reward: [(0, '-27.995')]
[36m[2025-07-03 17:49:49,607][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 223.5. Samples: 422464. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:49,607][07522] Avg episode reward: [(0, '-26.530')]
[36m[2025-07-03 17:49:54,568][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 409600. Throughput: 0: 224.2. Samples: 423824. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:54,568][07522] Avg episode reward: [(0, '-26.101')]
[36m[2025-07-03 17:49:59,606][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 409600. Throughput: 0: 223.6. Samples: 424512. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[36m[2025-07-03 17:49:59,606][07522] Avg episode reward: [(0, '-25.987')]
[36m[2025-07-03 17:50:04,572][07522] Fps is (10 sec: 1637.7, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 425984. Throughput: 0: 224.8. Samples: 425776. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:04,572][07522] Avg episode reward: [(0, '-27.082')]
[36m[2025-07-03 17:50:09,542][07522] Fps is (10 sec: 1648.8, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 425984. Throughput: 0: 224.9. Samples: 427008. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:09,543][07522] Avg episode reward: [(0, '-26.987')]
[36m[2025-07-03 17:50:14,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 425984. Throughput: 0: 224.7. Samples: 427712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:14,560][07522] Avg episode reward: [(0, '-28.784')]
[36m[2025-07-03 17:50:19,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 425984. Throughput: 0: 223.2. Samples: 429104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:19,569][07522] Avg episode reward: [(0, '-28.810')]
[36m[2025-07-03 17:50:24,586][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 425984. Throughput: 0: 223.8. Samples: 430480. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:24,586][07522] Avg episode reward: [(0, '-29.211')]
[36m[2025-07-03 17:50:29,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 425984. Throughput: 0: 221.5. Samples: 431104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:29,570][07522] Avg episode reward: [(0, '-26.423')]
[33m[1878957 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[1878957 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:50:34,578][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 425984. Throughput: 0: 220.9. Samples: 432400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:34,578][07522] Avg episode reward: [(0, '-27.313')]
[36m[2025-07-03 17:50:39,586][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 425984. Throughput: 0: 221.1. Samples: 433776. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:39,586][07522] Avg episode reward: [(0, '-26.246')]
[36m[2025-07-03 17:50:44,592][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 425984. Throughput: 0: 220.9. Samples: 434448. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:44,592][07522] Avg episode reward: [(0, '-26.645')]
[36m[2025-07-03 17:50:49,607][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 425984. Throughput: 0: 223.8. Samples: 435856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:49,607][07522] Avg episode reward: [(0, '-25.853')]
[36m[2025-07-03 17:50:54,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 425984. Throughput: 0: 226.5. Samples: 437200. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:54,546][07522] Avg episode reward: [(0, '-25.549')]
[36m[2025-07-03 17:50:59,601][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 425984. Throughput: 0: 225.9. Samples: 437888. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:50:59,601][07522] Avg episode reward: [(0, '-25.559')]
[36m[2025-07-03 17:51:04,558][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 425984. Throughput: 0: 228.3. Samples: 439376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:04,558][07522] Avg episode reward: [(0, '-25.779')]
[36m[2025-07-03 17:51:09,594][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 425984. Throughput: 0: 225.4. Samples: 440624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:09,594][07522] Avg episode reward: [(0, '-25.191')]
[36m[2025-07-03 17:51:14,581][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 425984. Throughput: 0: 225.7. Samples: 441264. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:14,581][07522] Avg episode reward: [(0, '-24.935')]
[36m[2025-07-03 17:51:19,558][07522] Fps is (10 sec: 1644.3, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 442368. Throughput: 0: 225.9. Samples: 442560. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:19,558][07522] Avg episode reward: [(0, '-24.510')]
[37m[1m[2025-07-03 17:51:19,626][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000864_442368.pth...
[36m[2025-07-03 17:51:19,631][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000576_294912.pth
[36m[2025-07-03 17:51:24,602][07522] Fps is (10 sec: 1634.9, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 442368. Throughput: 0: 223.9. Samples: 443856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:24,602][07522] Avg episode reward: [(0, '-25.887')]
[36m[2025-07-03 17:51:29,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 442368. Throughput: 0: 222.7. Samples: 444464. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:29,571][07522] Avg episode reward: [(0, '-27.505')]
[36m[2025-07-03 17:51:34,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 442368. Throughput: 0: 220.1. Samples: 445744. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:34,541][07522] Avg episode reward: [(0, '-29.507')]
[36m[2025-07-03 17:51:39,550][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 442368. Throughput: 0: 216.9. Samples: 446960. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:39,550][07522] Avg episode reward: [(0, '-27.037')]
[36m[2025-07-03 17:51:44,588][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 442368. Throughput: 0: 216.2. Samples: 447616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:44,589][07522] Avg episode reward: [(0, '-24.866')]
[36m[2025-07-03 17:51:49,616][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 442368. Throughput: 0: 210.6. Samples: 448864. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:49,617][07522] Avg episode reward: [(0, '-24.362')]
[36m[2025-07-03 17:51:54,597][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 442368. Throughput: 0: 211.9. Samples: 450160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:54,597][07522] Avg episode reward: [(0, '-26.309')]
[36m[2025-07-03 17:51:59,598][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 442368. Throughput: 0: 213.3. Samples: 450864. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:51:59,598][07522] Avg episode reward: [(0, '-25.616')]
[36m[2025-07-03 17:52:04,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 442368. Throughput: 0: 214.0. Samples: 452192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:52:04,561][07522] Avg episode reward: [(0, '-24.136')]
[36m[2025-07-03 17:52:09,585][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 442368. Throughput: 0: 213.8. Samples: 453472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:52:09,585][07522] Avg episode reward: [(0, '-22.968')]
[36m[2025-07-03 17:52:14,622][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 442368. Throughput: 0: 215.2. Samples: 454160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:52:14,622][07522] Avg episode reward: [(0, '-25.166')]
[36m[2025-07-03 17:52:19,608][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 442368. Throughput: 0: 216.9. Samples: 455520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:52:19,608][07522] Avg episode reward: [(0, '-25.167')]
[36m[2025-07-03 17:52:24,540][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 442368. Throughput: 0: 219.8. Samples: 456848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:52:24,540][07522] Avg episode reward: [(0, '-23.776')]
[36m[2025-07-03 17:52:29,600][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 442368. Throughput: 0: 219.7. Samples: 457504. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:52:29,600][07522] Avg episode reward: [(0, '-26.621')]
[36m[2025-07-03 17:52:34,594][07522] Fps is (10 sec: 1629.7, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 458752. Throughput: 0: 222.0. Samples: 458848. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:52:34,594][07522] Avg episode reward: [(0, '-26.880')]
[36m[2025-07-03 17:52:39,542][07522] Fps is (10 sec: 1647.9, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 458752. Throughput: 0: 222.9. Samples: 460176. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:52:39,542][07522] Avg episode reward: [(0, '-25.936')]
[36m[2025-07-03 17:52:44,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 458752. Throughput: 0: 222.1. Samples: 460848. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:52:44,552][07522] Avg episode reward: [(0, '-23.815')]
[36m[2025-07-03 17:52:49,565][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 458752. Throughput: 0: 220.8. Samples: 462128. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:52:49,565][07522] Avg episode reward: [(0, '-24.730')]
[36m[2025-07-03 17:52:54,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 458752. Throughput: 0: 222.0. Samples: 463456. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:52:54,555][07522] Avg episode reward: [(0, '-25.226')]
[36m[2025-07-03 17:52:59,580][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 458752. Throughput: 0: 221.0. Samples: 464096. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:52:59,580][07522] Avg episode reward: [(0, '-25.691')]
[36m[2025-07-03 17:53:04,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 458752. Throughput: 0: 221.4. Samples: 465472. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:53:04,552][07522] Avg episode reward: [(0, '-22.367')]
[37m[1m[2025-07-03 17:53:04,618][07522] Saving new best policy, reward=-22.367!
[33m[2032784 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[2032784 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:53:09,604][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 458752. Throughput: 0: 219.4. Samples: 466736. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:53:09,605][07522] Avg episode reward: [(0, '-21.422')]
[37m[1m[2025-07-03 17:53:09,734][07522] Saving new best policy, reward=-21.422!
[36m[2025-07-03 17:53:14,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 458752. Throughput: 0: 219.2. Samples: 467360. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:53:14,561][07522] Avg episode reward: [(0, '-20.242')]
[37m[1m[2025-07-03 17:53:14,627][07522] Saving new best policy, reward=-20.242!
[36m[2025-07-03 17:53:19,550][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 458752. Throughput: 0: 219.9. Samples: 468736. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:53:19,551][07522] Avg episode reward: [(0, '-19.120')]
[37m[1m[2025-07-03 17:53:19,643][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000896_458752.pth...
[36m[2025-07-03 17:53:19,647][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000640_327680.pth
[37m[1m[2025-07-03 17:53:19,648][07522] Saving new best policy, reward=-19.120!
[36m[2025-07-03 17:53:24,556][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 458752. Throughput: 0: 219.0. Samples: 470032. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:53:24,556][07522] Avg episode reward: [(0, '-18.510')]
[37m[1m[2025-07-03 17:53:24,618][07522] Saving new best policy, reward=-18.510!
[36m[2025-07-03 17:53:29,591][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 458752. Throughput: 0: 219.2. Samples: 470720. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:53:29,591][07522] Avg episode reward: [(0, '-19.908')]
[36m[2025-07-03 17:53:34,589][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 458752. Throughput: 0: 221.0. Samples: 472080. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:53:34,589][07522] Avg episode reward: [(0, '-24.475')]
[GIF] Episode 1800 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0018_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0018_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0018_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0018_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0018_merged_dual_camera.gif
[36m[2025-07-03 17:53:39,591][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 458752. Throughput: 0: 221.0. Samples: 473408. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:53:39,592][07522] Avg episode reward: [(0, '-24.478')]
[36m[2025-07-03 17:53:44,613][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 458752. Throughput: 0: 223.8. Samples: 474176. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 17:53:44,614][07522] Avg episode reward: [(0, '-21.343')]
[36m[2025-07-03 17:53:49,563][07522] Fps is (10 sec: 1643.1, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 475136. Throughput: 0: 222.2. Samples: 475472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:53:49,563][07522] Avg episode reward: [(0, '-21.050')]
[36m[2025-07-03 17:53:54,581][07522] Fps is (10 sec: 1643.8, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 475136. Throughput: 0: 223.8. Samples: 476800. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:53:54,581][07522] Avg episode reward: [(0, '-22.194')]
[36m[2025-07-03 17:53:59,602][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 475136. Throughput: 0: 224.5. Samples: 477472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:53:59,602][07522] Avg episode reward: [(0, '-20.986')]
[36m[2025-07-03 17:54:04,611][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 475136. Throughput: 0: 223.3. Samples: 478800. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:04,612][07522] Avg episode reward: [(0, '-20.958')]
[36m[2025-07-03 17:54:09,638][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 475136. Throughput: 0: 223.9. Samples: 480128. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:09,639][07522] Avg episode reward: [(0, '-22.047')]
[36m[2025-07-03 17:54:14,547][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 475136. Throughput: 0: 223.1. Samples: 480752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:14,548][07522] Avg episode reward: [(0, '-24.581')]
[36m[2025-07-03 17:54:19,603][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 475136. Throughput: 0: 221.4. Samples: 482048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:19,604][07522] Avg episode reward: [(0, '-23.042')]
[36m[2025-07-03 17:54:24,589][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 475136. Throughput: 0: 221.5. Samples: 483376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:24,590][07522] Avg episode reward: [(0, '-21.894')]
[36m[2025-07-03 17:54:29,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 475136. Throughput: 0: 218.6. Samples: 484000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:29,547][07522] Avg episode reward: [(0, '-20.248')]
[36m[2025-07-03 17:54:34,621][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 475136. Throughput: 0: 217.3. Samples: 485264. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:34,622][07522] Avg episode reward: [(0, '-22.363')]
[36m[2025-07-03 17:54:39,598][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 475136. Throughput: 0: 217.2. Samples: 486576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:39,598][07522] Avg episode reward: [(0, '-22.560')]
[36m[2025-07-03 17:54:44,559][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 475136. Throughput: 0: 217.8. Samples: 487264. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:44,559][07522] Avg episode reward: [(0, '-22.981')]
[36m[2025-07-03 17:54:49,566][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 475136. Throughput: 0: 218.9. Samples: 488640. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:49,567][07522] Avg episode reward: [(0, '-23.644')]
[36m[2025-07-03 17:54:54,572][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 475136. Throughput: 0: 219.0. Samples: 489968. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:54,573][07522] Avg episode reward: [(0, '-24.077')]
[36m[2025-07-03 17:54:59,601][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 475136. Throughput: 0: 219.5. Samples: 490640. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:54:59,601][07522] Avg episode reward: [(0, '-22.487')]
[36m[2025-07-03 17:55:04,594][07522] Fps is (10 sec: 1634.9, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 491520. Throughput: 0: 219.1. Samples: 491904. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:04,594][07522] Avg episode reward: [(0, '-20.216')]
[36m[2025-07-03 17:55:09,551][07522] Fps is (10 sec: 1646.6, 60 sec: 273.5, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 221.0. Samples: 493312. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:09,551][07522] Avg episode reward: [(0, '-16.879')]
[37m[1m[2025-07-03 17:55:09,657][07522] Saving new best policy, reward=-16.879!
[36m[2025-07-03 17:55:14,589][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 491520. Throughput: 0: 222.7. Samples: 494032. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:14,589][07522] Avg episode reward: [(0, '-22.063')]
[36m[2025-07-03 17:55:19,559][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 223.2. Samples: 495296. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:19,559][07522] Avg episode reward: [(0, '-22.444')]
[37m[1m[2025-07-03 17:55:19,628][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000960_491520.pth...
[36m[2025-07-03 17:55:19,644][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000704_360448.pth
[36m[2025-07-03 17:55:24,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 222.5. Samples: 496576. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:24,546][07522] Avg episode reward: [(0, '-21.279')]
[36m[2025-07-03 17:55:29,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 220.8. Samples: 497200. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:29,561][07522] Avg episode reward: [(0, '-20.054')]
[36m[2025-07-03 17:55:34,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 221.3. Samples: 498592. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:34,540][07522] Avg episode reward: [(0, '-20.282')]
[36m[2025-07-03 17:55:39,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 218.7. Samples: 499808. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:39,570][07522] Avg episode reward: [(0, '-21.205')]
[36m[2025-07-03 17:55:44,584][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 216.6. Samples: 500384. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:44,584][07522] Avg episode reward: [(0, '-21.703')]
[33m[2190090 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[2190090 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:55:49,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 218.5. Samples: 501728. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:49,552][07522] Avg episode reward: [(0, '-18.852')]
[36m[2025-07-03 17:55:54,581][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 216.4. Samples: 503056. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:54,581][07522] Avg episode reward: [(0, '-17.807')]
[36m[2025-07-03 17:55:59,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 215.3. Samples: 503712. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:55:59,540][07522] Avg episode reward: [(0, '-19.158')]
[36m[2025-07-03 17:56:04,604][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 491520. Throughput: 0: 214.9. Samples: 504976. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:56:04,605][07522] Avg episode reward: [(0, '-21.806')]
[36m[2025-07-03 17:56:09,580][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 491520. Throughput: 0: 214.9. Samples: 506256. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:56:09,581][07522] Avg episode reward: [(0, '-22.292')]
[36m[2025-07-03 17:56:14,573][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 491520. Throughput: 0: 217.2. Samples: 506976. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 17:56:14,573][07522] Avg episode reward: [(0, '-22.820')]
[36m[2025-07-03 17:56:19,585][07522] Fps is (10 sec: 1637.7, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 214.9. Samples: 508272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:56:19,585][07522] Avg episode reward: [(0, '-22.066')]
[36m[2025-07-03 17:56:24,548][07522] Fps is (10 sec: 1642.5, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 215.6. Samples: 509504. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:56:24,548][07522] Avg episode reward: [(0, '-23.204')]
[36m[2025-07-03 17:56:29,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 507904. Throughput: 0: 217.0. Samples: 510144. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:56:29,552][07522] Avg episode reward: [(0, '-18.145')]
[36m[2025-07-03 17:56:34,585][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 507904. Throughput: 0: 218.5. Samples: 511568. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:56:34,586][07522] Avg episode reward: [(0, '-18.175')]
[36m[2025-07-03 17:56:39,556][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 220.6. Samples: 512976. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:56:39,556][07522] Avg episode reward: [(0, '-17.763')]
[36m[2025-07-03 17:56:44,604][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 220.8. Samples: 513664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:56:44,604][07522] Avg episode reward: [(0, '-19.823')]
[36m[2025-07-03 17:56:49,595][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 223.7. Samples: 515040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:56:49,595][07522] Avg episode reward: [(0, '-19.088')]
[36m[2025-07-03 17:56:54,547][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 227.4. Samples: 516480. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:56:54,547][07522] Avg episode reward: [(0, '-18.933')]
[36m[2025-07-03 17:56:59,612][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 507904. Throughput: 0: 226.3. Samples: 517168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:56:59,612][07522] Avg episode reward: [(0, '-19.639')]
[36m[2025-07-03 17:57:04,591][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 227.9. Samples: 518528. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:57:04,592][07522] Avg episode reward: [(0, '-17.236')]
[36m[2025-07-03 17:57:09,594][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 231.9. Samples: 519952. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:57:09,595][07522] Avg episode reward: [(0, '-16.766')]
[37m[1m[2025-07-03 17:57:09,659][07522] Saving new best policy, reward=-16.766!
[36m[2025-07-03 17:57:14,580][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 233.1. Samples: 520640. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:57:14,580][07522] Avg episode reward: [(0, '-14.200')]
[37m[1m[2025-07-03 17:57:14,665][07522] Saving new best policy, reward=-14.200!
[36m[2025-07-03 17:57:19,613][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 507904. Throughput: 0: 232.0. Samples: 522016. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:57:19,613][07522] Avg episode reward: [(0, '-15.174')]
[37m[1m[2025-07-03 17:57:19,712][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000992_507904.pth...
[36m[2025-07-03 17:57:19,718][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000736_376832.pth
[36m[2025-07-03 17:57:24,545][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 507904. Throughput: 0: 229.7. Samples: 523312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 17:57:24,545][07522] Avg episode reward: [(0, '-14.789')]
[36m[2025-07-03 17:57:29,559][07522] Fps is (10 sec: 1647.3, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 229.9. Samples: 524000. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:57:29,559][07522] Avg episode reward: [(0, '-13.881')]
[37m[1m[2025-07-03 17:57:29,629][07522] Saving new best policy, reward=-13.881!
[36m[2025-07-03 17:57:34,555][07522] Fps is (10 sec: 1636.7, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 524288. Throughput: 0: 229.9. Samples: 525376. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:57:34,555][07522] Avg episode reward: [(0, '-14.275')]
[GIF] Episode 1900 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0019_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0019_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0019_static_depth.gif
[36m[2025-07-03 17:57:39,588][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 524288. Throughput: 0: 227.3. Samples: 526720. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:57:39,588][07522] Avg episode reward: [(0, '-17.379')]
[GIF] Saved static segmentation: ./gif_episodes/episode_0019_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0019_merged_dual_camera.gif
[36m[2025-07-03 17:57:44,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 226.4. Samples: 527344. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:57:44,569][07522] Avg episode reward: [(0, '-18.710')]
[36m[2025-07-03 17:57:49,606][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 524288. Throughput: 0: 227.1. Samples: 528752. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:57:49,607][07522] Avg episode reward: [(0, '-20.424')]
[36m[2025-07-03 17:57:54,622][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 524288. Throughput: 0: 224.2. Samples: 530048. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:57:54,622][07522] Avg episode reward: [(0, '-18.528')]
[36m[2025-07-03 17:57:59,582][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 524288. Throughput: 0: 222.9. Samples: 530672. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:57:59,582][07522] Avg episode reward: [(0, '-18.190')]
[36m[2025-07-03 17:58:04,550][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 222.9. Samples: 532032. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:58:04,551][07522] Avg episode reward: [(0, '-18.553')]
[36m[2025-07-03 17:58:09,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 524288. Throughput: 0: 222.1. Samples: 533312. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:58:09,573][07522] Avg episode reward: [(0, '-17.785')]
[36m[2025-07-03 17:58:14,547][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 220.9. Samples: 533936. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:58:14,547][07522] Avg episode reward: [(0, '-17.264')]
[36m[2025-07-03 17:58:19,595][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 524288. Throughput: 0: 220.3. Samples: 535296. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:58:19,595][07522] Avg episode reward: [(0, '-15.771')]
[36m[2025-07-03 17:58:24,570][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 220.2. Samples: 536624. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:58:24,570][07522] Avg episode reward: [(0, '-15.356')]
[33m[2352107 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[2352107 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 17:58:29,574][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 221.8. Samples: 537328. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:58:29,574][07522] Avg episode reward: [(0, '-17.341')]
[36m[2025-07-03 17:58:34,614][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 524288. Throughput: 0: 220.8. Samples: 538688. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:58:34,615][07522] Avg episode reward: [(0, '-14.435')]
[36m[2025-07-03 17:58:39,588][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 524288. Throughput: 0: 222.7. Samples: 540064. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 17:58:39,588][07522] Avg episode reward: [(0, '-15.737')]
[36m[2025-07-03 17:58:44,585][07522] Fps is (10 sec: 1643.2, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 540672. Throughput: 0: 223.3. Samples: 540720. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:58:44,586][07522] Avg episode reward: [(0, '-14.780')]
[36m[2025-07-03 17:58:49,606][07522] Fps is (10 sec: 1635.5, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 540672. Throughput: 0: 224.4. Samples: 542144. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:58:49,606][07522] Avg episode reward: [(0, '-14.813')]
[36m[2025-07-03 17:58:54,542][07522] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 540672. Throughput: 0: 225.9. Samples: 543472. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:58:54,542][07522] Avg episode reward: [(0, '-15.048')]
[36m[2025-07-03 17:58:59,542][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 540672. Throughput: 0: 227.2. Samples: 544160. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:58:59,542][07522] Avg episode reward: [(0, '-15.493')]
[36m[2025-07-03 17:59:04,591][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 540672. Throughput: 0: 228.3. Samples: 545568. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:59:04,591][07522] Avg episode reward: [(0, '-15.439')]
[36m[2025-07-03 17:59:09,572][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 540672. Throughput: 0: 230.7. Samples: 547008. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:59:09,572][07522] Avg episode reward: [(0, '-14.376')]
[36m[2025-07-03 17:59:14,591][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 540672. Throughput: 0: 230.0. Samples: 547680. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:59:14,591][07522] Avg episode reward: [(0, '-13.956')]
[36m[2025-07-03 17:59:19,612][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 540672. Throughput: 0: 232.2. Samples: 549136. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:59:19,612][07522] Avg episode reward: [(0, '-14.073')]
[37m[1m[2025-07-03 17:59:19,704][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001056_540672.pth...
[36m[2025-07-03 17:59:19,709][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000800_409600.pth
[36m[2025-07-03 17:59:24,597][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 540672. Throughput: 0: 231.1. Samples: 550464. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:59:24,597][07522] Avg episode reward: [(0, '-15.623')]
[36m[2025-07-03 17:59:29,554][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 540672. Throughput: 0: 232.7. Samples: 551184. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:59:29,555][07522] Avg episode reward: [(0, '-15.271')]
[36m[2025-07-03 17:59:34,564][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 540672. Throughput: 0: 231.3. Samples: 552544. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:59:34,564][07522] Avg episode reward: [(0, '-14.095')]
[36m[2025-07-03 17:59:39,581][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 540672. Throughput: 0: 232.0. Samples: 553920. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:59:39,582][07522] Avg episode reward: [(0, '-13.731')]
[37m[1m[2025-07-03 17:59:39,652][07522] Saving new best policy, reward=-13.731!
[36m[2025-07-03 17:59:44,539][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 540672. Throughput: 0: 232.2. Samples: 554608. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:59:44,539][07522] Avg episode reward: [(0, '-13.462')]
[37m[1m[2025-07-03 17:59:44,612][07522] Saving new best policy, reward=-13.462!
[36m[2025-07-03 17:59:49,557][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 540672. Throughput: 0: 233.4. Samples: 556064. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 17:59:49,557][07522] Avg episode reward: [(0, '-11.332')]
[37m[1m[2025-07-03 17:59:49,624][07522] Saving new best policy, reward=-11.332!
[36m[2025-07-03 17:59:54,578][07522] Fps is (10 sec: 1631.9, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 557056. Throughput: 0: 230.4. Samples: 557376. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 17:59:54,579][07522] Avg episode reward: [(0, '-10.042')]
[37m[1m[2025-07-03 17:59:54,672][07522] Saving new best policy, reward=-10.042!
[36m[2025-07-03 17:59:59,591][07522] Fps is (10 sec: 1632.8, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 557056. Throughput: 0: 230.0. Samples: 558032. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 17:59:59,591][07522] Avg episode reward: [(0, '-10.457')]
[36m[2025-07-03 18:00:04,566][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 557056. Throughput: 0: 229.6. Samples: 559456. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:04,567][07522] Avg episode reward: [(0, '-12.977')]
[36m[2025-07-03 18:00:09,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 557056. Throughput: 0: 230.3. Samples: 560816. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:09,556][07522] Avg episode reward: [(0, '-14.947')]
[36m[2025-07-03 18:00:14,538][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 557056. Throughput: 0: 229.4. Samples: 561504. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:14,538][07522] Avg episode reward: [(0, '-16.574')]
[36m[2025-07-03 18:00:19,584][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 557056. Throughput: 0: 232.8. Samples: 563024. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:19,584][07522] Avg episode reward: [(0, '-16.853')]
[36m[2025-07-03 18:00:24,588][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 557056. Throughput: 0: 232.5. Samples: 564384. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:24,588][07522] Avg episode reward: [(0, '-16.440')]
[36m[2025-07-03 18:00:29,564][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 557056. Throughput: 0: 232.0. Samples: 565056. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:29,564][07522] Avg episode reward: [(0, '-15.238')]
[36m[2025-07-03 18:00:34,549][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 557056. Throughput: 0: 232.6. Samples: 566528. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:34,549][07522] Avg episode reward: [(0, '-18.739')]
[36m[2025-07-03 18:00:39,548][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 557056. Throughput: 0: 236.2. Samples: 568000. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:39,548][07522] Avg episode reward: [(0, '-18.193')]
[36m[2025-07-03 18:00:44,576][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 557056. Throughput: 0: 236.2. Samples: 568656. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:44,576][07522] Avg episode reward: [(0, '-19.532')]
[36m[2025-07-03 18:00:49,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 557056. Throughput: 0: 236.9. Samples: 570112. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:49,545][07522] Avg episode reward: [(0, '-17.146')]
[36m[2025-07-03 18:00:54,568][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 557056. Throughput: 0: 237.1. Samples: 571488. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:54,568][07522] Avg episode reward: [(0, '-16.039')]
[36m[2025-07-03 18:00:59,592][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 557056. Throughput: 0: 237.2. Samples: 572192. Policy #0 lag: (min: 24.0, avg: 24.2, max: 56.0)
[36m[2025-07-03 18:00:59,593][07522] Avg episode reward: [(0, '-12.992')]
[36m[2025-07-03 18:01:04,569][07522] Fps is (10 sec: 1638.1, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 573440. Throughput: 0: 233.0. Samples: 573504. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:04,569][07522] Avg episode reward: [(0, '-12.847')]
[33m[2512598 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[2512598 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:01:09,623][07522] Fps is (10 sec: 1633.4, 60 sec: 272.8, 300 sec: 277.6). Total num frames: 573440. Throughput: 0: 232.7. Samples: 574864. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:09,624][07522] Avg episode reward: [(0, '-12.872')]
[36m[2025-07-03 18:01:14,618][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 229.1. Samples: 575376. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:14,618][07522] Avg episode reward: [(0, '-13.951')]
[36m[2025-07-03 18:01:19,548][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 573440. Throughput: 0: 216.9. Samples: 576288. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:19,548][07522] Avg episode reward: [(0, '-16.821')]
[37m[1m[2025-07-03 18:01:19,669][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001120_573440.pth...
[36m[2025-07-03 18:01:19,675][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000864_442368.pth
[36m[2025-07-03 18:01:24,578][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 202.9. Samples: 577136. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:24,579][07522] Avg episode reward: [(0, '-15.697')]
[36m[2025-07-03 18:01:29,622][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 199.6. Samples: 577648. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:29,623][07522] Avg episode reward: [(0, '-13.167')]
[36m[2025-07-03 18:01:34,613][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 189.9. Samples: 578672. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:34,613][07522] Avg episode reward: [(0, '-15.052')]
[36m[2025-07-03 18:01:39,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 573440. Throughput: 0: 185.7. Samples: 579840. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:39,547][07522] Avg episode reward: [(0, '-12.401')]
[36m[2025-07-03 18:01:44,539][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 573440. Throughput: 0: 185.1. Samples: 580512. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:44,540][07522] Avg episode reward: [(0, '-12.171')]
[36m[2025-07-03 18:01:49,582][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 184.8. Samples: 581824. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:49,582][07522] Avg episode reward: [(0, '-15.158')]
[36m[2025-07-03 18:01:54,579][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 573440. Throughput: 0: 182.2. Samples: 583056. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:54,579][07522] Avg episode reward: [(0, '-15.949')]
[36m[2025-07-03 18:01:59,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 573440. Throughput: 0: 181.6. Samples: 583536. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:01:59,546][07522] Avg episode reward: [(0, '-14.169')]
[36m[2025-07-03 18:02:04,555][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 573440. Throughput: 0: 182.4. Samples: 584496. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:02:04,555][07522] Avg episode reward: [(0, '-15.889')]
[GIF] Episode 2000 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0020_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0020_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0020_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0020_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0020_merged_dual_camera.gif
[36m[2025-07-03 18:02:09,542][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 573440. Throughput: 0: 192.5. Samples: 585792. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:02:09,543][07522] Avg episode reward: [(0, '-13.647')]
[36m[2025-07-03 18:02:14,543][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 573440. Throughput: 0: 195.2. Samples: 586416. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:02:14,543][07522] Avg episode reward: [(0, '-14.035')]
[36m[2025-07-03 18:02:19,553][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 573440. Throughput: 0: 201.9. Samples: 587744. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:02:19,554][07522] Avg episode reward: [(0, '-13.823')]
[36m[2025-07-03 18:02:24,545][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 573440. Throughput: 0: 207.7. Samples: 589184. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:02:24,545][07522] Avg episode reward: [(0, '-13.337')]
[36m[2025-07-03 18:02:29,555][07522] Fps is (10 sec: 1638.1, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 205.8. Samples: 589776. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:02:29,555][07522] Avg episode reward: [(0, '-12.966')]
[36m[2025-07-03 18:02:34,632][07522] Fps is (10 sec: 1624.3, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 589824. Throughput: 0: 196.8. Samples: 590688. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:02:34,632][07522] Avg episode reward: [(0, '-11.794')]
[36m[2025-07-03 18:02:39,550][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 188.9. Samples: 591552. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:02:39,551][07522] Avg episode reward: [(0, '-11.641')]
[36m[2025-07-03 18:02:44,574][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 191.9. Samples: 592176. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:02:44,574][07522] Avg episode reward: [(0, '-12.166')]
[36m[2025-07-03 18:02:49,554][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 197.0. Samples: 593360. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:02:49,554][07522] Avg episode reward: [(0, '-12.364')]
[36m[2025-07-03 18:02:54,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 196.3. Samples: 594624. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:02:54,546][07522] Avg episode reward: [(0, '-11.930')]
[36m[2025-07-03 18:02:59,577][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 589824. Throughput: 0: 199.0. Samples: 595376. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:02:59,578][07522] Avg episode reward: [(0, '-8.255')]
[37m[1m[2025-07-03 18:02:59,688][07522] Saving new best policy, reward=-8.255!
[36m[2025-07-03 18:03:04,579][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 195.1. Samples: 596528. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:04,580][07522] Avg episode reward: [(0, '-8.323')]
[36m[2025-07-03 18:03:09,559][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 589824. Throughput: 0: 184.8. Samples: 597504. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:09,559][07522] Avg episode reward: [(0, '-9.900')]
[36m[2025-07-03 18:03:14,622][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 589824. Throughput: 0: 183.5. Samples: 598048. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:14,623][07522] Avg episode reward: [(0, '-10.190')]
[36m[2025-07-03 18:03:19,594][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 589824. Throughput: 0: 185.4. Samples: 599024. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:19,594][07522] Avg episode reward: [(0, '-11.448')]
[37m[1m[2025-07-03 18:03:19,681][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001152_589824.pth...
[36m[2025-07-03 18:03:19,686][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000896_458752.pth
[36m[2025-07-03 18:03:24,558][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 193.4. Samples: 600256. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:24,559][07522] Avg episode reward: [(0, '-13.532')]
[36m[2025-07-03 18:03:29,605][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 189.0. Samples: 600688. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:29,605][07522] Avg episode reward: [(0, '-13.196')]
[36m[2025-07-03 18:03:34,538][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 589824. Throughput: 0: 188.5. Samples: 601840. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:34,538][07522] Avg episode reward: [(0, '-15.956')]
[36m[2025-07-03 18:03:39,581][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 188.3. Samples: 603104. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:39,581][07522] Avg episode reward: [(0, '-15.347')]
[36m[2025-07-03 18:03:44,575][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 182.8. Samples: 603600. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:44,575][07522] Avg episode reward: [(0, '-14.631')]
[36m[2025-07-03 18:03:49,602][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 175.6. Samples: 604432. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:49,602][07522] Avg episode reward: [(0, '-14.601')]
[36m[2025-07-03 18:03:54,546][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 589824. Throughput: 0: 175.0. Samples: 605376. Policy #0 lag: (min: 25.0, avg: 25.0, max: 25.0)
[36m[2025-07-03 18:03:54,546][07522] Avg episode reward: [(0, '-12.650')]
[36m[2025-07-03 18:03:59,601][07522] Fps is (10 sec: 1638.6, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 177.9. Samples: 606048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:03:59,601][07522] Avg episode reward: [(0, '-8.704')]
[36m[2025-07-03 18:04:04,599][07522] Fps is (10 sec: 1629.7, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 182.0. Samples: 607216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:04,600][07522] Avg episode reward: [(0, '-9.570')]
[36m[2025-07-03 18:04:09,557][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 606208. Throughput: 0: 177.1. Samples: 608224. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:09,557][07522] Avg episode reward: [(0, '-8.673')]
[36m[2025-07-03 18:04:14,607][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 606208. Throughput: 0: 184.2. Samples: 608976. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:14,607][07522] Avg episode reward: [(0, '-11.259')]
[36m[2025-07-03 18:04:19,627][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 181.3. Samples: 610016. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:19,627][07522] Avg episode reward: [(0, '-11.404')]
[36m[2025-07-03 18:04:24,601][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 173.8. Samples: 610928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:24,601][07522] Avg episode reward: [(0, '-10.980')]
[36m[2025-07-03 18:04:29,594][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 174.5. Samples: 611456. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:29,595][07522] Avg episode reward: [(0, '-12.185')]
[33m[2716944 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[2716944 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:04:34,597][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 188.1. Samples: 612896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:34,597][07522] Avg episode reward: [(0, '-12.147')]
[36m[2025-07-03 18:04:39,592][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 189.0. Samples: 613888. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:39,592][07522] Avg episode reward: [(0, '-11.503')]
[36m[2025-07-03 18:04:44,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 606208. Throughput: 0: 188.9. Samples: 614544. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:44,572][07522] Avg episode reward: [(0, '-15.647')]
[36m[2025-07-03 18:04:49,612][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 190.5. Samples: 615792. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:49,613][07522] Avg episode reward: [(0, '-13.082')]
[36m[2025-07-03 18:04:54,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 188.9. Samples: 616720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:54,541][07522] Avg episode reward: [(0, '-13.312')]
[36m[2025-07-03 18:04:59,577][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 183.2. Samples: 617216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:04:59,578][07522] Avg episode reward: [(0, '-14.591')]
[36m[2025-07-03 18:05:04,562][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 181.2. Samples: 618160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:04,563][07522] Avg episode reward: [(0, '-12.517')]
[36m[2025-07-03 18:05:09,569][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 186.4. Samples: 619312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:09,570][07522] Avg episode reward: [(0, '-13.107')]
[36m[2025-07-03 18:05:14,592][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 189.5. Samples: 619984. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:14,592][07522] Avg episode reward: [(0, '-12.175')]
[36m[2025-07-03 18:05:19,551][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 183.3. Samples: 621136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:19,552][07522] Avg episode reward: [(0, '-10.543')]
[37m[1m[2025-07-03 18:05:19,656][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001184_606208.pth...
[36m[2025-07-03 18:05:19,662][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000960_491520.pth
[36m[2025-07-03 18:05:24,559][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 606208. Throughput: 0: 188.2. Samples: 622352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:24,559][07522] Avg episode reward: [(0, '-10.821')]
[36m[2025-07-03 18:05:29,584][07522] Fps is (10 sec: 1633.1, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 622592. Throughput: 0: 182.3. Samples: 622752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:29,584][07522] Avg episode reward: [(0, '-8.204')]
[37m[1m[2025-07-03 18:05:29,711][07522] Saving new best policy, reward=-8.204!
[36m[2025-07-03 18:05:34,599][07522] Fps is (10 sec: 1631.9, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 622592. Throughput: 0: 175.7. Samples: 623696. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:34,599][07522] Avg episode reward: [(0, '-7.621')]
[37m[1m[2025-07-03 18:05:34,691][07522] Saving new best policy, reward=-7.621!
[36m[2025-07-03 18:05:39,620][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 622592. Throughput: 0: 175.0. Samples: 624608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:39,620][07522] Avg episode reward: [(0, '-6.304')]
[37m[1m[2025-07-03 18:05:39,722][07522] Saving new best policy, reward=-6.304!
[36m[2025-07-03 18:05:44,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 622592. Throughput: 0: 174.7. Samples: 625072. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:44,544][07522] Avg episode reward: [(0, '-6.528')]
[36m[2025-07-03 18:05:49,631][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 622592. Throughput: 0: 182.5. Samples: 626384. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:49,631][07522] Avg episode reward: [(0, '-7.268')]
[36m[2025-07-03 18:05:54,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 622592. Throughput: 0: 184.6. Samples: 627616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:54,560][07522] Avg episode reward: [(0, '-8.127')]
[36m[2025-07-03 18:05:59,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 185.4. Samples: 628320. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:05:59,553][07522] Avg episode reward: [(0, '-9.825')]
[36m[2025-07-03 18:06:04,577][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 184.8. Samples: 629456. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:04,578][07522] Avg episode reward: [(0, '-9.552')]
[36m[2025-07-03 18:06:09,545][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.7). Total num frames: 622592. Throughput: 0: 177.8. Samples: 630352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:09,545][07522] Avg episode reward: [(0, '-11.977')]
[36m[2025-07-03 18:06:14,548][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 183.6. Samples: 631008. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:14,549][07522] Avg episode reward: [(0, '-12.936')]
[36m[2025-07-03 18:06:19,568][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 191.4. Samples: 632304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:19,568][07522] Avg episode reward: [(0, '-14.301')]
[36m[2025-07-03 18:06:24,581][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 191.8. Samples: 633232. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:24,581][07522] Avg episode reward: [(0, '-11.832')]
[36m[2025-07-03 18:06:29,548][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 622592. Throughput: 0: 194.8. Samples: 633840. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:29,549][07522] Avg episode reward: [(0, '-9.915')]
[36m[2025-07-03 18:06:34,584][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 189.7. Samples: 634912. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:34,584][07522] Avg episode reward: [(0, '-10.210')]
[36m[2025-07-03 18:06:39,564][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 182.0. Samples: 635808. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:39,565][07522] Avg episode reward: [(0, '-8.363')]
[36m[2025-07-03 18:06:44,597][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 176.5. Samples: 636272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:44,598][07522] Avg episode reward: [(0, '-8.003')]
[36m[2025-07-03 18:06:49,636][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 170.4. Samples: 637136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:49,637][07522] Avg episode reward: [(0, '-7.605')]
[36m[2025-07-03 18:06:54,643][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 169.6. Samples: 638000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:54,644][07522] Avg episode reward: [(0, '-8.511')]
[36m[2025-07-03 18:06:59,613][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 622592. Throughput: 0: 164.4. Samples: 638416. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:06:59,613][07522] Avg episode reward: [(0, '-9.855')]
[36m[2025-07-03 18:07:04,576][07522] Fps is (10 sec: 1649.4, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 638976. Throughput: 0: 154.6. Samples: 639264. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:04,577][07522] Avg episode reward: [(0, '-9.633')]
[36m[2025-07-03 18:07:09,635][07522] Fps is (10 sec: 1634.8, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 638976. Throughput: 0: 154.1. Samples: 640176. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:09,635][07522] Avg episode reward: [(0, '-12.302')]
[36m[2025-07-03 18:07:14,639][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 638976. Throughput: 0: 150.5. Samples: 640624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:14,640][07522] Avg episode reward: [(0, '-14.439')]
[36m[2025-07-03 18:07:19,650][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 638976. Throughput: 0: 147.0. Samples: 641536. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:19,651][07522] Avg episode reward: [(0, '-12.961')]
[37m[1m[2025-07-03 18:07:19,753][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001248_638976.pth...
[36m[2025-07-03 18:07:19,762][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000000992_507904.pth
[36m[2025-07-03 18:07:24,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 146.5. Samples: 642400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:24,551][07522] Avg episode reward: [(0, '-13.882')]
[36m[2025-07-03 18:07:29,607][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 146.1. Samples: 642848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:29,608][07522] Avg episode reward: [(0, '-15.295')]
[36m[2025-07-03 18:07:34,612][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 145.9. Samples: 643696. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:34,613][07522] Avg episode reward: [(0, '-13.241')]
[36m[2025-07-03 18:07:39,601][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 146.6. Samples: 644592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:39,601][07522] Avg episode reward: [(0, '-12.261')]
[36m[2025-07-03 18:07:44,549][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 147.4. Samples: 645040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:44,550][07522] Avg episode reward: [(0, '-12.864')]
[36m[2025-07-03 18:07:49,562][07522] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 148.3. Samples: 645936. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:49,563][07522] Avg episode reward: [(0, '-14.380')]
[36m[2025-07-03 18:07:54,586][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 147.4. Samples: 646800. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:54,586][07522] Avg episode reward: [(0, '-15.882')]
[36m[2025-07-03 18:07:59,566][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 147.8. Samples: 647264. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:07:59,567][07522] Avg episode reward: [(0, '-13.572')]
[GIF] Episode 2100 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0021_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0021_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0021_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0021_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0021_merged_dual_camera.gif
[36m[2025-07-03 18:08:04,550][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 147.5. Samples: 648160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:04,551][07522] Avg episode reward: [(0, '-11.634')]
[36m[2025-07-03 18:08:09,591][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 147.1. Samples: 649024. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:09,592][07522] Avg episode reward: [(0, '-12.747')]
[36m[2025-07-03 18:08:14,621][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 147.2. Samples: 649472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:14,622][07522] Avg episode reward: [(0, '-9.869')]
[36m[2025-07-03 18:08:19,652][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 147.4. Samples: 650336. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:19,652][07522] Avg episode reward: [(0, '-8.215')]
[36m[2025-07-03 18:08:24,546][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 638976. Throughput: 0: 146.7. Samples: 651184. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:24,547][07522] Avg episode reward: [(0, '-7.412')]
[36m[2025-07-03 18:08:29,604][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 146.7. Samples: 651648. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:29,604][07522] Avg episode reward: [(0, '-8.498')]
[33m[2956795 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[2956795 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:08:34,612][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 146.0. Samples: 652512. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:34,612][07522] Avg episode reward: [(0, '-8.852')]
[36m[2025-07-03 18:08:39,639][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 146.7. Samples: 653408. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:39,640][07522] Avg episode reward: [(0, '-10.986')]
[36m[2025-07-03 18:08:44,606][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 146.4. Samples: 653856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:44,606][07522] Avg episode reward: [(0, '-11.645')]
[36m[2025-07-03 18:08:49,569][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 638976. Throughput: 0: 146.4. Samples: 654752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:49,569][07522] Avg episode reward: [(0, '-11.616')]
[36m[2025-07-03 18:08:54,559][07522] Fps is (10 sec: 1646.1, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 146.6. Samples: 655616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:54,560][07522] Avg episode reward: [(0, '-11.468')]
[36m[2025-07-03 18:08:59,571][07522] Fps is (10 sec: 1638.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 146.7. Samples: 656064. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:08:59,572][07522] Avg episode reward: [(0, '-10.172')]
[36m[2025-07-03 18:09:04,628][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 147.6. Samples: 656976. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:04,629][07522] Avg episode reward: [(0, '-9.893')]
[36m[2025-07-03 18:09:09,599][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 148.4. Samples: 657872. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:09,599][07522] Avg episode reward: [(0, '-8.578')]
[36m[2025-07-03 18:09:14,570][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 148.0. Samples: 658304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:14,571][07522] Avg episode reward: [(0, '-7.243')]
[36m[2025-07-03 18:09:19,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 149.2. Samples: 659216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:19,546][07522] Avg episode reward: [(0, '-6.979')]
[37m[1m[2025-07-03 18:09:19,651][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001280_655360.pth...
[36m[2025-07-03 18:09:19,657][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001056_540672.pth
[36m[2025-07-03 18:09:24,584][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 148.8. Samples: 660096. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:24,584][07522] Avg episode reward: [(0, '-7.230')]
[36m[2025-07-03 18:09:29,619][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 148.2. Samples: 660528. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:29,619][07522] Avg episode reward: [(0, '-7.234')]
[36m[2025-07-03 18:09:34,625][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 147.4. Samples: 661392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:34,625][07522] Avg episode reward: [(0, '-8.247')]
[36m[2025-07-03 18:09:39,614][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 148.1. Samples: 662288. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:39,615][07522] Avg episode reward: [(0, '-7.727')]
[36m[2025-07-03 18:09:44,619][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 148.5. Samples: 662752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:44,619][07522] Avg episode reward: [(0, '-8.852')]
[36m[2025-07-03 18:09:49,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 149.9. Samples: 663712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:49,560][07522] Avg episode reward: [(0, '-9.710')]
[36m[2025-07-03 18:09:54,567][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 149.4. Samples: 664592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:54,568][07522] Avg episode reward: [(0, '-10.347')]
[36m[2025-07-03 18:09:59,589][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 150.3. Samples: 665072. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:09:59,589][07522] Avg episode reward: [(0, '-10.578')]
[36m[2025-07-03 18:10:04,564][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 150.3. Samples: 665984. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:10:04,565][07522] Avg episode reward: [(0, '-12.177')]
[36m[2025-07-03 18:10:09,598][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 150.0. Samples: 666848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:10:09,599][07522] Avg episode reward: [(0, '-13.616')]
[36m[2025-07-03 18:10:14,603][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 150.8. Samples: 667312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:10:14,603][07522] Avg episode reward: [(0, '-12.378')]
[36m[2025-07-03 18:10:19,561][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 655360. Throughput: 0: 152.8. Samples: 668256. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:10:19,561][07522] Avg episode reward: [(0, '-10.709')]
[36m[2025-07-03 18:10:24,580][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 111.1). Total num frames: 655360. Throughput: 0: 152.3. Samples: 669136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:10:24,580][07522] Avg episode reward: [(0, '-10.141')]
[36m[2025-07-03 18:10:29,554][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 111.1). Total num frames: 655360. Throughput: 0: 151.7. Samples: 669568. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:10:29,554][07522] Avg episode reward: [(0, '-9.017')]
[36m[2025-07-03 18:10:34,660][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 111.1). Total num frames: 655360. Throughput: 0: 149.7. Samples: 670464. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:10:34,660][07522] Avg episode reward: [(0, '-8.914')]
[36m[2025-07-03 18:10:39,605][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 111.1). Total num frames: 655360. Throughput: 0: 150.3. Samples: 671360. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:10:39,605][07522] Avg episode reward: [(0, '-9.112')]
[36m[2025-07-03 18:10:44,654][07522] Fps is (10 sec: 1639.4, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 148.8. Samples: 671776. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:10:44,654][07522] Avg episode reward: [(0, '-9.516')]
[36m[2025-07-03 18:10:49,607][07522] Fps is (10 sec: 1638.1, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 147.1. Samples: 672608. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:10:49,608][07522] Avg episode reward: [(0, '-10.094')]
[36m[2025-07-03 18:10:54,612][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 147.9. Samples: 673504. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:10:54,612][07522] Avg episode reward: [(0, '-9.001')]
[36m[2025-07-03 18:10:59,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 147.8. Samples: 673952. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:10:59,543][07522] Avg episode reward: [(0, '-6.362')]
[36m[2025-07-03 18:11:04,585][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 152.8. Samples: 675136. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:04,586][07522] Avg episode reward: [(0, '-5.317')]
[37m[1m[2025-07-03 18:11:04,661][07522] Saving new best policy, reward=-5.317!
[36m[2025-07-03 18:11:09,542][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 164.0. Samples: 676512. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:09,542][07522] Avg episode reward: [(0, '-6.780')]
[36m[2025-07-03 18:11:14,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 167.2. Samples: 677088. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:14,543][07522] Avg episode reward: [(0, '-5.699')]
[36m[2025-07-03 18:11:19,592][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 172.3. Samples: 678208. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:19,592][07522] Avg episode reward: [(0, '-8.579')]
[37m[1m[2025-07-03 18:11:19,654][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001312_671744.pth...
[36m[2025-07-03 18:11:19,658][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001120_573440.pth
[36m[2025-07-03 18:11:24,553][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 183.3. Samples: 679600. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:24,554][07522] Avg episode reward: [(0, '-9.466')]
[36m[2025-07-03 18:11:29,607][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 189.0. Samples: 680272. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:29,607][07522] Avg episode reward: [(0, '-10.395')]
[36m[2025-07-03 18:11:34,593][07522] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 201.3. Samples: 681664. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:34,593][07522] Avg episode reward: [(0, '-9.480')]
[36m[2025-07-03 18:11:39,595][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 212.0. Samples: 683040. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:39,595][07522] Avg episode reward: [(0, '-7.124')]
[36m[2025-07-03 18:11:44,552][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 671744. Throughput: 0: 218.3. Samples: 683776. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:44,552][07522] Avg episode reward: [(0, '-10.175')]
[36m[2025-07-03 18:11:49,637][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 225.2. Samples: 685280. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:49,637][07522] Avg episode reward: [(0, '-12.148')]
[36m[2025-07-03 18:11:54,568][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 671744. Throughput: 0: 224.9. Samples: 686640. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:54,569][07522] Avg episode reward: [(0, '-14.328')]
[36m[2025-07-03 18:11:59,602][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 111.1). Total num frames: 671744. Throughput: 0: 227.3. Samples: 687328. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[36m[2025-07-03 18:11:59,602][07522] Avg episode reward: [(0, '-13.174')]
[36m[2025-07-03 18:12:04,563][07522] Fps is (10 sec: 1639.2, 60 sec: 273.2, 300 sec: 166.7). Total num frames: 688128. Throughput: 0: 233.7. Samples: 688720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:04,563][07522] Avg episode reward: [(0, '-12.602')]
[36m[2025-07-03 18:12:09,543][07522] Fps is (10 sec: 1648.1, 60 sec: 273.1, 300 sec: 166.7). Total num frames: 688128. Throughput: 0: 232.6. Samples: 690064. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:09,543][07522] Avg episode reward: [(0, '-12.170')]
[36m[2025-07-03 18:12:14,559][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.7). Total num frames: 688128. Throughput: 0: 233.5. Samples: 690768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:14,559][07522] Avg episode reward: [(0, '-9.434')]
[36m[2025-07-03 18:12:19,557][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 234.5. Samples: 692208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:19,557][07522] Avg episode reward: [(0, '-9.424')]
[33m[3186111 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[3186112 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:12:24,593][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 235.4. Samples: 693632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:24,593][07522] Avg episode reward: [(0, '-6.969')]
[36m[2025-07-03 18:12:29,585][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 234.9. Samples: 694352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:29,585][07522] Avg episode reward: [(0, '-7.301')]
[36m[2025-07-03 18:12:34,577][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 233.9. Samples: 695792. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:34,577][07522] Avg episode reward: [(0, '-9.734')]
[36m[2025-07-03 18:12:39,575][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 234.6. Samples: 697200. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:39,576][07522] Avg episode reward: [(0, '-7.660')]
[36m[2025-07-03 18:12:44,577][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 234.4. Samples: 697872. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:44,577][07522] Avg episode reward: [(0, '-9.399')]
[36m[2025-07-03 18:12:49,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 234.0. Samples: 699248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:49,552][07522] Avg episode reward: [(0, '-8.449')]
[36m[2025-07-03 18:12:54,563][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 236.3. Samples: 700704. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:54,563][07522] Avg episode reward: [(0, '-9.427')]
[36m[2025-07-03 18:12:59,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 236.5. Samples: 701408. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:12:59,540][07522] Avg episode reward: [(0, '-8.646')]
[36m[2025-07-03 18:13:04,575][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 688128. Throughput: 0: 237.8. Samples: 702912. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:13:04,575][07522] Avg episode reward: [(0, '-8.981')]
[36m[2025-07-03 18:13:09,560][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.7). Total num frames: 688128. Throughput: 0: 237.3. Samples: 704304. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:13:09,560][07522] Avg episode reward: [(0, '-8.824')]
[36m[2025-07-03 18:13:14,543][07522] Fps is (10 sec: 1643.6, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 236.7. Samples: 704992. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:13:14,543][07522] Avg episode reward: [(0, '-6.257')]
[36m[2025-07-03 18:13:19,579][07522] Fps is (10 sec: 1635.3, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 704512. Throughput: 0: 236.8. Samples: 706448. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:13:19,579][07522] Avg episode reward: [(0, '-5.180')]
[37m[1m[2025-07-03 18:13:19,644][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001376_704512.pth...
[36m[2025-07-03 18:13:19,648][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001152_589824.pth
[37m[1m[2025-07-03 18:13:19,648][07522] Saving new best policy, reward=-5.180!
[36m[2025-07-03 18:13:24,578][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 237.5. Samples: 707888. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:13:24,578][07522] Avg episode reward: [(0, '-5.736')]
[36m[2025-07-03 18:13:29,576][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 238.2. Samples: 708592. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:13:29,576][07522] Avg episode reward: [(0, '-4.905')]
[37m[1m[2025-07-03 18:13:29,655][07522] Saving new best policy, reward=-4.905!
[36m[2025-07-03 18:13:34,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 237.4. Samples: 709936. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:13:34,569][07522] Avg episode reward: [(0, '-5.720')]
[GIF] Episode 2200 terminated - saving GIFs (every 100 episodes)
[36m[2025-07-03 18:13:39,593][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 235.2. Samples: 711296. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:13:39,594][07522] Avg episode reward: [(0, '-5.040')]
[GIF] Saved drone depth: ./gif_episodes/episode_0022_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0022_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0022_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0022_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0022_merged_dual_camera.gif
[36m[2025-07-03 18:13:44,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 704512. Throughput: 0: 233.9. Samples: 711936. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:13:44,555][07522] Avg episode reward: [(0, '-3.603')]
[37m[1m[2025-07-03 18:13:44,622][07522] Saving new best policy, reward=-3.603!
[36m[2025-07-03 18:13:49,589][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 704512. Throughput: 0: 232.8. Samples: 713392. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:13:49,589][07522] Avg episode reward: [(0, '-7.161')]
[36m[2025-07-03 18:13:54,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 166.6). Total num frames: 704512. Throughput: 0: 233.2. Samples: 714800. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:13:54,571][07522] Avg episode reward: [(0, '-5.735')]
[36m[2025-07-03 18:13:59,586][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 166.6). Total num frames: 704512. Throughput: 0: 231.2. Samples: 715408. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:13:59,586][07522] Avg episode reward: [(0, '-6.921')]
[36m[2025-07-03 18:14:04,558][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 704512. Throughput: 0: 229.8. Samples: 716784. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:14:04,558][07522] Avg episode reward: [(0, '-6.538')]
[36m[2025-07-03 18:14:09,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 166.6). Total num frames: 704512. Throughput: 0: 227.0. Samples: 718096. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:14:09,541][07522] Avg episode reward: [(0, '-4.550')]
[36m[2025-07-03 18:14:14,539][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 704512. Throughput: 0: 225.6. Samples: 718736. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:14:14,539][07522] Avg episode reward: [(0, '-4.331')]
[36m[2025-07-03 18:14:19,601][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 704512. Throughput: 0: 227.0. Samples: 720160. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:14:19,602][07522] Avg episode reward: [(0, '-3.979')]
[36m[2025-07-03 18:14:24,576][07522] Fps is (10 sec: 1632.3, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 226.2. Samples: 721472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:14:24,576][07522] Avg episode reward: [(0, '-2.034')]
[37m[1m[2025-07-03 18:14:24,647][07522] Saving new best policy, reward=-2.034!
[36m[2025-07-03 18:14:29,560][07522] Fps is (10 sec: 1645.2, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 225.8. Samples: 722096. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:14:29,560][07522] Avg episode reward: [(0, '-4.852')]
[36m[2025-07-03 18:14:34,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 222.4. Samples: 723392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:14:34,561][07522] Avg episode reward: [(0, '-3.816')]
[36m[2025-07-03 18:14:39,590][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 221.8. Samples: 724784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:14:39,591][07522] Avg episode reward: [(0, '-4.027')]
[36m[2025-07-03 18:14:44,548][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 222.8. Samples: 725424. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:14:44,548][07522] Avg episode reward: [(0, '-6.150')]
[36m[2025-07-03 18:14:49,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 221.6. Samples: 726752. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:14:49,541][07522] Avg episode reward: [(0, '-4.372')]
[36m[2025-07-03 18:14:54,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 220.8. Samples: 728032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:14:54,541][07522] Avg episode reward: [(0, '-6.297')]
[36m[2025-07-03 18:14:59,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 222.1. Samples: 728736. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:14:59,560][07522] Avg episode reward: [(0, '-5.524')]
[36m[2025-07-03 18:15:04,582][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 220.2. Samples: 730064. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:04,582][07522] Avg episode reward: [(0, '-5.711')]
[36m[2025-07-03 18:15:09,634][07522] Fps is (10 sec: 0.0, 60 sec: 272.6, 300 sec: 222.1). Total num frames: 720896. Throughput: 0: 218.4. Samples: 731312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:09,635][07522] Avg episode reward: [(0, '-6.510')]
[36m[2025-07-03 18:15:14,565][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 218.6. Samples: 731936. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:14,565][07522] Avg episode reward: [(0, '-5.061')]
[36m[2025-07-03 18:15:19,603][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 720896. Throughput: 0: 221.7. Samples: 733376. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:19,604][07522] Avg episode reward: [(0, '-6.301')]
[37m[1m[2025-07-03 18:15:19,693][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001408_720896.pth...
[36m[2025-07-03 18:15:19,698][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001184_606208.pth
[36m[2025-07-03 18:15:24,572][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 720896. Throughput: 0: 222.3. Samples: 734784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:24,572][07522] Avg episode reward: [(0, '-5.965')]
[33m[3371666 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[3371666 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:15:29,567][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 720896. Throughput: 0: 223.6. Samples: 735488. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:29,567][07522] Avg episode reward: [(0, '-7.039')]
[36m[2025-07-03 18:15:34,564][07522] Fps is (10 sec: 1639.7, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 737280. Throughput: 0: 226.0. Samples: 736928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:34,564][07522] Avg episode reward: [(0, '-6.923')]
[36m[2025-07-03 18:15:39,601][07522] Fps is (10 sec: 1632.9, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 228.3. Samples: 738320. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:39,601][07522] Avg episode reward: [(0, '-4.585')]
[36m[2025-07-03 18:15:44,556][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 226.9. Samples: 738944. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:44,556][07522] Avg episode reward: [(0, '-3.357')]
[36m[2025-07-03 18:15:49,553][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 228.4. Samples: 740336. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:49,553][07522] Avg episode reward: [(0, '0.052')]
[37m[1m[2025-07-03 18:15:49,624][07522] Saving new best policy, reward=0.052!
[36m[2025-07-03 18:15:54,546][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 233.0. Samples: 741776. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:54,546][07522] Avg episode reward: [(0, '-1.512')]
[36m[2025-07-03 18:15:59,590][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 234.5. Samples: 742496. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:15:59,590][07522] Avg episode reward: [(0, '-3.456')]
[36m[2025-07-03 18:16:04,563][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 737280. Throughput: 0: 234.9. Samples: 743936. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:04,563][07522] Avg episode reward: [(0, '-3.220')]
[36m[2025-07-03 18:16:09,545][07522] Fps is (10 sec: 0.0, 60 sec: 273.5, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 234.5. Samples: 745328. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:09,545][07522] Avg episode reward: [(0, '-5.777')]
[36m[2025-07-03 18:16:14,547][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 233.7. Samples: 746000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:14,547][07522] Avg episode reward: [(0, '-5.729')]
[36m[2025-07-03 18:16:19,548][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 233.0. Samples: 747408. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:19,548][07522] Avg episode reward: [(0, '-5.882')]
[36m[2025-07-03 18:16:24,582][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 230.1. Samples: 748672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:24,582][07522] Avg episode reward: [(0, '-3.842')]
[36m[2025-07-03 18:16:29,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 230.5. Samples: 749312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:29,545][07522] Avg episode reward: [(0, '-4.070')]
[36m[2025-07-03 18:16:34,549][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 229.0. Samples: 750640. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:34,549][07522] Avg episode reward: [(0, '-0.737')]
[36m[2025-07-03 18:16:39,601][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 737280. Throughput: 0: 227.6. Samples: 752032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:39,602][07522] Avg episode reward: [(0, '-0.440')]
[36m[2025-07-03 18:16:44,558][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 737280. Throughput: 0: 226.3. Samples: 752672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:44,558][07522] Avg episode reward: [(0, '-2.145')]
[36m[2025-07-03 18:16:49,580][07522] Fps is (10 sec: 1642.0, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 753664. Throughput: 0: 223.6. Samples: 754000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:49,580][07522] Avg episode reward: [(0, '-4.950')]
[36m[2025-07-03 18:16:54,549][07522] Fps is (10 sec: 1639.9, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 753664. Throughput: 0: 223.6. Samples: 755392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:54,549][07522] Avg episode reward: [(0, '-3.847')]
[36m[2025-07-03 18:16:59,601][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 224.8. Samples: 756128. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:16:59,601][07522] Avg episode reward: [(0, '-4.590')]
[36m[2025-07-03 18:17:04,554][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 223.6. Samples: 757472. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:04,554][07522] Avg episode reward: [(0, '-5.846')]
[36m[2025-07-03 18:17:09,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 228.0. Samples: 758928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:09,562][07522] Avg episode reward: [(0, '-4.933')]
[36m[2025-07-03 18:17:14,553][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 228.6. Samples: 759600. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:14,553][07522] Avg episode reward: [(0, '-8.954')]
[36m[2025-07-03 18:17:19,585][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 228.4. Samples: 760928. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:19,585][07522] Avg episode reward: [(0, '-8.541')]
[37m[1m[2025-07-03 18:17:19,687][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001472_753664.pth...
[36m[2025-07-03 18:17:19,695][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001248_638976.pth
[36m[2025-07-03 18:17:24,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 226.4. Samples: 762208. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:24,541][07522] Avg episode reward: [(0, '-7.209')]
[36m[2025-07-03 18:17:29,582][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 753664. Throughput: 0: 227.4. Samples: 762912. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:29,582][07522] Avg episode reward: [(0, '-7.113')]
[36m[2025-07-03 18:17:34,591][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 227.5. Samples: 764240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:34,592][07522] Avg episode reward: [(0, '-4.189')]
[36m[2025-07-03 18:17:39,585][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 224.9. Samples: 765520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:39,585][07522] Avg episode reward: [(0, '-2.047')]
[36m[2025-07-03 18:17:44,587][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 223.4. Samples: 766176. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:44,587][07522] Avg episode reward: [(0, '-4.173')]
[36m[2025-07-03 18:17:49,596][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 223.8. Samples: 767552. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:49,596][07522] Avg episode reward: [(0, '-3.299')]
[36m[2025-07-03 18:17:54,589][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 753664. Throughput: 0: 223.2. Samples: 768976. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:17:54,589][07522] Avg episode reward: [(0, '-2.235')]
[36m[2025-07-03 18:17:59,551][07522] Fps is (10 sec: 1645.8, 60 sec: 273.3, 300 sec: 277.7). Total num frames: 770048. Throughput: 0: 222.9. Samples: 769632. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:17:59,551][07522] Avg episode reward: [(0, '-1.140')]
[36m[2025-07-03 18:18:04,547][07522] Fps is (10 sec: 1645.4, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 770048. Throughput: 0: 222.4. Samples: 770928. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:04,547][07522] Avg episode reward: [(0, '-1.739')]
[36m[2025-07-03 18:18:09,562][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 221.1. Samples: 772160. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:09,563][07522] Avg episode reward: [(0, '-1.026')]
[36m[2025-07-03 18:18:14,550][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 216.7. Samples: 772656. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:14,550][07522] Avg episode reward: [(0, '-1.307')]
[36m[2025-07-03 18:18:19,602][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 207.2. Samples: 773568. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:19,603][07522] Avg episode reward: [(0, '-2.092')]
[36m[2025-07-03 18:18:24,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 198.2. Samples: 774432. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:24,544][07522] Avg episode reward: [(0, '-0.215')]
[36m[2025-07-03 18:18:29,562][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 193.9. Samples: 774896. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:29,563][07522] Avg episode reward: [(0, '-0.555')]
[36m[2025-07-03 18:18:34,638][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 182.2. Samples: 775760. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:34,639][07522] Avg episode reward: [(0, '0.812')]
[37m[1m[2025-07-03 18:18:34,772][07522] Saving new best policy, reward=0.812!
[36m[2025-07-03 18:18:39,559][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 170.4. Samples: 776640. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:39,559][07522] Avg episode reward: [(0, '1.131')]
[37m[1m[2025-07-03 18:18:39,656][07522] Saving new best policy, reward=1.131!
[36m[2025-07-03 18:18:44,557][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 169.9. Samples: 777280. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:44,557][07522] Avg episode reward: [(0, '1.752')]
[37m[1m[2025-07-03 18:18:44,664][07522] Saving new best policy, reward=1.752!
[33m[3573256 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[3573257 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:18:49,586][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 169.1. Samples: 778544. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:49,587][07522] Avg episode reward: [(0, '1.513')]
[GIF] Episode 2300 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0023_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0023_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0023_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0023_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0023_merged_dual_camera.gif
[36m[2025-07-03 18:18:54,596][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 168.1. Samples: 779728. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:54,596][07522] Avg episode reward: [(0, '0.404')]
[36m[2025-07-03 18:18:59,541][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 171.8. Samples: 780384. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:18:59,541][07522] Avg episode reward: [(0, '-0.684')]
[36m[2025-07-03 18:19:04,573][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 183.9. Samples: 781840. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:19:04,573][07522] Avg episode reward: [(0, '-0.972')]
[36m[2025-07-03 18:19:09,601][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 770048. Throughput: 0: 194.2. Samples: 783184. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:19:09,601][07522] Avg episode reward: [(0, '-3.287')]
[36m[2025-07-03 18:19:14,576][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 770048. Throughput: 0: 199.8. Samples: 783888. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:19:14,576][07522] Avg episode reward: [(0, '-0.701')]
[36m[2025-07-03 18:19:19,551][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 770048. Throughput: 0: 213.4. Samples: 785344. Policy #0 lag: (min: 0.0, avg: 0.2, max: 32.0)
[36m[2025-07-03 18:19:19,551][07522] Avg episode reward: [(0, '-3.978')]
[37m[1m[2025-07-03 18:19:19,613][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001504_770048.pth...
[36m[2025-07-03 18:19:19,617][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001280_655360.pth
[36m[2025-07-03 18:19:24,594][07522] Fps is (10 sec: 1635.4, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 786432. Throughput: 0: 222.4. Samples: 786656. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:19:24,595][07522] Avg episode reward: [(0, '-4.171')]
[36m[2025-07-03 18:19:29,554][07522] Fps is (10 sec: 1638.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 224.4. Samples: 787376. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:19:29,554][07522] Avg episode reward: [(0, '-3.326')]
[36m[2025-07-03 18:19:34,582][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 228.3. Samples: 788816. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:19:34,583][07522] Avg episode reward: [(0, '-3.219')]
[36m[2025-07-03 18:19:39,576][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 786432. Throughput: 0: 232.6. Samples: 790192. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:19:39,577][07522] Avg episode reward: [(0, '-2.751')]
[36m[2025-07-03 18:19:44,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 235.4. Samples: 790976. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:19:44,541][07522] Avg episode reward: [(0, '-0.966')]
[36m[2025-07-03 18:19:49,548][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 235.5. Samples: 792432. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:19:49,548][07522] Avg episode reward: [(0, '-2.302')]
[36m[2025-07-03 18:19:54,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 786432. Throughput: 0: 236.9. Samples: 793840. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:19:54,573][07522] Avg episode reward: [(0, '-5.168')]
[36m[2025-07-03 18:19:59,569][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 238.3. Samples: 794608. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:19:59,569][07522] Avg episode reward: [(0, '-1.815')]
[36m[2025-07-03 18:20:04,602][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 238.7. Samples: 796096. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:20:04,602][07522] Avg episode reward: [(0, '-0.221')]
[36m[2025-07-03 18:20:09,623][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 786432. Throughput: 0: 242.7. Samples: 797584. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:20:09,623][07522] Avg episode reward: [(0, '0.731')]
[36m[2025-07-03 18:20:14,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 241.8. Samples: 798256. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:20:14,543][07522] Avg episode reward: [(0, '2.184')]
[37m[1m[2025-07-03 18:20:14,627][07522] Saving new best policy, reward=2.184!
[36m[2025-07-03 18:20:19,570][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 240.1. Samples: 799616. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:20:19,570][07522] Avg episode reward: [(0, '2.685')]
[37m[1m[2025-07-03 18:20:19,650][07522] Saving new best policy, reward=2.685!
[36m[2025-07-03 18:20:24,541][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 786432. Throughput: 0: 240.9. Samples: 801024. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:20:24,541][07522] Avg episode reward: [(0, '1.048')]
[36m[2025-07-03 18:20:29,574][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 786432. Throughput: 0: 239.1. Samples: 801744. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[36m[2025-07-03 18:20:29,574][07522] Avg episode reward: [(0, '0.014')]
[36m[2025-07-03 18:20:34,592][07522] Fps is (10 sec: 1630.1, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 802816. Throughput: 0: 239.4. Samples: 803216. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:20:34,592][07522] Avg episode reward: [(0, '0.356')]
[36m[2025-07-03 18:20:39,600][07522] Fps is (10 sec: 1634.1, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 240.9. Samples: 804688. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:20:39,600][07522] Avg episode reward: [(0, '-0.817')]
[36m[2025-07-03 18:20:44,574][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 239.3. Samples: 805376. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:20:44,574][07522] Avg episode reward: [(0, '-1.579')]
[36m[2025-07-03 18:20:49,587][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 238.7. Samples: 806832. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:20:49,587][07522] Avg episode reward: [(0, '-1.196')]
[36m[2025-07-03 18:20:54,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 802816. Throughput: 0: 234.3. Samples: 808112. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:20:54,560][07522] Avg episode reward: [(0, '-3.066')]
[36m[2025-07-03 18:20:59,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 232.4. Samples: 808720. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:20:59,573][07522] Avg episode reward: [(0, '-3.585')]
[36m[2025-07-03 18:21:04,579][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 232.8. Samples: 810096. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:21:04,580][07522] Avg episode reward: [(0, '-3.542')]
[36m[2025-07-03 18:21:09,587][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 231.9. Samples: 811472. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:21:09,587][07522] Avg episode reward: [(0, '-3.618')]
[36m[2025-07-03 18:21:14,595][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 232.1. Samples: 812192. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:21:14,595][07522] Avg episode reward: [(0, '-2.489')]
[36m[2025-07-03 18:21:19,554][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 802816. Throughput: 0: 229.2. Samples: 813520. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:21:19,554][07522] Avg episode reward: [(0, '-2.193')]
[37m[1m[2025-07-03 18:21:19,636][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001568_802816.pth...
[36m[2025-07-03 18:21:19,640][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001312_671744.pth
[36m[2025-07-03 18:21:24,593][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 226.5. Samples: 814880. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:21:24,593][07522] Avg episode reward: [(0, '-0.934')]
[36m[2025-07-03 18:21:29,580][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 226.5. Samples: 815568. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:21:29,580][07522] Avg episode reward: [(0, '-1.893')]
[36m[2025-07-03 18:21:34,572][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 802816. Throughput: 0: 224.1. Samples: 816912. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:21:34,573][07522] Avg episode reward: [(0, '-1.025')]
[36m[2025-07-03 18:21:39,571][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 802816. Throughput: 0: 225.7. Samples: 818272. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[36m[2025-07-03 18:21:39,571][07522] Avg episode reward: [(0, '-1.184')]
[36m[2025-07-03 18:21:44,547][07522] Fps is (10 sec: 1642.6, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 819200. Throughput: 0: 227.3. Samples: 818944. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:21:44,547][07522] Avg episode reward: [(0, '-2.350')]
[36m[2025-07-03 18:21:49,604][07522] Fps is (10 sec: 1633.1, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 819200. Throughput: 0: 226.4. Samples: 820288. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:21:49,604][07522] Avg episode reward: [(0, '0.200')]
[36m[2025-07-03 18:21:54,563][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 819200. Throughput: 0: 227.0. Samples: 821680. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:21:54,563][07522] Avg episode reward: [(0, '0.916')]
[33m[3762233 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[3762233 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:21:59,549][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 819200. Throughput: 0: 227.1. Samples: 822400. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:21:59,549][07522] Avg episode reward: [(0, '3.003')]
[37m[1m[2025-07-03 18:21:59,620][07522] Saving new best policy, reward=3.003!
[36m[2025-07-03 18:22:04,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 819200. Throughput: 0: 228.5. Samples: 823808. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:22:04,574][07522] Avg episode reward: [(0, '3.466')]
[37m[1m[2025-07-03 18:22:04,633][07522] Saving new best policy, reward=3.466!
[36m[2025-07-03 18:22:09,566][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 819200. Throughput: 0: 229.5. Samples: 825200. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:22:09,566][07522] Avg episode reward: [(0, '3.565')]
[37m[1m[2025-07-03 18:22:09,634][07522] Saving new best policy, reward=3.565!
[36m[2025-07-03 18:22:14,548][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 819200. Throughput: 0: 230.6. Samples: 825936. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:22:14,548][07522] Avg episode reward: [(0, '1.239')]
[36m[2025-07-03 18:22:19,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 819200. Throughput: 0: 233.3. Samples: 827408. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:22:19,569][07522] Avg episode reward: [(0, '-0.416')]
[36m[2025-07-03 18:22:24,542][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 819200. Throughput: 0: 232.0. Samples: 828704. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:22:24,542][07522] Avg episode reward: [(0, '-2.719')]
[36m[2025-07-03 18:22:29,545][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 819200. Throughput: 0: 231.1. Samples: 829344. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:22:29,546][07522] Avg episode reward: [(0, '0.048')]
[36m[2025-07-03 18:22:34,581][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 819200. Throughput: 0: 230.9. Samples: 830672. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:22:34,581][07522] Avg episode reward: [(0, '3.947')]
[37m[1m[2025-07-03 18:22:34,658][07522] Saving new best policy, reward=3.947!
[36m[2025-07-03 18:22:39,580][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 819200. Throughput: 0: 230.3. Samples: 832048. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:22:39,580][07522] Avg episode reward: [(0, '3.501')]
[36m[2025-07-03 18:22:44,548][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 819200. Throughput: 0: 229.3. Samples: 832720. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:22:44,548][07522] Avg episode reward: [(0, '3.486')]
[36m[2025-07-03 18:22:49,557][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 819200. Throughput: 0: 226.9. Samples: 834016. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[36m[2025-07-03 18:22:49,557][07522] Avg episode reward: [(0, '2.009')]
[36m[2025-07-03 18:22:54,621][07522] Fps is (10 sec: 1626.5, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 835584. Throughput: 0: 226.9. Samples: 835424. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:22:54,621][07522] Avg episode reward: [(0, '0.428')]
[36m[2025-07-03 18:22:59,538][07522] Fps is (10 sec: 1641.5, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 835584. Throughput: 0: 226.2. Samples: 836112. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:22:59,538][07522] Avg episode reward: [(0, '0.179')]
[36m[2025-07-03 18:23:04,591][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 835584. Throughput: 0: 226.0. Samples: 837584. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:04,592][07522] Avg episode reward: [(0, '-2.297')]
[36m[2025-07-03 18:23:09,618][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 835584. Throughput: 0: 228.6. Samples: 839008. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:09,618][07522] Avg episode reward: [(0, '-0.186')]
[36m[2025-07-03 18:23:14,568][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 835584. Throughput: 0: 229.6. Samples: 839680. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:14,568][07522] Avg episode reward: [(0, '-0.279')]
[36m[2025-07-03 18:23:19,609][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 835584. Throughput: 0: 230.3. Samples: 841040. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:19,609][07522] Avg episode reward: [(0, '1.683')]
[37m[1m[2025-07-03 18:23:19,690][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001632_835584.pth...
[36m[2025-07-03 18:23:19,697][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001376_704512.pth
[36m[2025-07-03 18:23:24,574][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 835584. Throughput: 0: 232.2. Samples: 842496. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:24,574][07522] Avg episode reward: [(0, '3.762')]
[36m[2025-07-03 18:23:29,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 835584. Throughput: 0: 233.3. Samples: 843216. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:29,541][07522] Avg episode reward: [(0, '1.405')]
[36m[2025-07-03 18:23:34,579][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 835584. Throughput: 0: 236.3. Samples: 844656. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:34,579][07522] Avg episode reward: [(0, '2.253')]
[36m[2025-07-03 18:23:39,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 835584. Throughput: 0: 237.2. Samples: 846080. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:39,552][07522] Avg episode reward: [(0, '4.526')]
[37m[1m[2025-07-03 18:23:39,626][07522] Saving new best policy, reward=4.526!
[36m[2025-07-03 18:23:44,580][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 835584. Throughput: 0: 236.6. Samples: 846768. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:44,580][07522] Avg episode reward: [(0, '3.709')]
[GIF] Episode 2400 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0024_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0024_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0024_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0024_static_seg.gif
[36m[2025-07-03 18:23:49,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 835584. Throughput: 0: 235.9. Samples: 848192. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:49,561][07522] Avg episode reward: [(0, '4.161')]
[GIF] Saved merged dual camera: ./gif_episodes/episode_0024_merged_dual_camera.gif
[36m[2025-07-03 18:23:54,548][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 835584. Throughput: 0: 232.9. Samples: 849472. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:54,548][07522] Avg episode reward: [(0, '2.694')]
[36m[2025-07-03 18:23:59,574][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 835584. Throughput: 0: 234.6. Samples: 850240. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[36m[2025-07-03 18:23:59,574][07522] Avg episode reward: [(0, '2.074')]
[36m[2025-07-03 18:24:04,619][07522] Fps is (10 sec: 1626.8, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 851968. Throughput: 0: 236.7. Samples: 851696. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:04,619][07522] Avg episode reward: [(0, '2.175')]
[36m[2025-07-03 18:24:09,610][07522] Fps is (10 sec: 1632.5, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 851968. Throughput: 0: 234.5. Samples: 853056. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:09,611][07522] Avg episode reward: [(0, '2.324')]
[36m[2025-07-03 18:24:14,587][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 851968. Throughput: 0: 233.7. Samples: 853744. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:14,587][07522] Avg episode reward: [(0, '4.567')]
[37m[1m[2025-07-03 18:24:14,649][07522] Saving new best policy, reward=4.567!
[36m[2025-07-03 18:24:19,626][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 851968. Throughput: 0: 234.1. Samples: 855200. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:19,627][07522] Avg episode reward: [(0, '4.282')]
[36m[2025-07-03 18:24:24,589][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 851968. Throughput: 0: 234.8. Samples: 856656. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:24,589][07522] Avg episode reward: [(0, '3.515')]
[36m[2025-07-03 18:24:29,585][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 851968. Throughput: 0: 236.1. Samples: 857392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:29,585][07522] Avg episode reward: [(0, '1.465')]
[36m[2025-07-03 18:24:34,596][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 851968. Throughput: 0: 237.3. Samples: 858880. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:34,596][07522] Avg episode reward: [(0, '-0.369')]
[36m[2025-07-03 18:24:39,592][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 851968. Throughput: 0: 241.5. Samples: 860352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:39,592][07522] Avg episode reward: [(0, '0.190')]
[36m[2025-07-03 18:24:44,565][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 851968. Throughput: 0: 240.8. Samples: 861072. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:44,565][07522] Avg episode reward: [(0, '0.747')]
[36m[2025-07-03 18:24:49,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 851968. Throughput: 0: 242.8. Samples: 862608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:49,560][07522] Avg episode reward: [(0, '0.275')]
[36m[2025-07-03 18:24:54,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 851968. Throughput: 0: 244.9. Samples: 864064. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:54,561][07522] Avg episode reward: [(0, '4.137')]
[36m[2025-07-03 18:24:59,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 851968. Throughput: 0: 245.1. Samples: 864768. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:24:59,562][07522] Avg episode reward: [(0, '5.400')]
[37m[1m[2025-07-03 18:24:59,637][07522] Saving new best policy, reward=5.400!
[36m[2025-07-03 18:25:04,597][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 851968. Throughput: 0: 243.7. Samples: 866160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:25:04,597][07522] Avg episode reward: [(0, '10.666')]
[37m[1m[2025-07-03 18:25:04,658][07522] Saving new best policy, reward=10.349!
[36m[2025-07-03 18:25:09,555][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 851968. Throughput: 0: 243.7. Samples: 867616. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:25:09,555][07522] Avg episode reward: [(0, '7.984')]
[33m[3955302 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[3955302 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:25:14,560][07522] Fps is (10 sec: 1644.6, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 868352. Throughput: 0: 243.7. Samples: 868352. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:25:14,560][07522] Avg episode reward: [(0, '7.145')]
[36m[2025-07-03 18:25:19,582][07522] Fps is (10 sec: 1634.0, 60 sec: 273.3, 300 sec: 277.7). Total num frames: 868352. Throughput: 0: 241.1. Samples: 869728. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:25:19,582][07522] Avg episode reward: [(0, '2.199')]
[37m[1m[2025-07-03 18:25:19,675][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001696_868352.pth...
[36m[2025-07-03 18:25:19,679][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001408_720896.pth
[36m[2025-07-03 18:25:24,549][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 277.7). Total num frames: 868352. Throughput: 0: 240.2. Samples: 871152. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:25:24,549][07522] Avg episode reward: [(0, '1.828')]
[36m[2025-07-03 18:25:29,599][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 868352. Throughput: 0: 240.2. Samples: 871888. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:25:29,600][07522] Avg episode reward: [(0, '2.331')]
[36m[2025-07-03 18:25:34,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 868352. Throughput: 0: 237.5. Samples: 873296. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:25:34,553][07522] Avg episode reward: [(0, '3.087')]
[36m[2025-07-03 18:25:39,570][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 868352. Throughput: 0: 237.5. Samples: 874752. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:25:39,570][07522] Avg episode reward: [(0, '3.962')]
[36m[2025-07-03 18:25:44,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 868352. Throughput: 0: 238.2. Samples: 875488. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:25:44,569][07522] Avg episode reward: [(0, '4.393')]
[36m[2025-07-03 18:25:49,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 868352. Throughput: 0: 239.5. Samples: 876928. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:25:49,561][07522] Avg episode reward: [(0, '3.089')]
[36m[2025-07-03 18:25:54,549][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 868352. Throughput: 0: 238.3. Samples: 878336. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:25:54,550][07522] Avg episode reward: [(0, '1.820')]
[36m[2025-07-03 18:25:59,591][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 868352. Throughput: 0: 237.3. Samples: 879040. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:25:59,591][07522] Avg episode reward: [(0, '0.506')]
[36m[2025-07-03 18:26:04,542][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 868352. Throughput: 0: 239.9. Samples: 880512. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:26:04,542][07522] Avg episode reward: [(0, '0.836')]
[36m[2025-07-03 18:26:09,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 868352. Throughput: 0: 239.5. Samples: 881936. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:26:09,571][07522] Avg episode reward: [(0, '-0.315')]
[36m[2025-07-03 18:26:14,559][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 868352. Throughput: 0: 239.5. Samples: 882656. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:26:14,559][07522] Avg episode reward: [(0, '2.112')]
[36m[2025-07-03 18:26:19,565][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 868352. Throughput: 0: 240.3. Samples: 884112. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:26:19,565][07522] Avg episode reward: [(0, '3.261')]
[36m[2025-07-03 18:26:24,575][07522] Fps is (10 sec: 1635.8, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 884736. Throughput: 0: 237.8. Samples: 885456. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:26:24,575][07522] Avg episode reward: [(0, '3.132')]
[36m[2025-07-03 18:26:29,591][07522] Fps is (10 sec: 1634.2, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 884736. Throughput: 0: 237.0. Samples: 886160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:26:29,591][07522] Avg episode reward: [(0, '5.262')]
[36m[2025-07-03 18:26:34,559][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 884736. Throughput: 0: 235.4. Samples: 887520. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:26:34,559][07522] Avg episode reward: [(0, '7.037')]
[36m[2025-07-03 18:26:39,585][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 884736. Throughput: 0: 234.5. Samples: 888896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:26:39,585][07522] Avg episode reward: [(0, '8.397')]
[36m[2025-07-03 18:26:44,571][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 884736. Throughput: 0: 235.5. Samples: 889632. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:26:44,571][07522] Avg episode reward: [(0, '9.308')]
[36m[2025-07-03 18:26:49,605][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 884736. Throughput: 0: 234.7. Samples: 891088. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:26:49,605][07522] Avg episode reward: [(0, '7.527')]
[36m[2025-07-03 18:26:54,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 884736. Throughput: 0: 231.2. Samples: 892336. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:26:54,555][07522] Avg episode reward: [(0, '5.492')]
[36m[2025-07-03 18:26:59,615][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 884736. Throughput: 0: 230.5. Samples: 893040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:26:59,615][07522] Avg episode reward: [(0, '4.384')]
[36m[2025-07-03 18:27:04,598][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 884736. Throughput: 0: 228.5. Samples: 894400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:04,598][07522] Avg episode reward: [(0, '7.512')]
[36m[2025-07-03 18:27:09,600][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 884736. Throughput: 0: 227.8. Samples: 895712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:09,600][07522] Avg episode reward: [(0, '6.778')]
[36m[2025-07-03 18:27:14,566][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 884736. Throughput: 0: 226.6. Samples: 896352. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:14,567][07522] Avg episode reward: [(0, '9.217')]
[36m[2025-07-03 18:27:19,563][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 884736. Throughput: 0: 226.1. Samples: 897696. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:19,563][07522] Avg episode reward: [(0, '9.012')]
[37m[1m[2025-07-03 18:27:19,632][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001728_884736.pth...
[36m[2025-07-03 18:27:19,636][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001472_753664.pth
[36m[2025-07-03 18:27:24,608][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 884736. Throughput: 0: 224.9. Samples: 899024. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:24,608][07522] Avg episode reward: [(0, '10.082')]
[36m[2025-07-03 18:27:29,622][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 884736. Throughput: 0: 222.7. Samples: 899664. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:29,623][07522] Avg episode reward: [(0, '10.062')]
[36m[2025-07-03 18:27:34,547][07522] Fps is (10 sec: 1648.5, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 901120. Throughput: 0: 220.7. Samples: 901008. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:34,547][07522] Avg episode reward: [(0, '7.798')]
[36m[2025-07-03 18:27:39,555][07522] Fps is (10 sec: 1649.5, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 901120. Throughput: 0: 223.3. Samples: 902384. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:39,555][07522] Avg episode reward: [(0, '9.716')]
[36m[2025-07-03 18:27:44,550][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 901120. Throughput: 0: 224.7. Samples: 903136. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:44,550][07522] Avg episode reward: [(0, '10.506')]
[37m[1m[2025-07-03 18:27:44,612][07522] Saving new best policy, reward=10.506!
[36m[2025-07-03 18:27:49,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 901120. Throughput: 0: 226.6. Samples: 904592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:49,573][07522] Avg episode reward: [(0, '11.591')]
[37m[1m[2025-07-03 18:27:49,638][07522] Saving new best policy, reward=11.591!
[36m[2025-07-03 18:27:54,576][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 901120. Throughput: 0: 231.6. Samples: 906128. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:54,577][07522] Avg episode reward: [(0, '14.361')]
[37m[1m[2025-07-03 18:27:54,650][07522] Saving new best policy, reward=14.361!
[36m[2025-07-03 18:27:59,609][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 901120. Throughput: 0: 233.0. Samples: 906848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:27:59,609][07522] Avg episode reward: [(0, '12.350')]
[36m[2025-07-03 18:28:04,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 901120. Throughput: 0: 234.8. Samples: 908256. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:28:04,541][07522] Avg episode reward: [(0, '7.417')]
[36m[2025-07-03 18:28:09,601][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 901120. Throughput: 0: 236.8. Samples: 909680. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:28:09,601][07522] Avg episode reward: [(0, '7.120')]
[36m[2025-07-03 18:28:14,594][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 901120. Throughput: 0: 238.7. Samples: 910400. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:28:14,595][07522] Avg episode reward: [(0, '7.758')]
[36m[2025-07-03 18:28:19,580][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 901120. Throughput: 0: 240.5. Samples: 911840. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:28:19,580][07522] Avg episode reward: [(0, '7.501')]
[36m[2025-07-03 18:28:24,565][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 901120. Throughput: 0: 242.8. Samples: 913312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:28:24,565][07522] Avg episode reward: [(0, '10.306')]
[36m[2025-07-03 18:28:29,572][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 901120. Throughput: 0: 242.0. Samples: 914032. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:28:29,573][07522] Avg episode reward: [(0, '9.417')]
[33m[4156265 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[4156265 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:28:34,540][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 901120. Throughput: 0: 240.2. Samples: 915392. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:28:34,541][07522] Avg episode reward: [(0, '7.757')]
[36m[2025-07-03 18:28:39,571][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 901120. Throughput: 0: 238.3. Samples: 916848. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:28:39,571][07522] Avg episode reward: [(0, '8.475')]
[36m[2025-07-03 18:28:44,543][07522] Fps is (10 sec: 1637.9, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 917504. Throughput: 0: 238.9. Samples: 917584. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:28:44,543][07522] Avg episode reward: [(0, '9.927')]
[36m[2025-07-03 18:28:49,566][07522] Fps is (10 sec: 1639.2, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 917504. Throughput: 0: 239.9. Samples: 919056. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:28:49,566][07522] Avg episode reward: [(0, '13.565')]
[36m[2025-07-03 18:28:54,608][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 917504. Throughput: 0: 240.3. Samples: 920496. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:28:54,609][07522] Avg episode reward: [(0, '14.218')]
[36m[2025-07-03 18:28:59,580][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 917504. Throughput: 0: 240.1. Samples: 921200. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:28:59,581][07522] Avg episode reward: [(0, '13.508')]
[36m[2025-07-03 18:29:04,594][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 917504. Throughput: 0: 241.0. Samples: 922688. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:29:04,594][07522] Avg episode reward: [(0, '15.401')]
[37m[1m[2025-07-03 18:29:04,672][07522] Saving new best policy, reward=15.401!
[GIF] Episode 2500 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0025_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0025_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0025_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0025_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0025_merged_dual_camera.gif
[36m[2025-07-03 18:29:09,547][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 917504. Throughput: 0: 237.3. Samples: 923984. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:29:09,547][07522] Avg episode reward: [(0, '14.135')]
[36m[2025-07-03 18:29:14,586][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 917504. Throughput: 0: 237.4. Samples: 924720. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:29:14,586][07522] Avg episode reward: [(0, '14.642')]
[36m[2025-07-03 18:29:19,550][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 917504. Throughput: 0: 240.7. Samples: 926224. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:29:19,550][07522] Avg episode reward: [(0, '14.065')]
[37m[1m[2025-07-03 18:29:19,614][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001792_917504.pth...
[36m[2025-07-03 18:29:19,632][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001504_770048.pth
[36m[2025-07-03 18:29:24,575][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 917504. Throughput: 0: 239.3. Samples: 927616. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:29:24,575][07522] Avg episode reward: [(0, '9.040')]
[36m[2025-07-03 18:29:29,591][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 917504. Throughput: 0: 238.7. Samples: 928336. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:29:29,591][07522] Avg episode reward: [(0, '10.653')]
[36m[2025-07-03 18:29:34,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 917504. Throughput: 0: 238.7. Samples: 929792. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:29:34,552][07522] Avg episode reward: [(0, '10.224')]
[36m[2025-07-03 18:29:39,558][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 917504. Throughput: 0: 235.6. Samples: 931088. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:29:39,558][07522] Avg episode reward: [(0, '10.539')]
[36m[2025-07-03 18:29:44,564][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 917504. Throughput: 0: 234.8. Samples: 931760. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:29:44,564][07522] Avg episode reward: [(0, '13.073')]
[36m[2025-07-03 18:29:49,577][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 917504. Throughput: 0: 233.7. Samples: 933200. Policy #0 lag: (min: 29.0, avg: 29.0, max: 29.0)
[36m[2025-07-03 18:29:49,577][07522] Avg episode reward: [(0, '10.147')]
[36m[2025-07-03 18:29:54,585][07522] Fps is (10 sec: 1634.9, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 933888. Throughput: 0: 233.8. Samples: 934512. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:29:54,586][07522] Avg episode reward: [(0, '9.149')]
[36m[2025-07-03 18:29:59,591][07522] Fps is (10 sec: 1636.2, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 933888. Throughput: 0: 231.8. Samples: 935152. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:29:59,591][07522] Avg episode reward: [(0, '10.793')]
[36m[2025-07-03 18:30:04,583][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 933888. Throughput: 0: 225.6. Samples: 936384. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:04,583][07522] Avg episode reward: [(0, '7.843')]
[36m[2025-07-03 18:30:09,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 933888. Throughput: 0: 224.5. Samples: 937712. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:09,545][07522] Avg episode reward: [(0, '7.863')]
[36m[2025-07-03 18:30:14,558][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 933888. Throughput: 0: 224.5. Samples: 938432. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:14,558][07522] Avg episode reward: [(0, '11.244')]
[36m[2025-07-03 18:30:19,586][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 933888. Throughput: 0: 223.5. Samples: 939856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:19,586][07522] Avg episode reward: [(0, '10.725')]
[36m[2025-07-03 18:30:24,616][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 933888. Throughput: 0: 225.5. Samples: 941248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:24,616][07522] Avg episode reward: [(0, '13.733')]
[36m[2025-07-03 18:30:29,583][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 933888. Throughput: 0: 226.0. Samples: 941936. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:29,583][07522] Avg episode reward: [(0, '13.810')]
[36m[2025-07-03 18:30:34,562][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 933888. Throughput: 0: 223.7. Samples: 943264. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:34,562][07522] Avg episode reward: [(0, '13.509')]
[36m[2025-07-03 18:30:39,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 933888. Throughput: 0: 223.8. Samples: 944576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:39,551][07522] Avg episode reward: [(0, '8.781')]
[36m[2025-07-03 18:30:44,556][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 933888. Throughput: 0: 223.8. Samples: 945216. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:44,556][07522] Avg episode reward: [(0, '10.629')]
[36m[2025-07-03 18:30:49,545][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 933888. Throughput: 0: 227.7. Samples: 946624. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:49,545][07522] Avg episode reward: [(0, '9.937')]
[36m[2025-07-03 18:30:54,592][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 933888. Throughput: 0: 227.7. Samples: 947968. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:54,592][07522] Avg episode reward: [(0, '11.090')]
[36m[2025-07-03 18:30:59,567][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 933888. Throughput: 0: 228.2. Samples: 948704. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:30:59,567][07522] Avg episode reward: [(0, '12.353')]
[36m[2025-07-03 18:31:04,562][07522] Fps is (10 sec: 1643.4, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 950272. Throughput: 0: 226.6. Samples: 950048. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:04,562][07522] Avg episode reward: [(0, '13.081')]
[36m[2025-07-03 18:31:09,561][07522] Fps is (10 sec: 1639.4, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 950272. Throughput: 0: 224.3. Samples: 951328. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:09,561][07522] Avg episode reward: [(0, '13.329')]
[36m[2025-07-03 18:31:14,603][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 950272. Throughput: 0: 225.0. Samples: 952064. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:14,603][07522] Avg episode reward: [(0, '14.766')]
[36m[2025-07-03 18:31:19,594][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 950272. Throughput: 0: 226.0. Samples: 953440. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:19,594][07522] Avg episode reward: [(0, '17.082')]
[37m[1m[2025-07-03 18:31:19,710][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001856_950272.pth...
[36m[2025-07-03 18:31:19,718][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001568_802816.pth
[37m[1m[2025-07-03 18:31:19,719][07522] Saving new best policy, reward=17.082!
[36m[2025-07-03 18:31:24,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 950272. Throughput: 0: 226.9. Samples: 954784. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:24,541][07522] Avg episode reward: [(0, '16.418')]
[36m[2025-07-03 18:31:29,592][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 950272. Throughput: 0: 228.8. Samples: 955520. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:29,592][07522] Avg episode reward: [(0, '14.941')]
[36m[2025-07-03 18:31:34,572][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 950272. Throughput: 0: 225.3. Samples: 956768. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:34,573][07522] Avg episode reward: [(0, '16.255')]
[36m[2025-07-03 18:31:39,594][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 950272. Throughput: 0: 224.3. Samples: 958064. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:39,594][07522] Avg episode reward: [(0, '10.931')]
[36m[2025-07-03 18:31:44,605][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 950272. Throughput: 0: 221.0. Samples: 958656. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:44,606][07522] Avg episode reward: [(0, '9.877')]
[36m[2025-07-03 18:31:49,600][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 950272. Throughput: 0: 214.6. Samples: 959712. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:49,601][07522] Avg episode reward: [(0, '8.563')]
[36m[2025-07-03 18:31:54,542][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 950272. Throughput: 0: 210.9. Samples: 960816. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:54,542][07522] Avg episode reward: [(0, '10.616')]
[36m[2025-07-03 18:31:59,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 950272. Throughput: 0: 207.9. Samples: 961408. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:31:59,552][07522] Avg episode reward: [(0, '9.873')]
[36m[2025-07-03 18:32:04,550][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 950272. Throughput: 0: 208.9. Samples: 962832. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:32:04,550][07522] Avg episode reward: [(0, '11.047')]
[33m[4371336 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[4371336 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:32:09,551][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 950272. Throughput: 0: 205.8. Samples: 964048. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:32:09,551][07522] Avg episode reward: [(0, '13.157')]
[36m[2025-07-03 18:32:14,589][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 950272. Throughput: 0: 204.1. Samples: 964704. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:32:14,589][07522] Avg episode reward: [(0, '14.900')]
[36m[2025-07-03 18:32:19,607][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 950272. Throughput: 0: 204.3. Samples: 965968. Policy #0 lag: (min: 28.0, avg: 28.0, max: 28.0)
[36m[2025-07-03 18:32:19,608][07522] Avg episode reward: [(0, '13.195')]
[36m[2025-07-03 18:32:24,584][07522] Fps is (10 sec: 1639.2, 60 sec: 272.9, 300 sec: 277.7). Total num frames: 966656. Throughput: 0: 203.1. Samples: 967200. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:32:24,584][07522] Avg episode reward: [(0, '13.804')]
[36m[2025-07-03 18:32:29,573][07522] Fps is (10 sec: 1644.1, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 966656. Throughput: 0: 206.0. Samples: 967920. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:32:29,573][07522] Avg episode reward: [(0, '11.199')]
[36m[2025-07-03 18:32:34,584][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 966656. Throughput: 0: 212.0. Samples: 969248. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:32:34,584][07522] Avg episode reward: [(0, '9.108')]
[36m[2025-07-03 18:32:39,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 966656. Throughput: 0: 218.3. Samples: 970640. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:32:39,543][07522] Avg episode reward: [(0, '8.642')]
[36m[2025-07-03 18:32:44,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 966656. Throughput: 0: 219.0. Samples: 971264. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:32:44,555][07522] Avg episode reward: [(0, '7.673')]
[36m[2025-07-03 18:32:49,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 966656. Throughput: 0: 216.5. Samples: 972576. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:32:49,561][07522] Avg episode reward: [(0, '11.784')]
[36m[2025-07-03 18:32:54,562][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 966656. Throughput: 0: 215.1. Samples: 973728. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:32:54,562][07522] Avg episode reward: [(0, '12.668')]
[36m[2025-07-03 18:32:59,638][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 966656. Throughput: 0: 210.3. Samples: 974176. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:32:59,638][07522] Avg episode reward: [(0, '13.230')]
[36m[2025-07-03 18:33:04,599][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.2). Total num frames: 966656. Throughput: 0: 200.9. Samples: 975008. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:33:04,600][07522] Avg episode reward: [(0, '12.520')]
[36m[2025-07-03 18:33:09,597][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 966656. Throughput: 0: 194.4. Samples: 975952. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:33:09,597][07522] Avg episode reward: [(0, '13.705')]
[36m[2025-07-03 18:33:14,611][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 966656. Throughput: 0: 188.3. Samples: 976400. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:33:14,611][07522] Avg episode reward: [(0, '12.152')]
[36m[2025-07-03 18:33:19,625][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 966656. Throughput: 0: 177.6. Samples: 977248. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:33:19,626][07522] Avg episode reward: [(0, '11.185')]
[37m[1m[2025-07-03 18:33:19,744][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001888_966656.pth...
[36m[2025-07-03 18:33:19,750][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001632_835584.pth
[36m[2025-07-03 18:33:24,613][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 966656. Throughput: 0: 164.0. Samples: 978032. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:33:24,613][07522] Avg episode reward: [(0, '11.365')]
[36m[2025-07-03 18:33:29,557][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 966656. Throughput: 0: 165.7. Samples: 978720. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:33:29,557][07522] Avg episode reward: [(0, '11.325')]
[36m[2025-07-03 18:33:34,561][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 966656. Throughput: 0: 164.3. Samples: 979968. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:33:34,561][07522] Avg episode reward: [(0, '14.194')]
[36m[2025-07-03 18:33:39,557][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 966656. Throughput: 0: 170.0. Samples: 981376. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:33:39,557][07522] Avg episode reward: [(0, '13.791')]
[36m[2025-07-03 18:33:44,546][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 966656. Throughput: 0: 176.0. Samples: 982080. Policy #0 lag: (min: 16.0, avg: 16.2, max: 48.0)
[36m[2025-07-03 18:33:44,546][07522] Avg episode reward: [(0, '12.735')]
[36m[2025-07-03 18:33:49,577][07522] Fps is (10 sec: 1635.2, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 983040. Throughput: 0: 188.5. Samples: 983488. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:33:49,577][07522] Avg episode reward: [(0, '9.864')]
[36m[2025-07-03 18:33:54,568][07522] Fps is (10 sec: 1634.8, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 983040. Throughput: 0: 196.4. Samples: 984784. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:33:54,568][07522] Avg episode reward: [(0, '9.782')]
[36m[2025-07-03 18:33:59,581][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 983040. Throughput: 0: 201.4. Samples: 985456. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:33:59,582][07522] Avg episode reward: [(0, '7.492')]
[36m[2025-07-03 18:34:04,587][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 983040. Throughput: 0: 213.2. Samples: 986832. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:04,587][07522] Avg episode reward: [(0, '8.981')]
[36m[2025-07-03 18:34:09,633][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 983040. Throughput: 0: 227.1. Samples: 988256. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:09,633][07522] Avg episode reward: [(0, '11.361')]
[36m[2025-07-03 18:34:14,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 983040. Throughput: 0: 227.8. Samples: 988976. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:14,573][07522] Avg episode reward: [(0, '11.416')]
[36m[2025-07-03 18:34:19,610][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 983040. Throughput: 0: 232.3. Samples: 990432. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:19,610][07522] Avg episode reward: [(0, '11.403')]
[36m[2025-07-03 18:34:24,593][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 983040. Throughput: 0: 232.7. Samples: 991856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:24,593][07522] Avg episode reward: [(0, '10.675')]
[36m[2025-07-03 18:34:29,600][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 983040. Throughput: 0: 233.3. Samples: 992592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:29,600][07522] Avg episode reward: [(0, '8.148')]
[36m[2025-07-03 18:34:34,574][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 983040. Throughput: 0: 232.5. Samples: 993952. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:34,575][07522] Avg episode reward: [(0, '7.734')]
[36m[2025-07-03 18:34:39,574][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 983040. Throughput: 0: 233.9. Samples: 995312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:39,575][07522] Avg episode reward: [(0, '8.356')]
[36m[2025-07-03 18:34:44,587][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 983040. Throughput: 0: 235.3. Samples: 996048. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:44,587][07522] Avg episode reward: [(0, '7.018')]
[36m[2025-07-03 18:34:49,593][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 983040. Throughput: 0: 236.8. Samples: 997488. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:49,593][07522] Avg episode reward: [(0, '9.010')]
[36m[2025-07-03 18:34:54,590][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 983040. Throughput: 0: 236.3. Samples: 998880. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:34:54,590][07522] Avg episode reward: [(0, '9.271')]
[GIF] Episode 2600 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0026_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0026_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0026_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0026_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0026_merged_dual_camera.gif
[36m[2025-07-03 18:34:59,553][07522] Fps is (10 sec: 1644.9, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 999424. Throughput: 0: 233.7. Samples: 999488. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:34:59,553][07522] Avg episode reward: [(0, '10.669')]
[36m[2025-07-03 18:35:04,589][07522] Fps is (10 sec: 1638.6, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 999424. Throughput: 0: 234.1. Samples: 1000960. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:04,589][07522] Avg episode reward: [(0, '11.477')]
[36m[2025-07-03 18:35:09,582][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.1). Total num frames: 999424. Throughput: 0: 235.1. Samples: 1002432. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:09,582][07522] Avg episode reward: [(0, '12.644')]
[36m[2025-07-03 18:35:14,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 999424. Throughput: 0: 235.7. Samples: 1003184. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:14,543][07522] Avg episode reward: [(0, '10.922')]
[36m[2025-07-03 18:35:19,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 999424. Throughput: 0: 236.2. Samples: 1004576. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:19,552][07522] Avg episode reward: [(0, '12.427')]
[37m[1m[2025-07-03 18:35:19,652][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001952_999424.pth...
[36m[2025-07-03 18:35:19,656][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001696_868352.pth
[36m[2025-07-03 18:35:24,603][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 999424. Throughput: 0: 236.7. Samples: 1005968. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:24,603][07522] Avg episode reward: [(0, '12.312')]
[36m[2025-07-03 18:35:29,584][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 999424. Throughput: 0: 235.7. Samples: 1006656. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:29,584][07522] Avg episode reward: [(0, '10.574')]
[36m[2025-07-03 18:35:34,573][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 999424. Throughput: 0: 235.5. Samples: 1008080. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:34,573][07522] Avg episode reward: [(0, '12.961')]
[36m[2025-07-03 18:35:39,577][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 999424. Throughput: 0: 235.4. Samples: 1009472. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:39,577][07522] Avg episode reward: [(0, '11.068')]
[36m[2025-07-03 18:35:44,554][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 999424. Throughput: 0: 237.9. Samples: 1010192. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:44,554][07522] Avg episode reward: [(0, '10.023')]
[33m[4593295 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[4593296 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:35:49,556][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 999424. Throughput: 0: 234.8. Samples: 1011520. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:49,556][07522] Avg episode reward: [(0, '11.091')]
[36m[2025-07-03 18:35:54,602][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 999424. Throughput: 0: 231.7. Samples: 1012864. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:54,602][07522] Avg episode reward: [(0, '9.820')]
[36m[2025-07-03 18:35:59,560][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 999424. Throughput: 0: 231.4. Samples: 1013600. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:35:59,560][07522] Avg episode reward: [(0, '9.340')]
[36m[2025-07-03 18:36:04,596][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 999424. Throughput: 0: 228.8. Samples: 1014880. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[36m[2025-07-03 18:36:04,596][07522] Avg episode reward: [(0, '9.420')]
[36m[2025-07-03 18:36:09,599][07522] Fps is (10 sec: 1632.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1015808. Throughput: 0: 228.6. Samples: 1016256. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:09,599][07522] Avg episode reward: [(0, '8.088')]
[36m[2025-07-03 18:36:14,556][07522] Fps is (10 sec: 1645.1, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1015808. Throughput: 0: 228.4. Samples: 1016928. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:14,556][07522] Avg episode reward: [(0, '10.313')]
[36m[2025-07-03 18:36:19,598][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 1015808. Throughput: 0: 226.0. Samples: 1018256. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:19,598][07522] Avg episode reward: [(0, '10.433')]
[36m[2025-07-03 18:36:24,613][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 1015808. Throughput: 0: 224.5. Samples: 1019584. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:24,613][07522] Avg episode reward: [(0, '11.636')]
[36m[2025-07-03 18:36:29,551][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1015808. Throughput: 0: 224.0. Samples: 1020272. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:29,552][07522] Avg episode reward: [(0, '14.806')]
[36m[2025-07-03 18:36:34,553][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1015808. Throughput: 0: 226.5. Samples: 1021712. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:34,554][07522] Avg episode reward: [(0, '16.087')]
[36m[2025-07-03 18:36:39,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1015808. Throughput: 0: 225.7. Samples: 1023008. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:39,541][07522] Avg episode reward: [(0, '13.124')]
[36m[2025-07-03 18:36:44,564][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1015808. Throughput: 0: 222.9. Samples: 1023632. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:44,565][07522] Avg episode reward: [(0, '14.922')]
[36m[2025-07-03 18:36:49,560][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 1015808. Throughput: 0: 226.0. Samples: 1025040. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:49,561][07522] Avg episode reward: [(0, '13.194')]
[36m[2025-07-03 18:36:54,585][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 1015808. Throughput: 0: 224.8. Samples: 1026368. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:54,585][07522] Avg episode reward: [(0, '13.700')]
[36m[2025-07-03 18:36:59,583][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 1015808. Throughput: 0: 224.9. Samples: 1027056. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:36:59,584][07522] Avg episode reward: [(0, '12.750')]
[36m[2025-07-03 18:37:04,545][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 1015808. Throughput: 0: 223.9. Samples: 1028320. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:37:04,545][07522] Avg episode reward: [(0, '15.299')]
[36m[2025-07-03 18:37:09,588][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 1015808. Throughput: 0: 226.3. Samples: 1029760. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:37:09,588][07522] Avg episode reward: [(0, '14.521')]
[36m[2025-07-03 18:37:14,546][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 1015808. Throughput: 0: 226.2. Samples: 1030448. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[36m[2025-07-03 18:37:14,546][07522] Avg episode reward: [(0, '15.066')]
[36m[2025-07-03 18:37:19,552][07522] Fps is (10 sec: 1644.4, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 227.2. Samples: 1031936. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:37:19,552][07522] Avg episode reward: [(0, '17.380')]
[37m[1m[2025-07-03 18:37:19,616][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000002016_1032192.pth...
[36m[2025-07-03 18:37:19,620][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001728_884736.pth
[37m[1m[2025-07-03 18:37:19,621][07522] Saving new best policy, reward=17.380!
[36m[2025-07-03 18:37:24,540][07522] Fps is (10 sec: 1639.4, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 229.3. Samples: 1033328. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:37:24,540][07522] Avg episode reward: [(0, '16.747')]
[36m[2025-07-03 18:37:29,616][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 1032192. Throughput: 0: 230.5. Samples: 1034016. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:37:29,616][07522] Avg episode reward: [(0, '15.478')]
[36m[2025-07-03 18:37:34,621][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 1032192. Throughput: 0: 230.4. Samples: 1035424. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:37:34,621][07522] Avg episode reward: [(0, '14.841')]
[36m[2025-07-03 18:37:39,553][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 233.1. Samples: 1036848. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:37:39,553][07522] Avg episode reward: [(0, '15.849')]
[36m[2025-07-03 18:37:44,596][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 1032192. Throughput: 0: 232.8. Samples: 1037536. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:37:44,596][07522] Avg episode reward: [(0, '17.343')]
[36m[2025-07-03 18:37:49,592][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 1032192. Throughput: 0: 236.2. Samples: 1038960. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:37:49,592][07522] Avg episode reward: [(0, '18.325')]
[37m[1m[2025-07-03 18:37:49,657][07522] Saving new best policy, reward=18.325!
[36m[2025-07-03 18:37:54,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 233.1. Samples: 1040240. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:37:54,555][07522] Avg episode reward: [(0, '17.559')]
[36m[2025-07-03 18:37:59,590][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 231.2. Samples: 1040864. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:37:59,590][07522] Avg episode reward: [(0, '20.034')]
[37m[1m[2025-07-03 18:37:59,674][07522] Saving new best policy, reward=20.034!
[36m[2025-07-03 18:38:04,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 227.2. Samples: 1042160. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:38:04,543][07522] Avg episode reward: [(0, '18.091')]
[36m[2025-07-03 18:38:09,543][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 227.5. Samples: 1043568. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:38:09,543][07522] Avg episode reward: [(0, '16.453')]
[36m[2025-07-03 18:38:14,576][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 228.1. Samples: 1044272. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:38:14,576][07522] Avg episode reward: [(0, '16.809')]
[36m[2025-07-03 18:38:19,582][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 227.4. Samples: 1045648. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:38:19,582][07522] Avg episode reward: [(0, '14.444')]
[36m[2025-07-03 18:38:24,552][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 225.8. Samples: 1047008. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:38:24,552][07522] Avg episode reward: [(0, '11.169')]
[36m[2025-07-03 18:38:29,543][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 1032192. Throughput: 0: 227.5. Samples: 1047760. Policy #0 lag: (min: 23.0, avg: 23.0, max: 23.0)
[36m[2025-07-03 18:38:29,544][07522] Avg episode reward: [(0, '12.361')]
[36m[2025-07-03 18:38:34,543][07522] Fps is (10 sec: 1639.9, 60 sec: 273.4, 300 sec: 277.7). Total num frames: 1048576. Throughput: 0: 227.1. Samples: 1049168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:38:34,543][07522] Avg episode reward: [(0, '13.612')]
[36m[2025-07-03 18:38:39,578][07522] Fps is (10 sec: 1632.7, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 1048576. Throughput: 0: 228.9. Samples: 1050544. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:38:39,578][07522] Avg episode reward: [(0, '12.372')]
[36m[2025-07-03 18:38:44,610][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 1048576. Throughput: 0: 231.4. Samples: 1051280. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:38:44,611][07522] Avg episode reward: [(0, '15.782')]
[36m[2025-07-03 18:38:49,569][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1048576. Throughput: 0: 231.7. Samples: 1052592. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:38:49,570][07522] Avg episode reward: [(0, '16.311')]
[36m[2025-07-03 18:38:54,606][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 1048576. Throughput: 0: 233.3. Samples: 1054080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:38:54,606][07522] Avg episode reward: [(0, '17.650')]
[36m[2025-07-03 18:38:59,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1048576. Throughput: 0: 232.6. Samples: 1054736. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:38:59,555][07522] Avg episode reward: [(0, '23.999')]
[37m[1m[2025-07-03 18:38:59,619][07522] Saving new best policy, reward=23.999!
[36m[2025-07-03 18:39:04,564][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1048576. Throughput: 0: 234.4. Samples: 1056192. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:39:04,564][07522] Avg episode reward: [(0, '24.754')]
[37m[1m[2025-07-03 18:39:04,631][07522] Saving new best policy, reward=24.754!
[36m[2025-07-03 18:39:09,584][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 1048576. Throughput: 0: 233.8. Samples: 1057536. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:39:09,584][07522] Avg episode reward: [(0, '25.540')]
[37m[1m[2025-07-03 18:39:09,653][07522] Saving new best policy, reward=25.540!
[36m[2025-07-03 18:39:14,591][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1048576. Throughput: 0: 232.6. Samples: 1058240. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:39:14,591][07522] Avg episode reward: [(0, '21.008')]
[36m[2025-07-03 18:39:19,593][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1048576. Throughput: 0: 232.6. Samples: 1059648. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:39:19,593][07522] Avg episode reward: [(0, '20.911')]
[37m[1m[2025-07-03 18:39:19,656][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000002048_1048576.pth...
[36m[2025-07-03 18:39:19,660][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001792_917504.pth
[36m[2025-07-03 18:39:24,552][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 1048576. Throughput: 0: 234.8. Samples: 1061104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:39:24,552][07522] Avg episode reward: [(0, '18.950')]
[33m[4814115 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[4814115 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:39:29,579][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.2). Total num frames: 1048576. Throughput: 0: 234.5. Samples: 1061824. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:39:29,579][07522] Avg episode reward: [(0, '17.658')]
[36m[2025-07-03 18:39:34,593][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 1048576. Throughput: 0: 236.7. Samples: 1063248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:39:34,593][07522] Avg episode reward: [(0, '19.174')]
[36m[2025-07-03 18:39:39,601][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 1048576. Throughput: 0: 234.0. Samples: 1064608. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:39:39,601][07522] Avg episode reward: [(0, '19.858')]
[36m[2025-07-03 18:39:44,628][07522] Fps is (10 sec: 1632.6, 60 sec: 273.0, 300 sec: 277.7). Total num frames: 1064960. Throughput: 0: 231.8. Samples: 1065184. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:39:44,628][07522] Avg episode reward: [(0, '19.636')]
[36m[2025-07-03 18:39:49,546][07522] Fps is (10 sec: 1647.4, 60 sec: 273.2, 300 sec: 277.7). Total num frames: 1064960. Throughput: 0: 229.1. Samples: 1066496. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:39:49,546][07522] Avg episode reward: [(0, '21.165')]
[36m[2025-07-03 18:39:54,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 1064960. Throughput: 0: 232.0. Samples: 1067968. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:39:54,544][07522] Avg episode reward: [(0, '25.760')]
[37m[1m[2025-07-03 18:39:54,604][07522] Saving new best policy, reward=25.760!
[36m[2025-07-03 18:39:59,558][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 1064960. Throughput: 0: 232.0. Samples: 1068672. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:39:59,558][07522] Avg episode reward: [(0, '30.588')]
[37m[1m[2025-07-03 18:39:59,659][07522] Saving new best policy, reward=30.588!
[36m[2025-07-03 18:40:04,541][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1064960. Throughput: 0: 230.3. Samples: 1070000. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:04,541][07522] Avg episode reward: [(0, '30.658')]
[37m[1m[2025-07-03 18:40:04,605][07522] Saving new best policy, reward=30.658!
[36m[2025-07-03 18:40:09,555][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 1064960. Throughput: 0: 229.3. Samples: 1071424. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:09,556][07522] Avg episode reward: [(0, '31.796')]
[37m[1m[2025-07-03 18:40:09,657][07522] Saving new best policy, reward=31.796!
[36m[2025-07-03 18:40:14,562][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 1064960. Throughput: 0: 228.0. Samples: 1072080. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:14,562][07522] Avg episode reward: [(0, '29.151')]
[36m[2025-07-03 18:40:19,568][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1064960. Throughput: 0: 228.4. Samples: 1073520. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:19,569][07522] Avg episode reward: [(0, '20.615')]
[36m[2025-07-03 18:40:24,625][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 1064960. Throughput: 0: 229.2. Samples: 1074928. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:24,625][07522] Avg episode reward: [(0, '18.100')]
[36m[2025-07-03 18:40:29,593][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 1064960. Throughput: 0: 229.9. Samples: 1075520. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:29,594][07522] Avg episode reward: [(0, '24.676')]
[36m[2025-07-03 18:40:34,540][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 1064960. Throughput: 0: 232.9. Samples: 1076976. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:34,540][07522] Avg episode reward: [(0, '24.250')]
[GIF] Episode 2700 terminated - saving GIFs (every 100 episodes)
[GIF] Saved drone depth: ./gif_episodes/episode_0027_drone_depth.gif
[GIF] Saved drone segmentation: ./gif_episodes/episode_0027_drone_seg.gif
[GIF] Saved static depth: ./gif_episodes/episode_0027_static_depth.gif
[GIF] Saved static segmentation: ./gif_episodes/episode_0027_static_seg.gif
[GIF] Saved merged dual camera: ./gif_episodes/episode_0027_merged_dual_camera.gif
[36m[2025-07-03 18:40:39,607][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 1064960. Throughput: 0: 227.9. Samples: 1078240. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:39,607][07522] Avg episode reward: [(0, '25.859')]
[36m[2025-07-03 18:40:44,617][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 1064960. Throughput: 0: 224.1. Samples: 1078768. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:44,617][07522] Avg episode reward: [(0, '26.825')]
[36m[2025-07-03 18:40:49,617][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 1064960. Throughput: 0: 215.8. Samples: 1079728. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:49,618][07522] Avg episode reward: [(0, '28.489')]
[36m[2025-07-03 18:40:54,595][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 1064960. Throughput: 0: 206.0. Samples: 1080704. Policy #0 lag: (min: 18.0, avg: 18.0, max: 18.0)
[36m[2025-07-03 18:40:54,595][07522] Avg episode reward: [(0, '25.790')]
[36m[2025-07-03 18:40:59,544][07522] Fps is (10 sec: 1650.4, 60 sec: 273.1, 300 sec: 277.7). Total num frames: 1081344. Throughput: 0: 204.2. Samples: 1081264. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:40:59,545][07522] Avg episode reward: [(0, '24.328')]
[36m[2025-07-03 18:41:04,559][07522] Fps is (10 sec: 1644.3, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1081344. Throughput: 0: 198.1. Samples: 1082432. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:04,559][07522] Avg episode reward: [(0, '27.033')]
[36m[2025-07-03 18:41:09,577][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 1081344. Throughput: 0: 194.3. Samples: 1083664. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:09,577][07522] Avg episode reward: [(0, '25.788')]
[36m[2025-07-03 18:41:14,632][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 1081344. Throughput: 0: 196.1. Samples: 1084352. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:14,632][07522] Avg episode reward: [(0, '24.394')]
[36m[2025-07-03 18:41:19,587][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1081344. Throughput: 0: 190.7. Samples: 1085568. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:19,587][07522] Avg episode reward: [(0, '27.997')]
[37m[1m[2025-07-03 18:41:19,668][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000002112_1081344.pth...
[36m[2025-07-03 18:41:19,672][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001856_950272.pth
[36m[2025-07-03 18:41:24,556][07522] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 1081344. Throughput: 0: 189.4. Samples: 1086752. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:24,556][07522] Avg episode reward: [(0, '26.600')]
[36m[2025-07-03 18:41:29,592][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 1081344. Throughput: 0: 190.3. Samples: 1087328. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:29,593][07522] Avg episode reward: [(0, '25.182')]
[36m[2025-07-03 18:41:34,643][07522] Fps is (10 sec: 0.0, 60 sec: 272.6, 300 sec: 222.1). Total num frames: 1081344. Throughput: 0: 195.8. Samples: 1088544. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:34,643][07522] Avg episode reward: [(0, '26.065')]
[36m[2025-07-03 18:41:39,625][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 1081344. Throughput: 0: 200.4. Samples: 1089728. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:39,626][07522] Avg episode reward: [(0, '29.033')]
[36m[2025-07-03 18:41:44,547][07522] Fps is (10 sec: 0.0, 60 sec: 273.4, 300 sec: 222.2). Total num frames: 1081344. Throughput: 0: 201.6. Samples: 1090336. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:44,547][07522] Avg episode reward: [(0, '30.867')]
[36m[2025-07-03 18:41:49,595][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 1081344. Throughput: 0: 201.4. Samples: 1091504. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:49,595][07522] Avg episode reward: [(0, '28.111')]
[36m[2025-07-03 18:41:54,564][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1081344. Throughput: 0: 202.0. Samples: 1092752. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:54,564][07522] Avg episode reward: [(0, '27.009')]
[36m[2025-07-03 18:41:59,604][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 1081344. Throughput: 0: 199.9. Samples: 1093344. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:41:59,604][07522] Avg episode reward: [(0, '26.129')]
[36m[2025-07-03 18:42:04,569][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.2). Total num frames: 1081344. Throughput: 0: 199.2. Samples: 1094528. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:42:04,570][07522] Avg episode reward: [(0, '26.865')]
[36m[2025-07-03 18:42:09,616][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 1081344. Throughput: 0: 198.8. Samples: 1095712. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:42:09,617][07522] Avg episode reward: [(0, '20.090')]
[36m[2025-07-03 18:42:14,571][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1081344. Throughput: 0: 199.9. Samples: 1096320. Policy #0 lag: (min: 21.0, avg: 21.0, max: 21.0)
[36m[2025-07-03 18:42:14,571][07522] Avg episode reward: [(0, '22.168')]
[36m[2025-07-03 18:42:19,603][07522] Fps is (10 sec: 1640.5, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 1097728. Throughput: 0: 200.7. Samples: 1097568. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:42:19,604][07522] Avg episode reward: [(0, '21.283')]
[36m[2025-07-03 18:42:24,646][07522] Fps is (10 sec: 1626.2, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 1097728. Throughput: 0: 199.7. Samples: 1098720. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:42:24,646][07522] Avg episode reward: [(0, '22.251')]
[36m[2025-07-03 18:42:29,559][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1097728. Throughput: 0: 198.0. Samples: 1099248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:42:29,559][07522] Avg episode reward: [(0, '27.734')]
[36m[2025-07-03 18:42:34,612][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 1097728. Throughput: 0: 192.6. Samples: 1100176. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:42:34,613][07522] Avg episode reward: [(0, '23.204')]
[36m[2025-07-03 18:42:39,564][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 1097728. Throughput: 0: 185.6. Samples: 1101104. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:42:39,564][07522] Avg episode reward: [(0, '24.701')]
[36m[2025-07-03 18:42:44,624][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 1097728. Throughput: 0: 182.0. Samples: 1101536. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:42:44,624][07522] Avg episode reward: [(0, '26.220')]
[36m[2025-07-03 18:42:49,614][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.1). Total num frames: 1097728. Throughput: 0: 177.2. Samples: 1102512. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:42:49,614][07522] Avg episode reward: [(0, '26.386')]
[36m[2025-07-03 18:42:54,544][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.2). Total num frames: 1097728. Throughput: 0: 173.4. Samples: 1103504. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:42:54,544][07522] Avg episode reward: [(0, '27.894')]
[36m[2025-07-03 18:42:59,640][07522] Fps is (10 sec: 0.0, 60 sec: 272.9, 300 sec: 222.1). Total num frames: 1097728. Throughput: 0: 170.4. Samples: 1104000. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:42:59,641][07522] Avg episode reward: [(0, '26.903')]
[36m[2025-07-03 18:43:04,626][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 1097728. Throughput: 0: 162.4. Samples: 1104880. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:04,627][07522] Avg episode reward: [(0, '24.241')]
[36m[2025-07-03 18:43:09,596][07522] Fps is (10 sec: 0.0, 60 sec: 273.2, 300 sec: 222.1). Total num frames: 1097728. Throughput: 0: 157.7. Samples: 1105808. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:09,597][07522] Avg episode reward: [(0, '25.562')]
[36m[2025-07-03 18:43:14,561][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 1097728. Throughput: 0: 156.1. Samples: 1106272. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:14,561][07522] Avg episode reward: [(0, '26.633')]
[36m[2025-07-03 18:43:19,575][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 1097728. Throughput: 0: 155.5. Samples: 1107168. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:19,576][07522] Avg episode reward: [(0, '26.591')]
[37m[1m[2025-07-03 18:43:19,679][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000002144_1097728.pth...
[36m[2025-07-03 18:43:19,684][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001888_966656.pth
[33m[5048645 ms][IGE_viewer_control] - WARNING : Camera follow: False (IGE_viewer_control.py:217)
[36m[2025-07-03 18:43:24,607][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 222.1). Total num frames: 1097728. Throughput: 0: 154.9. Samples: 1108080. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:24,608][07522] Avg episode reward: [(0, '26.725')]
[36m[2025-07-03 18:43:29,604][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1097728. Throughput: 0: 156.5. Samples: 1108576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:29,604][07522] Avg episode reward: [(0, '23.136')]
[36m[2025-07-03 18:43:34,571][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1097728. Throughput: 0: 155.2. Samples: 1109488. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:34,571][07522] Avg episode reward: [(0, '25.111')]
[36m[2025-07-03 18:43:39,624][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1097728. Throughput: 0: 152.3. Samples: 1110368. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:39,624][07522] Avg episode reward: [(0, '27.027')]
[36m[2025-07-03 18:43:44,557][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1097728. Throughput: 0: 152.1. Samples: 1110832. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:44,558][07522] Avg episode reward: [(0, '25.386')]
[36m[2025-07-03 18:43:49,609][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1097728. Throughput: 0: 154.7. Samples: 1111840. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:49,609][07522] Avg episode reward: [(0, '23.721')]
[36m[2025-07-03 18:43:54,665][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1097728. Throughput: 0: 156.6. Samples: 1112864. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:54,666][07522] Avg episode reward: [(0, '23.973')]
[36m[2025-07-03 18:43:59,540][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1097728. Throughput: 0: 156.2. Samples: 1113296. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:43:59,540][07522] Avg episode reward: [(0, '27.133')]
[36m[2025-07-03 18:44:04,575][07522] Fps is (10 sec: 1653.4, 60 sec: 273.3, 300 sec: 222.2). Total num frames: 1114112. Throughput: 0: 155.4. Samples: 1114160. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:04,575][07522] Avg episode reward: [(0, '29.379')]
[36m[2025-07-03 18:44:09,586][07522] Fps is (10 sec: 1630.8, 60 sec: 273.1, 300 sec: 222.2). Total num frames: 1114112. Throughput: 0: 155.8. Samples: 1115088. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:09,587][07522] Avg episode reward: [(0, '33.080')]
[37m[1m[2025-07-03 18:44:09,670][07522] Saving new best policy, reward=33.080!
[36m[2025-07-03 18:44:14,633][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 222.1). Total num frames: 1114112. Throughput: 0: 157.1. Samples: 1115648. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:14,633][07522] Avg episode reward: [(0, '30.434')]
[33m[5101900 ms][navigation_task_gate] - WARNING : Gate Navigation Curriculum Level: 3, Progress: 0.0 (navigation_task_gate.py:434)
[33m[5101900 ms][navigation_task_gate] - WARNING : 
[33mSuccess Rate: 0.0
[33mCrash Rate: 1.0
[33mTimeout Rate: 0.0 (navigation_task_gate.py:437)
[36m[2025-07-03 18:44:19,634][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 1114112. Throughput: 0: 153.7. Samples: 1116416. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:19,634][07522] Avg episode reward: [(0, '30.934')]
[36m[2025-07-03 18:44:24,605][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 222.1). Total num frames: 1114112. Throughput: 0: 148.3. Samples: 1117040. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:24,606][07522] Avg episode reward: [(0, '32.465')]
[36m[2025-07-03 18:44:29,668][07522] Fps is (10 sec: 0.0, 60 sec: 272.8, 300 sec: 222.1). Total num frames: 1114112. Throughput: 0: 144.7. Samples: 1117360. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:29,668][07522] Avg episode reward: [(0, '33.803')]
[37m[1m[2025-07-03 18:44:29,823][07522] Saving new best policy, reward=33.803!
[36m[2025-07-03 18:44:34,583][07522] Fps is (10 sec: 0.0, 60 sec: 273.0, 300 sec: 222.2). Total num frames: 1114112. Throughput: 0: 136.3. Samples: 1117968. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:34,583][07522] Avg episode reward: [(0, '34.964')]
[37m[1m[2025-07-03 18:44:34,732][07522] Saving new best policy, reward=34.964!
[36m[2025-07-03 18:44:39,626][07522] Fps is (10 sec: 0.0, 60 sec: 273.1, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 127.0. Samples: 1118576. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:39,627][07522] Avg episode reward: [(0, '31.823')]
[36m[2025-07-03 18:44:45,881][07522] Fps is (10 sec: 0.0, 60 sec: 267.2, 300 sec: 165.9). Total num frames: 1114112. Throughput: 0: 120.5. Samples: 1118880. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:45,881][07522] Avg episode reward: [(0, '29.892')]
[36m[2025-07-03 18:44:49,548][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 114.6. Samples: 1119312. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:49,548][07522] Avg episode reward: [(0, '32.403')]
[36m[2025-07-03 18:44:54,606][07522] Fps is (10 sec: 0.0, 60 sec: 273.3, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 108.0. Samples: 1119952. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:54,606][07522] Avg episode reward: [(0, '28.121')]
[36m[2025-07-03 18:44:59,624][07522] Fps is (10 sec: 0.0, 60 sec: 272.7, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 102.4. Samples: 1120256. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:44:59,625][07522] Avg episode reward: [(0, '28.296')]
[36m[2025-07-03 18:45:04,568][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 99.7. Samples: 1120896. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:45:04,569][07522] Avg episode reward: [(0, '27.933')]
[36m[2025-07-03 18:45:09,549][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 100.0. Samples: 1121536. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:45:09,550][07522] Avg episode reward: [(0, '30.583')]
[36m[2025-07-03 18:45:14,660][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 99.9. Samples: 1121856. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:45:14,660][07522] Avg episode reward: [(0, '29.966')]
[36m[2025-07-03 18:45:19,701][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 100.4. Samples: 1122496. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:45:19,702][07522] Avg episode reward: [(0, '30.870')]
[37m[1m[2025-07-03 18:45:19,838][07522] Saving ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000002176_1114112.pth...
[36m[2025-07-03 18:45:19,848][07522] Removing ./train_dir/base_gate_rewards_classic34/checkpoint_p0/checkpoint_000001952_999424.pth
[36m[2025-07-03 18:45:24,630][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 103.8. Samples: 1123248. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:45:24,630][07522] Avg episode reward: [(0, '32.820')]
[36m[2025-07-03 18:45:29,554][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 111.4. Samples: 1123744. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:45:29,554][07522] Avg episode reward: [(0, '31.302')]
[33m[5178535 ms][IGE_viewer_control] - WARNING : Camera follow: True (IGE_viewer_control.py:217)
[36m[2025-07-03 18:45:34,647][07522] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 166.6). Total num frames: 1114112. Throughput: 0: 118.9. Samples: 1124672. Policy #0 lag: (min: 31.0, avg: 31.0, max: 31.0)
[36m[2025-07-03 18:45:34,647][07522] Avg episode reward: [(0, '29.421')]
[37m[1m[2025-07-03 18:45:35,597][07522] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 7522], exiting...
[37m[1m[2025-07-03 18:45:35,598][07522] Runner profile tree view:
[37m[1mmain_loop: 5169.4091
[37m[1m[2025-07-03 18:45:35,598][07522] Collected {0: 1114112}, FPS: 215.5