diff --git a/aerial_gym/config/asset_config/env_asset_config.py b/aerial_gym/config/asset_config/env_asset_config.py
index ee502a3..84a64ac 100644
--- a/aerial_gym/config/asset_config/env_asset_config.py
+++ b/aerial_gym/config/asset_config/env_asset_config.py
@@ -66,7 +66,7 @@ class EnvObjectConfig:
         semantic_id = -1
         color = [170, 66, 66]
 
-    class thin_asset_params(base_asset_params):
+    class thin_asset_params(BaseAssetParams):
         num_assets = 0
 
         asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/thin"
@@ -108,7 +108,7 @@ class EnvObjectConfig:
         semantic_id = THIN_SEMANTIC_ID
         color = [170, 66, 66]
 
-    class tree_asset_params(base_asset_params):
+    class tree_asset_params(BaseAssetParams):
         num_assets = 1
 
         asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/trees"
@@ -154,7 +154,7 @@ class EnvObjectConfig:
 
         semantic_masked_links = {}
 
-    class object_asset_params(base_asset_params):
+    class object_asset_params(BaseAssetParams):
         num_assets = 2
 
         asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/objects"
@@ -194,7 +194,7 @@ class EnvObjectConfig:
 
         # color = [80,255,100]
 
-    class left_wall(base_asset_params):
+    class left_wall(BaseAssetParams):
         num_assets = 1
 
         asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/walls"
@@ -240,7 +240,7 @@ class EnvObjectConfig:
         semantic_id = -1  # semantic_id = WALL_SEMANTIC_ID
         color = [100, 200, 210]
 
-    class right_wall(base_asset_params):
+    class right_wall(BaseAssetParams):
         num_assets = 1
 
         asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/walls"
@@ -283,7 +283,7 @@ class EnvObjectConfig:
         semantic_id = -1  # semantic_id = WALL_SEMANTIC_ID
         color = [100, 200, 210]
 
-    class top_wall(base_asset_params):
+    class top_wall(BaseAssetParams):
         num_assets = 1
 
         asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/walls"
@@ -329,7 +329,7 @@ class EnvObjectConfig:
         semantic_id = -1  # semantic_id = WALL_SEMANTIC_ID
         color = [100, 200, 210]
 
-    class bottom_wall(base_asset_params):
+    class bottom_wall(BaseAssetParams):
         num_assets = 1
         asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/walls"
         file = "bottom_wall.urdf"
@@ -374,7 +374,7 @@ class EnvObjectConfig:
         semantic_id = -1  # semantic_id = WALL_SEMANTIC_ID
         color = [100, 150, 150]
 
-    class front_wall(base_asset_params):
+    class front_wall(BaseAssetParams):
         num_assets = 1
 
         asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/walls"
@@ -420,7 +420,7 @@ class EnvObjectConfig:
         semantic_id = -1  # semantic_id = WALL_SEMANTIC_ID
         color = [100, 200, 210]
 
-    class back_wall(base_asset_params):
+    class back_wall(BaseAssetParams):
         num_assets = 1
 
         asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/walls"
@@ -464,3 +464,16 @@ class EnvObjectConfig:
         collapse_fixed_joints = True
         semantic_id = -1  # semantic_id = WALL_SEMANTIC_ID
         color = [100, 200, 210]
+
+
+# Create module-level exports for easier importing
+panel_asset_params = EnvObjectConfig.panel_asset_params
+thin_asset_params = EnvObjectConfig.thin_asset_params
+tree_asset_params = EnvObjectConfig.tree_asset_params
+object_asset_params = EnvObjectConfig.object_asset_params
+left_wall = EnvObjectConfig.left_wall
+right_wall = EnvObjectConfig.right_wall
+top_wall = EnvObjectConfig.top_wall
+bottom_wall = EnvObjectConfig.bottom_wall
+front_wall = EnvObjectConfig.front_wall
+back_wall = EnvObjectConfig.back_wall
diff --git a/aerial_gym/config/env_config/forest_env.py b/aerial_gym/config/env_config/forest_env.py
index 293a1ce..9f6a011 100644
--- a/aerial_gym/config/env_config/forest_env.py
+++ b/aerial_gym/config/env_config/forest_env.py
@@ -3,6 +3,107 @@ from aerial_gym.config.asset_config.env_object_config import (
     object_asset_params,
     bottom_wall,
 )
+from aerial_gym.config.asset_config.base_asset import BaseAssetParams
+
+import numpy as np
+from aerial_gym.config.asset_config.env_object_config import AERIAL_GYM_DIRECTORY
+
+# Create a custom tree configuration with more trees for a dense forest
+class dense_tree_asset_params(tree_asset_params):
+    num_assets = 6 # Increase from 1 to 8 trees for a denser forest
+    
+    # Spread trees more across the environment
+    min_state_ratio = [
+        0.05,  # Allow trees closer to edges (was 0.1)
+        0.05,  # Allow trees closer to edges (was 0.1) 
+        0.0,
+        0,
+        -tree_asset_params.min_state_ratio[4],  # Keep original rotation
+        -tree_asset_params.min_state_ratio[5],
+        1.0,
+        0.0,
+        0.0,
+        0.0,
+        0.0,
+        0.0,
+        0.0,
+    ]
+    max_state_ratio = [
+        0.95,  # Allow trees closer to edges (was 0.9)
+        0.95,  # Allow trees closer to edges (was 0.9)
+        0.0,
+        0,
+        tree_asset_params.max_state_ratio[4],   # Keep original rotation
+        tree_asset_params.max_state_ratio[5],
+        1.0,
+        0.0,
+        0.0,
+        0.0,
+        0.0,
+        0.0,
+        0.0,
+    ]
+
+# Create individual camera marker assets - small colored boxes to mark each camera position
+# North Camera Marker (Green) - positioned at (0, 3.5, 1.5), slightly closer than camera at (0, 4.0, 2.0)
+class north_camera_marker(BaseAssetParams):
+    num_assets = 1
+    asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/objects"
+    file = "small_cube.urdf"
+    
+    # Position at (0, 3.0, 2.5) in environment bounds [-5,-5,-1] to [5,5,3] -> ratios (0.5, 0.8, 0.875)
+    min_state_ratio = [0.5, 0.8, 0.875, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
+    max_state_ratio = [0.5, 0.8, 0.875, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
+    
+    collision_mask = 1
+    keep_in_env = True
+    collapse_fixed_joints = True
+    color = [0, 255, 0]  # Green
+
+# South Camera Marker (Red) - positioned at (0, -3.5, 1.5), slightly closer than camera at (0, -4.0, 2.0)
+class south_camera_marker(BaseAssetParams):
+    num_assets = 1
+    asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/objects"
+    file = "small_cube.urdf"
+    
+    # Position at (0, -3.0, 2.5) in environment bounds [-5,-5,-1] to [5,5,3] -> ratios (0.5, 0.2, 0.875)
+    min_state_ratio = [0.5, 0.2, 0.875, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
+    max_state_ratio = [0.5, 0.2, 0.875, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
+    
+    collision_mask = 1
+    keep_in_env = True
+    collapse_fixed_joints = True
+    color = [255, 0, 0]  # Red
+
+# East Camera Marker (Blue) - positioned at (3.5, 0, 1.5), slightly closer than camera at (4.0, 0, 2.0)
+class east_camera_marker(BaseAssetParams):
+    num_assets = 1
+    asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/objects"
+    file = "small_cube.urdf"
+    
+    # Position at (3.0, 0, 2.5) in environment bounds [-5,-5,-1] to [5,5,3] -> ratios (0.8, 0.5, 0.875)
+    min_state_ratio = [0.8, 0.5, 0.875, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
+    max_state_ratio = [0.8, 0.5, 0.875, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
+    
+    collision_mask = 1
+    keep_in_env = True
+    collapse_fixed_joints = True
+    color = [0, 0, 255]  # Blue
+
+# West Camera Marker (Yellow) - positioned at (-3.5, 0, 1.5), slightly closer than camera at (-4.0, 0, 2.0)
+class west_camera_marker(BaseAssetParams):
+    num_assets = 1
+    asset_folder = f"{AERIAL_GYM_DIRECTORY}/resources/models/environment_assets/objects"
+    file = "small_cube.urdf"
+    
+    # Position at (-3.0, 0, 2.5) in environment bounds [-5,-5,-1] to [5,5,3] -> ratios (0.2, 0.5, 0.875)
+    min_state_ratio = [0.2, 0.5, 0.875, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
+    max_state_ratio = [0.2, 0.5, 0.875, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
+    
+    collision_mask = 1
+    keep_in_env = True
+    collapse_fixed_joints = True
+    color = [255, 255, 0]  # Yellow
 
 import numpy as np
 
@@ -41,11 +142,19 @@ class ForestEnvCfg:
             "trees": True,
             "objects": True,
             "bottom_wall": True,
+            "north_camera_marker": True,  # Enable individual camera markers
+            "south_camera_marker": True,
+            "east_camera_marker": True,
+            "west_camera_marker": True,
         }
 
         # maps the above names to the classes defining the assets. They can be enabled and disabled above in include_asset_type
         asset_type_to_dict_map = {
-            "trees": tree_asset_params,
+            "trees": dense_tree_asset_params,  # Use dense tree configuration instead of default
             "objects": object_asset_params,
             "bottom_wall": bottom_wall,
+            "north_camera_marker": north_camera_marker,  # Add individual camera markers
+            "south_camera_marker": south_camera_marker,
+            "east_camera_marker": east_camera_marker,
+            "west_camera_marker": west_camera_marker,
         }
diff --git a/aerial_gym/config/robot_config/lmf2_config.py b/aerial_gym/config/robot_config/lmf2_config.py
index 4d719f9..108a4d1 100644
--- a/aerial_gym/config/robot_config/lmf2_config.py
+++ b/aerial_gym/config/robot_config/lmf2_config.py
@@ -174,3 +174,83 @@ class LMF2Cfg:
             max_thrust_rate = 100000.0
             thrust_to_torque_ratio = 0.07
             use_discrete_approximation = True  # use discrete approximation for motor dynamics
+
+
+# Configuration for Drone 1 (positioned at -2, 0, 1.5)
+class LMF2Drone1Cfg(LMF2Cfg):
+    class init_config(LMF2Cfg.init_config):
+        # Position drone 1 at (-2, 0, 1.5) - left side of center
+        min_init_state = [
+            0.3,  # ratio_x: -2.0 in [-5, 5] range = ((-2 + 5) / 10) = 0.3
+            0.5,  # ratio_y: 0.0 in [-5, 5] range = ((0 + 5) / 10) = 0.5 
+            0.625,  # ratio_z: 1.5 in [-1, 3] range = ((1.5 + 1) / 4) = 0.625
+            0,  # no rotation
+            0,  # no rotation 
+            0,  # no rotation
+            1.0,
+            0,  # no velocity
+            0,  # no velocity
+            0,  # no velocity
+            0,  # no angular velocity
+            0,  # no angular velocity
+            0,  # no angular velocity
+        ]
+        max_init_state = [
+            0.3,  # same as min for fixed position
+            0.5,  # same as min for fixed position
+            0.625,  # same as min for fixed position
+            0,  # no rotation
+            0,  # no rotation
+            0,  # no rotation
+            1.0,
+            0,  # no velocity
+            0,  # no velocity
+            0,  # no velocity
+            0,  # no angular velocity
+            0,  # no angular velocity
+            0,  # no angular velocity
+        ]
+    
+    class robot_asset(LMF2Cfg.robot_asset):
+        name = "drone_1"  # unique name for first drone
+        semantic_id = 1  # different semantic ID for identification
+
+
+# Configuration for Drone 2 (positioned at 2, 0, 1.5)
+class LMF2Drone2Cfg(LMF2Cfg):
+    class init_config(LMF2Cfg.init_config):
+        # Position drone 2 at (2, 0, 1.5) - right side of center
+        min_init_state = [
+            0.7,  # ratio_x: 2.0 in [-5, 5] range = ((2 + 5) / 10) = 0.7
+            0.5,  # ratio_y: 0.0 in [-5, 5] range = ((0 + 5) / 10) = 0.5
+            0.625,  # ratio_z: 1.5 in [-1, 3] range = ((1.5 + 1) / 4) = 0.625
+            0,  # no rotation
+            0,  # no rotation
+            0,  # no rotation
+            1.0,
+            0,  # no velocity
+            0,  # no velocity
+            0,  # no velocity
+            0,  # no angular velocity
+            0,  # no angular velocity
+            0,  # no angular velocity
+        ]
+        max_init_state = [
+            0.7,  # same as min for fixed position
+            0.5,  # same as min for fixed position
+            0.625,  # same as min for fixed position
+            0,  # no rotation
+            0,  # no rotation
+            0,  # no rotation
+            1.0,
+            0,  # no velocity
+            0,  # no velocity
+            0,  # no velocity
+            0,  # no angular velocity
+            0,  # no angular velocity
+            0,  # no angular velocity
+        ]
+    
+    class robot_asset(LMF2Cfg.robot_asset):
+        name = "drone_2"  # unique name for second drone
+        semantic_id = 2  # different semantic ID for identification
diff --git a/aerial_gym/config/task_config/navigation_task_config.py b/aerial_gym/config/task_config/navigation_task_config.py
index 7ecbda5..2424767 100644
--- a/aerial_gym/config/task_config/navigation_task_config.py
+++ b/aerial_gym/config/task_config/navigation_task_config.py
@@ -84,6 +84,7 @@ class task_config:
     #     processed_action[:, 3] = max_yawrate*processed_action[:, 3]
     #     return processed_action
 
+    @staticmethod
     def action_transformation_function(action):
         clamped_action = torch.clamp(action, -1.0, 1.0)
         max_speed = 2.0  # [m/s]
@@ -98,7 +99,7 @@ class task_config:
         clamped_action[:, 0] += 1.0
 
         processed_action = torch.zeros(
-            (clamped_action.shape[0], 4), device=task_config.device, requires_grad=False
+            (clamped_action.shape[0], 4), device="cuda:0", requires_grad=False
         )
         processed_action[:, 0] = (
             clamped_action[:, 0]
diff --git a/aerial_gym/env_manager/__init__.py b/aerial_gym/env_manager/__init__.py
index 54bfc08..d0f45ca 100644
--- a/aerial_gym/env_manager/__init__.py
+++ b/aerial_gym/env_manager/__init__.py
@@ -4,6 +4,7 @@ from aerial_gym.config.env_config.empty_env import EmptyEnvCfg
 from aerial_gym.config.env_config.forest_env import ForestEnvCfg
 from aerial_gym.config.env_config.env_config_2ms import EnvCfg2Ms
 from aerial_gym.config.env_config.dynamic_environment import DynamicEnvironmentCfg
+from aerial_gym.config.env_config.gate_env import GateEnvCfg
 
 from aerial_gym.registry.env_registry import env_config_registry
 
@@ -12,3 +13,4 @@ env_config_registry.register("empty_env", EmptyEnvCfg)
 env_config_registry.register("forest_env", ForestEnvCfg)
 env_config_registry.register("empty_env_2ms", EnvCfg2Ms)
 env_config_registry.register("dynamic_env", DynamicEnvironmentCfg)
+env_config_registry.register("gate_env", GateEnvCfg)
diff --git a/aerial_gym/examples/dce_rl_navigation/dce_navigation_task.py b/aerial_gym/examples/dce_rl_navigation/dce_navigation_task.py
index b9e9e2e..cf8c93a 100644
--- a/aerial_gym/examples/dce_rl_navigation/dce_navigation_task.py
+++ b/aerial_gym/examples/dce_rl_navigation/dce_navigation_task.py
@@ -10,9 +10,29 @@ import torch
 class DCE_RL_Navigation_Task(NavigationTask):
     def __init__(self, task_config, **kwargs):
         task_config.action_space_dim = 3
-        task_config.curriculum.min_level = 36
-        logger.critical("Hardcoding number of envs to 16 if it is greater than that.")
-        task_config.num_envs = 16 if task_config.num_envs > 16 else task_config.num_envs
+        # Start curriculum learning from easier level for better progression
+        task_config.curriculum.min_level = 15
+
+        # logger.critical("Hardcoding number of envs to 16 if it is greater than that.")
+        # task_config.num_envs = 4 if task_config.num_envs > 16 else task_config.num_envs
+        logger.critical("Setting number of environments to 16 for parallel training.")
+        task_config.num_envs = 16  # Sixteen parallel environments for testing
+        task_config.sim_name = "base_sim"
+        task_config.env_name = "env_with_obstacles"
+        # task_config.env_name = "forest_env"
+
+        # Configure the drone model to match save_camera_stream.py
+        # task_config.robot_name = "base_quadrotor_with_stereo_camera"
+        # task_config.controller_name = "lmf2_velocity_control" 
+
+        # task_config.controller_name = "lee_velocity_control"
+        task_config.robot_name = "lmf2"
+        task_config.controller_name = "lmf2_velocity_control"
+        
+        # Enable viewer for visual training feedback
+        task_config.headless = True
+        logger.critical("Enabling viewer for visual training feedback.")
+        
         super().__init__(task_config=task_config, **kwargs)
 
     # just changing how the observations are returned for the code to work
@@ -32,7 +52,9 @@ class DCE_RL_Navigation_Task(NavigationTask):
         self.task_obs["observations"][:, 7:10] = self.obs_dict["robot_body_linvel"]
         self.task_obs["observations"][:, 10:13] = self.obs_dict["robot_body_angvel"]
         self.task_obs["observations"][:, 13:17] = self.obs_dict["robot_actions"]
-        self.task_obs["observations"][:, 17:81] = self.image_latents
+        # Only use image latents if VAE is enabled
+        if hasattr(self, 'image_latents') and self.task_config.vae_config.use_vae:
+            self.task_obs["observations"][:, 17:81] = self.image_latents
 
 
 @torch.jit.script
diff --git a/aerial_gym/examples/dce_rl_navigation/dce_nn_navigation.py b/aerial_gym/examples/dce_rl_navigation/dce_nn_navigation.py
index bd7da65..06818fe 100644
--- a/aerial_gym/examples/dce_rl_navigation/dce_nn_navigation.py
+++ b/aerial_gym/examples/dce_rl_navigation/dce_nn_navigation.py
@@ -16,17 +16,34 @@ from aerial_gym.examples.dce_rl_navigation.sf_inference_class import NN_Inferenc
 import matplotlib
 import numpy as np
 from PIL import Image
+import os
+import cv2  # Import OpenCV for real-time display
+from datetime import datetime
+from typing import List
 
 
 def sample_command(args):
     use_warp = True
-    headless = args.headless
-    # seg_frames = []
-    # depth_frames = []
-    # merged_image_frames = []
-
+    headless = False  # Force viewer to be enabled to see 3D simulation
+    
+    # Flag to enable real-time visualization
+    show_realtime = not headless
+    
+    # 1) pick an output folder (side-by-side with your script)
+    output_dir = os.path.join(os.getcwd(), "gifs")
+    os.makedirs(output_dir, exist_ok=True)
+    
+    # 2) your frame buffers
+    # seg_frames: List[Image.Image] = []
+    # depth_frames: List[Image.Image] = []
+    merged_image_frames: List[Image.Image] = []
+
+    # Create task with minimal parameters
     rl_task = task_registry.make_task(
-        "dce_navigation_task", seed=42, use_warp=use_warp, headless=headless
+        "dce_navigation_task", 
+        seed=42, 
+        use_warp=use_warp, 
+        headless=headless
     )
     print("Number of environments", rl_task.num_envs)
     command_actions = torch.zeros((rl_task.num_envs, rl_task.task_config.action_space_dim))
@@ -37,6 +54,18 @@ def sample_command(args):
     nn_model.eval()
     nn_model.reset(torch.arange(rl_task.num_envs))
     rl_task.reset()
+    
+    # Create window for real-time display if not headless
+    if show_realtime:
+        # cv2.namedWindow("Depth Camera", cv2.WINDOW_NORMAL)
+        # cv2.namedWindow("Segmentation Camera", cv2.WINDOW_NORMAL)
+        cv2.namedWindow("Combined View", cv2.WINDOW_NORMAL)
+        # Set window sizes
+        # cv2.resizeWindow("Depth Camera", 480, 270)
+        # cv2.resizeWindow("Segmentation Camera", 480, 270)
+        cv2.resizeWindow("Combined View", 480, 540)
+        print("Real-time camera view enabled. Press 'q' to exit.")
+        
     for i in range(0, 50000):
         start_time = time.time()
         obs, rewards, termination, truncation, infos = rl_task.step(command_actions)
@@ -45,7 +74,7 @@ def sample_command(args):
         # print(obs["observations"].shape)
         action = nn_model.get_action(obs)
         # print("Action", action, action.shape)
-        action = torch.tensor(action).expand(rl_task.num_envs, -1)
+        action = torch.as_tensor(action, device=rl_task.device).expand(rl_task.num_envs, -1)
         command_actions[:] = action
 
         reset_ids = (termination + truncation).nonzero(as_tuple=True)
@@ -57,60 +86,96 @@ def sample_command(args):
             print(f"Resetting environments {truncated_envs} due to Timeout")
         nn_model.reset(reset_ids)
 
-    # # Uncomment the below lines to save the frames from an episode as a GIF
-    #     # save obs to file as a .gif
-    #     image1 = (
-    #         255.0 * rl_task.obs_dict["depth_range_pixels"][0, 0].cpu().numpy()
-    #     ).astype(np.uint8)
-    #     seg_image1 = rl_task.obs_dict["segmentation_pixels"][0, 0].cpu().numpy()
-    #     seg_image1[seg_image1 <= 0] = seg_image1[seg_image1 > 0].min()
-    #     seg_image1_normalized = (seg_image1 - seg_image1.min()) / (
-    #         seg_image1.max() - seg_image1.min()
-    #     )
-
-    #     # set colormap to plasma in matplotlib
-    #     seg_image1_normalized_plasma = matplotlib.cm.plasma(seg_image1_normalized)
-    #     seg_image1 = Image.fromarray((seg_image1_normalized_plasma * 255.0).astype(np.uint8))
-
-    #     depth_image1 = Image.fromarray(image1)
-    #     image_4d = np.zeros((image1.shape[0], image1.shape[1], 4))
-    #     image_4d[:, :, 0] = image1
-    #     image_4d[:, :, 1] = image1
-    #     image_4d[:, :, 2] = image1
-    #     image_4d[:, :, 3] = 255.0
-    #     merged_image = np.concatenate((image_4d, seg_image1_normalized_plasma * 255.0), axis=0)
-    #     # save frames to array:
-    #     seg_frames.append(seg_image1)
-    #     depth_frames.append(depth_image1)
-    #     merged_image_frames.append(Image.fromarray(merged_image.astype(np.uint8)))
-    # if termination[0] or truncation[0]:
-    #     print("i", i)
-    #     rl_task.reset()
-    #     # save frames as a gif:
-    #     seg_frames[0].save(
-    #         f"seg_frames_{i}.gif",
-    #         save_all=True,
-    #         append_images=seg_frames[1:],
-    #         duration=100,
-    #         loop=0,
-    #     )
-    #     depth_frames[0].save(
-    #         f"depth_frames_{i}.gif",
-    #         save_all=True,
-    #         append_images=depth_frames[1:],
-    #         duration=100,
-    #         loop=0,
-    #     )
-    #     merged_image_frames[0].save(
-    #         f"merged_image_frames_{i}.gif",
-    #         save_all=True,
-    #         append_images=merged_image_frames[1:],
-    #         duration=100,
-    #         loop=0,
-    #     )
-    #     seg_frames = []
-    #     depth_frames = []
-    #     merged_image_frames = []
+        # Capture frames for visualization
+        image1 = (
+            255.0 * rl_task.obs_dict["depth_range_pixels"][0, 0].cpu().numpy()
+        ).astype(np.uint8)
+        seg_image1 = rl_task.obs_dict["segmentation_pixels"][0, 0].cpu().numpy()
+        
+        # Fix the error when there are no positive values in the segmentation image
+        if np.any(seg_image1 > 0):
+            min_positive = seg_image1[seg_image1 > 0].min()
+            seg_image1[seg_image1 <= 0] = min_positive
+        else:
+            # If no positive values, set all to a small positive value
+            seg_image1[:] = 0.1
+            
+        seg_image1_normalized = (seg_image1 - seg_image1.min()) / (
+            seg_image1.max() - seg_image1.min() + 1e-8
+        )
+
+        # set colormap to plasma in matplotlib
+        seg_image1_normalized_plasma = matplotlib.cm.plasma(seg_image1_normalized)
+        seg_image1_pil = Image.fromarray((seg_image1_normalized_plasma * 255.0).astype(np.uint8))
+
+        depth_image1_pil = Image.fromarray(image1)
+        image_4d = np.zeros((image1.shape[0], image1.shape[1], 4))
+        image_4d[:, :, 0] = image1
+        image_4d[:, :, 1] = image1
+        image_4d[:, :, 2] = image1
+        image_4d[:, :, 3] = 255.0
+        merged_image = np.concatenate((image_4d, seg_image1_normalized_plasma * 255.0), axis=0)
+        
+        # Save frames to array for GIF creation - only keeping merged image
+        # seg_frames.append(seg_image1_pil)
+        # depth_frames.append(depth_image1_pil)
+        merged_image_frames.append(Image.fromarray(merged_image.astype(np.uint8)))
+        
+        # Display frames in real-time windows
+        if show_realtime:
+            # Convert PIL images to OpenCV format (RGB to BGR)
+            # depth_cv = cv2.cvtColor(np.array(depth_image1_pil), cv2.COLOR_RGB2BGR)
+            # seg_cv = cv2.cvtColor(np.array(seg_image1_pil), cv2.COLOR_RGBA2BGR)
+            merged_cv = cv2.cvtColor(merged_image[:,:,0:3].astype(np.uint8), cv2.COLOR_RGB2BGR)
+            
+            # Display images
+            # cv2.imshow("Depth Camera", depth_cv)
+            # cv2.imshow("Segmentation Camera", seg_cv)
+            cv2.imshow("Combined View", merged_cv)
+            
+            # Break loop if 'q' is pressed
+            if cv2.waitKey(1) & 0xFF == ord('q'):
+                print("User requested exit")
+                break
+        
+        # 3) detect end of episode
+        if termination[0] or truncation[0]:
+            # build a unique file-stem (episode index + timestamp)
+            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
+            stem = f"epi{i}_{ts}"
+            
+            # 4) save only the merged GIF
+            # seg_frames[0].save(
+            #     os.path.join(output_dir, f"{stem}_seg.gif"),
+            #     save_all=True,
+            #     append_images=seg_frames[1:],
+            #     duration=100,
+            #     loop=0,
+            # )
+            # depth_frames[0].save(
+            #     os.path.join(output_dir, f"{stem}_depth.gif"),
+            #     save_all=True,
+            #     append_images=depth_frames[1:],
+            #     duration=100,
+            #     loop=0,
+            # )
+            merged_image_frames[0].save(
+                os.path.join(output_dir, f"{stem}_merged.gif"),
+                save_all=True,
+                append_images=merged_image_frames[1:],
+                duration=100,
+                loop=0,
+            )
+            
+            # 5) reset buffers and environments
+            # seg_frames.clear()
+            # depth_frames.clear()
+            merged_image_frames.clear()
+            rl_task.reset()
+
+    # Clean up OpenCV windows when done
+    if show_realtime:
+        cv2.destroyAllWindows()
 
 
 def get_network(num_envs):
@@ -123,12 +188,11 @@ def get_network(num_envs):
 
 
 if __name__ == "__main__":
+    # Modified task registration
     task_registry.register_task(
         task_name="dce_navigation_task",
         task_class=DCE_RL_Navigation_Task,
-        task_config=task_registry.get_task_config(
-            "navigation_task"
-        ),  # same config as navigation task
+        task_config=task_registry.get_task_config("navigation_task"),
     )
     args = get_args()
     sample_command(args)
diff --git a/aerial_gym/examples/dce_rl_navigation/run_trained_navigation_policy.sh b/aerial_gym/examples/dce_rl_navigation/run_trained_navigation_policy.sh
index 9cfe955..3c9f135 100755
--- a/aerial_gym/examples/dce_rl_navigation/run_trained_navigation_policy.sh
+++ b/aerial_gym/examples/dce_rl_navigation/run_trained_navigation_policy.sh
@@ -1,3 +1,10 @@
 #!/usr/bin/env bash
 
+# Set environment variables to configure the drone model and environment
+export SIM_NAME="base_sim"
+export ENV_NAME="env_with_obstacles"
+export ROBOT_NAME="base_quadrotor_with_stereo_camera"
+export CONTROLLER_NAME="lee_velocity_control"
+
+# Run the navigation script with the required parameters
 python3 dce_nn_navigation.py --train_dir=$(pwd)/selected_network --experiment=selected_network --env=test --obs_key="observations" --load_checkpoint_kind=best
diff --git a/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_aerialgym.py b/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_aerialgym.py
index 9b81aba..9a94d08 100644
--- a/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_aerialgym.py
+++ b/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_aerialgym.py
@@ -192,6 +192,26 @@ env_configs = dict(
         wandb_project="quad",
         wandb_user="mihirkulkarni",
     ),
+    n_drone_navigation_task=dict(
+        train_for_env_steps=10000000,
+        encoder_mlp_layers=[512, 256, 128],
+        use_rnn=True,
+        rnn_num_layers=1,
+        rnn_size=512,
+        rnn_type="gru",
+        gamma=0.98,
+        rollout=32,
+        learning_rate=0.0003,
+        lr_schedule_kl_threshold=0.016,
+        batch_size=2048,
+        num_epochs=1,
+        max_grad_norm=4.0,
+        num_batches_per_epoch=4,
+        exploration_loss_coeff=0.001,
+        with_wandb=False,
+        wandb_project="n_drone_navigation",
+        wandb_user="aerial_gym",
+    ),
 )
 
 
diff --git a/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_aerialgym_custom_net.py b/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_aerialgym_custom_net.py
index 5c17be8..96604d1 100644
--- a/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_aerialgym_custom_net.py
+++ b/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_aerialgym_custom_net.py
@@ -36,10 +36,11 @@ class AerialGymVecEnv(gym.Env):
     def __init__(self, aerialgym_env, obs_key):
         self.env = aerialgym_env
         self.num_agents = self.env.num_envs
+        self.is_multiagent = True  # Fix: bypass BatchedMultiAgentWrapper to avoid tensor conversion error
         self.action_space = convert_space(self.env.action_space)
 
-        # isaacgym_examples environments actually return dicts
-        if obs_key == "obs" or obs_key == "observations":
+        # Aerial Gym examples environments actually return dicts
+        if obs_key == "obs":
             self.observation_space = gym.spaces.Dict(convert_space(self.env.observation_space))
         else:
             raise ValueError(f"Unknown observation key: {obs_key}")
@@ -65,6 +66,26 @@ def make_aerialgym_env(
     _env_config=None,
     render_mode: Optional[str] = None,
 ) -> Env:
+    
+    # Import task_registry for this function
+    from aerial_gym.registry.task_registry import task_registry
+    
+    # Ensure DCE navigation task is registered in this subprocess
+    if full_task_name == "dce_navigation_task":
+        try:
+            # Check if task is already registered
+            task_registry.get_task_class(full_task_name)
+        except KeyError:
+            # Task not registered, register it now
+            try:
+                from aerial_gym.examples.dce_rl_navigation.dce_navigation_task import DCE_RL_Navigation_Task
+                from aerial_gym.config.task_config.navigation_task_config import task_config
+                
+                dce_config = task_config()
+                task_registry.register_task("dce_navigation_task", DCE_RL_Navigation_Task, dce_config)
+                print(f"Registered dce_navigation_task in subprocess")
+            except Exception as e:
+                print(f"Failed to register dce_navigation_task in subprocess: {e}")
 
     return AerialGymVecEnv(task_registry.make_task(task_name=full_task_name), "obs")
 
@@ -125,6 +146,7 @@ def override_default_params_func(env, parser):
         adaptive_stddev=True,
         policy_initialization="torch_default",
         env_gpu_actions=True,
+        env_gpu_observations=True,  # Critical: Tell Sample Factory we're providing GPU tensors
         reward_scale=0.1,
         rollout=24,
         max_grad_norm=0.0,
@@ -198,6 +220,29 @@ env_configs = dict(
         wandb_project="quad",
         wandb_user="mihirkulkarni",
     ),
+    dce_navigation_task=dict(
+        train_for_env_steps=10000000,  # 10M steps for DCE navigation
+        encoder_mlp_layers=[256, 128, 64],
+        use_rnn=True,
+        encoder_conv_architecture="convnet_simple",
+        rnn_num_layers=1,
+        rnn_size=64,
+        rnn_type="gru",
+        gamma=0.98,
+        rollout=32,
+        learning_rate=1e-4,
+        lr_schedule_kl_threshold=0.016,
+        batch_size=1024,
+        num_epochs=4,
+        max_grad_norm=1.0,
+        num_batches_per_epoch=4,
+        exploration_loss_coeff=0.0,
+        with_wandb=True,  # Enable Weights & Biases logging
+        wandb_project="aerialgym-dce-navigation",  # Project name
+        wandb_user="ziya-ruso-ucl",  # Your team entity name
+        wandb_group="dce_navigation_training",
+        wandb_tags=["aerial_gym", "dce", "navigation", "sample_factory"],
+    ),
 )
 
 
@@ -238,6 +283,19 @@ def make_custom_encoder(cfg: Config, obs_space: ObsSpace) -> Encoder:
 
 
 def register_aerialgym_custom_components():
+    # Register DCE navigation task
+    try:
+        from aerial_gym.examples.dce_rl_navigation.dce_navigation_task import DCE_RL_Navigation_Task
+        from aerial_gym.config.task_config.navigation_task_config import task_config
+        from aerial_gym.registry.task_registry import task_registry
+        
+        # Use navigation task config as base for DCE navigation
+        dce_config = task_config()
+        task_registry.register_task("dce_navigation_task", DCE_RL_Navigation_Task, dce_config)
+        print("Successfully registered dce_navigation_task")
+    except Exception as e:
+        print(f"Warning: Could not register dce_navigation_task: {e}")
+    
     for env_name in env_configs:
         register_env(env_name, make_aerialgym_env)
 
diff --git a/aerial_gym/robots/__init__.py b/aerial_gym/robots/__init__.py
index e880238..75e9d9e 100644
--- a/aerial_gym/robots/__init__.py
+++ b/aerial_gym/robots/__init__.py
@@ -15,6 +15,7 @@ from aerial_gym.config.robot_config.snakey_config import SnakeyCfg
 from aerial_gym.config.robot_config.snakey5_config import Snakey5Cfg
 from aerial_gym.config.robot_config.snakey6_config import Snakey6Cfg
 from aerial_gym.config.robot_config.tinyprop_config import TinyPropCfg
+from aerial_gym.config.robot_config.x500_config import X500Cfg
 
 from aerial_gym.config.robot_config.lmf2_config import LMF2Cfg
 
@@ -47,6 +48,7 @@ robot_registry.register("lmf1", BaseMultirotor, LMF1Cfg)
 robot_registry.register("lmf2", BaseMultirotor, LMF2Cfg)
 
 robot_registry.register("tinyprop", BaseMultirotor, TinyPropCfg)
+robot_registry.register("x500", BaseMultirotor, X500Cfg)
 
 # register the special robot classes here for working with the examples
 robot_registry.register("base_quadrotor_with_imu", BaseMultirotor, BaseQuadWithImuCfg)
diff --git a/aerial_gym/robots/robot_manager.py b/aerial_gym/robots/robot_manager.py
index 65779e5..a2d51a4 100644
--- a/aerial_gym/robots/robot_manager.py
+++ b/aerial_gym/robots/robot_manager.py
@@ -19,7 +19,7 @@ logger = CustomLogger("robot_manager")
 
 
 class RobotManagerIGE(BaseManager):
-    def __init__(self, global_sim_dict, robot_name, controller_name, device):
+    def __init__(self, global_sim_dict, robot_name, controller_name, device, robot_id=0):
         logger.debug("Initializing RobotManagerIGE")
         self.gym = global_sim_dict["gym"]
         self.sim = global_sim_dict["sim"]
@@ -51,6 +51,9 @@ class RobotManagerIGE(BaseManager):
 
         self.dof_control_mode = "none"
 
+        self.robot_id = robot_id  # Unique identifier for this robot manager
+        self.robot_name_prefix = f"robot_{robot_id}_"  # Prefix for robot names
+
         if self.use_warp == False:
             if self.cfg.sensor_config.enable_camera:
                 logger.debug("Initializing Isaac Gym camera sensor")
@@ -278,7 +281,14 @@ class RobotManagerIGE(BaseManager):
         global_asset_counter,
         env_id,
         segmentation_counter,
+        robot_idx_in_env=None,
     ):
+        if robot_idx_in_env is None:
+            robot_idx_in_env = self.robot_id
+            
+        # Create unique robot name
+        robot_name = f"{self.robot_name_prefix}env_{env_id}"
+        
         self.actor_handle, _ = simulation_env_class.add_asset_to_env(
             self.robot_asset_dict,
             env_handle,
@@ -469,6 +479,12 @@ class RobotManagerIGE(BaseManager):
 
         self.robot_masses[env_id] = self.robot_mass
         self.robot_inertias[env_id] = self.robot_inertia
+        
+        # Store mapping of environment to robot index within that environment
+        if not hasattr(self, 'env_robot_mapping'):
+            self.env_robot_mapping = {}
+        self.env_robot_mapping[env_id] = robot_idx_in_env
+        
         return segmentation_counter + 1
 
     def reset(self):
@@ -499,3 +515,34 @@ class RobotManagerIGE(BaseManager):
             self.warp_sensor.update()
         if self.camera_sensor is not None:
             self.camera_sensor.update()
+
+    def get_observations(self):
+        """
+        Get observations with robot ID information
+        """
+        observations = super().get_observations()  # Get base observations
+        
+        # Add robot ID to observations for identification
+        observations["robot_id"] = self.robot_id
+        observations["robot_position"] = self.get_robot_positions()
+        observations["robot_velocity"] = self.get_robot_velocities()
+        
+        return observations
+        
+    def get_robot_positions(self):
+        """Get current robot positions across all environments"""
+        # Implementation depends on existing robot state access
+        # This should return tensor of shape (num_envs, 3)
+        pass
+        
+    def get_robot_velocities(self):
+        """Get current robot velocities across all environments"""
+        # Implementation depends on existing robot state access
+        # This should return tensor of shape (num_envs, 3)
+        pass
+        
+    def set_robot_positions(self, positions):
+        """Set robot positions for reset"""
+        # Implementation depends on existing robot control interface
+        # positions: tensor of shape (num_envs, 3)
+        pass
diff --git a/aerial_gym/sim2real/vae_image_encoder.py b/aerial_gym/sim2real/vae_image_encoder.py
index 43081b0..c8aaf87 100644
--- a/aerial_gym/sim2real/vae_image_encoder.py
+++ b/aerial_gym/sim2real/vae_image_encoder.py
@@ -35,9 +35,29 @@ class VAEImageEncoder:
         Class to encode the set of images to a latent space. We can return both the means and sampled latent space variables.
         """
         with torch.no_grad():
-            # need to squeeze 0th dimension and unsqueeze 1st dimension to make it work with the VAE
-            image_tensors = image_tensors.squeeze(0).unsqueeze(1)
-            x_res, y_res = image_tensors.shape[-2], image_tensors.shape[-1]
+            # Handle different input tensor shapes more robustly
+            original_shape = image_tensors.shape
+            
+            # If the tensor is 3D [batch, height, width], add channel dimension
+            if len(original_shape) == 3:
+                image_tensors = image_tensors.unsqueeze(1)  # Add channel dimension
+            # If the tensor is 2D [height, width], add batch and channel dimensions
+            elif len(original_shape) == 2:
+                image_tensors = image_tensors.unsqueeze(0).unsqueeze(0)
+            # If the tensor is already 4D [batch, channel, height, width], use as is
+            elif len(original_shape) == 4:
+                pass
+            else:
+                raise ValueError(f"Unexpected tensor shape: {original_shape}. Expected 2D, 3D, or 4D tensor.")
+            
+            # Ensure we have the expected dimensions: [batch, channels, height, width]
+            if len(image_tensors.shape) != 4:
+                raise ValueError(f"After processing, expected 4D tensor, got shape: {image_tensors.shape}")
+            
+            # Get actual image dimensions
+            batch_size, channels, x_res, y_res = image_tensors.shape
+            
+            # Check if we need to interpolate to match expected resolution
             if self.config.image_res != (x_res, y_res):
                 interpolated_image = torch.nn.functional.interpolate(
                     image_tensors,
@@ -46,6 +66,7 @@ class VAEImageEncoder:
                 )
             else:
                 interpolated_image = image_tensors
+            
             z_sampled, means, *_ = self.vae_model.encode(interpolated_image)
         if self.config.return_sampled_latent:
             returned_val = z_sampled
diff --git a/aerial_gym/task/navigation_task/navigation_task.py b/aerial_gym/task/navigation_task/navigation_task.py
index 341920a..d935cfb 100644
--- a/aerial_gym/task/navigation_task/navigation_task.py
+++ b/aerial_gym/task/navigation_task/navigation_task.py
@@ -268,6 +268,17 @@ class NavigationTask(BaseTask):
             logger.warning(
                 f"\nSuccesses: {self.success_aggregate}\nCrashes : {self.crashes_aggregate}\nTimeouts: {self.timeouts_aggregate}"
             )
+            
+            # Add curriculum metrics to infos for wandb logging
+            self.infos["curriculum/level"] = torch.tensor(self.curriculum_level, dtype=torch.float32)
+            self.infos["curriculum/progress"] = torch.tensor(self.curriculum_progress_fraction, dtype=torch.float32)
+            self.infos["curriculum/success_rate"] = torch.tensor(success_rate, dtype=torch.float32)
+            self.infos["curriculum/crash_rate"] = torch.tensor(crash_rate, dtype=torch.float32)
+            self.infos["curriculum/timeout_rate"] = torch.tensor(timeout_rate, dtype=torch.float32)
+            self.infos["curriculum/total_successes"] = torch.tensor(self.success_aggregate, dtype=torch.float32)
+            self.infos["curriculum/total_crashes"] = torch.tensor(self.crashes_aggregate, dtype=torch.float32)
+            self.infos["curriculum/total_timeouts"] = torch.tensor(self.timeouts_aggregate, dtype=torch.float32)
+            
             self.success_aggregate = 0
             self.crashes_aggregate = 0
             self.timeouts_aggregate = 0
@@ -330,6 +341,10 @@ class NavigationTask(BaseTask):
         self.infos["successes"] = successes
         self.infos["timeouts"] = timeouts
         self.infos["crashes"] = self.terminations
+        
+        # Add continuous curriculum tracking for wandb
+        self.infos["curriculum/current_level"] = torch.tensor(self.curriculum_level, dtype=torch.float32)
+        self.infos["curriculum/current_progress"] = torch.tensor(self.curriculum_progress_fraction, dtype=torch.float32)
 
         self.logging_sanity_check(self.infos)
         self.check_and_update_curriculum_level(
diff --git a/aerial_gym/utils/vae/vae_image_encoder.py b/aerial_gym/utils/vae/vae_image_encoder.py
index 8cfc0ae..5cd90cf 100644
--- a/aerial_gym/utils/vae/vae_image_encoder.py
+++ b/aerial_gym/utils/vae/vae_image_encoder.py
@@ -35,9 +35,29 @@ class VAEImageEncoder:
         Class to encode the set of images to a latent space. We can return both the means and sampled latent space variables.
         """
         with torch.no_grad():
-            # need to squeeze 0th dimension and unsqueeze 1st dimension to make it work with the VAE
-            image_tensors = image_tensors.squeeze(0).unsqueeze(1)
-            x_res, y_res = image_tensors.shape[-2], image_tensors.shape[-1]
+            # Handle different input tensor shapes more robustly
+            original_shape = image_tensors.shape
+            
+            # If the tensor is 3D [batch, height, width], add channel dimension
+            if len(original_shape) == 3:
+                image_tensors = image_tensors.unsqueeze(1)  # Add channel dimension
+            # If the tensor is 2D [height, width], add batch and channel dimensions
+            elif len(original_shape) == 2:
+                image_tensors = image_tensors.unsqueeze(0).unsqueeze(0)
+            # If the tensor is already 4D [batch, channel, height, width], use as is
+            elif len(original_shape) == 4:
+                pass
+            else:
+                raise ValueError(f"Unexpected tensor shape: {original_shape}. Expected 2D, 3D, or 4D tensor.")
+            
+            # Ensure we have the expected dimensions: [batch, channels, height, width]
+            if len(image_tensors.shape) != 4:
+                raise ValueError(f"After processing, expected 4D tensor, got shape: {image_tensors.shape}")
+            
+            # Get actual image dimensions
+            batch_size, channels, x_res, y_res = image_tensors.shape
+            
+            # Check if we need to interpolate to match expected resolution
             if self.config.image_res != (x_res, y_res):
                 interpolated_image = torch.nn.functional.interpolate(
                     image_tensors,
@@ -46,6 +66,7 @@ class VAEImageEncoder:
                 )
             else:
                 interpolated_image = image_tensors
+            
             z_sampled, means, *_ = self.vae_model.encode(interpolated_image)
         if self.config.return_sampled_latent:
             returned_val = z_sampled
diff --git a/examples/README_dual_camera_demo.md b/examples/README_dual_camera_demo.md
deleted file mode 100644
index c666e03..0000000
--- a/examples/README_dual_camera_demo.md
+++ /dev/null
@@ -1,80 +0,0 @@
-# Dual Camera Demo
-
-This demo showcases both a static environment camera and a drone with its onboard camera, displaying depth and segmentation outputs from both in real-time.
-
-## Features
-
-- **Single Environment**: Uses 1 environment instead of multiple for clear visualization
-- **Dual Camera System**: 
-  - Drone onboard camera (depth + segmentation)
-  - Static environment cameras positioned inside the chamber:
-    - Overhead view from 8m height (top-down monitoring)  
-    - Corner view from 8m distance, 6m height (security-style perspective)
-- **Dual Visualization**:
-  - Isaac Gym 3D viewer showing the simulation environment with camera markers
-  - Real-time OpenCV windows with side-by-side depth and segmentation images
-- **Camera Markers**: Visual indicators in the 3D simulation:
-  - Green sphere = Overhead camera position
-  - Blue sphere = Side/corner camera position
-- **No RL Training**: Pure visualization demo without any reinforcement learning
-
-## What You'll See
-
-The demo opens both a 3D simulation viewer and three camera windows:
-
-**Isaac Gym 3D Viewer**: 
-- Shows the full simulation environment with the drone flying
-- Green sphere marker indicates overhead camera position
-- Blue sphere marker indicates corner camera position
-- You can navigate the 3D view to see the cameras and drone from different angles
-
-**Camera Windows**:
-1. **Drone Camera - Onboard View**: Shows depth and segmentation from the drone's onboard camera
-2. **Overhead Camera - Top-Down View (8m high)**: Bird's eye view from inside the chamber, 8m above center
-3. **Corner Camera - Side View (Corner of chamber)**: Side perspective from a corner inside the environment chamber
-
-Each window displays:
-- **Left side**: Depth information (grayscale)
-- **Right side**: Segmentation information (colored with plasma colormap)
-
-## Controls
-
-- **q**: Quit the demo
-- **s**: Save current frames to disk
-- **ESC**: Also quits the demo
-
-## Running the Demo
-
-```bash
-cd examples
-python3 dual_camera_demo.py
-```
-
-Or make it executable and run directly:
-```bash
-chmod +x dual_camera_demo.py
-./dual_camera_demo.py
-```
-
-## Output
-
-The demo automatically saves images every 30 frames to a timestamped directory:
-- Combined visualization images (depth + segmentation side by side)
-- Raw depth data as .npy files
-- Raw segmentation data as .npy files
-
-## Technical Details
-
-- Uses single environment configuration for focused observation
-- Static cameras positioned inside the environment chamber for realistic indoor monitoring
-- Uses the DCE Navigation Task configuration which includes camera sensors
-- Implements static environment cameras using the Warp rendering pipeline
-- Drone follows a simple circular movement pattern for demonstration
-- All cameras provide both depth and segmentation information similar to the DCE navigation task
-
-## Requirements
-
-- CUDA-capable GPU (for Warp rendering)
-- OpenCV for visualization
-- Matplotlib for colormap processing
-- All standard Aerial Gym dependencies 
\ No newline at end of file
diff --git a/examples/dual_camera_demo.py b/examples/dual_camera_demo.py
deleted file mode 100755
index ee4a357..0000000
--- a/examples/dual_camera_demo.py
+++ /dev/null
@@ -1,502 +0,0 @@
-#!/usr/bin/env python3
-
-"""
-Dual Camera Demo: Static Environment Camera + Drone Camera
-
-This example demonstrates:
-1. A static environment camera providing overhead/side views
-2. A drone with an onboard camera
-3. Real-time visualization of depth and segmentation outputs from both cameras
-4. No RL training - just visualization of camera outputs
-
-The demo shows depth and segmentation information extraction similar to the DCE navigation task.
-"""
-
-import os
-import time
-import numpy as np
-import cv2
-import matplotlib.pyplot as plt
-import matplotlib.cm
-from PIL import Image
-from datetime import datetime
-from typing import List
-
-def main():
-    print("=" * 70)
-    print("DUAL CAMERA DEMO: Static Environment Camera + Drone Camera")
-    print("=" * 70)
-    
-    # Import Aerial Gym components FIRST (before torch) to avoid IsaacGym conflicts
-    print("Importing Aerial Gym components...")
-    from aerial_gym.registry.task_registry import task_registry
-    from aerial_gym.examples.dce_rl_navigation.dce_navigation_task import DCE_RL_Navigation_Task
-    from aerial_gym.sensors.warp.static_environment_camera import (
-        StaticEnvironmentCamera,
-        OverheadCameraConfig,
-        SideViewCameraConfig
-    )
-    
-    # Import torch AFTER aerial gym components
-    import torch
-    
-    print("All imports successful!")
-    
-    # Get the base navigation task configuration and modify it
-    task_config = task_registry.get_task_config("navigation_task")
-    
-    # Disable VAE processing - we just want raw camera outputs for the demo
-    task_config.vae_config.use_vae = False
-    # Adjust observation space dimension since we're not using VAE latents (64D)
-    task_config.observation_space_dim = 13 + 4  # root_state + action_dim (without latent_dims)
-    print(f"VAE processing disabled: use_vae = {task_config.vae_config.use_vae}")
-    print(f"Observation space dimension adjusted to: {task_config.observation_space_dim}")
-    
-    # Register the DCE navigation task (which has camera enabled)
-    task_registry.register_task(
-        task_name="dual_camera_demo_task",
-        task_class=DCE_RL_Navigation_Task,
-        task_config=task_config,
-    )
-    
-    # Create the navigation task with camera enabled
-    print("Creating navigation task with drone camera...")
-    use_warp = True
-    headless = False  # Enable Isaac Gym viewer to see the simulation
-    
-    rl_task = task_registry.make_task(
-        "dual_camera_demo_task",
-        seed=42,
-        use_warp=use_warp,
-        headless=headless
-    )
-    
-    print(f"Created task with {rl_task.num_envs} environments")
-    device = rl_task.device
-    
-    # Initialize the task to ensure all tensors are properly set up
-    print("Initializing task and resetting environments...")
-    rl_task.reset()
-    
-    # Get mesh IDs for Warp rendering (required for static cameras)
-    mesh_ids_list = rl_task.sim_env.global_tensor_dict.get("CONST_WARP_MESH_ID_LIST")
-    if mesh_ids_list is None:
-        raise ValueError("Warp mesh IDs not available. Make sure use_warp=True in config.")
-    
-    print(f"Mesh IDs type: {type(mesh_ids_list)}, length: {len(mesh_ids_list) if hasattr(mesh_ids_list, '__len__') else 'N/A'}")
-    
-    # Convert mesh_ids list to warp array
-    import warp as wp
-    mesh_ids = wp.array(mesh_ids_list, dtype=wp.uint64, device=device)
-    print(f"Converted mesh IDs to warp array: {mesh_ids.shape}")
-    
-    # Create static environment cameras for comprehensive drone observation
-    print("Creating multiple static environment cameras...")
-    
-    # Camera configurations and storage
-    static_cameras = []
-    camera_pixels = []
-    camera_segmentations = []
-    camera_names = []
-    
-    # Standard camera config
-    def create_camera_config():
-        config = OverheadCameraConfig()
-        config.width = 480
-        config.height = 480
-        return config
-    
-    # 1. Primary overhead camera - center view INSIDE the middle chamber
-    overhead1_config = create_camera_config()
-    overhead1_camera = StaticEnvironmentCamera(
-        camera_config=overhead1_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    overhead1_camera.set_overhead_view(height=2.0)  # Much lower - closer to drone level
-    overhead1_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    overhead1_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    overhead1_camera.set_image_tensors(overhead1_pixels, overhead1_segmentation)
-    
-    static_cameras.append(overhead1_camera)
-    camera_pixels.append(overhead1_pixels)
-    camera_segmentations.append(overhead1_segmentation)
-    camera_names.append("Overhead Center")
-    
-    # 2. Overhead camera - slightly off-center INSIDE the middle chamber  
-    overhead2_config = create_camera_config()
-    overhead2_camera = StaticEnvironmentCamera(
-        camera_config=overhead2_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    # Position offset from center, still inside the middle chamber
-    positions2 = torch.zeros((rl_task.num_envs, 1, 3), device=device)
-    positions2[:, 0, 0] = 1.5   # Small X offset to stay inside chamber
-    positions2[:, 0, 1] = 1.5   # Small Y offset to stay inside chamber
-    positions2[:, 0, 2] = 1.8   # Height much lower - closer to drone level
-    overhead2_camera.set_camera_poses(positions2)  # Uses default downward orientation
-    overhead2_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    overhead2_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    overhead2_camera.set_image_tensors(overhead2_pixels, overhead2_segmentation)
-    
-    static_cameras.append(overhead2_camera)
-    camera_pixels.append(overhead2_pixels)
-    camera_segmentations.append(overhead2_segmentation)
-    camera_names.append("Overhead Offset")
-    
-    # 3. Corner view - positioned INSIDE the middle chamber walls
-    corner1_config = create_camera_config()
-    corner1_camera = StaticEnvironmentCamera(
-        camera_config=corner1_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    corner1_camera.set_side_view(distance=2.0, height=1.5, angle_degrees=45.0)  # Much lower and closer to drone level
-    corner1_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    corner1_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    corner1_camera.set_image_tensors(corner1_pixels, corner1_segmentation)
-    
-    static_cameras.append(corner1_camera)
-    camera_pixels.append(corner1_pixels)
-    camera_segmentations.append(corner1_segmentation)
-    camera_names.append("Corner View")
-    
-    # 4. Opposite corner view - positioned INSIDE the middle chamber walls
-    corner2_config = create_camera_config()
-    corner2_camera = StaticEnvironmentCamera(
-        camera_config=corner2_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    corner2_camera.set_side_view(distance=2.0, height=1.5, angle_degrees=225.0)  # Much lower and closer to drone level
-    corner2_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    corner2_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    corner2_camera.set_image_tensors(corner2_pixels, corner2_segmentation)
-    
-    static_cameras.append(corner2_camera)
-    camera_pixels.append(corner2_pixels)
-    camera_segmentations.append(corner2_segmentation)
-    camera_names.append("Corner View 2")
-    
-    # 5. Mid-level overhead view - lower in the middle chamber
-    overhead3_config = create_camera_config()
-    overhead3_camera = StaticEnvironmentCamera(
-        camera_config=overhead3_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    overhead3_camera.set_overhead_view(height=1.2)  # Very low - almost at drone level
-    overhead3_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    overhead3_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    overhead3_camera.set_image_tensors(overhead3_pixels, overhead3_segmentation)
-    
-    static_cameras.append(overhead3_camera)
-    camera_pixels.append(overhead3_pixels)
-    camera_segmentations.append(overhead3_segmentation)
-    camera_names.append("Overhead Close")
-    
-    # 6. Side view - positioned near chamber wall but looking inward
-    wall_config = create_camera_config()
-    wall_camera = StaticEnvironmentCamera(
-        camera_config=wall_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    wall_camera.set_side_view(distance=1.8, height=1.0, angle_degrees=0.0)  # Very low and close to center
-    wall_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    wall_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    wall_camera.set_image_tensors(wall_pixels, wall_segmentation)
-    
-    static_cameras.append(wall_camera)
-    camera_pixels.append(wall_pixels)
-    camera_segmentations.append(wall_segmentation)
-    camera_names.append("Side View")
-    
-    print(f"Created {len(static_cameras)} static cameras for comprehensive drone observation")
-    
-    print("Static cameras created and configured!")
-    
-    # Add visual markers for static camera positions in the simulation
-    print("Adding visual markers for camera positions...")
-    
-    print("Attempting to add camera markers to Isaac Gym viewer...")
-    try:
-        # Get Isaac Gym objects properly
-        sim_env = rl_task.sim_env
-        ige_manager = sim_env.IGE_env
-        gym = ige_manager.gym
-        sim = ige_manager.sim
-        
-        print(f"Isaac Gym objects acquired. Number of environments: {len(ige_manager.envs) if hasattr(ige_manager, 'envs') else 'Unknown'}")
-        
-        if hasattr(ige_manager, 'envs') and len(ige_manager.envs) > 0:
-            env_handle = ige_manager.envs[0]
-            print(f"Using environment handle: {env_handle}")
-            
-            # Known camera positions based on our settings - hardcoded for debugging
-            marker_positions = [
-                [0.0, 0.0, 2.0],      # Overhead Center
-                [1.5, 1.5, 1.8],      # Overhead Offset
-                [1.41, 1.41, 1.5],    # Corner View (45 degrees, 2.0 distance)
-                [-1.41, -1.41, 1.5],  # Corner View 2 (225 degrees, 2.0 distance)
-                [0.0, 0.0, 1.2],      # Overhead Close
-                [1.8, 0.0, 1.0],      # Side View (0 degrees, 1.8 distance)
-            ]
-            
-            # Bright, contrasting colors for camera markers
-            camera_colors = [
-                gym.Vec3(0.0, 1.0, 0.0),    # BRIGHT GREEN - Overhead Center
-                gym.Vec3(1.0, 1.0, 0.0),    # BRIGHT YELLOW - Overhead Offset  
-                gym.Vec3(1.0, 0.0, 0.0),    # BRIGHT RED - Corner View
-                gym.Vec3(1.0, 0.0, 1.0),    # BRIGHT MAGENTA - Corner View 2
-                gym.Vec3(0.0, 1.0, 1.0),    # BRIGHT CYAN - Overhead Close
-                gym.Vec3(0.0, 0.0, 1.0),    # BRIGHT BLUE - Side View
-            ]
-            
-            print(f"Creating {len(marker_positions)} camera markers with hardcoded positions...")
-            for i, (pos, color, name) in enumerate(zip(marker_positions, camera_colors, camera_names)):
-                print(f"Creating marker {i} ({name}) at position: {pos}")
-                
-                # CREATE HUGE VISIBLE SPHERES
-                sphere_asset = gym.create_sphere(sim, 0.8, {})  # 80cm radius - very large
-                pose = gym.Transform()
-                pose.p = gym.Vec3(pos[0], pos[1], pos[2])
-                actor = gym.create_actor(env_handle, sphere_asset, pose, f"camera_marker_{i}", 0, 0)
-                gym.set_rigid_body_color(env_handle, actor, 0, gym.MESH_VISUAL, color)
-                print(f"✅ Added {name} marker (80cm sphere) at: {pos}")
-            
-            # Also add a reference marker at origin
-            origin_sphere = gym.create_sphere(sim, 0.3, {})
-            origin_pose = gym.Transform()
-            origin_pose.p = gym.Vec3(0.0, 0.0, 0.0)
-            origin_actor = gym.create_actor(env_handle, origin_sphere, origin_pose, "origin_marker", 0, 0)
-            gym.set_rigid_body_color(env_handle, origin_actor, 0, gym.MESH_VISUAL, gym.Vec3(1.0, 1.0, 1.0))  # White
-            print("✅ Added WHITE origin reference marker at (0,0,0)")
-            
-            print("🎯 ALL CAMERA MARKERS CREATED SUCCESSFULLY!")
-        else:
-            print("❌ Warning: Could not access environment handles for camera markers")
-    except Exception as e:
-        print(f"❌ Error adding camera markers: {e}")
-        import traceback
-        traceback.print_exc()
-        print("Continuing without visual markers...")
-    # Create output directory for captured images
-    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
-    output_dir = f"dual_camera_output_{timestamp}"
-    os.makedirs(output_dir, exist_ok=True)
-    print(f"Images will be saved to: {output_dir}")
-    
-    # Set up real-time visualization windows
-    print("Setting up real-time visualization...")
-    
-    # Create windows for drone camera and all static cameras
-    cv2.namedWindow("Drone Camera - Onboard View", cv2.WINDOW_NORMAL)
-    cv2.resizeWindow("Drone Camera - Onboard View", 800, 400)
-    
-    # Create windows for each static camera
-    static_camera_windows = []
-    for i, name in enumerate(camera_names):
-        window_name = f"Static Camera {i+1} - {name}"
-        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
-        cv2.resizeWindow(window_name, 600, 300)  # Smaller windows for multiple cameras
-        static_camera_windows.append(window_name)
-    
-    print("Real-time camera views enabled. Press 'q' to exit, 's' to save images.")
-    print("Note: You'll see both the Isaac Gym viewer and multiple OpenCV camera windows.")
-    print("- Isaac Gym viewer: Shows the 3D simulation with drone and BIG COLORED CAMERA MARKERS")
-    print("- BIG Camera markers (50cm spheres): Green=Center, Yellow=Offset, Red=Corner1, Magenta=Corner2, Cyan=Close, Blue=Side")
-    print(f"- OpenCV windows: {len(static_cameras)+1} total windows showing real-time depth+segmentation")
-    print("- All cameras positioned INSIDE the middle chamber where drone operates")
-    print("- Large bright colored spheres show exactly where each camera is positioned!")
-    
-    # Initialize simple movement commands  
-    command_actions = torch.zeros((rl_task.num_envs, rl_task.task_config.action_space_dim), device=device)
-    
-    # Set initial hovering command to prevent early crashes
-    command_actions[:, 0] = 0.0  # No forward movement initially
-    command_actions[:, 1] = 0.0  # No lateral movement initially  
-    command_actions[:, 2] = 0.0  # No vertical movement initially
-    
-    # Main visualization loop
-    frame_count = 0
-    save_images = False
-    segmentation_warning_shown = False  # To avoid spamming warnings
-    
-    def normalize_segmentation_image(seg_image):
-        """Normalize segmentation image for display"""
-        if np.any(seg_image > 0):
-            min_positive = seg_image[seg_image > 0].min()
-            seg_image[seg_image <= 0] = min_positive
-        else:
-            seg_image[:] = 0.1
-            
-        seg_normalized = (seg_image - seg_image.min()) / (seg_image.max() - seg_image.min() + 1e-8)
-        return seg_normalized
-    
-    def create_combined_image(depth_img, seg_img, title="Camera"):
-        """Create a combined depth + segmentation image"""
-        # Normalize depth image
-        depth_normalized = (depth_img * 255).astype(np.uint8)
-        
-        # Create depth image as 3-channel
-        depth_rgb = cv2.cvtColor(depth_normalized, cv2.COLOR_GRAY2RGB)
-        
-        # Normalize and colorize segmentation
-        seg_normalized = normalize_segmentation_image(seg_img.copy())
-        seg_colored = matplotlib.cm.plasma(seg_normalized)
-        seg_rgb = (seg_colored[:, :, :3] * 255).astype(np.uint8)
-        
-        # Combine images side by side
-        combined = np.hstack([depth_rgb, seg_rgb])
-        
-        # Add title
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, f"{title} - Depth | Segmentation", (10, 30), font, 0.7, (255, 255, 255), 2)
-        
-        return combined
-    
-    try:
-        while True:
-            start_time = time.time()
-            
-            # Simple circular movement pattern (start gentle after initial frames)
-            if frame_count > 50:  # Allow some time for initialization
-                t = (frame_count - 50) * 0.01  # Slower movement
-                command_actions[:, 0] = 0.3 * torch.cos(torch.tensor(t))  # Forward/backward
-                command_actions[:, 1] = 0.2 * torch.sin(torch.tensor(t))  # Left/right
-                command_actions[:, 2] = 0.1 * torch.sin(torch.tensor(t * 0.5))  # Up/down
-            else:
-                # Hover in place for first 50 frames
-                command_actions[:, 0] = 0.0
-                command_actions[:, 1] = 0.0
-                command_actions[:, 2] = 0.0
-            
-            # Step the simulation
-            obs, rewards, termination, truncation, infos = rl_task.step(command_actions)
-            
-            # Capture all static camera images
-            for camera in static_cameras:
-                camera.capture()
-            
-            # Get drone camera images (from obs_dict)
-            drone_depth = rl_task.obs_dict["depth_range_pixels"][0, 0].cpu().numpy()
-            
-            # Check if segmentation is available, otherwise create simulated segmentation
-            if "segmentation_pixels" in rl_task.obs_dict:
-                drone_seg = rl_task.obs_dict["segmentation_pixels"][0, 0].cpu().numpy()
-            else:
-                if not segmentation_warning_shown:
-                    print("Note: Creating simulated segmentation from depth data since segmentation_pixels not available")
-                    segmentation_warning_shown = True
-                # Create simulated segmentation based on depth for visualization
-                # Different depth ranges get different segment IDs
-                drone_seg = np.zeros_like(drone_depth)
-                drone_seg[drone_depth < 0.3] = 1.0  # Close objects
-                drone_seg[(drone_depth >= 0.3) & (drone_depth < 0.6)] = 2.0  # Medium distance
-                drone_seg[(drone_depth >= 0.6) & (drone_depth < 1.0)] = 3.0  # Far objects
-                drone_seg[drone_depth >= 1.0] = 0.5  # Background/walls
-            
-            # Create combined image for drone
-            drone_combined = create_combined_image(drone_depth, drone_seg, "Drone Onboard")
-            cv2.imshow("Drone Camera - Onboard View", drone_combined)
-            
-            # Process and display all static camera images
-            for i, (pixels, segmentation, name, window_name) in enumerate(zip(camera_pixels, camera_segmentations, camera_names, static_camera_windows)):
-                static_depth = pixels[0, 0].cpu().numpy()
-                static_seg = segmentation[0, 0].cpu().numpy()
-                static_combined = create_combined_image(static_depth, static_seg, name)
-                cv2.imshow(window_name, static_combined)
-            
-            # Handle key presses
-            key = cv2.waitKey(1) & 0xFF
-            if key == ord('q'):
-                print("User requested exit")
-                break
-            elif key == ord('s'):
-                save_images = True
-            
-            # Save images every 30 frames or when 's' is pressed
-            if frame_count % 30 == 0 or save_images:
-                print(f"Saving frame {frame_count} from {len(static_cameras)+1} cameras...")
-                
-                # Save drone camera
-                cv2.imwrite(
-                    os.path.join(output_dir, f"drone_combined_frame_{frame_count:04d}.png"),
-                    drone_combined
-                )
-                np.save(
-                    os.path.join(output_dir, f"drone_depth_frame_{frame_count:04d}.npy"),
-                    drone_depth
-                )
-                np.save(
-                    os.path.join(output_dir, f"drone_seg_frame_{frame_count:04d}.npy"),
-                    drone_seg
-                )
-                
-                # Save all static cameras
-                for i, (pixels, segmentation, name) in enumerate(zip(camera_pixels, camera_segmentations, camera_names)):
-                    static_depth = pixels[0, 0].cpu().numpy()
-                    static_seg = segmentation[0, 0].cpu().numpy()
-                    static_combined = create_combined_image(static_depth, static_seg, name)
-                    
-                    # Clean filename from camera name
-                    clean_name = name.lower().replace(" ", "_").replace("(", "").replace(")", "").replace("-", "_")
-                    
-                    cv2.imwrite(
-                        os.path.join(output_dir, f"static_{i+1}_{clean_name}_frame_{frame_count:04d}.png"),
-                        static_combined
-                    )
-                    np.save(
-                        os.path.join(output_dir, f"static_{i+1}_{clean_name}_depth_frame_{frame_count:04d}.npy"),
-                        static_depth
-                    )
-                    np.save(
-                        os.path.join(output_dir, f"static_{i+1}_{clean_name}_seg_frame_{frame_count:04d}.npy"),
-                        static_seg
-                    )
-                
-                save_images = False
-            
-            # Reset environments if needed
-            reset_ids = (termination + truncation).nonzero(as_tuple=True)
-            if torch.any(termination):
-                terminated_envs = termination.nonzero(as_tuple=True)
-                print(f"Resetting environments {terminated_envs} due to termination")
-                rl_task.reset()
-            if torch.any(truncation):
-                truncated_envs = truncation.nonzero(as_tuple=True)
-                print(f"Resetting environments {truncated_envs} due to timeout")
-                rl_task.reset()
-            
-            frame_count += 1
-            
-            # Print FPS info every 100 frames
-            if frame_count % 100 == 0:
-                end_time = time.time()
-                fps = 100 / (end_time - start_time) if end_time > start_time else 0
-                print(f"Frame {frame_count}, FPS: {fps:.1f}")
-    
-    except KeyboardInterrupt:
-        print("\nDemo interrupted by user")
-    
-    finally:
-        # Clean up
-        cv2.destroyAllWindows()
-        print(f"Demo completed. Output saved to: {output_dir}")
-        print("Summary:")
-        print(f"- Total frames processed: {frame_count}")
-        print(f"- Drone camera: Onboard depth + segmentation sensor")
-        print(f"- Static cameras: Overhead (8m high) and corner view (inside chamber)")
-        print(f"- All images saved to: {output_dir}")
-
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/dual_camera_demo_new_env.py b/examples/dual_camera_demo_new_env.py
deleted file mode 100644
index 7d0a406..0000000
--- a/examples/dual_camera_demo_new_env.py
+++ /dev/null
@@ -1,564 +0,0 @@
-#!/usr/bin/env python3
-
-"""
-Dual Drone Camera Demo: Dense Forest Environment with Two Stationary Drones
-
-This example demonstrates:
-1. A dense forest environment with multiple trees, objects, and ground plane
-2. Four static cameras positioned at environment boundaries, all facing center
-3. TWO stationary drones that don't move (hover in place at different positions)
-4. Real-time visualization of depth and segmentation outputs from all 4 boundary cameras
-5. Onboard camera feeds from both drones showing their individual perspectives
-6. No RL training - just visualization of camera outputs
-
-Features:
-- Dense forest environment with 6 trees
-- Ground plane with scattered objects and multiple trees
-- No walls, just trees, objects and ground
-- 4 boundary cameras at congruent marks (N, S, E, W) all facing center
-- 2 stationary drones with different IDs positioned at different locations:
-  * Drone 1: (-2, 0, 1.5) - left side
-  * Drone 2: (2, 0, 1.5) - right side
-- Each drone has its own onboard camera feed
-- Dual-drone surveillance system with 6 total camera views
-"""
-
-import os
-import time
-import numpy as np
-import cv2
-import matplotlib.pyplot as plt
-import matplotlib.cm
-from PIL import Image
-from datetime import datetime
-from typing import List
-
-def main():
-    print("=" * 80)
-    print("DUAL DRONE CAMERA DEMO: Dense Forest Environment with Two Stationary Drones")
-    print("=" * 80)
-    
-    # Import Aerial Gym components FIRST (before torch) to avoid IsaacGym conflicts
-    print("Importing Aerial Gym components...")
-    from aerial_gym.registry.task_registry import task_registry
-    from aerial_gym.task.position_setpoint_task.position_setpoint_task import PositionSetpointTask
-    from aerial_gym.sensors.warp.static_environment_camera import (
-        StaticEnvironmentCamera,
-        OverheadCameraConfig,
-        SideViewCameraConfig
-    )
-    
-    # Import torch AFTER aerial gym components
-    import torch
-    
-    print("All imports successful!")
-    
-    # Create custom environment configuration for dual drones
-    print("Creating dual drone forest environment configuration...")
-    
-    # Get the base position setpoint task configuration and modify it
-    task_config = task_registry.get_task_config("position_setpoint_task")
-    
-    # Configure for dual drone setup in forest environment
-    task_config.env_name = "forest_env"  # Dense forest environment
-    task_config.num_envs = 2  # 2 environments = 2 drones
-    task_config.sim_name = "base_sim"
-    task_config.robot_name = "lmf2"
-    task_config.controller_name = "lmf2_velocity_control"
-    task_config.headless = False  # Enable Isaac Gym viewer
-    task_config.use_warp = True
-    task_config.episode_len_steps = 10000  # Long episode for demo
-    
-    print(f"Task configuration set up for dual drone forest environment")
-    print(f"  - Number of environments (drones): {task_config.num_envs}")
-    print(f"  - Environment type: Dense forest with 6 trees")
-    print(f"  - Robot type: {task_config.robot_name}")
-    
-    # Create the position setpoint task with dual drones
-    print("Creating position setpoint task with dual drone setup...")
-    use_warp = True
-    headless = False  # Enable Isaac Gym viewer to see the simulation
-    
-    rl_task = task_registry.make_task(
-        "position_setpoint_task",
-        seed=42,
-        use_warp=use_warp,
-        headless=headless
-    )
-    
-    print(f"Created task with {rl_task.num_envs} environments (drones)")
-    device = rl_task.device
-    
-    # Initialize the task to ensure all tensors are properly set up
-    print("Initializing task and resetting environments...")
-    rl_task.reset()
-    
-    # Manually set drone positions to ensure they are at different locations
-    print("Setting specific drone positions...")
-    
-    # Define desired drone positions: Drone 1 left, Drone 2 right
-    drone_1_pos = np.array([-2.0, 0.0, 1.5])  # Left side
-    drone_2_pos = np.array([2.0, 0.0, 1.5])   # Right side
-    
-    # Access the root states and manually set positions
-    if hasattr(rl_task, 'root_states') and rl_task.root_states is not None:
-        # Environment 0: Drone 1 at left position
-        rl_task.root_states[0, 0] = drone_1_pos[0]  # X position
-        rl_task.root_states[0, 1] = drone_1_pos[1]  # Y position  
-        rl_task.root_states[0, 2] = drone_1_pos[2]  # Z position
-        
-        # Environment 1: Drone 2 at right position  
-        rl_task.root_states[1, 0] = drone_2_pos[0]  # X position
-        rl_task.root_states[1, 1] = drone_2_pos[1]  # Y position
-        rl_task.root_states[1, 2] = drone_2_pos[2]  # Z position
-        
-        # Reset velocities to zero for both drones
-        rl_task.root_states[0, 7:10] = 0.0  # Linear velocity for drone 1
-        rl_task.root_states[0, 10:13] = 0.0  # Angular velocity for drone 1
-        rl_task.root_states[1, 7:10] = 0.0  # Linear velocity for drone 2
-        rl_task.root_states[1, 10:13] = 0.0  # Angular velocity for drone 2
-        
-        print(f"✅ Set Drone 1 position to: {drone_1_pos}")
-        print(f"✅ Set Drone 2 position to: {drone_2_pos}")
-        
-        # Also try to update robot manager state if available
-        if hasattr(rl_task.sim_env, 'robot_manager') and hasattr(rl_task.sim_env.robot_manager, 'robot'):
-            robot = rl_task.sim_env.robot_manager.robot
-            if hasattr(robot, 'robot_state') and robot.robot_state is not None:
-                robot.robot_state[0, :3] = torch.from_numpy(drone_1_pos).to(device)
-                robot.robot_state[1, :3] = torch.from_numpy(drone_2_pos).to(device)
-                robot.robot_state[0, 7:10] = 0.0  # Zero velocity
-                robot.robot_state[0, 10:13] = 0.0
-                robot.robot_state[1, 7:10] = 0.0  # Zero velocity  
-                robot.robot_state[1, 10:13] = 0.0
-                print("✅ Updated robot manager states as well")
-    
-    # Get drone positions for camera targeting
-    print("Getting drone positions for camera targeting...")
-    drone_positions = []
-    
-    if hasattr(rl_task, 'root_states') and rl_task.root_states is not None:
-        # root_states contains [pos_x, pos_y, pos_z, quat_w, quat_x, quat_y, quat_z, vel_x, vel_y, vel_z, ang_vel_x, ang_vel_y, ang_vel_z]
-        for env_idx in range(rl_task.num_envs):
-            drone_pos = rl_task.root_states[env_idx, :3].cpu().numpy()  # position (x,y,z)
-            drone_positions.append(drone_pos)
-            print(f"Drone {env_idx + 1} position: {drone_pos}")
-    else:
-        # Use the manually set positions as defaults
-        drone_positions = [drone_1_pos, drone_2_pos]
-        print(f"Using manually set drone positions:")
-        for i, pos in enumerate(drone_positions):
-            print(f"  Drone {i + 1}: {pos}")
-    
-    # Check if we have access to warp mesh IDs
-    print("Checking for Warp mesh IDs...")
-    try:
-        mesh_ids_list = rl_task.sim_env.global_tensor_dict.get("CONST_WARP_MESH_ID_LIST")
-        if mesh_ids_list is None or len(mesh_ids_list) == 0:
-            print("WARNING: No Warp mesh IDs found. Creating dummy mesh ID list...")
-            mesh_ids_list = [0]  # Single dummy mesh ID
-        
-        print(f"Mesh IDs type: {type(mesh_ids_list)}, length: {len(mesh_ids_list) if hasattr(mesh_ids_list, '__len__') else 'N/A'}")
-        
-        # Convert mesh_ids list to warp array
-        import warp as wp
-        mesh_ids = wp.array(mesh_ids_list, dtype=wp.uint64, device=device)
-        print(f"Converted mesh IDs to warp array: {mesh_ids.shape}")
-    except Exception as e:
-        print(f"Error accessing mesh IDs: {e}")
-        print("Creating dummy mesh IDs for camera setup...")
-        import warp as wp
-        mesh_ids = wp.array([0], dtype=wp.uint64, device=device)
-    
-    # Create static environment cameras and onboard drone cameras
-    print("Creating static environment cameras and onboard drone cameras...")
-    
-    # Camera configurations and storage
-    static_cameras = []
-    camera_pixels = []
-    camera_segmentations = []
-    camera_names = []
-    
-    # Standard camera config
-    def create_camera_config():
-        config = OverheadCameraConfig()
-        config.width = 480
-        config.height = 480
-        config.horizontal_fov_deg = 80.0  # Good field of view for drone observation
-        return config
-    
-    try:
-        # === 1. BOUNDARY CAMERAS (4 cameras) ===
-        # Define 4 cameras inside environment bounds at congruent positions
-        # Environment bounds: [-5, -5] to [5, 5], position cameras inside bounds
-        # All cameras at same height, facing perpendicular towards center (0, 0, 1.5)
-        
-        camera_height = 2.0  # Same height for all cameras
-        boundary_offset = 1.0  # Position cameras 1m inside the boundaries for visibility
-        
-        # 1. North Camera - north side inside bounds, facing south
-        north_config = create_camera_config()
-        north_camera = StaticEnvironmentCamera(
-            camera_config=north_config,
-            num_envs=1,  # Single environment perspective for boundary cameras
-            mesh_ids_array=mesh_ids,
-            device=device
-        )
-        
-        north_positions = torch.zeros((1, 1, 3), device=device)
-        north_positions[:, 0, 0] = 0.0      # Middle of X axis
-        north_positions[:, 0, 1] = 5.0 - boundary_offset  # North side, inside bounds
-        north_positions[:, 0, 2] = camera_height
-        
-        # Quaternion for looking south (negative Y direction)
-        north_orientations = torch.zeros((1, 1, 4), device=device)
-        north_orientations[:, 0, 0] = 0.0   # x
-        north_orientations[:, 0, 1] = 0.0   # y
-        north_orientations[:, 0, 2] = 1.0   # z (180 degree rotation)
-        north_orientations[:, 0, 3] = 0.0   # w
-        
-        north_camera.set_camera_poses(north_positions, north_orientations)
-        north_pixels = torch.zeros((1, 1, 480, 480), device=device, requires_grad=False)
-        north_segmentation = torch.zeros((1, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-        north_camera.set_image_tensors(north_pixels, north_segmentation)
-        
-        static_cameras.append(north_camera)
-        camera_pixels.append(north_pixels)
-        camera_segmentations.append(north_segmentation)
-        camera_names.append("North Boundary")
-        
-        # 2. South Camera - south side inside bounds, facing north
-        south_config = create_camera_config()
-        south_camera = StaticEnvironmentCamera(
-            camera_config=south_config,
-            num_envs=1,
-            mesh_ids_array=mesh_ids,
-            device=device
-        )
-        
-        south_positions = torch.zeros((1, 1, 3), device=device)
-        south_positions[:, 0, 0] = 0.0      # Middle of X axis
-        south_positions[:, 0, 1] = -5.0 + boundary_offset  # South side, inside bounds
-        south_positions[:, 0, 2] = camera_height
-        
-        # Quaternion for looking north (positive Y direction) - no rotation needed
-        south_orientations = torch.zeros((1, 1, 4), device=device)
-        south_orientations[:, 0, 0] = 0.0   # x
-        south_orientations[:, 0, 1] = 0.0   # y
-        south_orientations[:, 0, 2] = 0.0   # z (no rotation)
-        south_orientations[:, 0, 3] = 1.0   # w
-        
-        south_camera.set_camera_poses(south_positions, south_orientations)
-        south_pixels = torch.zeros((1, 1, 480, 480), device=device, requires_grad=False)
-        south_segmentation = torch.zeros((1, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-        south_camera.set_image_tensors(south_pixels, south_segmentation)
-        
-        static_cameras.append(south_camera)
-        camera_pixels.append(south_pixels)
-        camera_segmentations.append(south_segmentation)
-        camera_names.append("South Boundary")
-        
-        # 3. East Camera - east side inside bounds, facing west
-        east_config = create_camera_config()
-        east_camera = StaticEnvironmentCamera(
-            camera_config=east_config,
-            num_envs=1,
-            mesh_ids_array=mesh_ids,
-            device=device
-        )
-        
-        east_positions = torch.zeros((1, 1, 3), device=device)
-        east_positions[:, 0, 0] = 5.0 - boundary_offset   # East side, inside bounds
-        east_positions[:, 0, 1] = 0.0      # Middle of Y axis
-        east_positions[:, 0, 2] = camera_height
-        
-        # Quaternion for looking west (negative X direction) - 90 degree rotation around Z
-        east_orientations = torch.zeros((1, 1, 4), device=device)
-        east_orientations[:, 0, 0] = 0.0    # x
-        east_orientations[:, 0, 1] = 0.0    # y
-        east_orientations[:, 0, 2] = 0.707  # z (90 degree rotation)
-        east_orientations[:, 0, 3] = 0.707  # w
-        
-        east_camera.set_camera_poses(east_positions, east_orientations)
-        east_pixels = torch.zeros((1, 1, 480, 480), device=device, requires_grad=False)
-        east_segmentation = torch.zeros((1, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-        east_camera.set_image_tensors(east_pixels, east_segmentation)
-        
-        static_cameras.append(east_camera)
-        camera_pixels.append(east_pixels)
-        camera_segmentations.append(east_segmentation)
-        camera_names.append("East Boundary")
-        
-        # 4. West Camera - west side inside bounds, facing east  
-        west_config = create_camera_config()
-        west_camera = StaticEnvironmentCamera(
-            camera_config=west_config,
-            num_envs=1,
-            mesh_ids_array=mesh_ids,
-            device=device
-        )
-        
-        west_positions = torch.zeros((1, 1, 3), device=device)
-        west_positions[:, 0, 0] = -5.0 + boundary_offset  # West side, inside bounds
-        west_positions[:, 0, 1] = 0.0      # Middle of Y axis
-        west_positions[:, 0, 2] = camera_height
-        
-        # Quaternion for looking east (positive X direction) - -90 degree rotation around Z
-        west_orientations = torch.zeros((1, 1, 4), device=device)
-        west_orientations[:, 0, 0] = 0.0    # x
-        west_orientations[:, 0, 1] = 0.0    # y
-        west_orientations[:, 0, 2] = -0.707 # z (-90 degree rotation)
-        west_orientations[:, 0, 3] = 0.707  # w
-        
-        west_camera.set_camera_poses(west_positions, west_orientations)
-        west_pixels = torch.zeros((1, 1, 480, 480), device=device, requires_grad=False)
-        west_segmentation = torch.zeros((1, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-        west_camera.set_image_tensors(west_pixels, west_segmentation)
-        
-        static_cameras.append(west_camera)
-        camera_pixels.append(west_pixels)
-        camera_segmentations.append(west_segmentation)
-        camera_names.append("West Boundary")
-        
-        # === 2. ONBOARD DRONE CAMERAS (2 cameras) ===
-        # Create onboard cameras for each drone, looking forward
-        
-        for drone_idx in range(rl_task.num_envs):
-            drone_pos = drone_positions[drone_idx]
-            
-            # Create onboard camera for this drone
-            onboard_config = create_camera_config()
-            onboard_config.width = 320  # Smaller resolution for onboard cameras
-            onboard_config.height = 240
-            onboard_config.horizontal_fov_deg = 60.0  # Slightly narrower FOV for onboard view
-            
-            onboard_camera = StaticEnvironmentCamera(
-                camera_config=onboard_config,
-                num_envs=1,  # Each drone camera is independent
-                mesh_ids_array=mesh_ids,
-                device=device
-            )
-            
-            # Position camera slightly in front of and above the drone
-            onboard_positions = torch.zeros((1, 1, 3), device=device)
-            onboard_positions[:, 0, 0] = drone_pos[0] + 0.3  # 30cm forward from drone
-            onboard_positions[:, 0, 1] = drone_pos[1]        # Same Y position
-            onboard_positions[:, 0, 2] = drone_pos[2] + 0.1  # 10cm above drone
-            
-            # Quaternion for looking forward (positive X direction for drone's forward view)
-            onboard_orientations = torch.zeros((1, 1, 4), device=device)
-            onboard_orientations[:, 0, 0] = 0.0   # x
-            onboard_orientations[:, 0, 1] = 0.0   # y
-            onboard_orientations[:, 0, 2] = 0.0   # z (no rotation - looking forward)
-            onboard_orientations[:, 0, 3] = 1.0   # w
-            
-            onboard_camera.set_camera_poses(onboard_positions, onboard_orientations)
-            onboard_pixels = torch.zeros((1, 1, 240, 320), device=device, requires_grad=False)
-            onboard_segmentation = torch.zeros((1, 1, 240, 320), dtype=torch.int32, device=device, requires_grad=False)
-            onboard_camera.set_image_tensors(onboard_pixels, onboard_segmentation)
-        
-            static_cameras.append(onboard_camera)
-            camera_pixels.append(onboard_pixels)
-            camera_segmentations.append(onboard_segmentation)
-            camera_names.append(f"Drone {drone_idx + 1} Onboard")
-        
-        print("Static environment cameras and onboard drone cameras created successfully!")
-        
-        # Camera positions information
-        print("📍 CAMERA SYSTEM OVERVIEW:")
-        print("   BOUNDARY CAMERAS (4x 480x480):")
-        print("   • North Camera: (0, 4.0, 2.0) - looking SOUTH toward center")
-        print("     🟢 GREEN CUBE marker at (0, 3.0, 2.5)")
-        print("   • South Camera: (0, -4.0, 2.0) - looking NORTH toward center")
-        print("     🔴 RED CUBE marker at (0, -3.0, 2.5)") 
-        print("   • East Camera: (4.0, 0, 2.0) - looking WEST toward center")
-        print("     🔵 BLUE CUBE marker at (3.0, 0, 2.5)")
-        print("   • West Camera: (-4.0, 0, 2.0) - looking EAST toward center")
-        print("     🟡 YELLOW CUBE marker at (-3.0, 0, 2.5)")
-        print("")
-        print("   ONBOARD DRONE CAMERAS (2x 320x240):")
-        for i, pos in enumerate(drone_positions):
-            print(f"   • Drone {i+1} Onboard: ({pos[0]+0.3:.1f}, {pos[1]:.1f}, {pos[2]+0.1:.1f}) - looking FORWARD")
-        print("")
-        print("   DRONE POSITIONS:")
-        for i, pos in enumerate(drone_positions):
-            print(f"   • Drone {i+1}: ({pos[0]:.1f}, {pos[1]:.1f}, {pos[2]:.1f})")
-        print("")
-        print("   Look for the COLORED CUBE MARKERS in the 3D viewer!")
-        
-    except Exception as e:
-        print(f"Error creating cameras: {e}")
-        print("Continuing with empty camera list - you'll only see the Isaac Gym viewer.")
-        static_cameras = []
-        camera_pixels = []
-        camera_segmentations = []
-        camera_names = []
-    
-    # Create output directory for captured images
-    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
-    output_dir = f"dual_drone_output_{timestamp}"
-    os.makedirs(output_dir, exist_ok=True)
-    print(f"Images will be saved to: {output_dir}")
-    
-    # Set up real-time visualization windows only if we have cameras
-    if static_cameras:
-        print("Setting up real-time visualization with 6 camera windows...")
-        cv2.namedWindow("North Boundary - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        cv2.namedWindow("South Boundary - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        cv2.namedWindow("East Boundary - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        cv2.namedWindow("West Boundary - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        cv2.namedWindow("Drone 1 Onboard - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        cv2.namedWindow("Drone 2 Onboard - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        
-        # Resize windows for better layout
-        cv2.resizeWindow("North Boundary - Depth & Segmentation", 800, 400)
-        cv2.resizeWindow("South Boundary - Depth & Segmentation", 800, 400)
-        cv2.resizeWindow("East Boundary - Depth & Segmentation", 800, 400)
-        cv2.resizeWindow("West Boundary - Depth & Segmentation", 800, 400)
-        cv2.resizeWindow("Drone 1 Onboard - Depth & Segmentation", 640, 240)
-        cv2.resizeWindow("Drone 2 Onboard - Depth & Segmentation", 640, 240)
-        
-        print("Real-time camera views enabled. Press 'q' to exit, 's' to save images.")
-    else:
-        print("No cameras available - only Isaac Gym viewer will be shown.")
-        print("You can still see both stationary drones in the Isaac Gym viewer window.")
-        print("Press 'q' in the console to exit.")
-    
-    print("Both drones will remain stationary (hover in place)")
-    
-    # Initialize stationary hover commands - both drones stay in place
-    command_actions = torch.zeros((rl_task.num_envs, rl_task.task_config.action_space_dim), device=device)
-    
-    # Set to hover commands (all zeros for stationary hover)
-    for drone_idx in range(rl_task.num_envs):
-        command_actions[drone_idx, 0] = 0.0  # No forward movement
-        command_actions[drone_idx, 1] = 0.0  # No lateral movement  
-        command_actions[drone_idx, 2] = 0.0  # No vertical movement
-        command_actions[drone_idx, 3] = 0.0  # No yaw rotation
-    
-    # Main visualization loop
-    frame_count = 0
-    save_images = False
-    
-    def normalize_segmentation_image(seg_image):
-        """Normalize segmentation image for display"""
-        if np.any(seg_image > 0):
-            min_positive = seg_image[seg_image > 0].min()
-            seg_image[seg_image <= 0] = min_positive
-        else:
-            seg_image[:] = 0.1
-            
-        seg_normalized = (seg_image - seg_image.min()) / (seg_image.max() - seg_image.min() + 1e-8)
-        return seg_normalized
-    
-    def create_combined_image(depth_img, seg_img, title="Camera"):
-        """Create a combined depth + segmentation image"""
-        # Normalize depth image
-        depth_normalized = (depth_img * 255).astype(np.uint8)
-        
-        # Create depth image as 3-channel
-        depth_rgb = cv2.cvtColor(depth_normalized, cv2.COLOR_GRAY2RGB)
-        
-        # Normalize and colorize segmentation
-        seg_normalized = normalize_segmentation_image(seg_img.copy())
-        seg_colored = matplotlib.cm.plasma(seg_normalized)
-        seg_rgb = (seg_colored[:, :, :3] * 255).astype(np.uint8)
-        
-        # Combine images side by side
-        combined = np.hstack([depth_rgb, seg_rgb])
-        
-        # Add title
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, f"{title} - Depth | Segmentation", (10, 30), font, 0.7, (255, 255, 255), 2)
-        
-        return combined
-    
-    print("\nStarting main loop...")
-    print("Watch the Isaac Gym viewer window to see both stationary drones!")
-    if static_cameras:
-        print("Additional camera windows should show:")
-        print("  - 4 boundary cameras showing overview of both drones")
-        print("  - 2 onboard cameras showing each drone's forward view")
-    
-    try:
-        while True:
-            start_time = time.time()
-            
-            # Keep both drones stationary - no movement commands
-            # Actions remain at zero for hover
-            
-            # Step the simulation with stationary commands
-            obs, rewards, termination, truncation, infos = rl_task.step(command_actions)
-            
-            # Only process cameras if they exist and are working
-            if static_cameras:
-                try:
-                    # Capture all static camera images
-                    for camera in static_cameras:
-                        camera.capture()
-                    
-                    # Get static camera images
-                    camera_images = []
-                    for i, (pixels, segmentation, name) in enumerate(zip(camera_pixels, camera_segmentations, camera_names)):
-                        depth = pixels[0, 0].cpu().numpy()
-                        seg = segmentation[0, 0].cpu().numpy()
-                        combined = create_combined_image(depth, seg, name)
-                        camera_images.append(combined)
-                    
-                    # Display all images
-                    cv2.imshow("North Boundary - Depth & Segmentation", camera_images[0])
-                    cv2.imshow("South Boundary - Depth & Segmentation", camera_images[1])
-                    cv2.imshow("East Boundary - Depth & Segmentation", camera_images[2])
-                    cv2.imshow("West Boundary - Depth & Segmentation", camera_images[3])
-                    cv2.imshow("Drone 1 Onboard - Depth & Segmentation", camera_images[4])
-                    cv2.imshow("Drone 2 Onboard - Depth & Segmentation", camera_images[5])
-                    
-                    # Save images if requested
-                    if save_images:
-                        # Save all cameras
-                        for i, (combined, name) in enumerate(zip(camera_images, camera_names)):
-                            safe_name = name.lower().replace(" ", "_")
-                            cv2.imwrite(f"{output_dir}/{safe_name}_combined_frame_{frame_count:04d}.png", combined)
-                        
-                        print(f"Saved frame {frame_count}")
-                    
-                    # Handle keyboard input for camera windows
-                    key = cv2.waitKey(1) & 0xFF
-                    if key == ord('q'):
-                        print("Quit requested by user")
-                        break
-                    elif key == ord('s'):
-                        save_images = not save_images
-                        print(f"Image saving {'enabled' if save_images else 'disabled'}")
-                        
-                except Exception as e:
-                    print(f"Error processing cameras: {e}")
-                    # Continue the simulation loop even if cameras fail
-            else:
-                # No cameras - just run simulation and check for quit in console
-                # Check for keyboard interrupt to quit
-                pass
-            
-            frame_count += 1
-            
-            # Print frame rate every 100 frames
-            if frame_count % 100 == 0:
-                elapsed_time = time.time() - start_time
-                fps = 1.0 / elapsed_time if elapsed_time > 0 else 0
-                print(f"Frame {frame_count}, FPS: {fps:.1f} - Both drones hovering in place")
-                if not static_cameras:
-                    print("  (No camera windows - check Isaac Gym viewer for dual drone visualization)")
-    
-    except KeyboardInterrupt:
-        print("\nInterrupted by user")
-    
-    finally:
-        print("Cleaning up...")
-        if static_cameras:
-            cv2.destroyAllWindows()
-        print(f"Demo completed. {frame_count} frames processed.")
-        if save_images and static_cameras:
-            print(f"Images saved to: {output_dir}")
-
-if __name__ == "__main__":
-    main()
diff --git a/examples/dual_camera_demo_new_env_dualdrone.py b/examples/dual_camera_demo_new_env_dualdrone.py
deleted file mode 100644
index 53c9f3a..0000000
--- a/examples/dual_camera_demo_new_env_dualdrone.py
+++ /dev/null
@@ -1,564 +0,0 @@
-#!/usr/bin/env python3
-
-"""
-Dual Drone Camera Demo: Dense Forest Environment with Two Stationary Drones
-
-This example demonstrates:
-1. A dense forest environment with multiple trees, objects, and ground plane
-2. Four static cameras positioned at environment boundaries, all facing center
-3. TWO stationary drones that don't move (hover in place at different positions)
-4. Real-time visualization of depth and segmentation outputs from all 4 boundary cameras
-5. Onboard camera feeds from both drones showing their individual perspectives
-6. No RL training - just visualization of camera outputs
-
-Features:
-- Dense forest environment with 6 trees
-- Ground plane with scattered objects and multiple trees
-- No walls, just trees, objects and ground
-- 4 boundary cameras at congruent marks (N, S, E, W) all facing center
-- 2 stationary drones with different IDs positioned at different locations:
-  * Drone 1: (-2, 0, 1.5) - left side
-  * Drone 2: (2, 0, 1.5) - right side
-- Each drone has its own onboard camera feed
-- Dual-drone surveillance system with 6 total camera views
-"""
-
-import os
-import time
-import numpy as np
-import cv2
-import matplotlib.pyplot as plt
-import matplotlib.cm
-from PIL import Image
-from datetime import datetime
-from typing import List
-
-def main():
-    print("=" * 80)
-    print("DUAL DRONE CAMERA DEMO: Dense Forest Environment with Two Stationary Drones")
-    print("=" * 80)
-    
-    # Import Aerial Gym components FIRST (before torch) to avoid IsaacGym conflicts
-    print("Importing Aerial Gym components...")
-    from aerial_gym.registry.task_registry import task_registry
-    from aerial_gym.task.position_setpoint_task.position_setpoint_task import PositionSetpointTask
-    from aerial_gym.sensors.warp.static_environment_camera import (
-        StaticEnvironmentCamera,
-        OverheadCameraConfig,
-        SideViewCameraConfig
-    )
-    
-    # Import torch AFTER aerial gym components
-    import torch
-    
-    print("All imports successful!")
-    
-    # Create custom environment configuration for dual drones
-    print("Creating dual drone forest environment configuration...")
-    
-    # Get the base position setpoint task configuration and modify it
-    task_config = task_registry.get_task_config("position_setpoint_task")
-    
-    # Configure for dual drone setup in forest environment
-    task_config.env_name = "forest_env"  # Dense forest environment
-    task_config.num_envs = 2  # 2 environments = 2 drones
-    task_config.sim_name = "base_sim"
-    task_config.robot_name = "lmf2"
-    task_config.controller_name = "lmf2_velocity_control"
-    task_config.headless = False  # Enable Isaac Gym viewer
-    task_config.use_warp = True
-    task_config.episode_len_steps = 10000  # Long episode for demo
-    
-    print(f"Task configuration set up for dual drone forest environment")
-    print(f"  - Number of environments (drones): {task_config.num_envs}")
-    print(f"  - Environment type: Dense forest with 6 trees")
-    print(f"  - Robot type: {task_config.robot_name}")
-    
-    # Create the position setpoint task with dual drones
-    print("Creating position setpoint task with dual drone setup...")
-    use_warp = True
-    headless = False  # Enable Isaac Gym viewer to see the simulation
-    
-    rl_task = task_registry.make_task(
-        "position_setpoint_task",
-        seed=42,
-        use_warp=use_warp,
-        headless=headless
-    )
-    
-    print(f"Created task with {rl_task.num_envs} environments (drones)")
-    device = rl_task.device
-    
-    # Initialize the task to ensure all tensors are properly set up
-    print("Initializing task and resetting environments...")
-    rl_task.reset()
-    
-    # Manually set drone positions to ensure they are at different locations
-    print("Setting specific drone positions...")
-    
-    # Define desired drone positions: Drone 1 left, Drone 2 right
-    drone_1_pos = np.array([-2.0, 0.0, 1.5])  # Left side
-    drone_2_pos = np.array([2.0, 0.0, 1.5])   # Right side
-    
-    # Access the root states and manually set positions
-    if hasattr(rl_task, 'root_states') and rl_task.root_states is not None:
-        # Environment 0: Drone 1 at left position
-        rl_task.root_states[0, 0] = drone_1_pos[0]  # X position
-        rl_task.root_states[0, 1] = drone_1_pos[1]  # Y position  
-        rl_task.root_states[0, 2] = drone_1_pos[2]  # Z position
-        
-        # Environment 1: Drone 2 at right position  
-        rl_task.root_states[1, 0] = drone_2_pos[0]  # X position
-        rl_task.root_states[1, 1] = drone_2_pos[1]  # Y position
-        rl_task.root_states[1, 2] = drone_2_pos[2]  # Z position
-        
-        # Reset velocities to zero for both drones
-        rl_task.root_states[0, 7:10] = 0.0  # Linear velocity for drone 1
-        rl_task.root_states[0, 10:13] = 0.0  # Angular velocity for drone 1
-        rl_task.root_states[1, 7:10] = 0.0  # Linear velocity for drone 2
-        rl_task.root_states[1, 10:13] = 0.0  # Angular velocity for drone 2
-        
-        print(f"✅ Set Drone 1 position to: {drone_1_pos}")
-        print(f"✅ Set Drone 2 position to: {drone_2_pos}")
-        
-        # Also try to update robot manager state if available
-        if hasattr(rl_task.sim_env, 'robot_manager') and hasattr(rl_task.sim_env.robot_manager, 'robot'):
-            robot = rl_task.sim_env.robot_manager.robot
-            if hasattr(robot, 'robot_state') and robot.robot_state is not None:
-                robot.robot_state[0, :3] = torch.from_numpy(drone_1_pos).to(device)
-                robot.robot_state[1, :3] = torch.from_numpy(drone_2_pos).to(device)
-                robot.robot_state[0, 7:10] = 0.0  # Zero velocity
-                robot.robot_state[0, 10:13] = 0.0
-                robot.robot_state[1, 7:10] = 0.0  # Zero velocity  
-                robot.robot_state[1, 10:13] = 0.0
-                print("✅ Updated robot manager states as well")
-    
-    # Get drone positions for camera targeting
-    print("Getting drone positions for camera targeting...")
-    drone_positions = []
-    
-    if hasattr(rl_task, 'root_states') and rl_task.root_states is not None:
-        # root_states contains [pos_x, pos_y, pos_z, quat_w, quat_x, quat_y, quat_z, vel_x, vel_y, vel_z, ang_vel_x, ang_vel_y, ang_vel_z]
-        for env_idx in range(rl_task.num_envs):
-            drone_pos = rl_task.root_states[env_idx, :3].cpu().numpy()  # position (x,y,z)
-            drone_positions.append(drone_pos)
-            print(f"Drone {env_idx + 1} position: {drone_pos}")
-    else:
-        # Use the manually set positions as defaults
-        drone_positions = [drone_1_pos, drone_2_pos]
-        print(f"Using manually set drone positions:")
-        for i, pos in enumerate(drone_positions):
-            print(f"  Drone {i + 1}: {pos}")
-    
-    # Check if we have access to warp mesh IDs
-    print("Checking for Warp mesh IDs...")
-    try:
-        mesh_ids_list = rl_task.sim_env.global_tensor_dict.get("CONST_WARP_MESH_ID_LIST")
-        if mesh_ids_list is None or len(mesh_ids_list) == 0:
-            print("WARNING: No Warp mesh IDs found. Creating dummy mesh ID list...")
-            mesh_ids_list = [0]  # Single dummy mesh ID
-        
-        print(f"Mesh IDs type: {type(mesh_ids_list)}, length: {len(mesh_ids_list) if hasattr(mesh_ids_list, '__len__') else 'N/A'}")
-        
-        # Convert mesh_ids list to warp array
-        import warp as wp
-        mesh_ids = wp.array(mesh_ids_list, dtype=wp.uint64, device=device)
-        print(f"Converted mesh IDs to warp array: {mesh_ids.shape}")
-    except Exception as e:
-        print(f"Error accessing mesh IDs: {e}")
-        print("Creating dummy mesh IDs for camera setup...")
-        import warp as wp
-        mesh_ids = wp.array([0], dtype=wp.uint64, device=device)
-    
-    # Create static environment cameras and onboard drone cameras
-    print("Creating static environment cameras and onboard drone cameras...")
-    
-    # Camera configurations and storage
-    static_cameras = []
-    camera_pixels = []
-    camera_segmentations = []
-    camera_names = []
-    
-    # Standard camera config
-    def create_camera_config():
-        config = OverheadCameraConfig()
-        config.width = 480
-        config.height = 480
-        config.horizontal_fov_deg = 80.0  # Good field of view for drone observation
-        return config
-    
-    try:
-        # === 1. BOUNDARY CAMERAS (4 cameras) ===
-        # Define 4 cameras inside environment bounds at congruent positions
-        # Environment bounds: [-5, -5] to [5, 5], position cameras inside bounds
-        # All cameras at same height, facing perpendicular towards center (0, 0, 1.5)
-        
-        camera_height = 2.0  # Same height for all cameras
-        boundary_offset = 1.0  # Position cameras 1m inside the boundaries for visibility
-        
-        # 1. North Camera - north side inside bounds, facing south
-        north_config = create_camera_config()
-        north_camera = StaticEnvironmentCamera(
-            camera_config=north_config,
-            num_envs=1,  # Single environment perspective for boundary cameras
-            mesh_ids_array=mesh_ids,
-            device=device
-        )
-        
-        north_positions = torch.zeros((1, 1, 3), device=device)
-        north_positions[:, 0, 0] = 0.0      # Middle of X axis
-        north_positions[:, 0, 1] = 5.0 - boundary_offset  # North side, inside bounds
-        north_positions[:, 0, 2] = camera_height
-        
-        # Quaternion for looking south (negative Y direction)
-        north_orientations = torch.zeros((1, 1, 4), device=device)
-        north_orientations[:, 0, 0] = 0.0   # x
-        north_orientations[:, 0, 1] = 0.0   # y
-        north_orientations[:, 0, 2] = 1.0   # z (180 degree rotation)
-        north_orientations[:, 0, 3] = 0.0   # w
-        
-        north_camera.set_camera_poses(north_positions, north_orientations)
-        north_pixels = torch.zeros((1, 1, 480, 480), device=device, requires_grad=False)
-        north_segmentation = torch.zeros((1, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-        north_camera.set_image_tensors(north_pixels, north_segmentation)
-        
-        static_cameras.append(north_camera)
-        camera_pixels.append(north_pixels)
-        camera_segmentations.append(north_segmentation)
-        camera_names.append("North Boundary")
-        
-        # 2. South Camera - south side inside bounds, facing north
-        south_config = create_camera_config()
-        south_camera = StaticEnvironmentCamera(
-            camera_config=south_config,
-            num_envs=1,
-            mesh_ids_array=mesh_ids,
-            device=device
-        )
-        
-        south_positions = torch.zeros((1, 1, 3), device=device)
-        south_positions[:, 0, 0] = 0.0      # Middle of X axis
-        south_positions[:, 0, 1] = -5.0 + boundary_offset  # South side, inside bounds
-        south_positions[:, 0, 2] = camera_height
-        
-        # Quaternion for looking north (positive Y direction) - no rotation needed
-        south_orientations = torch.zeros((1, 1, 4), device=device)
-        south_orientations[:, 0, 0] = 0.0   # x
-        south_orientations[:, 0, 1] = 0.0   # y
-        south_orientations[:, 0, 2] = 0.0   # z (no rotation)
-        south_orientations[:, 0, 3] = 1.0   # w
-        
-        south_camera.set_camera_poses(south_positions, south_orientations)
-        south_pixels = torch.zeros((1, 1, 480, 480), device=device, requires_grad=False)
-        south_segmentation = torch.zeros((1, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-        south_camera.set_image_tensors(south_pixels, south_segmentation)
-        
-        static_cameras.append(south_camera)
-        camera_pixels.append(south_pixels)
-        camera_segmentations.append(south_segmentation)
-        camera_names.append("South Boundary")
-        
-        # 3. East Camera - east side inside bounds, facing west
-        east_config = create_camera_config()
-        east_camera = StaticEnvironmentCamera(
-            camera_config=east_config,
-            num_envs=1,
-            mesh_ids_array=mesh_ids,
-            device=device
-        )
-        
-        east_positions = torch.zeros((1, 1, 3), device=device)
-        east_positions[:, 0, 0] = 5.0 - boundary_offset   # East side, inside bounds
-        east_positions[:, 0, 1] = 0.0      # Middle of Y axis
-        east_positions[:, 0, 2] = camera_height
-        
-        # Quaternion for looking west (negative X direction) - 90 degree rotation around Z
-        east_orientations = torch.zeros((1, 1, 4), device=device)
-        east_orientations[:, 0, 0] = 0.0    # x
-        east_orientations[:, 0, 1] = 0.0    # y
-        east_orientations[:, 0, 2] = 0.707  # z (90 degree rotation)
-        east_orientations[:, 0, 3] = 0.707  # w
-        
-        east_camera.set_camera_poses(east_positions, east_orientations)
-        east_pixels = torch.zeros((1, 1, 480, 480), device=device, requires_grad=False)
-        east_segmentation = torch.zeros((1, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-        east_camera.set_image_tensors(east_pixels, east_segmentation)
-        
-        static_cameras.append(east_camera)
-        camera_pixels.append(east_pixels)
-        camera_segmentations.append(east_segmentation)
-        camera_names.append("East Boundary")
-        
-        # 4. West Camera - west side inside bounds, facing east  
-        west_config = create_camera_config()
-        west_camera = StaticEnvironmentCamera(
-            camera_config=west_config,
-            num_envs=1,
-            mesh_ids_array=mesh_ids,
-            device=device
-        )
-        
-        west_positions = torch.zeros((1, 1, 3), device=device)
-        west_positions[:, 0, 0] = -5.0 + boundary_offset  # West side, inside bounds
-        west_positions[:, 0, 1] = 0.0      # Middle of Y axis
-        west_positions[:, 0, 2] = camera_height
-        
-        # Quaternion for looking east (positive X direction) - -90 degree rotation around Z
-        west_orientations = torch.zeros((1, 1, 4), device=device)
-        west_orientations[:, 0, 0] = 0.0    # x
-        west_orientations[:, 0, 1] = 0.0    # y
-        west_orientations[:, 0, 2] = -0.707 # z (-90 degree rotation)
-        west_orientations[:, 0, 3] = 0.707  # w
-        
-        west_camera.set_camera_poses(west_positions, west_orientations)
-        west_pixels = torch.zeros((1, 1, 480, 480), device=device, requires_grad=False)
-        west_segmentation = torch.zeros((1, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-        west_camera.set_image_tensors(west_pixels, west_segmentation)
-        
-        static_cameras.append(west_camera)
-        camera_pixels.append(west_pixels)
-        camera_segmentations.append(west_segmentation)
-        camera_names.append("West Boundary")
-        
-        # === 2. ONBOARD DRONE CAMERAS (2 cameras) ===
-        # Create onboard cameras for each drone, looking forward
-        
-        for drone_idx in range(rl_task.num_envs):
-            drone_pos = drone_positions[drone_idx]
-            
-            # Create onboard camera for this drone
-            onboard_config = create_camera_config()
-            onboard_config.width = 320  # Smaller resolution for onboard cameras
-            onboard_config.height = 240
-            onboard_config.horizontal_fov_deg = 60.0  # Slightly narrower FOV for onboard view
-            
-            onboard_camera = StaticEnvironmentCamera(
-                camera_config=onboard_config,
-                num_envs=1,  # Each drone camera is independent
-                mesh_ids_array=mesh_ids,
-                device=device
-            )
-            
-            # Position camera slightly in front of and above the drone
-            onboard_positions = torch.zeros((1, 1, 3), device=device)
-            onboard_positions[:, 0, 0] = drone_pos[0] + 0.3  # 30cm forward from drone
-            onboard_positions[:, 0, 1] = drone_pos[1]        # Same Y position
-            onboard_positions[:, 0, 2] = drone_pos[2] + 0.1  # 10cm above drone
-            
-            # Quaternion for looking forward (positive X direction for drone's forward view)
-            onboard_orientations = torch.zeros((1, 1, 4), device=device)
-            onboard_orientations[:, 0, 0] = 0.0   # x
-            onboard_orientations[:, 0, 1] = 0.0   # y
-            onboard_orientations[:, 0, 2] = 0.0   # z (no rotation - looking forward)
-            onboard_orientations[:, 0, 3] = 1.0   # w
-            
-            onboard_camera.set_camera_poses(onboard_positions, onboard_orientations)
-            onboard_pixels = torch.zeros((1, 1, 240, 320), device=device, requires_grad=False)
-            onboard_segmentation = torch.zeros((1, 1, 240, 320), dtype=torch.int32, device=device, requires_grad=False)
-            onboard_camera.set_image_tensors(onboard_pixels, onboard_segmentation)
-            
-            static_cameras.append(onboard_camera)
-            camera_pixels.append(onboard_pixels)
-            camera_segmentations.append(onboard_segmentation)
-            camera_names.append(f"Drone {drone_idx + 1} Onboard")
-        
-        print("Static environment cameras and onboard drone cameras created successfully!")
-        
-        # Camera positions information
-        print("📍 CAMERA SYSTEM OVERVIEW:")
-        print("   BOUNDARY CAMERAS (4x 480x480):")
-        print("   • North Camera: (0, 4.0, 2.0) - looking SOUTH toward center")
-        print("     🟢 GREEN CUBE marker at (0, 3.0, 2.5)")
-        print("   • South Camera: (0, -4.0, 2.0) - looking NORTH toward center")
-        print("     🔴 RED CUBE marker at (0, -3.0, 2.5)") 
-        print("   • East Camera: (4.0, 0, 2.0) - looking WEST toward center")
-        print("     🔵 BLUE CUBE marker at (3.0, 0, 2.5)")
-        print("   • West Camera: (-4.0, 0, 2.0) - looking EAST toward center")
-        print("     🟡 YELLOW CUBE marker at (-3.0, 0, 2.5)")
-        print("")
-        print("   ONBOARD DRONE CAMERAS (2x 320x240):")
-        for i, pos in enumerate(drone_positions):
-            print(f"   • Drone {i+1} Onboard: ({pos[0]+0.3:.1f}, {pos[1]:.1f}, {pos[2]+0.1:.1f}) - looking FORWARD")
-        print("")
-        print("   DRONE POSITIONS:")
-        for i, pos in enumerate(drone_positions):
-            print(f"   • Drone {i+1}: ({pos[0]:.1f}, {pos[1]:.1f}, {pos[2]:.1f})")
-        print("")
-        print("   Look for the COLORED CUBE MARKERS in the 3D viewer!")
-        
-    except Exception as e:
-        print(f"Error creating cameras: {e}")
-        print("Continuing with empty camera list - you'll only see the Isaac Gym viewer.")
-        static_cameras = []
-        camera_pixels = []
-        camera_segmentations = []
-        camera_names = []
-    
-    # Create output directory for captured images
-    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
-    output_dir = f"dual_drone_output_{timestamp}"
-    os.makedirs(output_dir, exist_ok=True)
-    print(f"Images will be saved to: {output_dir}")
-    
-    # Set up real-time visualization windows only if we have cameras
-    if static_cameras:
-        print("Setting up real-time visualization with 6 camera windows...")
-        cv2.namedWindow("North Boundary - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        cv2.namedWindow("South Boundary - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        cv2.namedWindow("East Boundary - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        cv2.namedWindow("West Boundary - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        cv2.namedWindow("Drone 1 Onboard - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        cv2.namedWindow("Drone 2 Onboard - Depth & Segmentation", cv2.WINDOW_NORMAL)
-        
-        # Resize windows for better layout
-        cv2.resizeWindow("North Boundary - Depth & Segmentation", 800, 400)
-        cv2.resizeWindow("South Boundary - Depth & Segmentation", 800, 400)
-        cv2.resizeWindow("East Boundary - Depth & Segmentation", 800, 400)
-        cv2.resizeWindow("West Boundary - Depth & Segmentation", 800, 400)
-        cv2.resizeWindow("Drone 1 Onboard - Depth & Segmentation", 640, 240)
-        cv2.resizeWindow("Drone 2 Onboard - Depth & Segmentation", 640, 240)
-        
-        print("Real-time camera views enabled. Press 'q' to exit, 's' to save images.")
-    else:
-        print("No cameras available - only Isaac Gym viewer will be shown.")
-        print("You can still see both stationary drones in the Isaac Gym viewer window.")
-        print("Press 'q' in the console to exit.")
-    
-    print("Both drones will remain stationary (hover in place)")
-    
-    # Initialize stationary hover commands - both drones stay in place
-    command_actions = torch.zeros((rl_task.num_envs, rl_task.task_config.action_space_dim), device=device)
-    
-    # Set to hover commands (all zeros for stationary hover)
-    for drone_idx in range(rl_task.num_envs):
-        command_actions[drone_idx, 0] = 0.0  # No forward movement
-        command_actions[drone_idx, 1] = 0.0  # No lateral movement  
-        command_actions[drone_idx, 2] = 0.0  # No vertical movement
-        command_actions[drone_idx, 3] = 0.0  # No yaw rotation
-    
-    # Main visualization loop
-    frame_count = 0
-    save_images = False
-    
-    def normalize_segmentation_image(seg_image):
-        """Normalize segmentation image for display"""
-        if np.any(seg_image > 0):
-            min_positive = seg_image[seg_image > 0].min()
-            seg_image[seg_image <= 0] = min_positive
-        else:
-            seg_image[:] = 0.1
-            
-        seg_normalized = (seg_image - seg_image.min()) / (seg_image.max() - seg_image.min() + 1e-8)
-        return seg_normalized
-    
-    def create_combined_image(depth_img, seg_img, title="Camera"):
-        """Create a combined depth + segmentation image"""
-        # Normalize depth image
-        depth_normalized = (depth_img * 255).astype(np.uint8)
-        
-        # Create depth image as 3-channel
-        depth_rgb = cv2.cvtColor(depth_normalized, cv2.COLOR_GRAY2RGB)
-        
-        # Normalize and colorize segmentation
-        seg_normalized = normalize_segmentation_image(seg_img.copy())
-        seg_colored = matplotlib.cm.plasma(seg_normalized)
-        seg_rgb = (seg_colored[:, :, :3] * 255).astype(np.uint8)
-        
-        # Combine images side by side
-        combined = np.hstack([depth_rgb, seg_rgb])
-        
-        # Add title
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, f"{title} - Depth | Segmentation", (10, 30), font, 0.7, (255, 255, 255), 2)
-        
-        return combined
-    
-    print("\nStarting main loop...")
-    print("Watch the Isaac Gym viewer window to see both stationary drones!")
-    if static_cameras:
-        print("Additional camera windows should show:")
-        print("  - 4 boundary cameras showing overview of both drones")
-        print("  - 2 onboard cameras showing each drone's forward view")
-    
-    try:
-        while True:
-            start_time = time.time()
-            
-            # Keep both drones stationary - no movement commands
-            # Actions remain at zero for hover
-            
-            # Step the simulation with stationary commands
-            obs, rewards, termination, truncation, infos = rl_task.step(command_actions)
-            
-            # Only process cameras if they exist and are working
-            if static_cameras:
-                try:
-                    # Capture all static camera images
-                    for camera in static_cameras:
-                        camera.capture()
-                    
-                    # Get static camera images
-                    camera_images = []
-                    for i, (pixels, segmentation, name) in enumerate(zip(camera_pixels, camera_segmentations, camera_names)):
-                        depth = pixels[0, 0].cpu().numpy()
-                        seg = segmentation[0, 0].cpu().numpy()
-                        combined = create_combined_image(depth, seg, name)
-                        camera_images.append(combined)
-                    
-                    # Display all images
-                    cv2.imshow("North Boundary - Depth & Segmentation", camera_images[0])
-                    cv2.imshow("South Boundary - Depth & Segmentation", camera_images[1])
-                    cv2.imshow("East Boundary - Depth & Segmentation", camera_images[2])
-                    cv2.imshow("West Boundary - Depth & Segmentation", camera_images[3])
-                    cv2.imshow("Drone 1 Onboard - Depth & Segmentation", camera_images[4])
-                    cv2.imshow("Drone 2 Onboard - Depth & Segmentation", camera_images[5])
-                    
-                    # Save images if requested
-                    if save_images:
-                        # Save all cameras
-                        for i, (combined, name) in enumerate(zip(camera_images, camera_names)):
-                            safe_name = name.lower().replace(" ", "_")
-                            cv2.imwrite(f"{output_dir}/{safe_name}_combined_frame_{frame_count:04d}.png", combined)
-                        
-                        print(f"Saved frame {frame_count}")
-                    
-                    # Handle keyboard input for camera windows
-                    key = cv2.waitKey(1) & 0xFF
-                    if key == ord('q'):
-                        print("Quit requested by user")
-                        break
-                    elif key == ord('s'):
-                        save_images = not save_images
-                        print(f"Image saving {'enabled' if save_images else 'disabled'}")
-                        
-                except Exception as e:
-                    print(f"Error processing cameras: {e}")
-                    # Continue the simulation loop even if cameras fail
-            else:
-                # No cameras - just run simulation and check for quit in console
-                # Check for keyboard interrupt to quit
-                pass
-            
-            frame_count += 1
-            
-            # Print frame rate every 100 frames
-            if frame_count % 100 == 0:
-                elapsed_time = time.time() - start_time
-                fps = 1.0 / elapsed_time if elapsed_time > 0 else 0
-                print(f"Frame {frame_count}, FPS: {fps:.1f} - Both drones hovering in place")
-                if not static_cameras:
-                    print("  (No camera windows - check Isaac Gym viewer for dual drone visualization)")
-    
-    except KeyboardInterrupt:
-        print("\nInterrupted by user")
-    
-    finally:
-        print("Cleaning up...")
-        if static_cameras:
-            cv2.destroyAllWindows()
-        print(f"Demo completed. {frame_count} frames processed.")
-        if save_images and static_cameras:
-            print(f"Images saved to: {output_dir}")
-
-if __name__ == "__main__":
-    main()
diff --git a/examples/dual_camera_demo_safe.py b/examples/dual_camera_demo_safe.py
deleted file mode 100755
index 1b486ed..0000000
--- a/examples/dual_camera_demo_safe.py
+++ /dev/null
@@ -1,318 +0,0 @@
-#!/usr/bin/env python3
-
-"""
-Dual Camera Demo: Static Environment Camera + Drone Camera
-
-This example demonstrates:
-1. A static environment camera providing overhead/side views
-2. A drone with an onboard camera
-3. Real-time visualization of depth and segmentation outputs from both cameras
-4. No RL training - just visualization of camera outputs
-
-The demo shows depth and segmentation information extraction similar to the DCE navigation task.
-"""
-
-import os
-import time
-import numpy as np
-import cv2
-import matplotlib.pyplot as plt
-import matplotlib.cm
-from PIL import Image
-from datetime import datetime
-from typing import List
-
-def main():
-    print("=" * 70)
-    print("DUAL CAMERA DEMO: Static Environment Camera + Drone Camera")
-    print("=" * 70)
-    
-    # Import Aerial Gym components FIRST (before torch) to avoid IsaacGym conflicts
-    print("Importing Aerial Gym components...")
-    from aerial_gym.registry.task_registry import task_registry
-    from aerial_gym.examples.dce_rl_navigation.dce_navigation_task import DCE_RL_Navigation_Task
-    from aerial_gym.sensors.warp.static_environment_camera import (
-        StaticEnvironmentCamera,
-        OverheadCameraConfig,
-        SideViewCameraConfig
-    )
-    
-    # Import torch AFTER aerial gym components
-    import torch
-    
-    print("All imports successful!")
-    
-    # Register the DCE navigation task (which has camera enabled)
-    task_registry.register_task(
-        task_name="dual_camera_demo_task",
-        task_class=DCE_RL_Navigation_Task,
-        task_config=task_registry.get_task_config("navigation_task"),
-    )
-    
-    # Create the navigation task with camera enabled
-    print("Creating navigation task with drone camera...")
-    use_warp = True
-    headless = True  # Use headless mode since we have our own visualization
-    
-    rl_task = task_registry.make_task(
-        "dual_camera_demo_task",
-        seed=42,
-        use_warp=use_warp,
-        headless=headless
-    )
-    
-    print(f"Created task with {rl_task.num_envs} environments")
-    device = rl_task.device
-    
-    # Initialize the task to ensure all tensors are properly set up
-    print("Initializing task and resetting environments...")
-    rl_task.reset()
-    
-    # Get mesh IDs for Warp rendering (required for static cameras)
-    mesh_ids_list = rl_task.sim_env.global_tensor_dict.get("CONST_WARP_MESH_ID_LIST")
-    if mesh_ids_list is None:
-        raise ValueError("Warp mesh IDs not available. Make sure use_warp=True in config.")
-    
-    print(f"Mesh IDs type: {type(mesh_ids_list)}, length: {len(mesh_ids_list) if hasattr(mesh_ids_list, '__len__') else 'N/A'}")
-    
-    # Convert mesh_ids list to warp array
-    import warp as wp
-    mesh_ids = wp.array(mesh_ids_list, dtype=wp.uint64, device=device)
-    print(f"Converted mesh IDs to warp array: {mesh_ids.shape}")
-    
-    # Create static environment cameras
-    print("Creating static environment cameras...")
-    
-    # 1. Overhead camera for bird's eye view
-    overhead_config = OverheadCameraConfig()
-    overhead_config.width = 480
-    overhead_config.height = 480
-    overhead_camera = StaticEnvironmentCamera(
-        camera_config=overhead_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    
-    # Set up overhead view 20m above the environment center
-    overhead_camera.set_overhead_view(height=20.0)
-    
-    # Create image tensors for overhead camera
-    overhead_pixels = torch.zeros(
-        (rl_task.num_envs, 1, overhead_config.height, overhead_config.width),
-        device=device, requires_grad=False
-    )
-    overhead_segmentation = torch.zeros(
-        (rl_task.num_envs, 1, overhead_config.height, overhead_config.width),
-        dtype=torch.int32, device=device, requires_grad=False
-    )
-    overhead_camera.set_image_tensors(overhead_pixels, overhead_segmentation)
-    
-    # 2. Side view camera
-    side_config = SideViewCameraConfig()
-    side_config.width = 480
-    side_config.height = 480
-    side_camera = StaticEnvironmentCamera(
-        camera_config=side_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    
-    # Set up side view 25m away, 10m high, looking from 45 degrees
-    side_camera.set_side_view(distance=25.0, height=10.0, angle_degrees=45.0)
-    
-    # Create image tensors for side camera
-    side_pixels = torch.zeros(
-        (rl_task.num_envs, 1, side_config.height, side_config.width),
-        device=device, requires_grad=False
-    )
-    side_segmentation = torch.zeros(
-        (rl_task.num_envs, 1, side_config.height, side_config.width),
-        dtype=torch.int32, device=device, requires_grad=False
-    )
-    side_camera.set_image_tensors(side_pixels, side_segmentation)
-    
-    print("Static cameras created and configured!")
-    
-    # Create output directory for captured images
-    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
-    output_dir = f"dual_camera_output_{timestamp}"
-    os.makedirs(output_dir, exist_ok=True)
-    print(f"Images will be saved to: {output_dir}")
-    
-    # Set up real-time visualization windows
-    print("Setting up real-time visualization...")
-    cv2.namedWindow("Drone Camera - Depth & Segmentation", cv2.WINDOW_NORMAL)
-    cv2.namedWindow("Overhead Camera - Depth & Segmentation", cv2.WINDOW_NORMAL)
-    cv2.namedWindow("Side Camera - Depth & Segmentation", cv2.WINDOW_NORMAL)
-    
-    # Resize windows
-    cv2.resizeWindow("Drone Camera - Depth & Segmentation", 800, 400)
-    cv2.resizeWindow("Overhead Camera - Depth & Segmentation", 800, 400)
-    cv2.resizeWindow("Side Camera - Depth & Segmentation", 800, 400)
-    
-    print("Real-time camera views enabled. Press 'q' to exit, 's' to save images.")
-    
-    # Initialize simple movement commands  
-    command_actions = torch.zeros((rl_task.num_envs, rl_task.task_config.action_space_dim), device=device)
-    
-    # Set initial hovering command to prevent early crashes
-    command_actions[:, 0] = 0.0  # No forward movement initially
-    command_actions[:, 1] = 0.0  # No lateral movement initially  
-    command_actions[:, 2] = 0.0  # No vertical movement initially
-    
-    # Main visualization loop
-    frame_count = 0
-    save_images = False
-    
-    def normalize_segmentation_image(seg_image):
-        """Normalize segmentation image for display"""
-        if np.any(seg_image > 0):
-            min_positive = seg_image[seg_image > 0].min()
-            seg_image[seg_image <= 0] = min_positive
-        else:
-            seg_image[:] = 0.1
-            
-        seg_normalized = (seg_image - seg_image.min()) / (seg_image.max() - seg_image.min() + 1e-8)
-        return seg_normalized
-    
-    def create_combined_image(depth_img, seg_img, title="Camera"):
-        """Create a combined depth + segmentation image"""
-        # Normalize depth image
-        depth_normalized = (depth_img * 255).astype(np.uint8)
-        
-        # Create depth image as 3-channel
-        depth_rgb = cv2.cvtColor(depth_normalized, cv2.COLOR_GRAY2RGB)
-        
-        # Normalize and colorize segmentation
-        seg_normalized = normalize_segmentation_image(seg_img.copy())
-        seg_colored = matplotlib.cm.plasma(seg_normalized)
-        seg_rgb = (seg_colored[:, :, :3] * 255).astype(np.uint8)
-        
-        # Combine images side by side
-        combined = np.hstack([depth_rgb, seg_rgb])
-        
-        # Add title
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, f"{title} - Depth | Segmentation", (10, 30), font, 0.7, (255, 255, 255), 2)
-        
-        return combined
-    
-    try:
-        while True:
-            start_time = time.time()
-            
-            # Simple circular movement pattern (start gentle after initial frames)
-            if frame_count > 50:  # Allow some time for initialization
-                t = (frame_count - 50) * 0.01  # Slower movement
-                command_actions[:, 0] = 0.3 * torch.cos(torch.tensor(t))  # Forward/backward
-                command_actions[:, 1] = 0.2 * torch.sin(torch.tensor(t))  # Left/right
-                command_actions[:, 2] = 0.1 * torch.sin(torch.tensor(t * 0.5))  # Up/down
-            else:
-                # Hover in place for first 50 frames
-                command_actions[:, 0] = 0.0
-                command_actions[:, 1] = 0.0
-                command_actions[:, 2] = 0.0
-            
-            # Step the simulation
-            obs, rewards, termination, truncation, infos = rl_task.step(command_actions)
-            
-            # Capture static camera images
-            overhead_camera.capture()
-            side_camera.capture()
-            
-            # Get drone camera images (from obs_dict)
-            drone_depth = rl_task.obs_dict["depth_range_pixels"][0, 0].cpu().numpy()
-            drone_seg = rl_task.obs_dict["segmentation_pixels"][0, 0].cpu().numpy()
-            
-            # Get static camera images
-            overhead_depth = overhead_pixels[0, 0].cpu().numpy()
-            overhead_seg = overhead_segmentation[0, 0].cpu().numpy()
-            
-            side_depth = side_pixels[0, 0].cpu().numpy()
-            side_seg = side_segmentation[0, 0].cpu().numpy()
-            
-            # Create combined images for display
-            drone_combined = create_combined_image(drone_depth, drone_seg, "Drone")
-            overhead_combined = create_combined_image(overhead_depth, overhead_seg, "Overhead")
-            side_combined = create_combined_image(side_depth, side_seg, "Side View")
-            
-            # Display images
-            cv2.imshow("Drone Camera - Depth & Segmentation", drone_combined)
-            cv2.imshow("Overhead Camera - Depth & Segmentation", overhead_combined)
-            cv2.imshow("Side Camera - Depth & Segmentation", side_combined)
-            
-            # Handle key presses
-            key = cv2.waitKey(1) & 0xFF
-            if key == ord('q'):
-                print("User requested exit")
-                break
-            elif key == ord('s'):
-                save_images = True
-            
-            # Save images every 30 frames or when 's' is pressed
-            if frame_count % 30 == 0 or save_images:
-                print(f"Saving frame {frame_count}...")
-                
-                # Save individual images
-                cv2.imwrite(
-                    os.path.join(output_dir, f"drone_combined_frame_{frame_count:04d}.png"),
-                    drone_combined
-                )
-                cv2.imwrite(
-                    os.path.join(output_dir, f"overhead_combined_frame_{frame_count:04d}.png"),
-                    overhead_combined
-                )
-                cv2.imwrite(
-                    os.path.join(output_dir, f"side_combined_frame_{frame_count:04d}.png"),
-                    side_combined
-                )
-                
-                # Save raw depth and segmentation data
-                np.save(
-                    os.path.join(output_dir, f"drone_depth_frame_{frame_count:04d}.npy"),
-                    drone_depth
-                )
-                np.save(
-                    os.path.join(output_dir, f"drone_seg_frame_{frame_count:04d}.npy"),
-                    drone_seg
-                )
-                
-                save_images = False
-            
-            # Reset environments if needed
-            reset_ids = (termination + truncation).nonzero(as_tuple=True)
-            if torch.any(termination):
-                terminated_envs = termination.nonzero(as_tuple=True)
-                print(f"Resetting environments {terminated_envs} due to termination")
-                rl_task.reset()
-            if torch.any(truncation):
-                truncated_envs = truncation.nonzero(as_tuple=True)
-                print(f"Resetting environments {truncated_envs} due to timeout")
-                rl_task.reset()
-            
-            frame_count += 1
-            
-            # Print FPS info every 100 frames
-            if frame_count % 100 == 0:
-                end_time = time.time()
-                fps = 100 / (end_time - start_time) if end_time > start_time else 0
-                print(f"Frame {frame_count}, FPS: {fps:.1f}")
-    
-    except KeyboardInterrupt:
-        print("\nDemo interrupted by user")
-    
-    finally:
-        # Clean up
-        cv2.destroyAllWindows()
-        print(f"Demo completed. Output saved to: {output_dir}")
-        print("Summary:")
-        print(f"- Total frames processed: {frame_count}")
-        print(f"- Drone camera: Depth + Segmentation from onboard sensor")
-        print(f"- Static cameras: Overhead and side view perspectives")
-        print(f"- All images saved to: {output_dir}")
-
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/dual_camera_no_drone.py b/examples/dual_camera_no_drone.py
deleted file mode 100755
index ee4a357..0000000
--- a/examples/dual_camera_no_drone.py
+++ /dev/null
@@ -1,502 +0,0 @@
-#!/usr/bin/env python3
-
-"""
-Dual Camera Demo: Static Environment Camera + Drone Camera
-
-This example demonstrates:
-1. A static environment camera providing overhead/side views
-2. A drone with an onboard camera
-3. Real-time visualization of depth and segmentation outputs from both cameras
-4. No RL training - just visualization of camera outputs
-
-The demo shows depth and segmentation information extraction similar to the DCE navigation task.
-"""
-
-import os
-import time
-import numpy as np
-import cv2
-import matplotlib.pyplot as plt
-import matplotlib.cm
-from PIL import Image
-from datetime import datetime
-from typing import List
-
-def main():
-    print("=" * 70)
-    print("DUAL CAMERA DEMO: Static Environment Camera + Drone Camera")
-    print("=" * 70)
-    
-    # Import Aerial Gym components FIRST (before torch) to avoid IsaacGym conflicts
-    print("Importing Aerial Gym components...")
-    from aerial_gym.registry.task_registry import task_registry
-    from aerial_gym.examples.dce_rl_navigation.dce_navigation_task import DCE_RL_Navigation_Task
-    from aerial_gym.sensors.warp.static_environment_camera import (
-        StaticEnvironmentCamera,
-        OverheadCameraConfig,
-        SideViewCameraConfig
-    )
-    
-    # Import torch AFTER aerial gym components
-    import torch
-    
-    print("All imports successful!")
-    
-    # Get the base navigation task configuration and modify it
-    task_config = task_registry.get_task_config("navigation_task")
-    
-    # Disable VAE processing - we just want raw camera outputs for the demo
-    task_config.vae_config.use_vae = False
-    # Adjust observation space dimension since we're not using VAE latents (64D)
-    task_config.observation_space_dim = 13 + 4  # root_state + action_dim (without latent_dims)
-    print(f"VAE processing disabled: use_vae = {task_config.vae_config.use_vae}")
-    print(f"Observation space dimension adjusted to: {task_config.observation_space_dim}")
-    
-    # Register the DCE navigation task (which has camera enabled)
-    task_registry.register_task(
-        task_name="dual_camera_demo_task",
-        task_class=DCE_RL_Navigation_Task,
-        task_config=task_config,
-    )
-    
-    # Create the navigation task with camera enabled
-    print("Creating navigation task with drone camera...")
-    use_warp = True
-    headless = False  # Enable Isaac Gym viewer to see the simulation
-    
-    rl_task = task_registry.make_task(
-        "dual_camera_demo_task",
-        seed=42,
-        use_warp=use_warp,
-        headless=headless
-    )
-    
-    print(f"Created task with {rl_task.num_envs} environments")
-    device = rl_task.device
-    
-    # Initialize the task to ensure all tensors are properly set up
-    print("Initializing task and resetting environments...")
-    rl_task.reset()
-    
-    # Get mesh IDs for Warp rendering (required for static cameras)
-    mesh_ids_list = rl_task.sim_env.global_tensor_dict.get("CONST_WARP_MESH_ID_LIST")
-    if mesh_ids_list is None:
-        raise ValueError("Warp mesh IDs not available. Make sure use_warp=True in config.")
-    
-    print(f"Mesh IDs type: {type(mesh_ids_list)}, length: {len(mesh_ids_list) if hasattr(mesh_ids_list, '__len__') else 'N/A'}")
-    
-    # Convert mesh_ids list to warp array
-    import warp as wp
-    mesh_ids = wp.array(mesh_ids_list, dtype=wp.uint64, device=device)
-    print(f"Converted mesh IDs to warp array: {mesh_ids.shape}")
-    
-    # Create static environment cameras for comprehensive drone observation
-    print("Creating multiple static environment cameras...")
-    
-    # Camera configurations and storage
-    static_cameras = []
-    camera_pixels = []
-    camera_segmentations = []
-    camera_names = []
-    
-    # Standard camera config
-    def create_camera_config():
-        config = OverheadCameraConfig()
-        config.width = 480
-        config.height = 480
-        return config
-    
-    # 1. Primary overhead camera - center view INSIDE the middle chamber
-    overhead1_config = create_camera_config()
-    overhead1_camera = StaticEnvironmentCamera(
-        camera_config=overhead1_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    overhead1_camera.set_overhead_view(height=2.0)  # Much lower - closer to drone level
-    overhead1_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    overhead1_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    overhead1_camera.set_image_tensors(overhead1_pixels, overhead1_segmentation)
-    
-    static_cameras.append(overhead1_camera)
-    camera_pixels.append(overhead1_pixels)
-    camera_segmentations.append(overhead1_segmentation)
-    camera_names.append("Overhead Center")
-    
-    # 2. Overhead camera - slightly off-center INSIDE the middle chamber  
-    overhead2_config = create_camera_config()
-    overhead2_camera = StaticEnvironmentCamera(
-        camera_config=overhead2_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    # Position offset from center, still inside the middle chamber
-    positions2 = torch.zeros((rl_task.num_envs, 1, 3), device=device)
-    positions2[:, 0, 0] = 1.5   # Small X offset to stay inside chamber
-    positions2[:, 0, 1] = 1.5   # Small Y offset to stay inside chamber
-    positions2[:, 0, 2] = 1.8   # Height much lower - closer to drone level
-    overhead2_camera.set_camera_poses(positions2)  # Uses default downward orientation
-    overhead2_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    overhead2_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    overhead2_camera.set_image_tensors(overhead2_pixels, overhead2_segmentation)
-    
-    static_cameras.append(overhead2_camera)
-    camera_pixels.append(overhead2_pixels)
-    camera_segmentations.append(overhead2_segmentation)
-    camera_names.append("Overhead Offset")
-    
-    # 3. Corner view - positioned INSIDE the middle chamber walls
-    corner1_config = create_camera_config()
-    corner1_camera = StaticEnvironmentCamera(
-        camera_config=corner1_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    corner1_camera.set_side_view(distance=2.0, height=1.5, angle_degrees=45.0)  # Much lower and closer to drone level
-    corner1_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    corner1_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    corner1_camera.set_image_tensors(corner1_pixels, corner1_segmentation)
-    
-    static_cameras.append(corner1_camera)
-    camera_pixels.append(corner1_pixels)
-    camera_segmentations.append(corner1_segmentation)
-    camera_names.append("Corner View")
-    
-    # 4. Opposite corner view - positioned INSIDE the middle chamber walls
-    corner2_config = create_camera_config()
-    corner2_camera = StaticEnvironmentCamera(
-        camera_config=corner2_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    corner2_camera.set_side_view(distance=2.0, height=1.5, angle_degrees=225.0)  # Much lower and closer to drone level
-    corner2_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    corner2_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    corner2_camera.set_image_tensors(corner2_pixels, corner2_segmentation)
-    
-    static_cameras.append(corner2_camera)
-    camera_pixels.append(corner2_pixels)
-    camera_segmentations.append(corner2_segmentation)
-    camera_names.append("Corner View 2")
-    
-    # 5. Mid-level overhead view - lower in the middle chamber
-    overhead3_config = create_camera_config()
-    overhead3_camera = StaticEnvironmentCamera(
-        camera_config=overhead3_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    overhead3_camera.set_overhead_view(height=1.2)  # Very low - almost at drone level
-    overhead3_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    overhead3_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    overhead3_camera.set_image_tensors(overhead3_pixels, overhead3_segmentation)
-    
-    static_cameras.append(overhead3_camera)
-    camera_pixels.append(overhead3_pixels)
-    camera_segmentations.append(overhead3_segmentation)
-    camera_names.append("Overhead Close")
-    
-    # 6. Side view - positioned near chamber wall but looking inward
-    wall_config = create_camera_config()
-    wall_camera = StaticEnvironmentCamera(
-        camera_config=wall_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    wall_camera.set_side_view(distance=1.8, height=1.0, angle_degrees=0.0)  # Very low and close to center
-    wall_pixels = torch.zeros((rl_task.num_envs, 1, 480, 480), device=device, requires_grad=False)
-    wall_segmentation = torch.zeros((rl_task.num_envs, 1, 480, 480), dtype=torch.int32, device=device, requires_grad=False)
-    wall_camera.set_image_tensors(wall_pixels, wall_segmentation)
-    
-    static_cameras.append(wall_camera)
-    camera_pixels.append(wall_pixels)
-    camera_segmentations.append(wall_segmentation)
-    camera_names.append("Side View")
-    
-    print(f"Created {len(static_cameras)} static cameras for comprehensive drone observation")
-    
-    print("Static cameras created and configured!")
-    
-    # Add visual markers for static camera positions in the simulation
-    print("Adding visual markers for camera positions...")
-    
-    print("Attempting to add camera markers to Isaac Gym viewer...")
-    try:
-        # Get Isaac Gym objects properly
-        sim_env = rl_task.sim_env
-        ige_manager = sim_env.IGE_env
-        gym = ige_manager.gym
-        sim = ige_manager.sim
-        
-        print(f"Isaac Gym objects acquired. Number of environments: {len(ige_manager.envs) if hasattr(ige_manager, 'envs') else 'Unknown'}")
-        
-        if hasattr(ige_manager, 'envs') and len(ige_manager.envs) > 0:
-            env_handle = ige_manager.envs[0]
-            print(f"Using environment handle: {env_handle}")
-            
-            # Known camera positions based on our settings - hardcoded for debugging
-            marker_positions = [
-                [0.0, 0.0, 2.0],      # Overhead Center
-                [1.5, 1.5, 1.8],      # Overhead Offset
-                [1.41, 1.41, 1.5],    # Corner View (45 degrees, 2.0 distance)
-                [-1.41, -1.41, 1.5],  # Corner View 2 (225 degrees, 2.0 distance)
-                [0.0, 0.0, 1.2],      # Overhead Close
-                [1.8, 0.0, 1.0],      # Side View (0 degrees, 1.8 distance)
-            ]
-            
-            # Bright, contrasting colors for camera markers
-            camera_colors = [
-                gym.Vec3(0.0, 1.0, 0.0),    # BRIGHT GREEN - Overhead Center
-                gym.Vec3(1.0, 1.0, 0.0),    # BRIGHT YELLOW - Overhead Offset  
-                gym.Vec3(1.0, 0.0, 0.0),    # BRIGHT RED - Corner View
-                gym.Vec3(1.0, 0.0, 1.0),    # BRIGHT MAGENTA - Corner View 2
-                gym.Vec3(0.0, 1.0, 1.0),    # BRIGHT CYAN - Overhead Close
-                gym.Vec3(0.0, 0.0, 1.0),    # BRIGHT BLUE - Side View
-            ]
-            
-            print(f"Creating {len(marker_positions)} camera markers with hardcoded positions...")
-            for i, (pos, color, name) in enumerate(zip(marker_positions, camera_colors, camera_names)):
-                print(f"Creating marker {i} ({name}) at position: {pos}")
-                
-                # CREATE HUGE VISIBLE SPHERES
-                sphere_asset = gym.create_sphere(sim, 0.8, {})  # 80cm radius - very large
-                pose = gym.Transform()
-                pose.p = gym.Vec3(pos[0], pos[1], pos[2])
-                actor = gym.create_actor(env_handle, sphere_asset, pose, f"camera_marker_{i}", 0, 0)
-                gym.set_rigid_body_color(env_handle, actor, 0, gym.MESH_VISUAL, color)
-                print(f"✅ Added {name} marker (80cm sphere) at: {pos}")
-            
-            # Also add a reference marker at origin
-            origin_sphere = gym.create_sphere(sim, 0.3, {})
-            origin_pose = gym.Transform()
-            origin_pose.p = gym.Vec3(0.0, 0.0, 0.0)
-            origin_actor = gym.create_actor(env_handle, origin_sphere, origin_pose, "origin_marker", 0, 0)
-            gym.set_rigid_body_color(env_handle, origin_actor, 0, gym.MESH_VISUAL, gym.Vec3(1.0, 1.0, 1.0))  # White
-            print("✅ Added WHITE origin reference marker at (0,0,0)")
-            
-            print("🎯 ALL CAMERA MARKERS CREATED SUCCESSFULLY!")
-        else:
-            print("❌ Warning: Could not access environment handles for camera markers")
-    except Exception as e:
-        print(f"❌ Error adding camera markers: {e}")
-        import traceback
-        traceback.print_exc()
-        print("Continuing without visual markers...")
-    # Create output directory for captured images
-    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
-    output_dir = f"dual_camera_output_{timestamp}"
-    os.makedirs(output_dir, exist_ok=True)
-    print(f"Images will be saved to: {output_dir}")
-    
-    # Set up real-time visualization windows
-    print("Setting up real-time visualization...")
-    
-    # Create windows for drone camera and all static cameras
-    cv2.namedWindow("Drone Camera - Onboard View", cv2.WINDOW_NORMAL)
-    cv2.resizeWindow("Drone Camera - Onboard View", 800, 400)
-    
-    # Create windows for each static camera
-    static_camera_windows = []
-    for i, name in enumerate(camera_names):
-        window_name = f"Static Camera {i+1} - {name}"
-        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
-        cv2.resizeWindow(window_name, 600, 300)  # Smaller windows for multiple cameras
-        static_camera_windows.append(window_name)
-    
-    print("Real-time camera views enabled. Press 'q' to exit, 's' to save images.")
-    print("Note: You'll see both the Isaac Gym viewer and multiple OpenCV camera windows.")
-    print("- Isaac Gym viewer: Shows the 3D simulation with drone and BIG COLORED CAMERA MARKERS")
-    print("- BIG Camera markers (50cm spheres): Green=Center, Yellow=Offset, Red=Corner1, Magenta=Corner2, Cyan=Close, Blue=Side")
-    print(f"- OpenCV windows: {len(static_cameras)+1} total windows showing real-time depth+segmentation")
-    print("- All cameras positioned INSIDE the middle chamber where drone operates")
-    print("- Large bright colored spheres show exactly where each camera is positioned!")
-    
-    # Initialize simple movement commands  
-    command_actions = torch.zeros((rl_task.num_envs, rl_task.task_config.action_space_dim), device=device)
-    
-    # Set initial hovering command to prevent early crashes
-    command_actions[:, 0] = 0.0  # No forward movement initially
-    command_actions[:, 1] = 0.0  # No lateral movement initially  
-    command_actions[:, 2] = 0.0  # No vertical movement initially
-    
-    # Main visualization loop
-    frame_count = 0
-    save_images = False
-    segmentation_warning_shown = False  # To avoid spamming warnings
-    
-    def normalize_segmentation_image(seg_image):
-        """Normalize segmentation image for display"""
-        if np.any(seg_image > 0):
-            min_positive = seg_image[seg_image > 0].min()
-            seg_image[seg_image <= 0] = min_positive
-        else:
-            seg_image[:] = 0.1
-            
-        seg_normalized = (seg_image - seg_image.min()) / (seg_image.max() - seg_image.min() + 1e-8)
-        return seg_normalized
-    
-    def create_combined_image(depth_img, seg_img, title="Camera"):
-        """Create a combined depth + segmentation image"""
-        # Normalize depth image
-        depth_normalized = (depth_img * 255).astype(np.uint8)
-        
-        # Create depth image as 3-channel
-        depth_rgb = cv2.cvtColor(depth_normalized, cv2.COLOR_GRAY2RGB)
-        
-        # Normalize and colorize segmentation
-        seg_normalized = normalize_segmentation_image(seg_img.copy())
-        seg_colored = matplotlib.cm.plasma(seg_normalized)
-        seg_rgb = (seg_colored[:, :, :3] * 255).astype(np.uint8)
-        
-        # Combine images side by side
-        combined = np.hstack([depth_rgb, seg_rgb])
-        
-        # Add title
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, f"{title} - Depth | Segmentation", (10, 30), font, 0.7, (255, 255, 255), 2)
-        
-        return combined
-    
-    try:
-        while True:
-            start_time = time.time()
-            
-            # Simple circular movement pattern (start gentle after initial frames)
-            if frame_count > 50:  # Allow some time for initialization
-                t = (frame_count - 50) * 0.01  # Slower movement
-                command_actions[:, 0] = 0.3 * torch.cos(torch.tensor(t))  # Forward/backward
-                command_actions[:, 1] = 0.2 * torch.sin(torch.tensor(t))  # Left/right
-                command_actions[:, 2] = 0.1 * torch.sin(torch.tensor(t * 0.5))  # Up/down
-            else:
-                # Hover in place for first 50 frames
-                command_actions[:, 0] = 0.0
-                command_actions[:, 1] = 0.0
-                command_actions[:, 2] = 0.0
-            
-            # Step the simulation
-            obs, rewards, termination, truncation, infos = rl_task.step(command_actions)
-            
-            # Capture all static camera images
-            for camera in static_cameras:
-                camera.capture()
-            
-            # Get drone camera images (from obs_dict)
-            drone_depth = rl_task.obs_dict["depth_range_pixels"][0, 0].cpu().numpy()
-            
-            # Check if segmentation is available, otherwise create simulated segmentation
-            if "segmentation_pixels" in rl_task.obs_dict:
-                drone_seg = rl_task.obs_dict["segmentation_pixels"][0, 0].cpu().numpy()
-            else:
-                if not segmentation_warning_shown:
-                    print("Note: Creating simulated segmentation from depth data since segmentation_pixels not available")
-                    segmentation_warning_shown = True
-                # Create simulated segmentation based on depth for visualization
-                # Different depth ranges get different segment IDs
-                drone_seg = np.zeros_like(drone_depth)
-                drone_seg[drone_depth < 0.3] = 1.0  # Close objects
-                drone_seg[(drone_depth >= 0.3) & (drone_depth < 0.6)] = 2.0  # Medium distance
-                drone_seg[(drone_depth >= 0.6) & (drone_depth < 1.0)] = 3.0  # Far objects
-                drone_seg[drone_depth >= 1.0] = 0.5  # Background/walls
-            
-            # Create combined image for drone
-            drone_combined = create_combined_image(drone_depth, drone_seg, "Drone Onboard")
-            cv2.imshow("Drone Camera - Onboard View", drone_combined)
-            
-            # Process and display all static camera images
-            for i, (pixels, segmentation, name, window_name) in enumerate(zip(camera_pixels, camera_segmentations, camera_names, static_camera_windows)):
-                static_depth = pixels[0, 0].cpu().numpy()
-                static_seg = segmentation[0, 0].cpu().numpy()
-                static_combined = create_combined_image(static_depth, static_seg, name)
-                cv2.imshow(window_name, static_combined)
-            
-            # Handle key presses
-            key = cv2.waitKey(1) & 0xFF
-            if key == ord('q'):
-                print("User requested exit")
-                break
-            elif key == ord('s'):
-                save_images = True
-            
-            # Save images every 30 frames or when 's' is pressed
-            if frame_count % 30 == 0 or save_images:
-                print(f"Saving frame {frame_count} from {len(static_cameras)+1} cameras...")
-                
-                # Save drone camera
-                cv2.imwrite(
-                    os.path.join(output_dir, f"drone_combined_frame_{frame_count:04d}.png"),
-                    drone_combined
-                )
-                np.save(
-                    os.path.join(output_dir, f"drone_depth_frame_{frame_count:04d}.npy"),
-                    drone_depth
-                )
-                np.save(
-                    os.path.join(output_dir, f"drone_seg_frame_{frame_count:04d}.npy"),
-                    drone_seg
-                )
-                
-                # Save all static cameras
-                for i, (pixels, segmentation, name) in enumerate(zip(camera_pixels, camera_segmentations, camera_names)):
-                    static_depth = pixels[0, 0].cpu().numpy()
-                    static_seg = segmentation[0, 0].cpu().numpy()
-                    static_combined = create_combined_image(static_depth, static_seg, name)
-                    
-                    # Clean filename from camera name
-                    clean_name = name.lower().replace(" ", "_").replace("(", "").replace(")", "").replace("-", "_")
-                    
-                    cv2.imwrite(
-                        os.path.join(output_dir, f"static_{i+1}_{clean_name}_frame_{frame_count:04d}.png"),
-                        static_combined
-                    )
-                    np.save(
-                        os.path.join(output_dir, f"static_{i+1}_{clean_name}_depth_frame_{frame_count:04d}.npy"),
-                        static_depth
-                    )
-                    np.save(
-                        os.path.join(output_dir, f"static_{i+1}_{clean_name}_seg_frame_{frame_count:04d}.npy"),
-                        static_seg
-                    )
-                
-                save_images = False
-            
-            # Reset environments if needed
-            reset_ids = (termination + truncation).nonzero(as_tuple=True)
-            if torch.any(termination):
-                terminated_envs = termination.nonzero(as_tuple=True)
-                print(f"Resetting environments {terminated_envs} due to termination")
-                rl_task.reset()
-            if torch.any(truncation):
-                truncated_envs = truncation.nonzero(as_tuple=True)
-                print(f"Resetting environments {truncated_envs} due to timeout")
-                rl_task.reset()
-            
-            frame_count += 1
-            
-            # Print FPS info every 100 frames
-            if frame_count % 100 == 0:
-                end_time = time.time()
-                fps = 100 / (end_time - start_time) if end_time > start_time else 0
-                print(f"Frame {frame_count}, FPS: {fps:.1f}")
-    
-    except KeyboardInterrupt:
-        print("\nDemo interrupted by user")
-    
-    finally:
-        # Clean up
-        cv2.destroyAllWindows()
-        print(f"Demo completed. Output saved to: {output_dir}")
-        print("Summary:")
-        print(f"- Total frames processed: {frame_count}")
-        print(f"- Drone camera: Onboard depth + segmentation sensor")
-        print(f"- Static cameras: Overhead (8m high) and corner view (inside chamber)")
-        print(f"- All images saved to: {output_dir}")
-
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/gate_camera_demo.py b/examples/gate_camera_demo.py
deleted file mode 100644
index a553d32..0000000
--- a/examples/gate_camera_demo.py
+++ /dev/null
@@ -1,414 +0,0 @@
-#!/usr/bin/env python3
-
-"""
-Gate Camera Demo: Static Camera Behind Gate + Drone Navigation
-
-This example demonstrates:
-1. A static camera positioned behind the gate with full view of gate panels
-2. A drone with an onboard camera navigating through the gate
-3. Real-time visualization of depth and segmentation outputs from both cameras
-4. Uses proper gate environment configuration
-5. No RL training - just visualization of gate navigation
-
-The demo focuses specifically on gate observation and drone-gate interaction.
-"""
-
-import os
-import time
-import numpy as np
-import cv2
-import matplotlib.pyplot as plt
-import matplotlib.cm
-from PIL import Image
-from datetime import datetime
-from typing import List
-import math
-
-def main():
-    print("=" * 80)
-    print("GATE CAMERA DEMO: Static Gate View Camera + Drone Navigation")
-    print("=" * 80)
-    
-    # Import Aerial Gym components FIRST (before torch) to avoid IsaacGym conflicts
-    print("Importing Aerial Gym components...")
-    from aerial_gym.registry.task_registry import task_registry
-    from aerial_gym.task.navigation_task.navigation_task import NavigationTask
-    from aerial_gym.config.env_config.gate_env import GateEnvCfg
-    from aerial_gym.config.robot_config.base_quad_config import BaseQuadCfg
-    from aerial_gym.config.controller_config.lee_controller_config import LeeControllerCfg
-    from aerial_gym.config.sensor_config.camera_config.base_depth_camera_config import BaseDepthCameraCfg
-    from aerial_gym.config.sim_config.base_sim_config import BaseSimConfig
-    from aerial_gym.sensors.warp.static_environment_camera import (
-        StaticEnvironmentCamera,
-        OverheadCameraConfig,
-        SideViewCameraConfig
-    )
-    
-    # Import torch AFTER aerial gym components
-    import torch
-    
-    print("All imports successful!")
-    
-    # Create a custom gate task configuration
-    class GateNavigationTaskConfig:
-        def __init__(self):
-            self.task = NavigationTask
-            self.env_config = GateEnvCfg
-            self.robot_config = BaseQuadCfg
-            self.controller_config = LeeControllerCfg
-            self.sensor_config = BaseDepthCameraCfg
-            self.sim_config = BaseSimConfig
-            
-            # Override some configurations for gate navigation
-            self.env_config.env.use_warp = True  # Enable Warp for static cameras
-            self.env_config.env.num_envs = 1     # Single environment for demo
-            self.sim_config.use_warp = True      # Enable Warp in sim config too
-            self.sensor_config.enable_camera = True
-            
-    # Create and register the gate navigation task
-    gate_task_config = GateNavigationTaskConfig()
-    
-    task_registry.register_task(
-        task_name="gate_camera_demo_task",
-        task_class=NavigationTask,
-        task_config=gate_task_config,
-    )
-    
-    # Create the gate navigation task with camera enabled
-    print("Creating gate navigation task with drone camera...")
-    use_warp = True
-    headless = True  # Use headless mode since we have our own visualization
-    
-    rl_task = task_registry.make_task(
-        "gate_camera_demo_task",
-        seed=42,
-        use_warp=use_warp,
-        headless=headless
-    )
-    
-    print(f"Created task with {rl_task.num_envs} environments")
-    device = rl_task.device
-    
-    # Initialize the task to ensure all tensors are properly set up
-    print("Initializing task and resetting environments...")
-    rl_task.reset()
-    
-    # Get mesh IDs for Warp rendering (required for static cameras)
-    mesh_ids_list = rl_task.sim_env.global_tensor_dict.get("CONST_WARP_MESH_ID_LIST")
-    if mesh_ids_list is None:
-        raise ValueError("Warp mesh IDs not available. Make sure use_warp=True in config.")
-    
-    print(f"Mesh IDs type: {type(mesh_ids_list)}, length: {len(mesh_ids_list) if hasattr(mesh_ids_list, '__len__') else 'N/A'}")
-    
-    # Convert mesh_ids list to warp array
-    import warp as wp
-    mesh_ids = wp.array(mesh_ids_list, dtype=wp.uint64, device=device)
-    print(f"Converted mesh IDs to warp array: {mesh_ids.shape}")
-    
-    # Create static environment cameras
-    print("Creating static environment cameras...")
-    
-    # 1. Gate View Camera - positioned behind the gate with full view of gate panels
-    print("Creating gate view camera positioned behind the gate...")
-    gate_config = SideViewCameraConfig()
-    gate_config.width = 640  # Higher resolution for detailed gate view
-    gate_config.height = 480
-    gate_config.horizontal_fov_deg = 60.0  # Narrower FOV for focused gate view
-    
-    gate_camera = StaticEnvironmentCamera(
-        camera_config=gate_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    
-    # Position camera behind the gate (gate is at center 0,0,0)
-    # Gate has scale 1.0 by default, so it's roughly 2m wide x 2m tall
-    # Position camera 6m behind the gate, at height 1.5m (middle of gate height)
-    # This should give a full frontal view of the gate panels
-    gate_positions = torch.zeros((rl_task.num_envs, 1, 3), device=device)
-    gate_positions[:, 0, 0] = 0.0   # Centered on X-axis with gate
-    gate_positions[:, 0, 1] = -6.0  # 6m behind the gate (negative Y direction)
-    gate_positions[:, 0, 2] = 1.5   # At height 1.5m (middle of gate height)
-    
-    # Create orientation quaternion to look forward toward the gate (positive Y direction)
-    # The gate should be directly in front of the camera
-    gate_orientations = torch.zeros((rl_task.num_envs, 1, 4), device=device)
-    gate_orientations[:, 0, 0] = 0.0   # x component
-    gate_orientations[:, 0, 1] = 0.0   # y component  
-    gate_orientations[:, 0, 2] = 0.0   # z component (no rotation around Z)
-    gate_orientations[:, 0, 3] = 1.0   # w component (identity quaternion)
-    
-    gate_camera.set_camera_poses(gate_positions, gate_orientations)
-    
-    # Create image tensors for gate camera
-    gate_pixels = torch.zeros(
-        (rl_task.num_envs, 1, gate_config.height, gate_config.width),
-        device=device, requires_grad=False
-    )
-    gate_segmentation = torch.zeros(
-        (rl_task.num_envs, 1, gate_config.height, gate_config.width),
-        dtype=torch.int32, device=device, requires_grad=False
-    )
-    gate_camera.set_image_tensors(gate_pixels, gate_segmentation)
-    
-    print("Gate view camera positioned for full frontal view of gate panels!")
-    print(f"Gate camera position: {gate_positions[0, 0].cpu().numpy()}")
-    print(f"Gate camera orientation: {gate_orientations[0, 0].cpu().numpy()}")
-    
-    # 2. Overhead camera for context
-    overhead_config = OverheadCameraConfig()
-    overhead_config.width = 480
-    overhead_config.height = 480
-    overhead_camera = StaticEnvironmentCamera(
-        camera_config=overhead_config,
-        num_envs=rl_task.num_envs,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    
-    # Set up overhead view 15m above the environment center
-    overhead_camera.set_overhead_view(height=15.0)
-    
-    # Create image tensors for overhead camera
-    overhead_pixels = torch.zeros(
-        (rl_task.num_envs, 1, overhead_config.height, overhead_config.width),
-        device=device, requires_grad=False
-    )
-    overhead_segmentation = torch.zeros(
-        (rl_task.num_envs, 1, overhead_config.height, overhead_config.width),
-        dtype=torch.int32, device=device, requires_grad=False
-    )
-    overhead_camera.set_image_tensors(overhead_pixels, overhead_segmentation)
-    
-    print("Static cameras created and configured!")
-    
-    # Create output directory for captured images
-    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
-    output_dir = f"gate_camera_output_{timestamp}"
-    os.makedirs(output_dir, exist_ok=True)
-    print(f"Images will be saved to: {output_dir}")
-    
-    # Set up real-time visualization windows
-    print("Setting up real-time visualization...")
-    cv2.namedWindow("Drone Camera - Depth & Segmentation", cv2.WINDOW_NORMAL)
-    cv2.namedWindow("Gate View Camera - Depth & Segmentation", cv2.WINDOW_NORMAL)
-    cv2.namedWindow("Overhead Camera - Depth & Segmentation", cv2.WINDOW_NORMAL)
-    
-    # Resize windows
-    cv2.resizeWindow("Drone Camera - Depth & Segmentation", 800, 400)
-    cv2.resizeWindow("Gate View Camera - Depth & Segmentation", 1000, 400)
-    cv2.resizeWindow("Overhead Camera - Depth & Segmentation", 600, 600)
-    
-    print("Real-time camera views enabled. Press 'q' to exit, 's' to save images.")
-    print("Flight pattern: Approach gate -> Fly through -> Return")
-    
-    # Initialize simple movement commands  
-    command_actions = torch.zeros((rl_task.num_envs, rl_task.task_config.action_space_dim), device=device)
-    
-    # Set initial hovering command to prevent early crashes
-    command_actions[:, 0] = 0.0  # No forward movement initially
-    command_actions[:, 1] = 0.0  # No lateral movement initially  
-    command_actions[:, 2] = 0.0  # No vertical movement initially
-    
-    # Main visualization loop
-    frame_count = 0
-    save_images = False
-    
-    def normalize_segmentation_image(seg_image):
-        """Normalize segmentation image for display"""
-        if np.any(seg_image > 0):
-            min_positive = seg_image[seg_image > 0].min()
-            seg_image[seg_image <= 0] = min_positive
-        else:
-            seg_image[:] = 0.1
-            
-        seg_normalized = (seg_image - seg_image.min()) / (seg_image.max() - seg_image.min() + 1e-8)
-        return seg_normalized
-    
-    def create_combined_image(depth_img, seg_img, title="Camera"):
-        """Create a combined depth + segmentation image"""
-        # Normalize depth image
-        depth_normalized = (depth_img * 255).astype(np.uint8)
-        
-        # Create depth image as 3-channel
-        depth_rgb = cv2.cvtColor(depth_normalized, cv2.COLOR_GRAY2RGB)
-        
-        # Normalize and colorize segmentation
-        seg_normalized = normalize_segmentation_image(seg_img.copy())
-        seg_colored = matplotlib.cm.plasma(seg_normalized)
-        seg_rgb = (seg_colored[:, :, :3] * 255).astype(np.uint8)
-        
-        # Combine images side by side
-        combined = np.hstack([depth_rgb, seg_rgb])
-        
-        # Add title
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, f"{title} - Depth | Segmentation", (10, 30), font, 0.7, (255, 255, 255), 2)
-        
-        return combined
-    
-    try:
-        while True:
-            start_time = time.time()
-            
-            # Enhanced gate navigation pattern
-            if frame_count > 50:  # Allow some time for initialization
-                t = (frame_count - 50) * 0.015  # Moderate speed movement
-                
-                # Create a flight pattern that specifically focuses on gate navigation
-                phase = t % (4 * math.pi)  # Longer cycle for complete gate traversal
-                
-                if phase < math.pi:  # First phase: approach gate from behind camera
-                    # Start from behind and approach the gate
-                    command_actions[:, 0] = 0.4 * torch.sin(torch.tensor(phase * 0.5))  # Gradual approach
-                    command_actions[:, 1] = 0.6 * torch.cos(torch.tensor(phase * 0.3))  # Side movement for better camera view
-                    command_actions[:, 2] = 0.2 * torch.sin(torch.tensor(phase * 0.7))  # Height variation
-                elif phase < 2 * math.pi:  # Second phase: fly through gate
-                    # Steady movement through the gate
-                    command_actions[:, 0] = 0.5  # Steady forward movement through gate
-                    command_actions[:, 1] = 0.0  # Straight through center
-                    command_actions[:, 2] = 0.0  # Maintain height
-                elif phase < 3 * math.pi:  # Third phase: continue past gate  
-                    # Continue past gate and maneuver
-                    command_actions[:, 0] = 0.3 * torch.cos(torch.tensor(phase))  # Slow down
-                    command_actions[:, 1] = 0.4 * torch.sin(torch.tensor(phase))  # Side movement
-                    command_actions[:, 2] = -0.2 * torch.sin(torch.tensor(phase * 0.5))  # Descent
-                else:  # Fourth phase: return through gate
-                    # Return back through gate
-                    command_actions[:, 0] = -0.4  # Move back toward gate
-                    command_actions[:, 1] = 0.2 * torch.sin(torch.tensor(phase * 2))  # Slight weaving
-                    command_actions[:, 2] = 0.1 * torch.cos(torch.tensor(phase))  # Height adjustment
-            else:
-                # Hover in place for first 50 frames
-                command_actions[:, 0] = 0.0
-                command_actions[:, 1] = 0.0
-                command_actions[:, 2] = 0.0
-            
-            # Step the simulation
-            obs, rewards, termination, truncation, infos = rl_task.step(command_actions)
-            
-            # Capture static camera images
-            gate_camera.capture()  # Gate view is primary focus
-            overhead_camera.capture()
-            
-            # Get drone camera images (from obs_dict)
-            drone_depth = rl_task.obs_dict["depth_range_pixels"][0, 0].cpu().numpy()
-            drone_seg = rl_task.obs_dict["segmentation_pixels"][0, 0].cpu().numpy()
-            
-            # Get static camera images
-            gate_depth = gate_pixels[0, 0].cpu().numpy()
-            gate_seg = gate_segmentation[0, 0].cpu().numpy()
-            
-            overhead_depth = overhead_pixels[0, 0].cpu().numpy()
-            overhead_seg = overhead_segmentation[0, 0].cpu().numpy()
-            
-            # Create combined images for display
-            drone_combined = create_combined_image(drone_depth, drone_seg, "Drone View")
-            gate_combined = create_combined_image(gate_depth, gate_seg, "Gate View (Behind)")
-            overhead_combined = create_combined_image(overhead_depth, overhead_seg, "Overhead")
-            
-            # Display images with gate view as primary focus
-            cv2.imshow("Gate View Camera - Depth & Segmentation", gate_combined)
-            cv2.imshow("Drone Camera - Depth & Segmentation", drone_combined)
-            cv2.imshow("Overhead Camera - Depth & Segmentation", overhead_combined)
-            
-            # Handle key presses
-            key = cv2.waitKey(1) & 0xFF
-            if key == ord('q'):
-                print("User requested exit")
-                break
-            elif key == ord('s'):
-                save_images = True
-            
-            # Save images every 30 frames or when 's' is pressed
-            if frame_count % 30 == 0 or save_images:
-                print(f"Saving frame {frame_count}...")
-                
-                # Save individual images
-                cv2.imwrite(
-                    os.path.join(output_dir, f"gate_view_combined_frame_{frame_count:04d}.png"),
-                    gate_combined
-                )
-                cv2.imwrite(
-                    os.path.join(output_dir, f"drone_combined_frame_{frame_count:04d}.png"),
-                    drone_combined
-                )
-                cv2.imwrite(
-                    os.path.join(output_dir, f"overhead_combined_frame_{frame_count:04d}.png"),
-                    overhead_combined
-                )
-                
-                # Save raw depth and segmentation data
-                np.save(
-                    os.path.join(output_dir, f"gate_depth_frame_{frame_count:04d}.npy"),
-                    gate_depth
-                )
-                np.save(
-                    os.path.join(output_dir, f"gate_seg_frame_{frame_count:04d}.npy"),
-                    gate_seg
-                )
-                np.save(
-                    os.path.join(output_dir, f"drone_depth_frame_{frame_count:04d}.npy"),
-                    drone_depth
-                )
-                np.save(
-                    os.path.join(output_dir, f"drone_seg_frame_{frame_count:04d}.npy"),
-                    drone_seg
-                )
-                
-                save_images = False
-            
-            # Reset environments if needed
-            reset_ids = (termination + truncation).nonzero(as_tuple=True)
-            if torch.any(termination):
-                terminated_envs = termination.nonzero(as_tuple=True)
-                print(f"Resetting environments {terminated_envs} due to termination")
-                rl_task.reset()
-            if torch.any(truncation):
-                truncated_envs = truncation.nonzero(as_tuple=True)
-                print(f"Resetting environments {truncated_envs} due to timeout")
-                rl_task.reset()
-            
-            frame_count += 1
-            
-            # Print FPS and drone position info every 100 frames
-            if frame_count % 100 == 0:
-                end_time = time.time()
-                fps = 100 / (end_time - start_time) if end_time > start_time else 0
-                
-                # Get drone position for debugging
-                drone_pos = obs["robot_position"][0].cpu().numpy() if "robot_position" in obs else [0, 0, 0]
-                
-                print(f"Frame {frame_count}, FPS: {fps:.1f}, Drone position: [{drone_pos[0]:.2f}, {drone_pos[1]:.2f}, {drone_pos[2]:.2f}]")
-                
-                # Print gate camera info and analysis
-                if frame_count == 100:
-                    print(f"Gate camera view active - showing full frontal view of gate panels")
-                    print(f"Gate semantic ID in segmentation should be: 10")
-                    print(f"Looking for gate at center (0, 0) in environment")
-                    
-                    # Analyze gate segmentation
-                    gate_pixels_count = np.sum(gate_seg == 10)  # Gate semantic ID is 10
-                    total_pixels = gate_seg.shape[0] * gate_seg.shape[1]
-                    gate_coverage = gate_pixels_count / total_pixels * 100
-                    print(f"Gate coverage in view: {gate_coverage:.1f}% of image")
-    
-    except KeyboardInterrupt:
-        print("\nDemo interrupted by user")
-    
-    finally:
-        # Clean up
-        cv2.destroyAllWindows()
-        print(f"Demo completed. Output saved to: {output_dir}")
-        print("Summary:")
-        print(f"- Total frames processed: {frame_count}")
-        print(f"- Primary focus: Gate view camera positioned behind gate")
-        print(f"- Secondary views: Drone camera and overhead perspective")
-        print(f"- Gate navigation: Approach, traverse, and return flight pattern")
-        print(f"- Gate semantic ID: 10 (visible in segmentation)")
-        print(f"- All images and data saved to: {output_dir}")
-
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/multi_agent_example.py b/examples/multi_agent_example.py
deleted file mode 100644
index 7d692fc..0000000
--- a/examples/multi_agent_example.py
+++ /dev/null
@@ -1,219 +0,0 @@
-#!/usr/bin/env python3
-
-"""
-Multi-Agent Aerial Gym Example
-
-This script demonstrates how to use the multi-agent capabilities of Aerial Gym
-for cooperative drone navigation and formation control.
-"""
-
-import torch
-import numpy as np
-from aerial_gym.envs.navigation_task.multi_agent_navigation_task import MultiAgentNavigationTask
-from aerial_gym.envs.navigation_task.multi_agent_navigation_task_config import (
-    MultiAgentNavigationTaskConfig,
-    MultiAgentFormationTaskConfig, 
-    MultiAgentSwarmTaskConfig
-)
-
-def run_multi_agent_navigation():
-    """Run basic multi-agent navigation task"""
-    print("=== Multi-Agent Navigation Task ===")
-    
-    # Initialize configuration
-    config = MultiAgentNavigationTaskConfig()
-    
-    # Create task
-    task = MultiAgentNavigationTask(
-        task_config=config.task_config,
-        env_config=config.env_config, 
-        sim_config=config.sim_config,
-        device="cuda" if torch.cuda.is_available() else "cpu"
-    )
-    
-    print(f"Created task with {config.task_config['num_robots_per_env']} robots per environment")
-    print(f"Multi-agent observation space: {task.multi_agent_observation_space.shape}")
-    print(f"Multi-agent action space: {task.multi_agent_action_space.shape}")
-    
-    # Reset environment
-    observations = task.reset()
-    print(f"Initial observations shape: {observations.shape}")
-    
-    # Run simulation
-    for step in range(100):
-        # Generate random actions for all robots
-        # Shape: (num_envs, num_robots_per_env, action_dim)
-        actions = torch.rand(
-            task.num_envs,
-            task.num_robots_per_env, 
-            task.multi_agent_action_space.shape[1],
-            device=task.device
-        ) * 2 - 1  # Random actions in [-1, 1]
-        
-        # Step environment
-        observations, rewards, dones, info = task.step(actions)
-        
-        # Print info every 20 steps
-        if step % 20 == 0:
-            print(f"Step {step}:")
-            if "individual" in rewards:
-                individual_rewards = rewards["individual"].mean(dim=0)
-                print(f"  Individual rewards: {individual_rewards}")
-            if "shared" in rewards:
-                shared_reward = rewards["shared"].mean()
-                print(f"  Shared reward: {shared_reward}")
-            print(f"  Target distances: {info.get('target_distances', 'N/A')}")
-            print(f"  Formation error: {info.get('formation_error', 'N/A')}")
-            
-        # Reset if any environment is done
-        if dones.any():
-            print("Resetting environments...")
-            observations = task.reset()
-
-def run_formation_flying():
-    """Run formation flying task"""
-    print("\n=== Formation Flying Task ===")
-    
-    # Initialize formation configuration
-    config = MultiAgentFormationTaskConfig()
-    
-    # Create task
-    task = MultiAgentNavigationTask(
-        task_config=config.task_config,
-        env_config=config.env_config,
-        sim_config=config.sim_config, 
-        device="cuda" if torch.cuda.is_available() else "cpu"
-    )
-    
-    print(f"Formation type: {config.task_config['desired_formation']}")
-    print(f"Formation scale: {config.task_config['formation_scale']}")
-    
-    # Reset and run
-    observations = task.reset()
-    
-    for step in range(50):
-        # Use simple PD controller for formation maintenance
-        actions = simple_formation_controller(task, observations)
-        
-        observations, rewards, dones, info = task.step(actions)
-        
-        if step % 10 == 0:
-            print(f"Step {step}: Formation error = {info.get('formation_error', 'N/A')}")
-            
-        if dones.any():
-            observations = task.reset()
-
-def simple_formation_controller(task, observations):
-    """
-    Simple PD controller for formation maintenance
-    """
-    # This is a placeholder - in practice you'd implement proper control logic
-    actions = torch.zeros(
-        task.num_envs,
-        task.num_robots_per_env,
-        task.multi_agent_action_space.shape[1],
-        device=task.device
-    )
-    
-    # Extract relative positions from observations if available
-    # Apply simple control law to maintain formation
-    # This would need to be implemented based on actual observation structure
-    
-    return actions * 0.1  # Small actions for stability
-
-def run_swarm_navigation():
-    """Run large swarm navigation"""
-    print("\n=== Swarm Navigation Task ===")
-    
-    config = MultiAgentSwarmTaskConfig()
-    
-    task = MultiAgentNavigationTask(
-        task_config=config.task_config,
-        env_config=config.env_config,
-        sim_config=config.sim_config,
-        device="cuda" if torch.cuda.is_available() else "cpu"
-    )
-    
-    print(f"Swarm size: {config.task_config['num_robots_per_env']} drones")
-    print(f"Communication range: {config.task_config['communication_range']} meters")
-    
-    observations = task.reset()
-    
-    for step in range(30):
-        # Random swarm movement
-        actions = torch.rand(
-            task.num_envs,
-            task.num_robots_per_env,
-            task.multi_agent_action_space.shape[1], 
-            device=task.device
-        ) * 0.5 - 0.25  # Smaller random actions
-        
-        observations, rewards, dones, info = task.step(actions)
-        
-        if step % 10 == 0:
-            avg_distances = np.mean(info.get('target_distances', [0]))
-            print(f"Step {step}: Average target distance = {avg_distances:.2f}")
-            
-        if dones.any():
-            observations = task.reset()
-
-def demonstrate_inter_agent_communication():
-    """Demonstrate inter-agent observation sharing"""
-    print("\n=== Inter-Agent Communication Demo ===")
-    
-    config = MultiAgentNavigationTaskConfig()
-    config.task_config["enable_inter_agent_obs"] = True
-    config.task_config["communication_range"] = 10.0
-    
-    task = MultiAgentNavigationTask(
-        task_config=config.task_config,
-        env_config=config.env_config,
-        sim_config=config.sim_config,
-        device="cuda" if torch.cuda.is_available() else "cpu"
-    )
-    
-    observations = task.reset()
-    
-    print(f"With inter-agent communication enabled:")
-    print(f"  Observation dimension per robot: {observations.shape[2]}")
-    print(f"  Communication range: {config.task_config['communication_range']} meters")
-    
-    # Demonstrate that agents can observe each other
-    for step in range(10):
-        actions = torch.zeros(
-            task.num_envs,
-            task.num_robots_per_env, 
-            task.multi_agent_action_space.shape[1],
-            device=task.device
-        )
-        
-        observations, rewards, dones, info = task.step(actions)
-        
-        if step == 5:
-            print(f"  Step {step}: Robots can share relative position/velocity information")
-            print(f"  This enables cooperative behaviors and collision avoidance")
-
-if __name__ == "__main__":
-    print("Multi-Agent Aerial Gym Examples")
-    print("==============================")
-    
-    try:
-        # Run different multi-agent scenarios
-        run_multi_agent_navigation()
-        run_formation_flying()
-        run_swarm_navigation()
-        demonstrate_inter_agent_communication()
-        
-        print("\n=== Summary ===")
-        print("Multi-agent capabilities demonstrated:")
-        print("✓ Multiple drones per environment")
-        print("✓ Individual and shared reward structures")
-        print("✓ Formation control and maintenance")
-        print("✓ Inter-agent communication and observation sharing")
-        print("✓ Scalable to large swarms")
-        print("✓ Collision avoidance between agents")
-        
-    except Exception as e:
-        print(f"Error running examples: {e}")
-        print("Note: Some functionality may require additional implementation")
-        print("in the base RobotManager and environment classes.") 
\ No newline at end of file
diff --git a/examples/run_gate_visualization.sh b/examples/run_gate_visualization.sh
deleted file mode 100755
index e821a10..0000000
--- a/examples/run_gate_visualization.sh
+++ /dev/null
@@ -1,25 +0,0 @@
-#!/bin/bash
-
-# Set up environment for Isaac Gym
-export LD_LIBRARY_PATH=/home/ziyar/miniforge3/envs/aerialgym/lib:$LD_LIBRARY_PATH
-
-# Add Isaac Gym to Python path
-export PYTHONPATH=/home/ziyar/aerialgym/IsaacGym_Preview_4_Package/isaacgym/python:$PYTHONPATH
-
-# Change to the examples directory
-cd "$(dirname "$0")"
-
-echo "Running Gate Environment Visualization..."
-echo "LD_LIBRARY_PATH: $LD_LIBRARY_PATH"
-echo "PYTHONPATH: $PYTHONPATH"
-echo "Current directory: $(pwd)"
-
-# Activate conda environment if not already active
-if [[ "$CONDA_DEFAULT_ENV" != "aerialgym" ]]; then
-    echo "Activating conda environment..."
-    source /home/ziyar/miniforge3/etc/profile.d/conda.sh
-    conda activate aerialgym
-fi
-
-# Run the visualization script
-python3 simple_gate_visualization.py 
\ No newline at end of file
diff --git a/examples/sim_builder experiment (copy).py b/examples/sim_builder experiment (copy).py
deleted file mode 100644
index d7e260f..0000000
--- a/examples/sim_builder experiment (copy).py	
+++ /dev/null
@@ -1,268 +0,0 @@
-"""
-Simple Gate Navigation with X500 Robot and D455 Camera using SimBuilder
-=======================================================================
-
-This script demonstrates navigation through a gate environment using:
-1. X500 quadrotor robot with D455 depth camera sensor
-2. Lee position controller for waypoint navigation
-3. Gate environment with background trees
-4. Real-time visualization of robot camera output
-
-Key features:
-- Uses SimBuilder for simple environment creation
-- X500 quadrotor robot with onboard D455 camera
-- Lee position controller for stable navigation
-- Gate environment with trees for visual richness
-- Waypoint navigation through the gate
-"""
-
-from aerial_gym.utils.logging import CustomLogger
-
-logger = CustomLogger(__name__)
-from aerial_gym.sim.sim_builder import SimBuilder
-import torch
-from aerial_gym.utils.helpers import get_args
-import cv2
-import numpy as np
-import time
-
-
-def create_combined_image(depth_img, seg_img, title="X500 D455 Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-    # Take absolute value to handle negative depths
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 10 meters for D455 range)
-        depth_norm = np.clip(depth_norm, 0, 10.0)  
-        depth_norm = (depth_norm / 10.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 10.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 10.0)
-            pseudo_seg = (pseudo_seg / 10.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-
-def run_gate_navigation_with_camera(env_manager, duration_seconds=180.0):
-    """Run waypoint navigation through the gate with camera visualization."""
-    logger.info(f"Starting gate navigation for {duration_seconds} seconds...")
-    logger.info("Press ESC in camera window to exit early")
-        
-        # Define waypoints for navigation through the gate
-        waypoints = [
-        torch.tensor([-2.5, 0.0, 0.8], device=env_manager.device),  # Start position
-        torch.tensor([-1.0, 0.0, 1.2], device=env_manager.device),  # Approach gate
-        torch.tensor([0.0, 0.0, 1.2], device=env_manager.device),   # Gate center
-        torch.tensor([1.0, 0.0, 1.2], device=env_manager.device),   # Exit gate
-        torch.tensor([2.5, 0.0, 0.8], device=env_manager.device),   # End position
-        torch.tensor([2.5, 2.0, 1.5], device=env_manager.device),   # Move to side and up
-        torch.tensor([0.0, 2.0, 1.8], device=env_manager.device),   # Above gate from side
-        torch.tensor([-2.5, 0.0, 0.8], device=env_manager.device),  # Return to start
-        ]
-        
-        # Waypoint navigation parameters
-        current_waypoint_idx = 0
-    waypoint_reach_threshold = 0.5  # 50cm threshold
-    waypoint_hold_time = 2.0  # Hold at each waypoint for 2 seconds
-        waypoint_reached_time = None
-        
-    logger.info(f"🎯 Waypoint Navigation: X500 will navigate through {len(waypoints)} waypoints")
-    logger.info("   Route: Start → Approach Gate → Through Gate → Exit → Side → Above → Return")
-        
-        start_time = time.time()
-    step_count = 0
-    
-    # Reset environment
-    env_manager.reset()
-        
-    while True:
-            current_time = time.time()
-            if current_time - start_time > duration_seconds:
-                break
-                
-        # Get current robot position from environment state
-        robot_positions = env_manager.global_tensor_dict["robot_position"]
-        current_pos = robot_positions[0]  # First environment
-            
-            # Get current target waypoint
-            current_target = waypoints[current_waypoint_idx]
-            
-            # Check if current waypoint is reached
-            distance_to_waypoint = torch.norm(current_pos - current_target).item()
-            
-            # Safety mechanism: if drone is very far from current waypoint, find closest waypoint
-            if distance_to_waypoint > 2.0:  # If more than 2 meters away
-                closest_waypoint_idx = 0
-                min_distance = float('inf')
-                for i, waypoint in enumerate(waypoints):
-                    dist = torch.norm(current_pos - waypoint).item()
-                    if dist < min_distance:
-                        min_distance = dist
-                        closest_waypoint_idx = i
-                
-                if closest_waypoint_idx != current_waypoint_idx:
-                logger.info(f"🔄 Drone too far from waypoint {current_waypoint_idx + 1}, switching to closest waypoint {closest_waypoint_idx + 1}")
-                    current_waypoint_idx = closest_waypoint_idx
-                    current_target = waypoints[current_waypoint_idx]
-                    waypoint_reached_time = None
-                    distance_to_waypoint = min_distance
-            
-            if distance_to_waypoint <= waypoint_reach_threshold:
-                if waypoint_reached_time is None:
-                    waypoint_reached_time = current_time
-                logger.info(f"🎯 Reached waypoint {current_waypoint_idx + 1}/{len(waypoints)}: [{current_target[0]:.2f}, {current_target[1]:.2f}, {current_target[2]:.2f}]")
-                
-                # Check if we've held at this waypoint long enough
-                if current_time - waypoint_reached_time >= waypoint_hold_time:
-                    # Move to next waypoint
-                    current_waypoint_idx = (current_waypoint_idx + 1) % len(waypoints)
-                    waypoint_reached_time = None
-                    next_target = waypoints[current_waypoint_idx]
-                logger.info(f"🚁 Moving to waypoint {current_waypoint_idx + 1}/{len(waypoints)}: [{next_target[0]:.2f}, {next_target[1]:.2f}, {next_target[2]:.2f}]")
-            else:
-                waypoint_reached_time = None  # Reset if we move away from waypoint
-            
-            # Debug control output every 300 steps (5 seconds at 60 FPS)
-        if step_count % 300 == 0:
-                pos_np = current_pos.cpu().numpy()
-                target_np = current_target.cpu().numpy()
-                error = current_target - current_pos
-                distance = torch.norm(error).item()
-            logger.info(f"Position: [{pos_np[0]:.2f}, {pos_np[1]:.2f}, {pos_np[2]:.2f}], Target: [{target_np[0]:.2f}, {target_np[1]:.2f}, {target_np[2]:.2f}]")
-            logger.info(f"Error: [{error[0]:.2f}, {error[1]:.2f}, {error[2]:.2f}], Distance: {distance:.2f}m, Waypoint: {current_waypoint_idx + 1}/{len(waypoints)}")
-        
-        # Create command actions for Lee controller: [x, y, z, yaw]
-        actions = torch.zeros((env_manager.num_envs, 4), device=env_manager.device)
-        actions[0, 0:3] = current_target  # Target position
-        actions[0, 3] = 0.0  # Target yaw (face forward)
-        
-        # Step environment
-        env_manager.step(actions=actions)
-        
-        # Capture and display camera images
-        if hasattr(env_manager, 'get_camera_images') and step_count % 3 == 0:  # Every 3 steps for performance
-            try:
-                camera_images = env_manager.get_camera_images()
-                if camera_images is not None and len(camera_images) > 0:
-                    # Get depth and segmentation images from first environment
-                    depth_img = camera_images[0].get('depth')
-                    seg_img = camera_images[0].get('segmentation')
-                    
-                    if depth_img is not None and seg_img is not None:
-                        # Convert tensors to numpy arrays
-                        if torch.is_tensor(depth_img):
-                            depth_img = depth_img.cpu().numpy()
-                        if torch.is_tensor(seg_img):
-                            seg_img = seg_img.cpu().numpy()
-                        
-                        # Create combined visualization
-                        combined = create_combined_image(depth_img, seg_img, "X500 D455 Camera")
-                        
-                        if combined is not None:
-                            cv2.imshow("X500 D455 Camera View", combined)
-                            
-                            # Print camera statistics periodically
-                            if step_count % 300 == 0:
-                                valid_depths = depth_img[depth_img != -np.inf]
-                    if len(valid_depths) > 0:
-                        abs_valid_depths = np.abs(valid_depths)
-                        min_depth = np.min(abs_valid_depths)
-                        max_depth = np.max(abs_valid_depths)
-                        mean_depth = np.mean(abs_valid_depths)
-                                    valid_ratio = len(valid_depths) / depth_img.size * 100
-                                    logger.info(f"X500 D455 - Depth range: {min_depth:.2f}-{max_depth:.2f}m, Mean: {mean_depth:.2f}m, Valid: {valid_ratio:.1f}%")
-                        
-                        # Check for ESC key press
-        key = cv2.waitKey(1) & 0xFF
-        if key == 27:  # ESC key
-                            logger.info("ESC pressed, exiting navigation")
-                            break
-                
-        except Exception as e:
-                if step_count % 300 == 0:  # Only log errors occasionally
-                    logger.warning(f"Camera capture error: {e}")
-        
-        step_count += 1
-    
-    logger.info(f"\n✅ Gate navigation completed after {current_time - start_time:.1f} seconds")
-
-
-def main():
-    """Main function."""
-    try:
-        args = get_args()
-        
-        logger.info("🚁 Starting Gate Navigation with X500 and D455 Camera using SimBuilder...")
-        
-        # Build environment using SimBuilder
-        env_manager = SimBuilder().build_env(
-            sim_name="base_sim",
-            env_name="gate_env",  # Use gate environment with trees
-            robot_name="x500",    # X500 robot with D455 camera capability
-            controller_name="lee_position_control",
-            args=args,
-            device="cuda:0" if torch.cuda.is_available() else "cpu",
-            num_envs=getattr(args, 'num_envs', 1),
-            headless=getattr(args, 'headless', False),
-            use_warp=getattr(args, 'use_warp', False),
-        )
-        
-        logger.info("✅ Environment built successfully using SimBuilder!")
-        logger.info(f"Environment: gate_env, Robot: x500, Controller: lee_position_control")
-        logger.info(f"Number of environments: {env_manager.num_envs}")
-        logger.info(f"Device: {env_manager.device}")
-        
-        # Run gate navigation with camera visualization
-        run_gate_navigation_with_camera(env_manager, duration_seconds=180.0)  # 3 minutes
-        
-    except KeyboardInterrupt:
-        logger.info("\n⚠️ Interrupted by user")
-    except Exception as e:
-        logger.error(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        cv2.destroyAllWindows()
-        logger.info("👋 Goodbye!")
-
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/sim_builder experiment.py b/examples/sim_builder experiment.py
deleted file mode 100644
index d7e260f..0000000
--- a/examples/sim_builder experiment.py	
+++ /dev/null
@@ -1,268 +0,0 @@
-"""
-Simple Gate Navigation with X500 Robot and D455 Camera using SimBuilder
-=======================================================================
-
-This script demonstrates navigation through a gate environment using:
-1. X500 quadrotor robot with D455 depth camera sensor
-2. Lee position controller for waypoint navigation
-3. Gate environment with background trees
-4. Real-time visualization of robot camera output
-
-Key features:
-- Uses SimBuilder for simple environment creation
-- X500 quadrotor robot with onboard D455 camera
-- Lee position controller for stable navigation
-- Gate environment with trees for visual richness
-- Waypoint navigation through the gate
-"""
-
-from aerial_gym.utils.logging import CustomLogger
-
-logger = CustomLogger(__name__)
-from aerial_gym.sim.sim_builder import SimBuilder
-import torch
-from aerial_gym.utils.helpers import get_args
-import cv2
-import numpy as np
-import time
-
-
-def create_combined_image(depth_img, seg_img, title="X500 D455 Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-    # Take absolute value to handle negative depths
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 10 meters for D455 range)
-        depth_norm = np.clip(depth_norm, 0, 10.0)  
-        depth_norm = (depth_norm / 10.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 10.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 10.0)
-            pseudo_seg = (pseudo_seg / 10.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-
-def run_gate_navigation_with_camera(env_manager, duration_seconds=180.0):
-    """Run waypoint navigation through the gate with camera visualization."""
-    logger.info(f"Starting gate navigation for {duration_seconds} seconds...")
-    logger.info("Press ESC in camera window to exit early")
-        
-        # Define waypoints for navigation through the gate
-        waypoints = [
-        torch.tensor([-2.5, 0.0, 0.8], device=env_manager.device),  # Start position
-        torch.tensor([-1.0, 0.0, 1.2], device=env_manager.device),  # Approach gate
-        torch.tensor([0.0, 0.0, 1.2], device=env_manager.device),   # Gate center
-        torch.tensor([1.0, 0.0, 1.2], device=env_manager.device),   # Exit gate
-        torch.tensor([2.5, 0.0, 0.8], device=env_manager.device),   # End position
-        torch.tensor([2.5, 2.0, 1.5], device=env_manager.device),   # Move to side and up
-        torch.tensor([0.0, 2.0, 1.8], device=env_manager.device),   # Above gate from side
-        torch.tensor([-2.5, 0.0, 0.8], device=env_manager.device),  # Return to start
-        ]
-        
-        # Waypoint navigation parameters
-        current_waypoint_idx = 0
-    waypoint_reach_threshold = 0.5  # 50cm threshold
-    waypoint_hold_time = 2.0  # Hold at each waypoint for 2 seconds
-        waypoint_reached_time = None
-        
-    logger.info(f"🎯 Waypoint Navigation: X500 will navigate through {len(waypoints)} waypoints")
-    logger.info("   Route: Start → Approach Gate → Through Gate → Exit → Side → Above → Return")
-        
-        start_time = time.time()
-    step_count = 0
-    
-    # Reset environment
-    env_manager.reset()
-        
-    while True:
-            current_time = time.time()
-            if current_time - start_time > duration_seconds:
-                break
-                
-        # Get current robot position from environment state
-        robot_positions = env_manager.global_tensor_dict["robot_position"]
-        current_pos = robot_positions[0]  # First environment
-            
-            # Get current target waypoint
-            current_target = waypoints[current_waypoint_idx]
-            
-            # Check if current waypoint is reached
-            distance_to_waypoint = torch.norm(current_pos - current_target).item()
-            
-            # Safety mechanism: if drone is very far from current waypoint, find closest waypoint
-            if distance_to_waypoint > 2.0:  # If more than 2 meters away
-                closest_waypoint_idx = 0
-                min_distance = float('inf')
-                for i, waypoint in enumerate(waypoints):
-                    dist = torch.norm(current_pos - waypoint).item()
-                    if dist < min_distance:
-                        min_distance = dist
-                        closest_waypoint_idx = i
-                
-                if closest_waypoint_idx != current_waypoint_idx:
-                logger.info(f"🔄 Drone too far from waypoint {current_waypoint_idx + 1}, switching to closest waypoint {closest_waypoint_idx + 1}")
-                    current_waypoint_idx = closest_waypoint_idx
-                    current_target = waypoints[current_waypoint_idx]
-                    waypoint_reached_time = None
-                    distance_to_waypoint = min_distance
-            
-            if distance_to_waypoint <= waypoint_reach_threshold:
-                if waypoint_reached_time is None:
-                    waypoint_reached_time = current_time
-                logger.info(f"🎯 Reached waypoint {current_waypoint_idx + 1}/{len(waypoints)}: [{current_target[0]:.2f}, {current_target[1]:.2f}, {current_target[2]:.2f}]")
-                
-                # Check if we've held at this waypoint long enough
-                if current_time - waypoint_reached_time >= waypoint_hold_time:
-                    # Move to next waypoint
-                    current_waypoint_idx = (current_waypoint_idx + 1) % len(waypoints)
-                    waypoint_reached_time = None
-                    next_target = waypoints[current_waypoint_idx]
-                logger.info(f"🚁 Moving to waypoint {current_waypoint_idx + 1}/{len(waypoints)}: [{next_target[0]:.2f}, {next_target[1]:.2f}, {next_target[2]:.2f}]")
-            else:
-                waypoint_reached_time = None  # Reset if we move away from waypoint
-            
-            # Debug control output every 300 steps (5 seconds at 60 FPS)
-        if step_count % 300 == 0:
-                pos_np = current_pos.cpu().numpy()
-                target_np = current_target.cpu().numpy()
-                error = current_target - current_pos
-                distance = torch.norm(error).item()
-            logger.info(f"Position: [{pos_np[0]:.2f}, {pos_np[1]:.2f}, {pos_np[2]:.2f}], Target: [{target_np[0]:.2f}, {target_np[1]:.2f}, {target_np[2]:.2f}]")
-            logger.info(f"Error: [{error[0]:.2f}, {error[1]:.2f}, {error[2]:.2f}], Distance: {distance:.2f}m, Waypoint: {current_waypoint_idx + 1}/{len(waypoints)}")
-        
-        # Create command actions for Lee controller: [x, y, z, yaw]
-        actions = torch.zeros((env_manager.num_envs, 4), device=env_manager.device)
-        actions[0, 0:3] = current_target  # Target position
-        actions[0, 3] = 0.0  # Target yaw (face forward)
-        
-        # Step environment
-        env_manager.step(actions=actions)
-        
-        # Capture and display camera images
-        if hasattr(env_manager, 'get_camera_images') and step_count % 3 == 0:  # Every 3 steps for performance
-            try:
-                camera_images = env_manager.get_camera_images()
-                if camera_images is not None and len(camera_images) > 0:
-                    # Get depth and segmentation images from first environment
-                    depth_img = camera_images[0].get('depth')
-                    seg_img = camera_images[0].get('segmentation')
-                    
-                    if depth_img is not None and seg_img is not None:
-                        # Convert tensors to numpy arrays
-                        if torch.is_tensor(depth_img):
-                            depth_img = depth_img.cpu().numpy()
-                        if torch.is_tensor(seg_img):
-                            seg_img = seg_img.cpu().numpy()
-                        
-                        # Create combined visualization
-                        combined = create_combined_image(depth_img, seg_img, "X500 D455 Camera")
-                        
-                        if combined is not None:
-                            cv2.imshow("X500 D455 Camera View", combined)
-                            
-                            # Print camera statistics periodically
-                            if step_count % 300 == 0:
-                                valid_depths = depth_img[depth_img != -np.inf]
-                    if len(valid_depths) > 0:
-                        abs_valid_depths = np.abs(valid_depths)
-                        min_depth = np.min(abs_valid_depths)
-                        max_depth = np.max(abs_valid_depths)
-                        mean_depth = np.mean(abs_valid_depths)
-                                    valid_ratio = len(valid_depths) / depth_img.size * 100
-                                    logger.info(f"X500 D455 - Depth range: {min_depth:.2f}-{max_depth:.2f}m, Mean: {mean_depth:.2f}m, Valid: {valid_ratio:.1f}%")
-                        
-                        # Check for ESC key press
-        key = cv2.waitKey(1) & 0xFF
-        if key == 27:  # ESC key
-                            logger.info("ESC pressed, exiting navigation")
-                            break
-                
-        except Exception as e:
-                if step_count % 300 == 0:  # Only log errors occasionally
-                    logger.warning(f"Camera capture error: {e}")
-        
-        step_count += 1
-    
-    logger.info(f"\n✅ Gate navigation completed after {current_time - start_time:.1f} seconds")
-
-
-def main():
-    """Main function."""
-    try:
-        args = get_args()
-        
-        logger.info("🚁 Starting Gate Navigation with X500 and D455 Camera using SimBuilder...")
-        
-        # Build environment using SimBuilder
-        env_manager = SimBuilder().build_env(
-            sim_name="base_sim",
-            env_name="gate_env",  # Use gate environment with trees
-            robot_name="x500",    # X500 robot with D455 camera capability
-            controller_name="lee_position_control",
-            args=args,
-            device="cuda:0" if torch.cuda.is_available() else "cpu",
-            num_envs=getattr(args, 'num_envs', 1),
-            headless=getattr(args, 'headless', False),
-            use_warp=getattr(args, 'use_warp', False),
-        )
-        
-        logger.info("✅ Environment built successfully using SimBuilder!")
-        logger.info(f"Environment: gate_env, Robot: x500, Controller: lee_position_control")
-        logger.info(f"Number of environments: {env_manager.num_envs}")
-        logger.info(f"Device: {env_manager.device}")
-        
-        # Run gate navigation with camera visualization
-        run_gate_navigation_with_camera(env_manager, duration_seconds=180.0)  # 3 minutes
-        
-    except KeyboardInterrupt:
-        logger.info("\n⚠️ Interrupted by user")
-    except Exception as e:
-        logger.error(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        cv2.destroyAllWindows()
-        logger.info("👋 Goodbye!")
-
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/sim_builder_experiment.py b/examples/sim_builder_experiment.py
deleted file mode 100644
index 040ae8c..0000000
--- a/examples/sim_builder_experiment.py
+++ /dev/null
@@ -1,462 +0,0 @@
-"""
-Simple Gate Navigation with X500 Robot and D455 Camera using SimBuilder
-=======================================================================
-
-This script demonstrates navigation through a gate environment using:
-1. X500 quadrotor robot with D455 depth camera sensor
-2. Lee position controller for waypoint navigation
-3. Gate environment with background trees
-4. Real-time visualization of robot camera output with DCE RL Navigation processing
-
-Key features:
-- Uses SimBuilder for simple environment creation
-- X500 quadrotor robot with onboard D455 camera
-- Lee position controller for stable navigation
-- Gate environment with trees for visual richness
-- Waypoint navigation through the gate
-- DCE RL Navigation depth and segmentation processing pipeline
-
-Camera Processing Pipeline (DCE RL Navigation Method):
-- Depth: Normalized [0,1] tensor → uint8 (×255) → JET colormap
-- Segmentation: Raw segment IDs → 3-step DCE processing → Plasma colormap
-  Step 1: Fix zero/negative values with min_positive
-  Step 2: Normalize to [0,1] range
-  Step 3: Apply plasma colormap for visualization
-"""
-
-from aerial_gym.utils.logging import CustomLogger
-
-logger = CustomLogger(__name__)
-from aerial_gym.sim.sim_builder import SimBuilder
-import torch
-from aerial_gym.utils.helpers import get_args
-import cv2
-import numpy as np
-import time
-import matplotlib.cm
-
-# Isaac Gym imports for native camera API
-from isaacgym import gymapi, gymtorch
-
-
-def capture_robot_camera_images(env_manager):
-    """Capture depth and segmentation images from robot camera using global tensor dictionary.
-    
-    Uses the exact same method as DCE RL navigation for consistency.
-    """
-    try:
-        # Ensure sensors are rendered before capture (critical for proper data)
-        env_manager.render(render_components="sensors")
-        
-        # Access camera data through global_tensor_dict (like DCE navigation and other examples)
-        if not hasattr(env_manager, 'global_tensor_dict'):
-            return None, None
-        
-        global_tensor_dict = env_manager.global_tensor_dict
-        
-        # Get depth and segmentation images from first environment
-        depth_img = None
-        seg_img = None
-        
-        if "depth_range_pixels" in global_tensor_dict and global_tensor_dict["depth_range_pixels"] is not None:
-            # Get depth image from first environment, first camera
-            depth_tensor = global_tensor_dict["depth_range_pixels"][0, 0]  # [env_idx, camera_idx]
-            if depth_tensor is not None:
-                # DCE Navigation Method: Convert normalized depth (0-1) to uint8 for visualization
-                depth_img = (255.0 * depth_tensor.cpu().numpy()).astype(np.uint8)
-        
-        if "segmentation_pixels" in global_tensor_dict and global_tensor_dict["segmentation_pixels"] is not None:
-            # Get segmentation image from first environment, first camera
-            seg_tensor = global_tensor_dict["segmentation_pixels"][0, 0]  # [env_idx, camera_idx]
-            if seg_tensor is not None:
-                # DCE Navigation Method: Raw segmentation data (will be processed in create_combined_image)
-                seg_img = seg_tensor.cpu().numpy()
-        
-        return depth_img, seg_img
-        
-    except Exception as e:
-        logger.debug(f"Camera capture error: {e}")
-        return None, None
-
-
-def create_combined_image(depth_img, seg_img, title="X500 D455 Camera", collision_count=0, force_magnitude=0.0):
-    """Create combined visualization of depth and segmentation images with collision status.
-    
-    Uses the exact same processing pipeline as DCE RL navigation for consistency:
-    - Depth: Normalized [0,1] → uint8 → JET colormap
-    - Segmentation: Raw segment IDs → 3-step DCE processing → Plasma colormap
-    """
-    if depth_img is None or seg_img is None:
-        return None
-    
-    # === DEPTH PROCESSING (DCE Navigation Method) ===
-    # Input: depth_img is already uint8 from capture function (255.0 * normalized_depth)
-    # Apply JET colormap for depth visualization (same as DCE)
-    depth_colored = cv2.applyColorMap(depth_img, cv2.COLORMAP_JET)
-    
-    # === SEGMENTATION PROCESSING (DCE Navigation 3-Step Method) ===
-    seg_image_processed = seg_img.copy()
-    
-    # Step 1: Fix the error when there are no positive values (DCE method)
-    if np.any(seg_image_processed > 0):
-        min_positive = seg_image_processed[seg_image_processed > 0].min()
-        seg_image_processed[seg_image_processed <= 0] = min_positive
-    else:
-        # If no positive values, set all to a small positive value
-        seg_image_processed[:] = 0.1
-    
-    # Step 2: Normalize to [0,1] range (DCE method)
-    seg_normalized = (seg_image_processed - seg_image_processed.min()) / (
-        seg_image_processed.max() - seg_image_processed.min() + 1e-8
-    )
-    
-    # Step 3: Apply plasma colormap (DCE method)
-    seg_colored_float = matplotlib.cm.plasma(seg_normalized)
-    seg_colored = (seg_colored_float[:, :, :3] * 255.0).astype(np.uint8)
-    
-    # === COMBINED VISUALIZATION ===
-    # Create side-by-side layout
-    h, w = depth_colored.shape[:2]
-    combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-    combined[:, :w] = depth_colored      # Left: Depth (JET colormap)
-    combined[:, w:] = seg_colored        # Right: Segmentation (Plasma colormap)
-    
-    # Add simple labels only
-    font = cv2.FONT_HERSHEY_SIMPLEX
-    cv2.putText(combined, "Depth", (10, 20), font, 0.5, (255, 255, 255), 1)
-    cv2.putText(combined, "Segmentation", (w + 10, 20), font, 0.5, (255, 255, 255), 1)
-    
-    return combined
-
-
-def run_gate_navigation_with_camera(env_manager, duration_seconds=180.0):
-    """Run waypoint navigation through the gate with camera visualization and collision detection."""
-    logger.info(f"Starting gate navigation for {duration_seconds} seconds...")
-    logger.info("Press ESC in camera window to exit early")
-    logger.info("🛡️ Collision detection enabled - environment will reset on gate contact")
-    
-    # Define waypoints for navigation through the gate
-    # Gate is positioned at ground level (Z=0), so drone should fly at reasonable height
-    waypoints = [
-        torch.tensor([-2.5, 0.0, 1.0], device=env_manager.device),  # Start position (1m height)
-        # torch.tensor([0.0, 0.0, 0.5], device=env_manager.device),   # COLLISION TEST: Fly into gate at low height
-        # torch.tensor([-1.0, 0.0, 1.2], device=env_manager.device),  # Approach gate (after reset)
-        # torch.tensor([0.0, 0.0, 1.2], device=env_manager.device),   # Gate center (1.2m height to clear gate)
-        # torch.tensor([1.0, 0.0, 1.2], device=env_manager.device),   # Exit gate
-        # torch.tensor([2.5, 0.0, 1.0], device=env_manager.device),   # End position
-        # torch.tensor([2.5, 2.0, 1.5], device=env_manager.device),   # Move to side and up
-        # torch.tensor([0.0, 2.0, 1.8], device=env_manager.device),   # Above gate from side
-        # torch.tensor([-2.5, 0.0, 1.0], device=env_manager.device),  # Return to start
-    ]
-    
-    # Waypoint navigation parameters
-    current_waypoint_idx = 0
-    waypoint_reach_threshold = 0.5  # 50cm threshold
-    waypoint_hold_time = 2.0  # Hold at each waypoint for 2 seconds
-    waypoint_reached_time = None
-    
-    # Collision detection parameters
-    collision_count = 0
-    last_collision_time = 0
-    collision_cooldown = 2.0  # Don't log collisions too frequently
-    
-    logger.info(f"🎯 Waypoint Navigation: X500 will navigate through {len(waypoints)} waypoints")
-    logger.info("   Route: Start → Approach Gate → Through Gate → Exit → Side → Above → Return")
-    
-    start_time = time.time()
-    step_count = 0
-    
-    # Reset environment
-    env_manager.reset()
-    
-    while True:
-        current_time = time.time()
-        if current_time - start_time > duration_seconds:
-            break
-        
-        # Get current robot position from environment state
-        robot_positions = env_manager.global_tensor_dict["robot_position"]
-        current_pos = robot_positions[0]  # First environment
-        
-        # Get current target waypoint
-        current_target = waypoints[current_waypoint_idx]
-        
-        # Check if current waypoint is reached
-        distance_to_waypoint = torch.norm(current_pos - current_target).item()
-        
-        # Safety mechanism: if drone is very far from current waypoint, find closest waypoint
-        if distance_to_waypoint > 2.0:  # If more than 2 meters away
-            closest_waypoint_idx = 0
-            min_distance = float('inf')
-            for i, waypoint in enumerate(waypoints):
-                dist = torch.norm(current_pos - waypoint).item()
-                if dist < min_distance:
-                    min_distance = dist
-                    closest_waypoint_idx = i
-            
-            if closest_waypoint_idx != current_waypoint_idx:
-                logger.info(f"🔄 Drone too far from waypoint {current_waypoint_idx + 1}, switching to closest waypoint {closest_waypoint_idx + 1}")
-                current_waypoint_idx = closest_waypoint_idx
-                current_target = waypoints[current_waypoint_idx]
-                waypoint_reached_time = None
-                distance_to_waypoint = min_distance
-        
-        if distance_to_waypoint <= waypoint_reach_threshold:
-            if waypoint_reached_time is None:
-                waypoint_reached_time = current_time
-                logger.info(f"🎯 Reached waypoint {current_waypoint_idx + 1}/{len(waypoints)}: [{current_target[0]:.2f}, {current_target[1]:.2f}, {current_target[2]:.2f}]")
-            
-            # Check if we've held at this waypoint long enough
-            if current_time - waypoint_reached_time >= waypoint_hold_time:
-                # Move to next waypoint
-                current_waypoint_idx = (current_waypoint_idx + 1) % len(waypoints)
-                waypoint_reached_time = None
-                next_target = waypoints[current_waypoint_idx]
-                logger.info(f"🚁 Moving to waypoint {current_waypoint_idx + 1}/{len(waypoints)}: [{next_target[0]:.2f}, {next_target[1]:.2f}, {next_target[2]:.2f}]")
-        else:
-            waypoint_reached_time = None  # Reset if we move away from waypoint
-        
-        # Debug control output every 300 steps (5 seconds at 60 FPS)
-        if step_count % 300 == 0:
-            pos_np = current_pos.cpu().numpy()
-            target_np = current_target.cpu().numpy()
-            error = current_target - current_pos
-            distance = torch.norm(error).item()
-            logger.info(f"Position: [{pos_np[0]:.2f}, {pos_np[1]:.2f}, {pos_np[2]:.2f}], Target: [{target_np[0]:.2f}, {target_np[1]:.2f}, {target_np[2]:.2f}]")
-            logger.info(f"Error: [{error[0]:.2f}, {error[1]:.2f}, {error[2]:.2f}], Distance: {distance:.2f}m, Waypoint: {current_waypoint_idx + 1}/{len(waypoints)}")
-            
-            # Debug collision detection data
-            try:
-                if hasattr(env_manager, 'global_tensor_dict'):
-                    # Check collision tensor status
-                    if hasattr(env_manager, 'collision_tensor'):
-                        collision_status = env_manager.collision_tensor[0].item()
-                        logger.info(f"Collision tensor: {collision_status}")
-                    
-                    # Check contact forces
-                    if 'robot_contact_force_tensor' in env_manager.global_tensor_dict:
-                        contact_forces = env_manager.global_tensor_dict['robot_contact_force_tensor']
-                        if contact_forces is not None and len(contact_forces) > 0:
-                            contact_force_magnitude = torch.norm(contact_forces[0]).item()
-                            logger.info(f"Contact force magnitude: {contact_force_magnitude:.4f} N")
-                    
-                    # Check force sensor data
-                    if 'robot_force_sensor' in env_manager.global_tensor_dict:
-                        force_data = env_manager.global_tensor_dict['robot_force_sensor']
-                        if force_data is not None and len(force_data) > 0:
-                            force_sensor_magnitude = torch.norm(force_data[0, :3]).item()
-                            logger.info(f"Force sensor magnitude: {force_sensor_magnitude:.4f} N")
-                    
-                    # Show collision threshold
-                    if hasattr(env_manager, 'cfg') and hasattr(env_manager.cfg, 'env'):
-                        threshold = env_manager.cfg.env.collision_force_threshold
-                        logger.info(f"Collision threshold: {threshold:.4f} N")
-                        
-            except Exception as e:
-                logger.debug(f"Debug info error: {e}")
-        
-        # Create command actions for Lee controller: [x, y, z, yaw]
-        actions = torch.zeros((env_manager.num_envs, 4), device=env_manager.device)
-        actions[0, 0:3] = current_target  # Target position
-        actions[0, 3] = 0.0  # Target yaw (face forward)
-        
-        # Step environment
-        env_manager.step(actions=actions)
-        
-        # Manually trigger collision detection and environment reset
-        try:
-            # Call compute_observations to update collision tensor
-            if hasattr(env_manager, 'compute_observations'):
-                env_manager.compute_observations()
-            
-            # Check for collisions using the environment's collision detection system
-            if hasattr(env_manager, 'collision_tensor'):
-                collision_detected = env_manager.collision_tensor[0].item() > 0
-                if collision_detected:
-                    current_time = time.time()
-                    if current_time - last_collision_time > collision_cooldown:
-                        collision_count += 1
-                        last_collision_time = current_time
-                        pos_np = current_pos.cpu().numpy()
-                        logger.warning(f"💥 COLLISION DETECTED! #{collision_count}")
-                        logger.warning(f"   Position at collision: [{pos_np[0]:.2f}, {pos_np[1]:.2f}, {pos_np[2]:.2f}]")
-                        logger.warning(f"   Target waypoint: {current_waypoint_idx + 1}/{len(waypoints)}")
-                        logger.warning("   Environment will reset automatically...")
-                        
-                        # Reset waypoint to start position for safety after reset
-                        current_waypoint_idx = 0
-                        waypoint_reached_time = None
-            
-            # Call the environment's reset function for terminated environments
-            if hasattr(env_manager, 'reset_terminated_and_truncated_envs'):
-                envs_reset = env_manager.reset_terminated_and_truncated_envs()
-                if len(envs_reset) > 0:
-                    logger.info(f"🔄 Environment(s) {envs_reset.tolist()} reset due to collision/termination")
-            
-            # Check contact forces for display purposes
-            current_force = 0.0
-            if 'robot_contact_force_tensor' in env_manager.global_tensor_dict:
-                contact_forces = env_manager.global_tensor_dict['robot_contact_force_tensor']
-                if contact_forces is not None and len(contact_forces) > 0:
-                    current_force = torch.norm(contact_forces[0]).item()
-            
-            # Alternative: Check force sensor data for display
-            elif 'robot_force_sensor' in env_manager.global_tensor_dict:
-                force_data = env_manager.global_tensor_dict['robot_force_sensor']
-                if force_data is not None and len(force_data) > 0:
-                    current_force = torch.norm(force_data[0, :3]).item()
-        
-        except Exception as e:
-            if step_count % 300 == 0:  # Only log errors occasionally
-                logger.debug(f"Collision detection error: {e}")
-        
-        # Capture and display camera images using Isaac Gym native API
-        if step_count % 3 == 0:  # Every 3 steps for performance
-            try:
-                # Render sensors to update camera data (crucial step!)
-                env_manager.render(render_components="sensors")
-                
-                # Use Isaac Gym native camera capture (inspired by reference file)
-                depth_img, seg_img = capture_robot_camera_images(env_manager)
-                
-                if depth_img is not None and seg_img is not None:
-                    # Use the current_force from collision detection above
-                    # (current_force is already calculated in the collision detection section)
-                    
-                    # Create combined visualization with collision status
-                    combined = create_combined_image(depth_img, seg_img, "X500 D455 Camera", 
-                                                   collision_count, current_force)
-                    
-                    if combined is not None:
-                        # Create named window with proper flags for visibility
-                        cv2.namedWindow("X500 D455 Camera View", cv2.WINDOW_NORMAL)
-                        cv2.resizeWindow("X500 D455 Camera View", 960, 270)  # D455 resolution scaled
-                        cv2.imshow("X500 D455 Camera View", combined)
-                        
-                        # Print camera statistics periodically (DCE Navigation style)
-                        if step_count % 300 == 0:
-                            logger.info("📸 === DCE-Style Camera Data Analysis ===")
-                            
-                            # Depth analysis (on uint8 visualization data)
-                            valid_depths = depth_img[depth_img > 0]  # Valid depth pixels
-                            if len(valid_depths) > 0:
-                                min_depth_vis = np.min(valid_depths)
-                                max_depth_vis = np.max(valid_depths)
-                                mean_depth_vis = np.mean(valid_depths)
-                                valid_ratio = len(valid_depths) / depth_img.size * 100
-                                logger.info(f"   Depth (uint8): range {min_depth_vis}-{max_depth_vis}, mean {mean_depth_vis:.1f}, valid {valid_ratio:.1f}%")
-                                
-                                # Convert back to actual depth values for reference
-                                actual_min = min_depth_vis / 255.0 * 10.0  # Assuming 10m max range
-                                actual_max = max_depth_vis / 255.0 * 10.0
-                                actual_mean = mean_depth_vis / 255.0 * 10.0
-                                logger.info(f"   Depth (actual): range {actual_min:.2f}-{actual_max:.2f}m, mean {actual_mean:.2f}m")
-                            else:
-                                logger.warning("   Depth: No valid pixels detected!")
-                                
-                            # Segmentation analysis (DCE method)
-                            unique_segs = np.unique(seg_img)
-                            logger.info(f"   Segmentation (raw): {len(unique_segs)} unique values, range {unique_segs.min():.1f} to {unique_segs.max():.1f}")
-                            
-                            # Show segment distribution
-                            if len(unique_segs) <= 10:  # Only show if not too many segments
-                                seg_counts = [(val, np.sum(seg_img == val)) for val in unique_segs]
-                                logger.info(f"   Segment distribution: {seg_counts}")
-                            
-                            # Show processing pipeline status
-                            pos_seg_count = np.sum(seg_img > 0)
-                            zero_neg_count = np.sum(seg_img <= 0)
-                            logger.info(f"   Segmentation processing: {pos_seg_count} positive pixels, {zero_neg_count} zero/negative pixels")
-                            
-                            # Expected segmentation with collision-enabled trees:
-                            # - Gate: Should appear as distinct segments (cyan/turquoise in plasma)
-                            # - Trees: Should now appear as tree segments (different plasma colors)
-                            # - Ground: Background/ground plane segments (dark colors in plasma)
-                            # - Sky/Empty: Zero/negative values (will be fixed by DCE processing)
-                            
-                            if zero_neg_count > 0:
-                                logger.info("   → DCE Step 1: Will fix zero/negative values with min_positive")
-                            logger.info("   → DCE Step 2: Normalizing to [0,1] range")
-                            logger.info("   → DCE Step 3: Applying plasma colormap")
-                            logger.info("   Expected segments: Gate + Trees + Walls + Ground (collision-enabled objects)")
-                            logger.info("📸 === End Camera Analysis ===\n")
-                    
-                    # Check for ESC key press
-                    key = cv2.waitKey(1) & 0xFF
-                    if key == 27:  # ESC key
-                        logger.info("ESC pressed, exiting navigation")
-                        break
-                else:
-                    # Show debug info when no camera data
-                    if step_count % 300 == 0:
-                        logger.warning("No camera images captured - camera may not be properly configured")
-                            
-            except Exception as e:
-                if step_count % 300 == 0:  # Only log errors occasionally
-                    logger.warning(f"Camera capture error: {e}")
-        
-        step_count += 1
-    
-    logger.info(f"\n✅ Gate navigation completed after {current_time - start_time:.1f} seconds")
-    logger.info(f"📊 Navigation Statistics:")
-    logger.info(f"   Total collisions detected: {collision_count}")
-    logger.info(f"   Total simulation steps: {step_count}")
-    if collision_count > 0:
-        logger.info(f"   Collision rate: {collision_count / (current_time - start_time) * 60:.2f} collisions/minute")
-    else:
-        logger.info("   🏆 Perfect flight - no collisions detected!")
-
-
-def main():
-    """Main function."""
-    try:
-        args = get_args()
-        
-        logger.info("🚁 Starting Gate Navigation with X500 and D455 Camera using SimBuilder...")
-        
-        # Build environment using SimBuilder
-        num_envs_requested = getattr(args, 'num_envs', 1)
-        logger.info(f"🔧 Requesting {num_envs_requested} environments")
-        
-        env_manager = SimBuilder().build_env(
-            sim_name="base_sim",
-            env_name="gate_env",  # Use gate environment with trees
-            robot_name="x500",    # X500 robot with D455 camera capability
-            controller_name="lee_position_control",
-            args=args,
-            device="cuda:0" if torch.cuda.is_available() else "cpu",
-            num_envs=num_envs_requested,
-            headless=getattr(args, 'headless', False),
-            use_warp=getattr(args, 'use_warp', False),
-        )
-        
-        logger.info("✅ Environment built successfully using SimBuilder!")
-        logger.info(f"Environment: gate_env, Robot: x500, Controller: lee_position_control")
-        logger.info(f"Number of environments: {env_manager.num_envs}")
-        logger.info(f"Device: {env_manager.device}")
-        
-        # Check if num_envs was properly set
-        if env_manager.num_envs != num_envs_requested:
-            logger.error(f"❌ Environment created {env_manager.num_envs} environments instead of requested {num_envs_requested}!")
-            logger.error("This suggests the environment configuration is not properly overriding the default values.")
-            logger.error("Attempting to continue with the actual number of environments...")
-        else:
-            logger.info(f"✅ Environment correctly created {num_envs_requested} environment(s)")
-        
-        # Run gate navigation with camera visualization
-        run_gate_navigation_with_camera(env_manager, duration_seconds=180.0)  # 3 minutes
-        
-    except KeyboardInterrupt:
-        logger.info("\n⚠️ Interrupted by user")
-    except Exception as e:
-        logger.error(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        cv2.destroyAllWindows()
-        logger.info("👋 Goodbye!")
-
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_demo.py b/examples/simple_gate_demo.py
deleted file mode 100644
index 349a897..0000000
--- a/examples/simple_gate_demo.py
+++ /dev/null
@@ -1,164 +0,0 @@
-"""
-Simple Gate Environment Demo
-
-A straightforward demo script to test the gate environment with:
-- Single environment (no parallelization)
-- Fixed gate position (non-randomized) 
-- Simple automated flight pattern
-- Clear visualization and logging
-
-This is perfect for initial testing and debugging of the gate environment.
-"""
-
-import numpy as np
-import time
-from aerial_gym.sim.sim_builder import SimBuilder
-from aerial_gym.config.env_config.gate_env import GateEnvCfg
-from aerial_gym.config.robot_config.base_quad_config import BaseQuadCfg
-from aerial_gym.config.controller_config.lee_controller_config import LeeControllerCfg
-import torch
-
-
-class SimpleGateEnvCfg(GateEnvCfg):
-    """Modified gate environment config for single environment testing."""
-    
-    class env(GateEnvCfg.env):
-        # Single environment for easy testing
-        num_envs = 1
-        
-        # Smaller environment bounds for easier visualization
-        lower_bound_min = [-5.0, -5.0, -0.5]
-        lower_bound_max = [-5.0, -5.0, -0.5]  # Fixed bounds
-        upper_bound_min = [5.0, 5.0, 3.0]
-        upper_bound_max = [5.0, 5.0, 3.0]    # Fixed bounds
-        
-        # More responsive simulation
-        render_viewer_every_n_steps = 1
-        
-        # Less sensitive collision detection for testing
-        collision_force_threshold = 0.1
-        
-        # Create ground plane for reference
-        create_ground_plane = True
-
-
-def main():
-    """Main demo function."""
-    
-    print("="*60)
-    print("SIMPLE GATE ENVIRONMENT DEMO")
-    print("="*60)
-    print("Testing gate environment with:")
-    print("- Single environment (no parallelization)")
-    print("- Fixed gate position at center")
-    print("- Automated flight pattern")
-    print("="*60)
-    
-    # Configuration
-    env_cfg = SimpleGateEnvCfg
-    robot_cfg = BaseQuadCfg
-    controller_cfg = LeeControllerCfg
-    
-    print("\nBuilding simulation...")
-    
-    # Create simulation builder
-    sim_builder = SimBuilder(
-        env_config=env_cfg,
-        robot_config=robot_cfg,
-        controller_config=controller_cfg,
-        args=None
-    )
-    
-    # Build environment
-    env = sim_builder.build_env()
-    
-    print(f"✓ Environment built successfully!")
-    print(f"✓ Number of environments: {env.num_envs}")
-    print(f"✓ Environment bounds: {env.env_bounds}")
-    
-    # Reset environment
-    obs = env.reset()
-    
-    print(f"✓ Environment initialized!")
-    print(f"✓ Robot starting position: {obs['robot_position'][0]}")
-    
-    print("\nStarting flight demonstration...")
-    print("Flight plan:")
-    print("1. Hover and stabilize (steps 0-100)")
-    print("2. Move toward gate (steps 100-300)")
-    print("3. Fly through gate (steps 300-500)")
-    print("4. Continue past gate (steps 500-700)")
-    print("5. Return back through gate (steps 700-1000)")
-    
-    # Flight demonstration
-    for step in range(1000):
-        
-        # Define flight phases
-        if step < 100:
-            # Phase 1: Hover and stabilize
-            actions = torch.tensor([[0.0, 0.0, 0.0, 0.6]], device=env.device)
-            phase = "Hovering"
-            
-        elif step < 300:
-            # Phase 2: Move toward gate (approach on X-axis)
-            actions = torch.tensor([[0.4, 0.0, 0.0, 0.6]], device=env.device)
-            phase = "Approaching gate"
-            
-        elif step < 500:
-            # Phase 3: Fly through gate (slower, controlled)
-            actions = torch.tensor([[0.2, 0.0, 0.0, 0.6]], device=env.device)
-            phase = "Flying through gate"
-            
-        elif step < 700:
-            # Phase 4: Continue past gate
-            actions = torch.tensor([[0.1, 0.0, 0.0, 0.6]], device=env.device)
-            phase = "Past gate"
-            
-        else:
-            # Phase 5: Return back through gate
-            actions = torch.tensor([[-0.3, 0.0, 0.0, 0.6]], device=env.device)
-            phase = "Returning through gate"
-        
-        # Step environment
-        obs, rewards, dones, infos = env.step(actions)
-        
-        # Get robot state
-        robot_pos = obs["robot_position"][0]
-        robot_vel = obs["robot_body_linvel"][0] if "robot_body_linvel" in obs else torch.zeros(3)
-        
-        # Log progress every 50 steps
-        if step % 50 == 0:
-            print(f"Step {step:4d} | {phase:20s} | "
-                  f"Pos: ({robot_pos[0]:+5.2f}, {robot_pos[1]:+5.2f}, {robot_pos[2]:+5.2f}) | "
-                  f"Vel: ({robot_vel[0]:+5.2f}, {robot_vel[1]:+5.2f}, {robot_vel[2]:+5.2f})")
-        
-        # Check for collisions
-        if dones[0]:
-            print(f"⚠️  Episode ended at step {step} (collision or reset)")
-            obs = env.reset()
-            print(f"🔄 Environment reset, continuing...")
-        
-        # Small delay for visualization
-        time.sleep(0.02)
-    
-    print("\n" + "="*60)
-    print("DEMO COMPLETED SUCCESSFULLY!")
-    print("="*60)
-    print("Gate environment is working correctly!")
-    print("\nEnvironment features tested:")
-    print("✓ Gate asset loading and positioning")
-    print("✓ Robot spawning and control")
-    print("✓ Physics simulation")
-    print("✓ Collision detection")
-    print("✓ Environment bounds")
-    print("✓ Flight dynamics")
-    
-    print("\nNext steps:")
-    print("- Use this environment for RL training")
-    print("- Add sensors (cameras, lidar) for perception")
-    print("- Create navigation tasks")
-    print("- Test with different robot configurations")
-
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization.py b/examples/simple_gate_visualization.py
deleted file mode 100644
index 75b756f..0000000
--- a/examples/simple_gate_visualization.py
+++ /dev/null
@@ -1,344 +0,0 @@
-"""
-Simple Gate Visualization Demo
-
-This script creates and visualizes the gate environment using Isaac Gym.
-It spawns a gate in the environment and allows you to view it interactively.
-"""
-
-import sys
-import os
-import numpy as np
-import time
-
-# Add the aerial_gym path
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
-
-try:
-    # Import Isaac Gym and Aerial Gym components
-    import isaacgym
-    from isaacgym import gymapi, gymtorch, gymutil
-    
-    # Import aerial gym components
-    from aerial_gym.config.env_config.gate_env import GateEnvCfg
-    from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-    from aerial_gym.env_manager.asset_manager import AssetManager
-    from aerial_gym.sim.sim_builder import SimBuilder
-    
-    print("✓ Successfully imported all required modules!")
-    
-except ImportError as e:
-    print(f"❌ Import error: {e}")
-    print("This might be due to missing dependencies or Python environment issues.")
-    sys.exit(1)
-
-
-class GateEnvironmentVisualizer:
-    """
-    A simple visualizer for the gate environment.
-    """
-    
-    def __init__(self, headless=False):
-        """
-        Initialize the gate environment visualizer.
-        
-        Args:
-            headless (bool): Whether to run in headless mode (no graphics)
-        """
-        self.headless = headless
-        self.gym = None
-        self.sim = None
-        self.viewer = None
-        self.env_handles = []
-        self.gate_handles = []
-        
-        # Environment parameters
-        self.num_envs = 1  # Single environment for visualization
-        self.env_spacing = 10.0  # Spacing between environments
-        
-        # Initialize the environment
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        
-        if not self.headless:
-            self._create_viewer()
-            self._setup_camera()
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        # Configure simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0  # 60 FPS
-        sim_params.substeps = 2
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        
-        # Physics engine settings
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 8
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.rest_offset = 0.0
-        sim_params.physx.contact_offset = 0.001
-        sim_params.physx.friction_offset_threshold = 0.001
-        sim_params.physx.friction_correlation_distance = 0.0005
-        sim_params.physx.num_threads = 0
-        sim_params.physx.use_gpu = True
-        
-        # GPU settings
-        self.device = 'cuda:0'
-        sim_params.use_gpu_pipeline = True
-        
-        self.sim_params = sim_params
-        
-    def _create_sim(self):
-        """Create the simulation."""
-        print("Creating simulation...")
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(
-            compute_device=0,
-            graphics_device=0 if not self.headless else -1,
-            type=gymapi.SIM_PHYSX,
-            params=self.sim_params
-        )
-        
-        if self.sim is None:
-            raise RuntimeError("Failed to create simulation")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0, 0, 1)
-        plane_params.distance = 0
-        plane_params.static_friction = 1.0
-        plane_params.dynamic_friction = 1.0
-        plane_params.restitution = 0.0
-        
-        self.gym.add_ground(self.sim, plane_params)
-    
-    def _load_gate_asset(self):
-        """Load the gate asset."""
-        print("Loading gate asset...")
-        
-        # Asset loading options - simplified for static gate
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True  # Gate is fixed in place
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True  # Static object doesn't need gravity
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET  # Use normals from asset
-        
-        # Load gate asset
-        gate_asset_path = f"{gate_asset_params.asset_folder}/{gate_asset_params.file}"
-        
-        if not os.path.exists(gate_asset_path):
-            print(f"❌ Gate URDF not found at: {gate_asset_path}")
-            print("Please ensure the gate URDF file exists!")
-            sys.exit(1)
-        
-        print(f"Loading gate from: {gate_asset_path}")
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise RuntimeError(f"Failed to load gate asset from {gate_asset_path}")
-        
-        print("✓ Gate asset loaded successfully!")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create the environments with gates."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Center position
-        gate_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # No rotation
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Note: Gate color is set in the URDF material properties
-        # Isaac Gym will use the default material colors from the URDF
-        
-        print("✓ Environment created with gate!")
-    
-    def _create_viewer(self):
-        """Create the viewer for visualization."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Create viewer
-        self.viewer = self.gym.create_viewer(self.sim, gymapi.CameraProperties())
-        
-        if self.viewer is None:
-            raise RuntimeError("Failed to create viewer")
-    
-    def _setup_camera(self):
-        """Setup camera position for good gate viewing."""
-        if self.headless or self.viewer is None:
-            return
-        
-        print("Setting up camera...")
-        
-        # Position camera to get a good view of the gate
-        cam_pos = gymapi.Vec3(8.0, -8.0, 4.0)  # Position for angled view
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look at center of gate
-        
-        self.gym.viewer_camera_look_at(self.viewer, None, cam_pos, cam_target)
-    
-    def run_visualization(self, duration=60.0, physics_mode=True):
-        """
-        Run the visualization loop.
-        
-        Args:
-            duration (float): How long to run the visualization in seconds
-            physics_mode (bool): Whether to run physics simulation or just render
-        """
-        print(f"Starting visualization for {duration} seconds...")
-        print("Controls:")
-        print("  - Mouse: Look around")
-        print("  - W/A/S/D: Move camera")
-        print("  - Q/E: Move camera up/down")
-        print("  - ESC: Exit")
-        
-        if physics_mode:
-            print("Running with physics simulation...")
-            # Prepare simulation
-            self.gym.prepare_sim(self.sim)
-        else:
-            print("Running in render-only mode (no physics)...")
-        
-        start_time = time.time()
-        
-        try:
-            while not self.gym.query_viewer_has_closed(self.viewer):
-                if physics_mode:
-                    # Step simulation - use simpler approach for static objects
-                    self.gym.simulate(self.sim)
-                    self.gym.fetch_results(self.sim, True)
-                
-                # Update viewer (this works even without physics)
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                
-                # Check if duration exceeded
-                if time.time() - start_time > duration:
-                    print(f"Visualization completed after {duration} seconds.")
-                    break
-                
-                # Small delay to prevent excessive CPU usage
-                time.sleep(0.016)  # ~60 FPS
-                
-        except KeyboardInterrupt:
-            print("Visualization interrupted by user.")
-        except Exception as e:
-            print(f"Error during visualization loop: {e}")
-            print("Trying render-only mode...")
-            if physics_mode:
-                # Retry without physics
-                self.run_visualization(duration, physics_mode=False)
-    
-    def print_environment_info(self):
-        """Print information about the created environment."""
-        print("\n" + "="*60)
-        print("GATE ENVIRONMENT INFORMATION")
-        print("="*60)
-        
-        print(f"Number of environments: {len(self.env_handles)}")
-        print(f"Number of gates: {len(self.gate_handles)}")
-        print(f"Environment bounds: -8m to +8m in X,Y and 0m to +8m in Z")
-        print(f"Gate position: Center of environment (0, 0, 0)")
-        print(f"Gate dimensions: ~3m wide × 3m tall opening")
-        
-        if self.viewer:
-            print(f"Viewer: Active (interactive)")
-        else:
-            print(f"Viewer: Headless mode")
-        
-        print(f"Physics: Isaac Gym PhysX")
-        print(f"Simulation timestep: {self.sim_params.dt:.4f}s")
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        if self.viewer:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if self.sim:
-            self.gym.destroy_sim(self.sim)
-
-
-def main():
-    """Main function to run the gate visualization."""
-    
-    print("GATE ENVIRONMENT VISUALIZATION")
-    print("="*60)
-    
-    # Check if gate URDF exists
-    gate_urdf_path = f"{gate_asset_params.asset_folder}/{gate_asset_params.file}"
-    if not os.path.exists(gate_urdf_path):
-        print(f"❌ Gate URDF file not found: {gate_urdf_path}")
-        print("Please create the gate URDF file first!")
-        return 1
-    
-    try:
-        # Create visualizer
-        visualizer = GateEnvironmentVisualizer(headless=False)
-        
-        # Print environment information
-        visualizer.print_environment_info()
-        
-        # Run visualization
-        visualizer.run_visualization(duration=300.0)  # 5 minutes
-        
-        # Cleanup
-        visualizer.cleanup()
-        
-        print("✓ Gate visualization completed successfully!")
-        return 0
-        
-    except Exception as e:
-        print(f"❌ Error during visualization: {e}")
-        import traceback
-        traceback.print_exc()
-        return 1
-
-
-if __name__ == "__main__":
-    exit_code = main()
-    sys.exit(exit_code) 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_racing.py b/examples/simple_gate_visualization_racing.py
deleted file mode 100644
index abe147a..0000000
--- a/examples/simple_gate_visualization_racing.py
+++ /dev/null
@@ -1,183 +0,0 @@
-"""
-Simple Racing Gate Visualization Demo
-
-This script visualizes the racing-patterned gate environment using Isaac Gym.
-"""
-
-import sys
-import os
-import numpy as np
-import time
-
-# Add the aerial_gym path
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
-
-try:
-    # Import Isaac Gym and Aerial Gym components
-    import isaacgym
-    from isaacgym import gymapi, gymtorch, gymutil
-    
-    # Import aerial gym components
-    from aerial_gym.config.env_config.gate_env import GateEnvCfg
-    
-    print("✓ Successfully imported all required modules!")
-    
-except ImportError as e:
-    print(f"❌ Import error: {e}")
-    print("This might be due to missing dependencies or Python environment issues.")
-    sys.exit(1)
-
-
-class GateEnvironmentVisualizer:
-    """
-    A simple visualizer for the racing gate environment.
-    """
-    
-    def __init__(self, headless=False):
-        self.headless = headless
-        self.gym = None
-        self.sim = None
-        self.viewer = None
-        self.env_handles = []
-        self.gate_handles = []
-        
-        # Initialize the environment
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        
-        if not self.headless:
-            self._create_viewer()
-            self._setup_camera()
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        self.gym = gymapi.acquire_gym()
-        
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0
-        sim_params.substeps = 2
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 8
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.use_gpu = True
-        
-        self.device = 'cuda:0'
-        sim_params.use_gpu_pipeline = True
-        self.sim_params = sim_params
-        
-    def _create_sim(self):
-        """Create the simulation."""
-        print("Creating simulation...")
-        self.sim = self.gym.create_sim(0, 0 if not self.headless else -1, gymapi.SIM_PHYSX, self.sim_params)
-        if self.sim is None:
-            raise RuntimeError("Failed to create simulation")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0, 0, 1)
-        self.gym.add_ground(self.sim, plane_params)
-    
-    def _load_gate_asset(self):
-        """Load the racing gate asset."""
-        print("Loading racing gate asset...")
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True
-        asset_options.use_mesh_materials = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        asset_options.disable_gravity = True
-
-        gate_asset_file = "gate_racing.urdf"
-        asset_root = f"{os.path.dirname(os.path.abspath(__file__))}/../resources/models/environment_assets"
-        
-        # Pre-flight check for texture and model files
-        texture_path = os.path.join(asset_root, "objects", "textures", "racing_pattern.png")
-        model_path = os.path.join(asset_root, "objects", "gate.obj")
-        urdf_path = os.path.join(asset_root, "objects", gate_asset_file)
-
-        if not os.path.exists(texture_path):
-            print(f"❌ CRITICAL ERROR: Texture file not found at:\n   {texture_path}")
-            sys.exit(1)
-        if not os.path.exists(model_path):
-            print(f"❌ CRITICAL ERROR: 3D model file not found at:\n   {model_path}")
-            sys.exit(1)
-
-        print(f"Loading URDF from: {urdf_path}")
-        gate_asset = self.gym.load_asset(self.sim, asset_root, urdf_path, asset_options)
-        if gate_asset is None:
-            raise RuntimeError(f"Failed to load asset from {urdf_path}")
-        
-        print("✓ Racing Gate asset loaded successfully!")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create environments with the racing gate."""
-        gate_asset = self._load_gate_asset()
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        pose = gymapi.Transform()
-        pose.p = gymapi.Vec3(0.0, 0.0, 0.0)
-        
-        gate_handle = self.gym.create_actor(env_handle, gate_asset, pose, "gate_racing", 0, 1)
-        self.gate_handles.append(gate_handle)
-        
-        print("✓ Environment created with racing gate!")
-    
-    def _create_viewer(self):
-        """Create viewer."""
-        self.viewer = self.gym.create_viewer(self.sim, gymapi.CameraProperties())
-        if self.viewer is None:
-            raise RuntimeError("Failed to create viewer")
-    
-    def _setup_camera(self):
-        """Setup camera position."""
-        cam_pos = gymapi.Vec3(5.0, -5.0, 3.0)
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.5)
-        self.gym.viewer_camera_look_at(self.viewer, None, cam_pos, cam_target)
-    
-    def run_visualization(self, duration=300.0):
-        """Run the visualization loop."""
-        print("Starting visualization...")
-        start_time = time.time()
-        
-        while not self.gym.query_viewer_has_closed(self.viewer):
-            self.gym.simulate(self.sim)
-            self.gym.fetch_results(self.sim, True)
-            self.gym.step_graphics(self.sim)
-            self.gym.draw_viewer(self.viewer, self.sim, True)
-            
-            if time.time() - start_time > duration:
-                break
-            time.sleep(0.016)
-    
-    def cleanup(self):
-        """Clean up resources."""
-        if self.viewer:
-            self.gym.destroy_viewer(self.viewer)
-        if self.sim:
-            self.gym.destroy_sim(self.sim)
-
-def main():
-    print("RACING GATE ENVIRONMENT VISUALIZATION")
-    print("="*60)
-    try:
-        visualizer = GateEnvironmentVisualizer()
-        visualizer.run_visualization()
-        visualizer.cleanup()
-        print("✓ Visualization completed successfully!")
-    except Exception as e:
-        print(f"❌ Error during visualization: {e}")
-        import traceback
-        traceback.print_exc()
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_ucl.py b/examples/simple_gate_visualization_ucl.py
deleted file mode 100644
index 163fe4a..0000000
--- a/examples/simple_gate_visualization_ucl.py
+++ /dev/null
@@ -1,350 +0,0 @@
-"""
-Simple UCL Gate Visualization Demo
-
-This script creates and visualizes the UCL-branded gate environment using Isaac Gym.
-It spawns a gate with the UCL texture in the environment and allows you to view it interactively.
-"""
-
-import sys
-import os
-import numpy as np
-import time
-
-# Add the aerial_gym path
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
-
-try:
-    # Import Isaac Gym and Aerial Gym components
-    import isaacgym
-    from isaacgym import gymapi, gymtorch, gymutil
-    
-    # Import aerial gym components
-    from aerial_gym.config.env_config.gate_env import GateEnvCfg
-    from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-    from aerial_gym.env_manager.asset_manager import AssetManager
-    from aerial_gym.sim.sim_builder import SimBuilder
-    
-    print("✓ Successfully imported all required modules!")
-    
-except ImportError as e:
-    print(f"❌ Import error: {e}")
-    print("This might be due to missing dependencies or Python environment issues.")
-    sys.exit(1)
-
-
-class GateEnvironmentVisualizer:
-    """
-    A simple visualizer for the UCL gate environment.
-    """
-    
-    def __init__(self, headless=False):
-        """
-        Initialize the gate environment visualizer.
-        
-        Args:
-            headless (bool): Whether to run in headless mode (no graphics)
-        """
-        self.headless = headless
-        self.gym = None
-        self.sim = None
-        self.viewer = None
-        self.env_handles = []
-        self.gate_handles = []
-        
-        # Environment parameters
-        self.num_envs = 1  # Single environment for visualization
-        self.env_spacing = 10.0  # Spacing between environments
-        
-        # Initialize the environment
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        
-        if not self.headless:
-            self._create_viewer()
-            self._setup_camera()
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        # Configure simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0  # 60 FPS
-        sim_params.substeps = 2
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        
-        # Physics engine settings
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 8
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.rest_offset = 0.0
-        sim_params.physx.contact_offset = 0.001
-        sim_params.physx.friction_offset_threshold = 0.001
-        sim_params.physx.friction_correlation_distance = 0.0005
-        sim_params.physx.num_threads = 0
-        sim_params.physx.use_gpu = True
-        
-        # GPU settings
-        self.device = 'cuda:0'
-        sim_params.use_gpu_pipeline = True
-        
-        self.sim_params = sim_params
-        
-    def _create_sim(self):
-        """Create the simulation."""
-        print("Creating simulation...")
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(
-            compute_device=0,
-            graphics_device=0 if not self.headless else -1,
-            type=gymapi.SIM_PHYSX,
-            params=self.sim_params
-        )
-        
-        if self.sim is None:
-            raise RuntimeError("Failed to create simulation")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0, 0, 1)
-        plane_params.distance = 0
-        plane_params.static_friction = 1.0
-        plane_params.dynamic_friction = 1.0
-        plane_params.restitution = 0.0
-        
-        self.gym.add_ground(self.sim, plane_params)
-    
-    def _load_gate_asset(self):
-        """Load the UCL gate asset."""
-        print("Loading UCL gate asset...")
-        
-        # Asset loading options - simplified for static gate
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True  # Gate is fixed in place
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True  # Static object doesn't need gravity
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET  # Use normals from asset
-        
-        # Define the path to the UCL gate URDF
-        gate_asset_file = "gate_ucl.urdf"
-        gate_asset_folder = f"{os.path.dirname(os.path.abspath(__file__))}/../resources/models/environment_assets/objects"
-        gate_asset_path = os.path.join(gate_asset_folder, gate_asset_file)
-        
-        # Pre-flight check: Verify that the texture file exists before loading
-        texture_path = os.path.join(gate_asset_folder, "textures", "ucl_banner.png")
-        if not os.path.exists(texture_path):
-            print(f"❌ CRITICAL ERROR: Texture file not found at the expected path:")
-            print(f"   {texture_path}")
-            print("Please ensure 'ucl_banner.png' is inside a 'textures' folder next to the URDF file.")
-            sys.exit(1)
-
-        if not os.path.exists(gate_asset_path):
-            print(f"❌ Gate URDF not found at: {gate_asset_path}")
-            print("Please ensure the gate_ucl.urdf file exists!")
-            sys.exit(1)
-        
-        print(f"Loading gate from: {gate_asset_path}")
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_folder, 
-            gate_asset_file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise RuntimeError(f"Failed to load gate asset from {gate_asset_path}")
-        
-        print("✓ UCL Gate asset loaded successfully!")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create the environments with the UCL gate."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Center position
-        gate_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # No rotation
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate_ucl",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Note: Gate color is set by the material in the URDF
-        
-        print("✓ Environment created with UCL gate!")
-    
-    def _create_viewer(self):
-        """Create the viewer for visualization."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Create viewer
-        self.viewer = self.gym.create_viewer(self.sim, gymapi.CameraProperties())
-        
-        if self.viewer is None:
-            raise RuntimeError("Failed to create viewer")
-    
-    def _setup_camera(self):
-        """Setup camera position for good gate viewing."""
-        if self.headless or self.viewer is None:
-            return
-        
-        print("Setting up camera...")
-        
-        # Position camera to get a good view of the gate
-        cam_pos = gymapi.Vec3(8.0, -8.0, 4.0)  # Position for angled view
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look at center of gate
-        
-        self.gym.viewer_camera_look_at(self.viewer, None, cam_pos, cam_target)
-    
-    def run_visualization(self, duration=60.0, physics_mode=True):
-        """
-        Run the visualization loop.
-        
-        Args:
-            duration (float): How long to run the visualization in seconds
-            physics_mode (bool): Whether to run physics simulation or just render
-        """
-        print(f"Starting visualization for {duration} seconds...")
-        print("Controls:")
-        print("  - Mouse: Look around")
-        print("  - W/A/S/D: Move camera")
-        print("  - Q/E: Move camera up/down")
-        print("  - ESC: Exit")
-        
-        if physics_mode:
-            print("Running with physics simulation...")
-            # Prepare simulation
-            self.gym.prepare_sim(self.sim)
-        else:
-            print("Running in render-only mode (no physics)...")
-        
-        start_time = time.time()
-        
-        try:
-            while not self.gym.query_viewer_has_closed(self.viewer):
-                if physics_mode:
-                    # Step simulation - use simpler approach for static objects
-                    self.gym.simulate(self.sim)
-                    self.gym.fetch_results(self.sim, True)
-                
-                # Update viewer (this works even without physics)
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                
-                # Check if duration exceeded
-                if time.time() - start_time > duration:
-                    print(f"Visualization completed after {duration} seconds.")
-                    break
-                
-                # Small delay to prevent excessive CPU usage
-                time.sleep(0.016)  # ~60 FPS
-                
-        except KeyboardInterrupt:
-            print("Visualization interrupted by user.")
-        except Exception as e:
-            print(f"Error during visualization loop: {e}")
-            print("This might be due to graphics driver or Isaac Gym compatibility issues.")
-    
-    def print_environment_info(self):
-        """Print information about the created environment."""
-        print("\n" + "="*60)
-        print("UCL GATE ENVIRONMENT INFORMATION")
-        print("="*60)
-        
-        print(f"Number of environments: {len(self.env_handles)}")
-        print(f"Number of gates: {len(self.gate_handles)}")
-        print(f"Environment bounds: -8m to +8m in X,Y and 0m to +8m in Z")
-        print(f"Gate position: Center of environment (0, 0, 0)")
-        print(f"Gate dimensions: ~2.5m wide × ~2.3m tall opening")
-        
-        if self.viewer:
-            print(f"Viewer: Active (interactive)")
-        else:
-            print(f"Viewer: Headless mode")
-        
-        print(f"Physics: Isaac Gym PhysX")
-        print(f"Simulation timestep: {self.sim_params.dt:.4f}s")
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        if self.viewer:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if self.sim:
-            self.gym.destroy_sim(self.sim)
-
-
-def main():
-    """Main function to run the UCL gate visualization."""
-    
-    print("UCL GATE ENVIRONMENT VISUALIZATION")
-    print("="*60)
-    
-    # Check if gate URDF exists
-    gate_urdf_path = f"{os.path.dirname(os.path.abspath(__file__))}/../resources/models/environment_assets/objects/gate_ucl.urdf"
-    if not os.path.exists(gate_urdf_path):
-        print(f"❌ Gate URDF file not found: {gate_urdf_path}")
-        print("Please create the gate_ucl.urdf file first!")
-        return 1
-    
-    try:
-        # Create visualizer
-        visualizer = GateEnvironmentVisualizer(headless=False)
-        
-        # Print environment information
-        visualizer.print_environment_info()
-        
-        # Run visualization
-        visualizer.run_visualization(duration=300.0)  # 5 minutes
-        
-        # Cleanup
-        visualizer.cleanup()
-        
-        print("✓ UCL Gate visualization completed successfully!")
-        return 0
-        
-    except Exception as e:
-        print(f"❌ Error during visualization: {e}")
-        import traceback
-        traceback.print_exc()
-        return 1
-
-
-if __name__ == "__main__":
-    exit_code = main()
-    sys.exit(exit_code) 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_with_camera.py b/examples/simple_gate_visualization_with_camera.py
deleted file mode 100644
index ca88bc5..0000000
--- a/examples/simple_gate_visualization_with_camera.py
+++ /dev/null
@@ -1,759 +0,0 @@
-"""
-Simple Gate Visualization Demo with Static Camera
-
-This script creates and visualizes the gate environment using Isaac Gym with a static Warp-based camera.
-It spawns a gate in the environment and uses NVIDIA Warp to render depth/RGB images from a static camera viewpoint.
-"""
-
-import sys
-import os
-import numpy as np
-import time
-import cv2
-import matplotlib.pyplot as plt
-
-# Add the aerial_gym path
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
-
-try:
-    # Import Isaac Gym first (before PyTorch)
-    import isaacgym
-    from isaacgym import gymapi, gymtorch, gymutil
-    
-    # Import aerial gym components (still before PyTorch)
-    from aerial_gym.config.env_config.gate_env import GateEnvCfg
-    from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-    from aerial_gym.env_manager.asset_manager import AssetManager
-    from aerial_gym.sim.sim_builder import SimBuilder
-    from aerial_gym.sensors.warp.static_environment_camera import StaticEnvironmentCamera
-    from aerial_gym.assets.warp_asset import WarpAsset
-    from aerial_gym.env_manager.warp_env_manager import WarpEnv
-    
-    # Import PyTorch and Warp after Isaac Gym
-    import torch
-    import warp as wp
-    
-    print("✓ Successfully imported all required modules!")
-    
-except ImportError as e:
-    print(f"❌ Import error: {e}")
-    print("This might be due to missing dependencies or Python environment issues.")
-    sys.exit(1)
-
-
-class GateEnvironmentWithCamera:
-    """
-    A gate environment visualizer with static Warp-based camera.
-    """
-    
-    def __init__(self, headless=False):
-        """
-        Initialize the gate environment with camera.
-        
-        Args:
-            headless (bool): Whether to run in headless mode (no graphics)
-        """
-        self.headless = headless
-        self.gym = None
-        self.sim = None
-        self.viewer = None
-        self.env_handles = []
-        self.gate_handles = []
-        self.warp_env = None
-        self.static_camera = None
-        
-        # Environment parameters
-        self.num_envs = 1  # Single environment for visualization
-        self.env_spacing = 10.0  # Spacing between environments
-        self.device = 'cuda:0'
-        
-        # Camera parameters
-        self.camera_width = 640
-        self.camera_height = 480
-        self.camera_fov = 80  # degrees - wider FOV for better coverage
-        
-        # Initialize Warp
-        wp.init()
-        wp.config.mode = "release"
-        
-        # Initialize the environment
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._setup_warp_env()
-        self._create_environments()
-        self._setup_static_camera()
-        
-        if not self.headless:
-            self._create_viewer()
-            self._setup_camera()
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        # Configure simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0  # 60 FPS
-        sim_params.substeps = 2
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        
-        # Physics engine settings
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 8
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.rest_offset = 0.0
-        sim_params.physx.contact_offset = 0.001
-        sim_params.physx.friction_offset_threshold = 0.001
-        sim_params.physx.friction_correlation_distance = 0.0005
-        sim_params.physx.num_threads = 0
-        sim_params.physx.use_gpu = True
-        
-        # GPU settings
-        sim_params.use_gpu_pipeline = True
-        
-        self.sim_params = sim_params
-        
-    def _create_sim(self):
-        """Create the simulation."""
-        print("Creating simulation...")
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(
-            compute_device=0,
-            graphics_device=0 if not self.headless else -1,
-            type=gymapi.SIM_PHYSX,
-            params=self.sim_params
-        )
-        
-        if self.sim is None:
-            raise RuntimeError("Failed to create simulation")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0, 0, 1)
-        plane_params.distance = 0
-        plane_params.static_friction = 1.0
-        plane_params.dynamic_friction = 1.0
-        plane_params.restitution = 0.0
-        
-        self.gym.add_ground(self.sim, plane_params)
-    
-    def _setup_warp_env(self):
-        """Setup Warp environment for camera rendering."""
-        print("Setting up Warp environment...")
-        
-        # Create a minimal global_sim_dict for WarpEnv
-        global_sim_dict = {
-            "num_envs": self.num_envs,
-            "env_cfg": None  # We'll use minimal config
-        }
-        
-        # Create WarpEnv for mesh management
-        self.warp_env = WarpEnv(global_sim_dict, self.device)
-        
-        # Create environments in WarpEnv
-        for i in range(self.num_envs):
-            self.warp_env.create_env(i)
-    
-    def _load_gate_asset(self):
-        """Load the gate asset for both Isaac Gym and Warp."""
-        print("Loading gate asset...")
-        
-        # Isaac Gym asset loading options
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True  # Gate is fixed in place
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True  # Static object doesn't need gravity
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        
-        # Load gate asset for Isaac Gym
-        gate_asset_path = f"{gate_asset_params.asset_folder}/{gate_asset_params.file}"
-        
-        if not os.path.exists(gate_asset_path):
-            print(f"❌ Gate URDF not found at: {gate_asset_path}")
-            print("Please ensure the gate URDF file exists!")
-            sys.exit(1)
-        
-        print(f"Loading gate from: {gate_asset_path}")
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise RuntimeError(f"Failed to load gate asset from {gate_asset_path}")
-        
-        # Create WarpAsset for camera rendering
-        asset_file_path = f"{gate_asset_params.asset_folder}/{gate_asset_params.file}"
-        
-        # Create loading options from gate asset params
-        loading_options = {
-            'semantic_id': getattr(gate_asset_params, 'semantic_id', 1),
-            'per_link_semantic': getattr(gate_asset_params, 'per_link_semantic', True),
-            'semantic_masked_links': getattr(gate_asset_params, 'semantic_masked_links', {}),
-            'use_collision_mesh_instead_of_visual': getattr(gate_asset_params, 'use_collision_mesh_instead_of_visual', False)
-        }
-        
-        self.warp_gate_asset = WarpAsset(
-            asset_name="gate",
-            asset_file=asset_file_path,
-            loading_options=loading_options
-        )
-        
-        print("✓ Gate asset loaded successfully for both Isaac Gym and Warp!")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create the environments with gates."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Gate on ground level
-        gate_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # No rotation
-        
-        # Create gate actor in Isaac Gym
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Add gate to Warp environment for camera rendering
-        asset_info_dict = {
-            "warp_asset": self.warp_gate_asset,
-            "filename": gate_asset_params.file
-        }
-        
-        # Add gate asset to environment with proper parameters
-        self.warp_env.add_asset_to_env(
-            asset_info_dict=asset_info_dict,
-            env_id=0,
-            global_asset_counter=0,
-            segmentation_counter=1
-        )
-        
-        # Add some trees behind the gate for better visualization and diagnosis
-        self._add_background_trees()
-        
-        print("✓ Environment created with gate for both Isaac Gym and Warp!")
-    
-    def _add_background_trees(self):
-        """Add some trees behind the gate for better camera visualization."""
-        print("Adding background trees...")
-        
-        try:
-            # Load a tree asset from the existing tree models
-            tree_asset_folder = f"{gate_asset_params.asset_folder}/../trees"
-            available_trees = ["tree_0.urdf", "tree_1.urdf", "tree_2.urdf", "tree_3.urdf", "tree_4.urdf"]
-            
-            asset_counter = 1  # Start from 1 since gate is 0
-            
-            # Add trees at various positions behind the gate (negative X from camera perspective)
-            tree_positions = [
-                (-3.0, -2.0, 0.0),  # Behind and left of gate
-                (-4.0, 0.0, 0.0),   # Directly behind gate
-                (-3.0, 2.0, 0.0),   # Behind and right of gate
-                (-5.0, -1.0, 0.0),  # Further behind, left
-                (-5.0, 1.0, 0.0),   # Further behind, right
-            ]
-            
-            for i, (x, y, z) in enumerate(tree_positions):
-                if i >= len(available_trees):
-                    break
-                    
-                tree_file = available_trees[i]
-                tree_path = f"{tree_asset_folder}/{tree_file}"
-                
-                # Check if tree file exists
-                if not os.path.exists(tree_path):
-                    print(f"Tree file not found: {tree_path}, skipping...")
-                    continue
-                
-                # Load tree asset for Isaac Gym
-                tree_asset_options = gymapi.AssetOptions()
-                tree_asset_options.fix_base_link = True
-                tree_asset_options.collapse_fixed_joints = True
-                tree_asset_options.disable_gravity = True
-                tree_asset_options.replace_cylinder_with_capsule = True
-                tree_asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-                
-                tree_asset = self.gym.load_asset(
-                    self.sim, 
-                    tree_asset_folder, 
-                    tree_file, 
-                    tree_asset_options
-                )
-                
-                if tree_asset is None:
-                    print(f"Failed to load tree asset: {tree_file}")
-                    continue
-                
-                # Create tree actor in Isaac Gym
-                tree_pose = gymapi.Transform()
-                tree_pose.p = gymapi.Vec3(x, y, z)
-                tree_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
-                
-                tree_handle = self.gym.create_actor(
-                    self.env_handles[0],
-                    tree_asset,
-                    tree_pose,
-                    f"tree_{i}",
-                    0,  # Collision group
-                    1   # Collision filter
-                )
-                
-                # Create WarpAsset for camera rendering
-                tree_loading_options = {
-                    'semantic_id': 100 + i,  # Different semantic ID for trees
-                    'per_link_semantic': False,
-                    'semantic_masked_links': {},
-                    'use_collision_mesh_instead_of_visual': False
-                }
-                
-                warp_tree_asset = WarpAsset(
-                    asset_name=f"tree_{i}",
-                    asset_file=tree_path,
-                    loading_options=tree_loading_options
-                )
-                
-                # Add tree to Warp environment
-                tree_asset_info_dict = {
-                    "warp_asset": warp_tree_asset,
-                    "filename": tree_file
-                }
-                
-                self.warp_env.add_asset_to_env(
-                    asset_info_dict=tree_asset_info_dict,
-                    env_id=0,
-                    global_asset_counter=asset_counter,
-                    segmentation_counter=100 + i  # Different segmentation for trees
-                )
-                
-                asset_counter += 1
-                print(f"Added tree {i+1} at position ({x}, {y}, {z})")
-                
-        except Exception as e:
-            print(f"Warning: Failed to add background trees: {e}")
-            print("Continuing without trees...")
-    
-    def _setup_static_camera(self):
-        """Setup static camera using Warp."""
-        print("Setting up static camera...")
-        
-        # Create necessary tensors for WarpEnv
-        # The WarpEnv expects asset state tensors for tracking transformations
-        # Since our gate is static, we can create simple identity transforms
-        num_assets = 1  # Just the gate
-        
-        # Create asset state tensor: [pos_x, pos_y, pos_z, quat_x, quat_y, quat_z, quat_w, scale, vel_x, vel_y, vel_z, ang_vel_x, ang_vel_y, ang_vel_z]
-        # We now have more assets: gate + trees
-        total_assets = 6  # gate + up to 5 trees
-        asset_state = torch.zeros((self.num_envs, total_assets, 13), device=self.device)
-        
-        # Gate at origin
-        asset_state[:, 0, 0:3] = torch.tensor([0.0, 0.0, 0.0], device=self.device)  # Gate position
-        asset_state[:, 0, 6] = 1.0  # quat_w (identity quaternion)
-        asset_state[:, 0, 7] = 1.0  # scale
-        
-        # Trees behind gate (negative X)
-        tree_positions = [
-            (-3.0, -2.0, 0.0), (-4.0, 0.0, 0.0), (-3.0, 2.0, 0.0), 
-            (-5.0, -1.0, 0.0), (-5.0, 1.0, 0.0)
-        ]
-        for i, (x, y, z) in enumerate(tree_positions):
-            asset_state[:, i+1, 0:3] = torch.tensor([x, y, z], device=self.device)
-            asset_state[:, i+1, 6] = 1.0  # quat_w (identity quaternion) 
-            asset_state[:, i+1, 7] = 1.0  # scale
-        
-        global_tensor_dict = {
-            'unfolded_env_asset_state_tensor': asset_state.view(-1, 13)
-        }
-        
-        # Prepare Warp environment for simulation
-        try:
-            self.warp_env.prepare_for_simulation(global_tensor_dict)
-            
-            # Get mesh IDs for camera
-            if self.warp_env.CONST_WARP_MESH_ID_LIST is not None:
-                mesh_ids_array = wp.array(self.warp_env.CONST_WARP_MESH_ID_LIST, dtype=wp.uint64, device=self.device)
-            else:
-                print("Warning: No meshes found in WarpEnv, creating dummy mesh array")
-                mesh_ids_array = wp.array([0], dtype=wp.uint64, device=self.device)
-                
-        except Exception as e:
-            print(f"Warning: WarpEnv preparation failed: {e}")
-            print("Continuing with simplified camera setup...")
-            mesh_ids_array = wp.array([0], dtype=wp.uint64, device=self.device)
-        
-        # Camera configuration - create a simple config object
-        class CameraConfig:
-            def __init__(self, parent):
-                self.width = parent.camera_width
-                self.height = parent.camera_height
-                self.horizontal_fov_deg = parent.camera_fov
-                self.max_range = 20.0  # Reduced max range
-                self.min_range = 0.1
-                self.calculate_depth = True
-                self.return_pointcloud = False
-                self.pointcloud_in_world_frame = True
-                self.segmentation_camera = True
-                self.num_sensors = 1
-                self.normalize_range = True
-                self.near_out_of_range_value = 0.0
-                self.far_out_of_range_value = 1.0
-        
-        camera_config = CameraConfig(self)
-        
-        # Create static environment camera
-        try:
-            self.static_camera = StaticEnvironmentCamera(
-                camera_config=camera_config,
-                num_envs=self.num_envs,
-                mesh_ids_array=mesh_ids_array,
-                device=self.device
-            )
-            
-            # Set camera pose to look at the gate from the front
-            # Position camera 8 meters in front of gate, 3 meters high for better viewing angle
-            camera_positions = torch.tensor([[8.0, 0.0, 3.0]], device=self.device).repeat(self.num_envs, 1, 1)
-            
-            # Create orientation looking toward gate center 
-            # The gate is at (0,0,0) and extends upward, so look slightly down from camera position
-            import math
-            from aerial_gym.utils.math import quat_from_euler_xyz_tensor
-            
-            # Calculate look-at direction manually:
-            # Camera at (8, 0, 3) looking at gate center approximately (0, 0, 1.5)
-            # This means: look in direction (-8, 0, -1.5) normalized
-            
-            # Use a simple downward-looking orientation with rotation toward negative X
-            # Euler angles: roll=0, pitch=-10deg (look down slightly), yaw=180deg (face negative X direction)
-            euler_angles = torch.tensor([0.0, -math.pi/18, math.pi], device=self.device)
-            orientation_quat = quat_from_euler_xyz_tensor(euler_angles)
-            camera_orientations = orientation_quat.unsqueeze(0).unsqueeze(0).repeat(self.num_envs, 1, 1)
-            
-            self.static_camera.set_camera_poses(camera_positions, camera_orientations)
-            
-            print(f"Camera positioned at: (8.0, 0.0, 3.0)")
-            print(f"Camera orientation (roll, pitch, yaw): (0°, -10°, 180°)")
-            print(f"Gate position: (0.0, 0.0, 0.0)")
-            print(f"Expected objects in view: Gate at center, trees in background")
-            
-            # Set up image tensors for capturing
-            self.depth_buffer = torch.zeros((self.num_envs, 1, self.camera_height, self.camera_width), 
-                                            device=self.device, dtype=torch.float32)
-            self.segmentation_buffer = torch.zeros((self.num_envs, 1, self.camera_height, self.camera_width), 
-                                                   device=self.device, dtype=torch.int32)
-            
-            self.static_camera.set_image_tensors(self.depth_buffer, self.segmentation_buffer)
-            
-            print("✓ Static camera setup complete!")
-            
-        except Exception as e:
-            print(f"Warning: Static camera setup failed: {e}")
-            print("Continuing without camera functionality...")
-            self.static_camera = None
-    
-    def _create_viewer(self):
-        """Create the viewer for visualization."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Create viewer
-        self.viewer = self.gym.create_viewer(self.sim, gymapi.CameraProperties())
-        
-        if self.viewer is None:
-            raise RuntimeError("Failed to create viewer")
-    
-    def _setup_camera(self):
-        """Setup Isaac Gym viewer camera position."""
-        if self.headless or self.viewer is None:
-            return
-        
-        print("Setting up Isaac Gym viewer camera...")
-        
-        # Position viewer camera to see both the gate and the static camera position
-        cam_pos = gymapi.Vec3(8.0, -8.0, 4.0)  # Position for angled view
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look at center of gate
-        
-        self.gym.viewer_camera_look_at(self.viewer, None, cam_pos, cam_target)
-    
-    def capture_camera_images(self):
-        """Capture depth and segmentation images from the static camera."""
-        if self.static_camera is None:
-            return None, None
-        
-        try:
-            # Capture images using the static camera
-            depth_image = self.static_camera.capture()
-            
-            # Convert to numpy arrays for processing
-            if depth_image is not None:
-                depth_np = depth_image[0, 0].cpu().numpy()  # First environment, first camera
-                # Normalize depth for visualization
-                if depth_np.max() > 0:
-                    depth_normalized = depth_np / depth_np.max()
-                else:
-                    depth_normalized = depth_np
-                # Create a simple RGB representation from depth for visualization
-                rgb_np = np.stack([depth_normalized, depth_normalized, depth_normalized], axis=-1)
-                rgb_np = (rgb_np * 255).astype(np.uint8)
-            else:
-                rgb_np = None
-                depth_np = None
-                
-            # Get segmentation if available
-            if hasattr(self, 'segmentation_buffer'):
-                seg_np = self.segmentation_buffer[0, 0].cpu().numpy()
-            else:
-                seg_np = None
-            
-            return rgb_np, depth_np
-            
-        except Exception as e:
-            print(f"Warning: Camera capture failed: {e}")
-            return None, None
-    
-    def save_camera_images(self, rgb_image, depth_image, step_count):
-        """Save camera images to disk."""
-        try:
-            if rgb_image is not None:
-                rgb_bgr = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)
-                cv2.imwrite(f"gate_rgb_{step_count:04d}.jpg", rgb_bgr)
-            
-            if depth_image is not None:
-                # Normalize depth for visualization
-                if np.max(depth_image) > 0:
-                    depth_vis = (depth_image / np.max(depth_image) * 255).astype(np.uint8)
-                    depth_vis = cv2.applyColorMap(depth_vis, cv2.COLORMAP_JET)
-                    cv2.imwrite(f"gate_depth_{step_count:04d}.jpg", depth_vis)
-        except Exception as e:
-            print(f"Warning: Failed to save images at step {step_count}: {e}")
-    
-    def display_camera_images(self, rgb_image, depth_image):
-        """Display camera images in OpenCV windows."""
-        try:
-            if rgb_image is not None:
-                # Display RGB image
-                cv2.imshow('Static Camera - RGB', rgb_image)
-            
-            if depth_image is not None:
-                # Create colorized depth image for display
-                if np.max(depth_image) > 0:
-                    depth_normalized = depth_image / np.max(depth_image)
-                    depth_vis = cv2.applyColorMap((depth_normalized * 255).astype(np.uint8), cv2.COLORMAP_JET)
-                    cv2.imshow('Static Camera - Depth', depth_vis)
-                    
-                    # Also show raw depth values
-                    print(f"Depth range: {np.min(depth_image):.3f} to {np.max(depth_image):.3f}")
-            
-            # Check for ESC key to close windows
-            key = cv2.waitKey(1) & 0xFF
-            if key == 27:  # ESC key
-                cv2.destroyAllWindows()
-                
-        except Exception as e:
-            print(f"Warning: Failed to display images: {e}")
-            
-    def close_camera_windows(self):
-        """Close camera display windows."""
-        cv2.destroyAllWindows()
-    
-    def run_visualization(self, duration=60.0, save_images=True):
-        """
-        Run the visualization loop with camera capture.
-        
-        Args:
-            duration (float): How long to run the visualization in seconds
-            save_images (bool): Whether to save camera images to disk
-        """
-        print(f"Starting visualization with camera for {duration} seconds...")
-        print("Controls:")
-        print("  - Mouse: Look around")
-        print("  - W/A/S/D: Move camera")
-        print("  - Q/E: Move camera up/down")
-        print("  - ESC: Exit")
-        
-        if save_images:
-            print("Saving camera images to current directory...")
-        
-        # Prepare simulation
-        self.gym.prepare_sim(self.sim)
-        
-        start_time = time.time()
-        step_count = 0
-        
-        try:
-            while not self.gym.query_viewer_has_closed(self.viewer):
-                # Step simulation
-                self.gym.simulate(self.sim)
-                self.gym.fetch_results(self.sim, True)
-                
-                # Capture camera images
-                rgb_image, depth_image = self.capture_camera_images()
-                
-                # Display camera images in real-time
-                if rgb_image is not None or depth_image is not None:
-                    self.display_camera_images(rgb_image, depth_image)
-                
-                # Save images periodically
-                if save_images and step_count % 30 == 0:  # Save every 30 steps (~0.5 seconds)
-                    self.save_camera_images(rgb_image, depth_image, step_count)
-                    if rgb_image is not None or depth_image is not None:
-                        print(f"Step {step_count}: Camera captured images successfully!")
-                    # Print depth stats every 60 steps to track what camera is seeing
-                    if step_count % 60 == 0 and depth_image is not None:
-                        print(f"  Depth stats - Min: {np.min(depth_image):.3f}, Max: {np.max(depth_image):.3f}, Mean: {np.mean(depth_image):.3f}")
-                        unique_depths = np.unique(depth_image)
-                        print(f"  Unique depth values: {len(unique_depths)} (showing first 5: {unique_depths[:5]})")
-                
-                # Update viewer
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                
-                # Check if duration exceeded
-                if time.time() - start_time > duration:
-                    print(f"Visualization completed after {duration} seconds.")
-                    break
-                
-                step_count += 1
-                
-                # Small delay to prevent excessive CPU usage
-                time.sleep(0.016)  # ~60 FPS
-                
-        except KeyboardInterrupt:
-            print("Visualization interrupted by user.")
-        except Exception as e:
-            print(f"Error during visualization loop: {e}")
-            import traceback
-            traceback.print_exc()
-    
-    def print_environment_info(self):
-        """Print information about the created environment."""
-        print("\n" + "="*60)
-        print("GATE ENVIRONMENT WITH CAMERA INFORMATION")
-        print("="*60)
-        
-        print(f"Number of environments: {len(self.env_handles)}")
-        print(f"Number of gates: {len(self.gate_handles)}")
-        print(f"Environment bounds: -8m to +8m in X,Y and 0m to +8m in Z")
-        print(f"Gate position: Center of environment (0, 0, 0)")
-        print(f"Gate dimensions: ~3m wide × 3m tall opening")
-        
-        if self.static_camera:
-            print(f"Static camera: Active")
-            print(f"Camera resolution: {self.camera_width}x{self.camera_height}")
-            print(f"Camera FOV: {self.camera_fov} degrees")
-            print(f"Camera position: (8.0, 0.0, 3.0)")
-            print(f"Camera looking toward gate center")
-            print(f"Camera will display live depth/RGB feeds in separate windows")
-        else:
-            print(f"Static camera: Failed to initialize")
-        
-        if self.viewer:
-            print(f"Isaac Gym Viewer: Active (interactive)")
-        else:
-            print(f"Isaac Gym Viewer: Headless mode")
-        
-        print(f"Physics: Isaac Gym PhysX")
-        print(f"Camera: NVIDIA Warp raycasting")
-        print(f"Simulation timestep: {self.sim_params.dt:.4f}s")
-        
-        # Print Warp environment info
-        if hasattr(self.warp_env, 'CONST_WARP_MESH_ID_LIST') and self.warp_env.CONST_WARP_MESH_ID_LIST:
-            print(f"Warp meshes: {len(self.warp_env.CONST_WARP_MESH_ID_LIST)} loaded")
-        else:
-            print(f"Warp meshes: None loaded (camera may not work)")
-        
-        print("\nPress ESC in camera windows to close them.")
-        print("The static camera should show depth/segmentation of the gate.")
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        # Close camera windows
-        self.close_camera_windows()
-        
-        if self.static_camera:
-            del self.static_camera
-        
-        if self.warp_env:
-            del self.warp_env
-        
-        if self.viewer:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if self.sim:
-            self.gym.destroy_sim(self.sim)
-
-
-def main():
-    """Main function to run the gate visualization with camera."""
-    
-    print("GATE ENVIRONMENT WITH STATIC CAMERA VISUALIZATION")
-    print("="*60)
-    
-    # Check if gate URDF exists
-    gate_urdf_path = f"{gate_asset_params.asset_folder}/{gate_asset_params.file}"
-    if not os.path.exists(gate_urdf_path):
-        print(f"❌ Gate URDF file not found: {gate_urdf_path}")
-        print("Please create the gate URDF file first!")
-        return 1
-    
-    try:
-        # Create visualizer with camera
-        visualizer = GateEnvironmentWithCamera(headless=False)
-        
-        # Print environment information
-        visualizer.print_environment_info()
-        
-        # Run visualization with camera capture
-        visualizer.run_visualization(duration=300.0, save_images=True)  # 5 minutes
-        
-        # Cleanup
-        visualizer.cleanup()
-        
-        print("✓ Gate visualization with camera completed successfully!")
-        print("Camera images saved as gate_rgb_XXXX.jpg and gate_depth_XXXX.jpg")
-        return 0
-        
-    except Exception as e:
-        print(f"❌ Error during visualization: {e}")
-        import traceback
-        traceback.print_exc()
-        return 1
-
-
-if __name__ == "__main__":
-    exit_code = main()
-    sys.exit(exit_code) 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_with_camera_background_trees (copy).py b/examples/simple_gate_visualization_with_camera_background_trees (copy).py
deleted file mode 100644
index a2d3dd8..0000000
--- a/examples/simple_gate_visualization_with_camera_background_trees (copy).py	
+++ /dev/null
@@ -1,579 +0,0 @@
-"""
-Simple Gate Visualization with Static Camera using Isaac Gym Native API
-========================================================================
-
-This script creates a simple visualization of a gate environment with a static depth camera
-using Isaac Gym's native camera API. This approach is simpler and more reliable than
-the Warp-based approach.
-
-Key features:
-- Gate environment with optional background trees
-- Static world-mounted camera positioned 3m from gate
-- Real-time depth and segmentation image display
-- Isaac Gym native camera API (no Warp dependency)
-"""
-
-import os
-import sys
-import time
-import cv2
-import numpy as np
-
-# Isaac Gym must be imported first
-from isaacgym import gymapi, gymtorch, gymutil
-
-# Aerial Gym configs
-from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-import torch
-
-class GateEnvironmentWithNativeCamera:
-    """
-    Gate environment with static camera using Isaac Gym native API.
-    """
-    
-    def __init__(self, headless=False):
-        """Initialize the environment."""
-        print("🚁 Initializing Gate Environment with Native Isaac Gym Camera...")
-        
-        self.headless = headless
-        self.device = "cuda" if torch.cuda.is_available() else "cpu"
-        self.num_envs = 1
-        
-        # Environment handles
-        self.env_handles = []
-        self.gate_handles = []
-        self.tree_handles = []
-        
-        # Camera handles and setup
-        self.camera_handles = []
-        self.camera_setup_success = False
-        
-        # Initialize gym
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        self._setup_static_camera()
-        
-        if not self.headless:
-            self._create_viewer()
-        
-        # Prepare simulation for rendering
-        self.gym.prepare_sim(self.sim)
-        
-        print("✅ Environment initialization complete!")
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Parse arguments
-        custom_parameters = [
-            {"name": "--headless", "action": "store_true", "help": "Run headless without viewer"},
-        ]
-        args = gymutil.parse_arguments(custom_parameters=custom_parameters)
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        print("✓ Isaac Gym initialized")
-    
-    def _create_sim(self):
-        """Create simulation."""
-        print("Creating simulation...")
-        
-        # Simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        
-        # Physics backend
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 4
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.contact_offset = 0.01
-        sim_params.physx.rest_offset = 0.0
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)
-        if self.sim is None:
-            raise Exception("Failed to create simulation")
-        
-        print("✓ Simulation created")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
-        plane_params.distance = 0.0
-        self.gym.add_ground(self.sim, plane_params)
-    
-        print("✓ Ground plane created")
-    
-    def _load_gate_asset(self):
-        """Load gate asset."""
-        print(f"Loading gate asset from: {gate_asset_params.file}")
-        
-        # Asset loading options
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        
-        # Load asset
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise Exception(f"Failed to load gate asset: {gate_asset_params.file}")
-        
-        print("✓ Gate asset loaded successfully")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create environment with gate and optional trees."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Gate on ground level
-        
-        # Rotate gate by 90 degrees around Z-axis so trees are directly behind it
-        import math
-        gate_pose.r = gymapi.Quat(0.0, 0.0, math.sin(math.pi/4), math.cos(math.pi/4))  # 90° rotation around Z-axis
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Set gate color for better visibility
-        self.gym.set_rigid_body_color(
-            env_handle, gate_handle, 0, 
-            gymapi.MESH_VISUAL, gymapi.Vec3(0.8, 0.2, 0.2)  # Red gate
-        )
-        
-        # Add some trees behind the gate for better visualization
-        self._add_background_trees(env_handle)
-        
-        print("✓ Environment created with gate!")
-    
-    def _add_background_trees(self, env_handle):
-        """Add some trees behind the gate for better camera visualization."""
-        print("Adding background trees...")
-        
-        try:
-            # Load a tree asset from the existing tree models
-            tree_asset_folder = f"{gate_asset_params.asset_folder}/../trees"
-            available_trees = ["tree_0.urdf", "tree_1.urdf", "tree_2.urdf", "tree_3.urdf", "tree_4.urdf"]
-            
-            # Add trees at various positions behind the gate (negative Y from camera perspective)
-            tree_positions = [
-                (-2.0, 3.0, 0.0),   # Left behind gate
-                (0.0, 4.0, 0.0),    # Directly behind gate
-                (2.0, 3.0, 0.0),    # Right behind gate
-                (-1.0, 5.0, 0.0),   # Further behind, left
-                (1.0, 5.0, 0.0),    # Further behind, right
-            ]
-            
-            for i, (x, y, z) in enumerate(tree_positions):
-                if i >= len(available_trees):
-                    break
-                    
-                tree_file = available_trees[i]
-                tree_path = f"{tree_asset_folder}/{tree_file}"
-                
-                # Check if tree file exists
-                if not os.path.exists(tree_path):
-                    print(f"Tree file not found: {tree_path}, skipping...")
-                    continue
-                
-                # Load tree asset
-                tree_asset_options = gymapi.AssetOptions()
-                tree_asset_options.fix_base_link = True
-                tree_asset_options.collapse_fixed_joints = True
-                tree_asset_options.disable_gravity = True
-                tree_asset_options.replace_cylinder_with_capsule = True
-                tree_asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-                
-                tree_asset = self.gym.load_asset(
-                    self.sim, 
-                    tree_asset_folder, 
-                    tree_file, 
-                    tree_asset_options
-                )
-                
-                if tree_asset is None:
-                    print(f"Failed to load tree asset: {tree_file}")
-                    continue
-                
-                # Create tree actor
-                tree_pose = gymapi.Transform()
-                tree_pose.p = gymapi.Vec3(x, y, z)
-                tree_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
-                
-                tree_handle = self.gym.create_actor(
-                    env_handle,
-                    tree_asset,
-                    tree_pose,
-                    f"tree_{i}",
-                    0,  # Collision group
-                    1   # Collision filter
-                )
-                
-                self.tree_handles.append(tree_handle)
-                
-                # Set tree color for variety
-                colors = [
-                    gymapi.Vec3(0.2, 0.6, 0.2),  # Green
-                    gymapi.Vec3(0.4, 0.8, 0.2),  # Light green
-                    gymapi.Vec3(0.1, 0.4, 0.1),  # Dark green
-                    gymapi.Vec3(0.3, 0.7, 0.3),  # Medium green
-                    gymapi.Vec3(0.5, 0.9, 0.1),  # Yellow-green
-                ]
-                color = colors[i % len(colors)]
-                self.gym.set_rigid_body_color(
-                    env_handle, tree_handle, 0, 
-                    gymapi.MESH_VISUAL, color
-                )
-                
-                print(f"Added tree {i+1} at position ({x}, {y}, {z})")
-                
-        except Exception as e:
-            print(f"Warning: Failed to add background trees: {e}")
-            print("Continuing without trees...")
-    
-    def _setup_static_camera(self):
-        """Setup static camera using Isaac Gym native camera API."""
-        print("Setting up static camera using Isaac Gym native API...")
-        
-        try:
-            # Camera properties (D455 depth camera specifications)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = 1280  # D455 depth resolution
-            camera_props.height = 720  # D455 depth resolution
-            camera_props.horizontal_fov = 87.0  # D455 FOV
-            camera_props.near_plane = 0.4  # D455 minimum depth distance
-            camera_props.far_plane = 20.0  # D455 maximum range
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"Camera properties (D455 specs): {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"Depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-        
-            # Create camera sensor in each environment
-            self.camera_handles = []
-            for i, env_handle in enumerate(self.env_handles):
-                cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-                self.camera_handles.append(cam_handle)
-                print(f"Created camera sensor {i} in environment {i}")
-            
-            # Position camera to face the gate directly (gate now rotated 90°)
-            # Trees are positioned at: (-2,3,0), (0,4,0), (2,3,0), (-1,5,0), (1,5,0) - behind rotated gate
-            # Gate is at (0,0,0) rotated 90°, so place camera in front of gate looking through it toward trees
-            camera_pos = gymapi.Vec3(0.0, -3.0, 1.5)  # 3m in front of gate, at gate center height
-            camera_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look directly at gate center
-            
-            # Set camera transform for each environment using look_at
-            for i, (env_handle, cam_handle) in enumerate(zip(self.env_handles, self.camera_handles)):
-                # Use Isaac Gym's camera look_at functionality
-                self.gym.set_camera_location(cam_handle, env_handle, camera_pos, camera_target)
-                print(f"Set camera {i} to look from ({camera_pos.x}, {camera_pos.y}, {camera_pos.z}) toward ({camera_target.x}, {camera_target.y}, {camera_target.z})")
-            
-            print(f"✓ Static cameras positioned to face gate directly")
-            print(f"Camera position: (0, -3, 1.5)")
-            print(f"Camera target: (0, 0, 1.5) - gate center")
-            print(f"View: Looking through rotated gate toward trees behind it")
-            
-            self.camera_setup_success = True
-            
-        except Exception as e:
-            print(f"❌ ERROR: Isaac Gym camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.camera_setup_success = False
-    
-    def _create_viewer(self):
-        """Create viewer."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Viewer camera properties
-        cam_props = gymapi.CameraProperties()
-        viewer = self.gym.create_viewer(self.sim, cam_props)
-        
-        if viewer is None:
-            raise Exception("Failed to create viewer")
-        
-        # Set viewer camera
-        cam_pos = gymapi.Vec3(-5.0, -5.0, 3.0)
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.0)
-        self.gym.viewer_camera_look_at(viewer, None, cam_pos, cam_target)
-        
-        self.viewer = viewer
-        print("✓ Viewer created")
-    
-    def capture_camera_images(self):
-        """Capture depth and segmentation images from static camera."""
-        if not self.camera_setup_success or len(self.camera_handles) == 0:
-            return None, None
-        
-        try:
-            # Step graphics first to ensure everything is rendered
-            self.gym.step_graphics(self.sim)
-            
-            # Render all camera sensors
-            self.gym.render_all_camera_sensors(self.sim)
-            
-            # Start access to image tensors
-            self.gym.start_access_image_tensors(self.sim)
-            
-            # Get images from first camera
-            env_handle = self.env_handles[0]
-            cam_handle = self.camera_handles[0]
-            
-            # Get depth image
-            depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                self.sim, env_handle, cam_handle, gymapi.IMAGE_DEPTH
-            )
-            depth_img = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-            
-            # Get segmentation image
-            seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                self.sim, env_handle, cam_handle, gymapi.IMAGE_SEGMENTATION
-            )
-            seg_img = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-            
-            # End access to image tensors
-            self.gym.end_access_image_tensors(self.sim)
-            
-            return depth_img, seg_img
-                
-        except Exception as e:
-            print(f"Error capturing camera images: {e}")
-            return None, None
-            
-    def create_combined_image(self, depth_img, seg_img, title="Static Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-        # Take absolute value to handle negative depths (coordinate system issue)
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 5 meters for close objects)
-        depth_norm = np.clip(depth_norm, 0, 5.0)  
-        depth_norm = (depth_norm / 5.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 5.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 5.0)
-            pseudo_seg = (pseudo_seg / 5.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-    def save_camera_image(self, combined_image, step_count):
-        """Save camera image to file."""
-        if combined_image is not None:
-            filename = f"static_camera_combined_{step_count:04d}.jpg"
-            cv2.imwrite(filename, combined_image)
-            print(f"Saved image: {filename}")
-    
-    def run_visualization(self, duration=60.0, save_images=False):
-        """Run the visualization loop."""
-        print(f"Starting visualization for {duration} seconds...")
-        print("Press ESC to exit early")
-        
-        start_time = time.time()
-        step_count = 0
-        
-        # OpenCV window for camera display
-        cv2.namedWindow("Static Camera View", cv2.WINDOW_NORMAL)
-        cv2.resizeWindow("Static Camera View", 2560, 720)  # Side-by-side 1280x720 images
-        
-        while True:
-            current_time = time.time()
-            elapsed_time = current_time - start_time
-            
-            # Check if duration exceeded
-            if elapsed_time > duration:
-                print(f"Visualization completed after {duration} seconds")
-                break
-            
-            # Step simulation
-            self.gym.simulate(self.sim)
-            self.gym.fetch_results(self.sim, True)
-            
-            # Capture camera images
-            depth_img, seg_img = self.capture_camera_images()
-            
-            if depth_img is not None and seg_img is not None:
-                # Create combined visualization
-                combined_image = self.create_combined_image(depth_img, seg_img)
-                
-                if combined_image is not None:
-                    # Display images
-                    cv2.imshow("Static Camera View", combined_image)
-                
-                    # Note: Image saving functionality removed as requested
-                    
-                    # Print depth statistics periodically
-                    if step_count % 60 == 0:  # Every second at 60 FPS
-                        # Filter out -inf values for better statistics
-                        valid_depths = depth_img[depth_img != -np.inf]
-                        if len(valid_depths) > 0:
-                            # Use absolute values for meaningful distance measurements
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = depth_img.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            print(f"Step {step_count}: Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-                        else:
-                            print(f"Step {step_count}: No valid depth data (all -inf)")
-                        
-                        unique_segs = len(np.unique(seg_img))
-                        print(f"  Segmentation: {unique_segs} unique values")
-                
-            # Handle viewer events
-            if not self.headless:
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                if self.gym.query_viewer_has_closed(self.viewer):
-                    break
-            
-            # Check for ESC key press in OpenCV window
-            key = cv2.waitKey(1) & 0xFF
-            if key == 27:  # ESC key
-                print("ESC pressed, exiting visualization")
-                break
-            
-            step_count += 1
-        
-        cv2.destroyAllWindows()
-        print("Visualization loop completed")
-    
-    def print_environment_info(self):
-        """Print information about the environment."""
-        print("\n" + "="*50)
-        print("ENVIRONMENT INFORMATION")
-        print("="*50)
-        print(f"Number of environments: {self.num_envs}")
-        print(f"Device: {self.device}")
-        print(f"Gate asset: {gate_asset_params.file}")
-        print(f"Camera setup success: {self.camera_setup_success}")
-        print(f"Number of cameras: {len(self.camera_handles)}")
-        print(f"Number of trees: {len(self.tree_handles)}")
-        
-        if self.camera_setup_success:
-            print(f"Camera position: (0, -3, 1.5)")
-            print(f"Camera target: (0, 0, 1.5) - gate center")
-            print(f"Gate position: (0, 0, 0) - rotated 90°")
-            print(f"Setup: Camera faces gate directly, trees visible behind gate")
-        
-        print("="*50)
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        cv2.destroyAllWindows()
-        
-        if hasattr(self, 'viewer') and self.viewer is not None:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if hasattr(self, 'sim') and self.sim is not None:
-            self.gym.destroy_sim(self.sim)
-
-        print("✓ Cleanup completed")
-
-def main():
-    """Main function."""
-    try:
-        print("🚁 Starting Gate Visualization with Native Isaac Gym Camera...")
-        
-        # Create environment
-        env = GateEnvironmentWithNativeCamera(headless=False)
-        
-        # Print environment information
-        env.print_environment_info()
-        
-        # Run visualization
-        env.run_visualization(duration=120.0, save_images=False)
-        
-    except KeyboardInterrupt:
-        print("\n⚠️ Interrupted by user")
-    except Exception as e:
-        print(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        if 'env' in locals():
-            env.cleanup()
-        print("👋 Goodbye!")
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_with_camera_background_trees.py b/examples/simple_gate_visualization_with_camera_background_trees.py
deleted file mode 100644
index e3dda3d..0000000
--- a/examples/simple_gate_visualization_with_camera_background_trees.py
+++ /dev/null
@@ -1,579 +0,0 @@
-"""
-Simple Gate Visualization with Static Camera using Isaac Gym Native API
-========================================================================
-
-This script creates a simple visualization of a gate environment with a static depth camera
-using Isaac Gym's native camera API. This approach is simpler and more reliable than
-the Warp-based approach.
-
-Key features:
-- Gate environment with optional background trees
-- Static world-mounted camera positioned 3m from gate
-- Real-time depth and segmentation image display
-- Isaac Gym native camera API (no Warp dependency)
-"""
-
-import os
-import sys
-import time
-import cv2
-import numpy as np
-
-# Isaac Gym must be imported first
-    from isaacgym import gymapi, gymtorch, gymutil
-    
-# Aerial Gym configs
-    from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-    import torch
-
-class GateEnvironmentWithNativeCamera:
-    """
-    Gate environment with static camera using Isaac Gym native API.
-    """
-    
-    def __init__(self, headless=False):
-        """Initialize the environment."""
-        print("🚁 Initializing Gate Environment with Native Isaac Gym Camera...")
-        
-        self.headless = headless
-        self.device = "cuda" if torch.cuda.is_available() else "cpu"
-        self.num_envs = 1
-        
-        # Environment handles
-        self.env_handles = []
-        self.gate_handles = []
-        self.tree_handles = []
-        
-        # Camera handles and setup
-        self.camera_handles = []
-        self.camera_setup_success = False
-        
-        # Initialize gym
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        self._setup_static_camera()
-        
-        if not self.headless:
-            self._create_viewer()
-        
-        # Prepare simulation for rendering
-        self.gym.prepare_sim(self.sim)
-        
-        print("✅ Environment initialization complete!")
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Parse arguments
-        custom_parameters = [
-            {"name": "--headless", "action": "store_true", "help": "Run headless without viewer"},
-        ]
-        args = gymutil.parse_arguments(custom_parameters=custom_parameters)
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        print("✓ Isaac Gym initialized")
-    
-    def _create_sim(self):
-        """Create simulation."""
-        print("Creating simulation...")
-        
-        # Simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        
-        # Physics backend
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 4
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.contact_offset = 0.01
-        sim_params.physx.rest_offset = 0.0
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)
-        if self.sim is None:
-            raise Exception("Failed to create simulation")
-        
-        print("✓ Simulation created")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
-        plane_params.distance = 0.0
-        self.gym.add_ground(self.sim, plane_params)
-    
-        print("✓ Ground plane created")
-    
-    def _load_gate_asset(self):
-        """Load gate asset."""
-        print(f"Loading gate asset from: {gate_asset_params.file}")
-        
-        # Asset loading options
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        
-        # Load asset
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise Exception(f"Failed to load gate asset: {gate_asset_params.file}")
-        
-        print("✓ Gate asset loaded successfully")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create environment with gate and optional trees."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Gate on ground level
-        
-        # Rotate gate by 90 degrees around Z-axis so trees are directly behind it
-        import math
-        gate_pose.r = gymapi.Quat(0.0, 0.0, math.sin(math.pi/4), math.cos(math.pi/4))  # 90° rotation around Z-axis
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Set gate color for better visibility
-        self.gym.set_rigid_body_color(
-            env_handle, gate_handle, 0, 
-            gymapi.MESH_VISUAL, gymapi.Vec3(0.2, 0.2, 0.8)  # blue-ish
-        )
-        
-        # Add some trees behind the gate for better visualization
-        self._add_background_trees(env_handle)
-        
-        print("✓ Environment created with gate!")
-    
-    def _add_background_trees(self, env_handle):
-        """Add some trees behind the gate for better camera visualization."""
-        print("Adding background trees...")
-        
-        try:
-            # Load a tree asset from the existing tree models
-            tree_asset_folder = f"{gate_asset_params.asset_folder}/../trees"
-            available_trees = ["tree_0.urdf", "tree_1.urdf", "tree_2.urdf", "tree_3.urdf", "tree_4.urdf"]
-            
-            # Add trees at various positions behind the gate (negative Y from camera perspective)
-            tree_positions = [
-                (-2.0, 3.0, 0.0),   # Left behind gate
-                (0.0, 4.0, 0.0),    # Directly behind gate
-                (2.0, 3.0, 0.0),    # Right behind gate
-                (-1.0, 5.0, 0.0),   # Further behind, left
-                (1.0, 5.0, 0.0),    # Further behind, right
-            ]
-            
-            for i, (x, y, z) in enumerate(tree_positions):
-                if i >= len(available_trees):
-                    break
-                    
-                tree_file = available_trees[i]
-                tree_path = f"{tree_asset_folder}/{tree_file}"
-                
-                # Check if tree file exists
-                if not os.path.exists(tree_path):
-                    print(f"Tree file not found: {tree_path}, skipping...")
-                    continue
-                
-                # Load tree asset
-                tree_asset_options = gymapi.AssetOptions()
-                tree_asset_options.fix_base_link = True
-                tree_asset_options.collapse_fixed_joints = True
-                tree_asset_options.disable_gravity = True
-                tree_asset_options.replace_cylinder_with_capsule = True
-                tree_asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-                
-                tree_asset = self.gym.load_asset(
-                    self.sim, 
-                    tree_asset_folder, 
-                    tree_file, 
-                    tree_asset_options
-                )
-                
-                if tree_asset is None:
-                    print(f"Failed to load tree asset: {tree_file}")
-                    continue
-                
-                # Create tree actor
-                tree_pose = gymapi.Transform()
-                tree_pose.p = gymapi.Vec3(x, y, z)
-                tree_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
-                
-                tree_handle = self.gym.create_actor(
-                    env_handle,
-                    tree_asset,
-                    tree_pose,
-                    f"tree_{i}",
-                    0,  # Collision group
-                    1   # Collision filter
-                )
-                
-                self.tree_handles.append(tree_handle)
-                
-                # Set tree color for variety
-                colors = [
-                    gymapi.Vec3(0.2, 0.6, 0.2),  # Green
-                    gymapi.Vec3(0.4, 0.8, 0.2),  # Light green
-                    gymapi.Vec3(0.1, 0.4, 0.1),  # Dark green
-                    gymapi.Vec3(0.3, 0.7, 0.3),  # Medium green
-                    gymapi.Vec3(0.5, 0.9, 0.1),  # Yellow-green
-                ]
-                color = colors[i % len(colors)]
-                self.gym.set_rigid_body_color(
-                    env_handle, tree_handle, 0, 
-                    gymapi.MESH_VISUAL, color
-                )
-                
-                print(f"Added tree {i+1} at position ({x}, {y}, {z})")
-                
-        except Exception as e:
-            print(f"Warning: Failed to add background trees: {e}")
-            print("Continuing without trees...")
-    
-    def _setup_static_camera(self):
-        """Setup static camera using Isaac Gym native camera API."""
-        print("Setting up static camera using Isaac Gym native API...")
-        
-        try:
-            # Camera properties (D455 depth camera specifications)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = 1280  # D455 depth resolution
-            camera_props.height = 720  # D455 depth resolution
-            camera_props.horizontal_fov = 87.0  # D455 FOV
-            camera_props.near_plane = 0.4  # D455 minimum depth distance
-            camera_props.far_plane = 20.0  # D455 maximum range
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"Camera properties (D455 specs): {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"Depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-        
-            # Create camera sensor in each environment
-            self.camera_handles = []
-            for i, env_handle in enumerate(self.env_handles):
-                cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-                self.camera_handles.append(cam_handle)
-                print(f"Created camera sensor {i} in environment {i}")
-            
-            # Position camera to face the gate directly (gate now rotated 90°)
-            # Trees are positioned at: (-2,3,0), (0,4,0), (2,3,0), (-1,5,0), (1,5,0) - behind rotated gate
-            # Gate is at (0,0,0) rotated 90°, so place camera in front of gate looking through it toward trees
-            camera_pos = gymapi.Vec3(0.0, -3.0, 1.5)  # 3m in front of gate, at gate center height
-            camera_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look directly at gate center
-            
-            # Set camera transform for each environment using look_at
-            for i, (env_handle, cam_handle) in enumerate(zip(self.env_handles, self.camera_handles)):
-                # Use Isaac Gym's camera look_at functionality
-                self.gym.set_camera_location(cam_handle, env_handle, camera_pos, camera_target)
-                print(f"Set camera {i} to look from ({camera_pos.x}, {camera_pos.y}, {camera_pos.z}) toward ({camera_target.x}, {camera_target.y}, {camera_target.z})")
-            
-            print(f"✓ Static cameras positioned to face gate directly")
-            print(f"Camera position: (0, -3, 1.5)")
-            print(f"Camera target: (0, 0, 1.5) - gate center")
-            print(f"View: Looking through rotated gate toward trees behind it")
-            
-            self.camera_setup_success = True
-            
-        except Exception as e:
-            print(f"❌ ERROR: Isaac Gym camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.camera_setup_success = False
-    
-    def _create_viewer(self):
-        """Create viewer."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Viewer camera properties
-        cam_props = gymapi.CameraProperties()
-        viewer = self.gym.create_viewer(self.sim, cam_props)
-        
-        if viewer is None:
-            raise Exception("Failed to create viewer")
-        
-        # Set viewer camera
-        cam_pos = gymapi.Vec3(-5.0, -5.0, 3.0)
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.0)
-        self.gym.viewer_camera_look_at(viewer, None, cam_pos, cam_target)
-        
-        self.viewer = viewer
-        print("✓ Viewer created")
-    
-    def capture_camera_images(self):
-        """Capture depth and segmentation images from static camera."""
-        if not self.camera_setup_success or len(self.camera_handles) == 0:
-            return None, None
-        
-        try:
-            # Step graphics first to ensure everything is rendered
-            self.gym.step_graphics(self.sim)
-            
-            # Render all camera sensors
-            self.gym.render_all_camera_sensors(self.sim)
-            
-            # Start access to image tensors
-            self.gym.start_access_image_tensors(self.sim)
-            
-            # Get images from first camera
-            env_handle = self.env_handles[0]
-            cam_handle = self.camera_handles[0]
-            
-            # Get depth image
-            depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                self.sim, env_handle, cam_handle, gymapi.IMAGE_DEPTH
-            )
-            depth_img = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-            
-            # Get segmentation image
-            seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                self.sim, env_handle, cam_handle, gymapi.IMAGE_SEGMENTATION
-            )
-            seg_img = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-            
-            # End access to image tensors
-            self.gym.end_access_image_tensors(self.sim)
-            
-            return depth_img, seg_img
-                
-        except Exception as e:
-            print(f"Error capturing camera images: {e}")
-            return None, None
-            
-    def create_combined_image(self, depth_img, seg_img, title="Static Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-        # Take absolute value to handle negative depths (coordinate system issue)
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 10 meters for D455 range)
-        depth_norm = np.clip(depth_norm, 0, 10.0)  
-        depth_norm = (depth_norm / 10.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 10.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 10.0)
-            pseudo_seg = (pseudo_seg / 10.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-    def save_camera_image(self, combined_image, step_count):
-        """Save camera image to file."""
-        if combined_image is not None:
-            filename = f"static_camera_combined_{step_count:04d}.jpg"
-            cv2.imwrite(filename, combined_image)
-            print(f"Saved image: {filename}")
-    
-    def run_visualization(self, duration=60.0, save_images=False):
-        """Run the visualization loop."""
-        print(f"Starting visualization for {duration} seconds...")
-        print("Press ESC to exit early")
-        
-        start_time = time.time()
-        step_count = 0
-        
-        # OpenCV window for camera display
-        cv2.namedWindow("Static Camera View", cv2.WINDOW_NORMAL)
-        cv2.resizeWindow("Static Camera View", 2560, 720)  # Side-by-side 1280x720 images
-        
-        while True:
-            current_time = time.time()
-            elapsed_time = current_time - start_time
-            
-            # Check if duration exceeded
-            if elapsed_time > duration:
-                print(f"Visualization completed after {duration} seconds")
-                break
-            
-                # Step simulation
-                self.gym.simulate(self.sim)
-                self.gym.fetch_results(self.sim, True)
-                
-                # Capture camera images
-            depth_img, seg_img = self.capture_camera_images()
-            
-            if depth_img is not None and seg_img is not None:
-                # Create combined visualization
-                combined_image = self.create_combined_image(depth_img, seg_img)
-                
-                if combined_image is not None:
-                    # Display images
-                    cv2.imshow("Static Camera View", combined_image)
-                
-                    # Note: Image saving functionality removed as requested
-                    
-                    # Print depth statistics periodically
-                    if step_count % 60 == 0:  # Every second at 60 FPS
-                        # Filter out -inf values for better statistics
-                        valid_depths = depth_img[depth_img != -np.inf]
-                        if len(valid_depths) > 0:
-                            # Use absolute values for meaningful distance measurements
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = depth_img.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            print(f"Step {step_count}: Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-                        else:
-                            print(f"Step {step_count}: No valid depth data (all -inf)")
-                        
-                        unique_segs = len(np.unique(seg_img))
-                        print(f"  Segmentation: {unique_segs} unique values")
-                
-            # Handle viewer events
-            if not self.headless:
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                if self.gym.query_viewer_has_closed(self.viewer):
-                    break
-            
-            # Check for ESC key press in OpenCV window
-            key = cv2.waitKey(1) & 0xFF
-            if key == 27:  # ESC key
-                print("ESC pressed, exiting visualization")
-                    break
-                
-                step_count += 1
-                
-        cv2.destroyAllWindows()
-        print("Visualization loop completed")
-    
-    def print_environment_info(self):
-        """Print information about the environment."""
-        print("\n" + "="*50)
-        print("ENVIRONMENT INFORMATION")
-        print("="*50)
-        print(f"Number of environments: {self.num_envs}")
-        print(f"Device: {self.device}")
-        print(f"Gate asset: {gate_asset_params.file}")
-        print(f"Camera setup success: {self.camera_setup_success}")
-        print(f"Number of cameras: {len(self.camera_handles)}")
-        print(f"Number of trees: {len(self.tree_handles)}")
-        
-        if self.camera_setup_success:
-            print(f"Camera position: (0, -3, 1.5)")
-            print(f"Camera target: (0, 0, 1.5) - gate center")
-            print(f"Gate position: (0, 0, 0) - rotated 90°")
-            print(f"Setup: Camera faces gate directly, trees visible behind gate")
-        
-        print("="*50)
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        cv2.destroyAllWindows()
-        
-        if hasattr(self, 'viewer') and self.viewer is not None:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if hasattr(self, 'sim') and self.sim is not None:
-            self.gym.destroy_sim(self.sim)
-
-        print("✓ Cleanup completed")
-
-def main():
-    """Main function."""
-    try:
-        print("🚁 Starting Gate Visualization with Native Isaac Gym Camera...")
-        
-        # Create environment
-        env = GateEnvironmentWithNativeCamera(headless=False)
-        
-        # Print environment information
-        env.print_environment_info()
-        
-        # Run visualization
-        env.run_visualization(duration=120.0, save_images=False)
-        
-    except KeyboardInterrupt:
-        print("\n⚠️ Interrupted by user")
-    except Exception as e:
-        print(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        if 'env' in locals():
-            env.cleanup()
-        print("👋 Goodbye!")
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_with_camera_background_trees_X500.py b/examples/simple_gate_visualization_with_camera_background_trees_X500.py
deleted file mode 100644
index f3ca99f..0000000
--- a/examples/simple_gate_visualization_with_camera_background_trees_X500.py
+++ /dev/null
@@ -1,642 +0,0 @@
-"""
-Simple Gate Visualization with Static Camera and X500 Robot using Isaac Gym Native API
-=====================================================================================
-
-This script creates a simple visualization of a gate environment with a static depth camera
-and an X500 quadrotor robot using Isaac Gym's native camera API. This approach is simpler 
-and more reliable than the Warp-based approach.
-
-Key features:
-- Gate environment with optional background trees
-- X500 quadrotor robot for visual observation
-- Static world-mounted camera positioned 3m from gate
-- Real-time depth and segmentation image display
-- Isaac Gym native camera API (no Warp dependency)
-"""
-
-import os
-import sys
-import time
-import cv2
-import numpy as np
-
-# Isaac Gym must be imported first
-from isaacgym import gymapi, gymtorch, gymutil
-
-# Aerial Gym configs
-from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-from aerial_gym.config.robot_config.x500_config import X500Cfg
-import torch
-
-class GateEnvironmentWithNativeCameraAndX500:
-    """
-    Gate environment with static camera and X500 robot using Isaac Gym native API.
-    """
-    
-    def __init__(self, headless=False):
-        """Initialize the environment."""
-        print("🚁 Initializing Gate Environment with Native Isaac Gym Camera and X500 Robot...")
-        
-        self.headless = headless
-        self.device = "cuda" if torch.cuda.is_available() else "cpu"
-        self.num_envs = 1
-        
-        # Environment handles
-        self.env_handles = []
-        self.gate_handles = []
-        self.tree_handles = []
-        self.x500_handles = []  # Add X500 robot handles
-        
-        # Camera handles and setup
-        self.camera_handles = []
-        self.camera_setup_success = False
-        
-        # Initialize gym
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        self._setup_static_camera()
-        
-        if not self.headless:
-            self._create_viewer()
-        
-        # Prepare simulation for rendering
-        self.gym.prepare_sim(self.sim)
-        
-        print("✅ Environment initialization complete!")
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Parse arguments
-        custom_parameters = [
-            {"name": "--headless", "action": "store_true", "help": "Run headless without viewer"},
-        ]
-        args = gymutil.parse_arguments(custom_parameters=custom_parameters)
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        print("✓ Isaac Gym initialized")
-    
-    def _create_sim(self):
-        """Create simulation."""
-        print("Creating simulation...")
-        
-        # Simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        
-        # Physics backend
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 4
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.contact_offset = 0.01
-        sim_params.physx.rest_offset = 0.0
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)
-        if self.sim is None:
-            raise Exception("Failed to create simulation")
-        
-        print("✓ Simulation created")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
-        plane_params.distance = 0.0
-        self.gym.add_ground(self.sim, plane_params)
-    
-        print("✓ Ground plane created")
-    
-    def _load_gate_asset(self):
-        """Load gate asset."""
-        print(f"Loading gate asset from: {gate_asset_params.file}")
-        
-        # Asset loading options
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        
-        # Load asset
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise Exception(f"Failed to load gate asset: {gate_asset_params.file}")
-        
-        print("✓ Gate asset loaded successfully")
-        return gate_asset
-    
-    def _load_x500_asset(self):
-        """Load X500 robot asset."""
-        print(f"Loading X500 robot asset from: {X500Cfg.robot_asset.file}")
-        
-        # Asset loading options for X500
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = X500Cfg.robot_asset.fix_base_link
-        asset_options.collapse_fixed_joints = X500Cfg.robot_asset.collapse_fixed_joints
-        asset_options.disable_gravity = X500Cfg.robot_asset.disable_gravity
-        asset_options.replace_cylinder_with_capsule = X500Cfg.robot_asset.replace_cylinder_with_capsule
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        asset_options.flip_visual_attachments = X500Cfg.robot_asset.flip_visual_attachments
-        asset_options.density = X500Cfg.robot_asset.density
-        asset_options.angular_damping = X500Cfg.robot_asset.angular_damping
-        asset_options.linear_damping = X500Cfg.robot_asset.linear_damping
-        asset_options.max_angular_velocity = X500Cfg.robot_asset.max_angular_velocity
-        asset_options.max_linear_velocity = X500Cfg.robot_asset.max_linear_velocity
-        asset_options.armature = X500Cfg.robot_asset.armature
-        
-        # Load X500 asset
-        x500_asset = self.gym.load_asset(
-            self.sim, 
-            X500Cfg.robot_asset.asset_folder, 
-            X500Cfg.robot_asset.file, 
-            asset_options
-        )
-        
-        if x500_asset is None:
-            raise Exception(f"Failed to load X500 robot asset: {X500Cfg.robot_asset.file}")
-        
-        print("✓ X500 robot asset loaded successfully")
-        return x500_asset
-    
-    def _create_environments(self):
-        """Create environment with gate and optional trees."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Load X500 asset
-        x500_asset = self._load_x500_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Gate on ground level
-        
-        # Rotate gate by 90 degrees around Z-axis so trees are directly behind it
-        import math
-        gate_pose.r = gymapi.Quat(0.0, 0.0, math.sin(math.pi/4), math.cos(math.pi/4))  # 90° rotation around Z-axis
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Set gate color for better visibility
-        self.gym.set_rigid_body_color(
-            env_handle, gate_handle, 0, 
-            gymapi.MESH_VISUAL, gymapi.Vec3(0.2, 0.2, 0.8)  # blue-ish
-        )
-        
-        # Add some trees behind the gate for better visualization
-        self._add_background_trees(env_handle)
-        
-        # Create X500 robot actor
-        x500_pose = gymapi.Transform()
-        x500_pose.p = gymapi.Vec3(-1.5, 0.0, 1.0)  # Position X500 to the left of gate, 1m above ground
-        x500_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # Default orientation
-        
-        x500_handle = self.gym.create_actor(
-            env_handle,
-            x500_asset,
-            x500_pose,
-            "x500",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.x500_handles.append(x500_handle)
-        
-        # Set X500 color for better visibility
-        self.gym.set_rigid_body_color(
-            env_handle, x500_handle, 0, 
-            gymapi.MESH_VISUAL, gymapi.Vec3(0.8, 0.8, 0.2)  # Yellow X500
-        )
-        
-        print("✓ Environment created with gate and X500 robot!")
-    
-    def _add_background_trees(self, env_handle):
-        """Add some trees behind the gate for better camera visualization."""
-        print("Adding background trees...")
-        
-        try:
-            # Load a tree asset from the existing tree models
-            tree_asset_folder = f"{gate_asset_params.asset_folder}/../trees"
-            available_trees = ["tree_0.urdf", "tree_1.urdf", "tree_2.urdf", "tree_3.urdf", "tree_4.urdf"]
-            
-            # Add trees at various positions behind the gate (negative Y from camera perspective)
-            tree_positions = [
-                (-2.0, 3.0, 0.0),   # Left behind gate
-                (0.0, 4.0, 0.0),    # Directly behind gate
-                (2.0, 3.0, 0.0),    # Right behind gate
-                (-1.0, 5.0, 0.0),   # Further behind, left
-                (1.0, 5.0, 0.0),    # Further behind, right
-            ]
-            
-            for i, (x, y, z) in enumerate(tree_positions):
-                if i >= len(available_trees):
-                    break
-                    
-                tree_file = available_trees[i]
-                tree_path = f"{tree_asset_folder}/{tree_file}"
-                
-                # Check if tree file exists
-                if not os.path.exists(tree_path):
-                    print(f"Tree file not found: {tree_path}, skipping...")
-                    continue
-                
-                # Load tree asset
-                tree_asset_options = gymapi.AssetOptions()
-                tree_asset_options.fix_base_link = True
-                tree_asset_options.collapse_fixed_joints = True
-                tree_asset_options.disable_gravity = True
-                tree_asset_options.replace_cylinder_with_capsule = True
-                tree_asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-                
-                tree_asset = self.gym.load_asset(
-                    self.sim, 
-                    tree_asset_folder, 
-                    tree_file, 
-                    tree_asset_options
-                )
-                
-                if tree_asset is None:
-                    print(f"Failed to load tree asset: {tree_file}")
-                    continue
-                
-                # Create tree actor
-                tree_pose = gymapi.Transform()
-                tree_pose.p = gymapi.Vec3(x, y, z)
-                tree_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
-                
-                tree_handle = self.gym.create_actor(
-                    env_handle,
-                    tree_asset,
-                    tree_pose,
-                    f"tree_{i}",
-                    0,  # Collision group
-                    1   # Collision filter
-                )
-                
-                self.tree_handles.append(tree_handle)
-                
-                # Set tree color for variety
-                colors = [
-                    gymapi.Vec3(0.2, 0.6, 0.2),  # Green
-                    gymapi.Vec3(0.4, 0.8, 0.2),  # Light green
-                    gymapi.Vec3(0.1, 0.4, 0.1),  # Dark green
-                    gymapi.Vec3(0.3, 0.7, 0.3),  # Medium green
-                    gymapi.Vec3(0.5, 0.9, 0.1),  # Yellow-green
-                ]
-                color = colors[i % len(colors)]
-                self.gym.set_rigid_body_color(
-                    env_handle, tree_handle, 0, 
-                    gymapi.MESH_VISUAL, color
-                )
-                
-                print(f"Added tree {i+1} at position ({x}, {y}, {z})")
-                
-        except Exception as e:
-            print(f"Warning: Failed to add background trees: {e}")
-            print("Continuing without trees...")
-    
-    def _setup_static_camera(self):
-        """Setup static camera using Isaac Gym native camera API."""
-        print("Setting up static camera using Isaac Gym native API...")
-        
-        try:
-            # Camera properties (D455 depth camera specifications)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = 1280  # D455 depth resolution
-            camera_props.height = 720  # D455 depth resolution
-            camera_props.horizontal_fov = 87.0  # D455 FOV
-            camera_props.near_plane = 0.4  # D455 minimum depth distance
-            camera_props.far_plane = 20.0  # D455 maximum range
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"Camera properties (D455 specs): {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"Depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-        
-            # Create camera sensor in each environment
-            self.camera_handles = []
-            for i, env_handle in enumerate(self.env_handles):
-                cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-                self.camera_handles.append(cam_handle)
-                print(f"Created camera sensor {i} in environment {i}")
-            
-            # Position camera to face the gate directly (gate now rotated 90°)
-            # Trees are positioned at: (-2,3,0), (0,4,0), (2,3,0), (-1,5,0), (1,5,0) - behind rotated gate
-            # Gate is at (0,0,0) rotated 90°, so place camera in front of gate looking through it toward trees
-            camera_pos = gymapi.Vec3(0.0, -3.0, 1.5)  # 3m in front of gate, at gate center height
-            camera_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look directly at gate center
-            
-            # Set camera transform for each environment using look_at
-            for i, (env_handle, cam_handle) in enumerate(zip(self.env_handles, self.camera_handles)):
-                # Use Isaac Gym's camera look_at functionality
-                self.gym.set_camera_location(cam_handle, env_handle, camera_pos, camera_target)
-                print(f"Set camera {i} to look from ({camera_pos.x}, {camera_pos.y}, {camera_pos.z}) toward ({camera_target.x}, {camera_target.y}, {camera_target.z})")
-            
-            print(f"✓ Static cameras positioned to face gate directly")
-            print(f"Camera position: (0, -3, 1.5)")
-            print(f"Camera target: (0, 0, 1.5) - gate center")
-            print(f"View: Looking through rotated gate toward trees behind it")
-            
-            self.camera_setup_success = True
-            
-        except Exception as e:
-            print(f"❌ ERROR: Isaac Gym camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.camera_setup_success = False
-    
-    def _create_viewer(self):
-        """Create viewer."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Viewer camera properties
-        cam_props = gymapi.CameraProperties()
-        viewer = self.gym.create_viewer(self.sim, cam_props)
-        
-        if viewer is None:
-            raise Exception("Failed to create viewer")
-        
-        # Set viewer camera
-        cam_pos = gymapi.Vec3(-5.0, -5.0, 3.0)
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.0)
-        self.gym.viewer_camera_look_at(viewer, None, cam_pos, cam_target)
-        
-        self.viewer = viewer
-        print("✓ Viewer created")
-    
-    def capture_camera_images(self):
-        """Capture depth and segmentation images from static camera."""
-        if not self.camera_setup_success or len(self.camera_handles) == 0:
-            return None, None
-        
-        try:
-            # Step graphics first to ensure everything is rendered
-            self.gym.step_graphics(self.sim)
-            
-            # Render all camera sensors
-            self.gym.render_all_camera_sensors(self.sim)
-            
-            # Start access to image tensors
-            self.gym.start_access_image_tensors(self.sim)
-            
-            # Get images from first camera
-            env_handle = self.env_handles[0]
-            cam_handle = self.camera_handles[0]
-            
-            # Get depth image
-            depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                self.sim, env_handle, cam_handle, gymapi.IMAGE_DEPTH
-            )
-            depth_img = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-            
-            # Get segmentation image
-            seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                self.sim, env_handle, cam_handle, gymapi.IMAGE_SEGMENTATION
-            )
-            seg_img = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-            
-            # End access to image tensors
-            self.gym.end_access_image_tensors(self.sim)
-            
-            return depth_img, seg_img
-                
-        except Exception as e:
-            print(f"Error capturing camera images: {e}")
-            return None, None
-            
-    def create_combined_image(self, depth_img, seg_img, title="Static Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-        # Take absolute value to handle negative depths (coordinate system issue)
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 10 meters for D455 range)
-        depth_norm = np.clip(depth_norm, 0, 10.0)  
-        depth_norm = (depth_norm / 10.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 10.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 10.0)
-            pseudo_seg = (pseudo_seg / 10.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-    def save_camera_image(self, combined_image, step_count):
-        """Save camera image to file."""
-        if combined_image is not None:
-            filename = f"static_camera_combined_{step_count:04d}.jpg"
-            cv2.imwrite(filename, combined_image)
-            print(f"Saved image: {filename}")
-    
-    def run_visualization(self, duration=60.0, save_images=False):
-        """Run the visualization loop."""
-        print(f"Starting visualization for {duration} seconds...")
-        print("Press ESC to exit early")
-        
-        start_time = time.time()
-        step_count = 0
-        
-        # OpenCV window for camera display
-        cv2.namedWindow("Static Camera View", cv2.WINDOW_NORMAL)
-        cv2.resizeWindow("Static Camera View", 2560, 720)  # Side-by-side 1280x720 images
-        
-        while True:
-            current_time = time.time()
-            elapsed_time = current_time - start_time
-            
-            # Check if duration exceeded
-            if elapsed_time > duration:
-                print(f"Visualization completed after {duration} seconds")
-                break
-            
-            # Step simulation
-            self.gym.simulate(self.sim)
-            self.gym.fetch_results(self.sim, True)
-            
-            # Capture camera images
-            depth_img, seg_img = self.capture_camera_images()
-            
-            if depth_img is not None and seg_img is not None:
-                # Create combined visualization
-                combined_image = self.create_combined_image(depth_img, seg_img)
-                
-                if combined_image is not None:
-                    # Display images
-                    cv2.imshow("Static Camera View", combined_image)
-                
-                    # Note: Image saving functionality removed as requested
-                    
-                    # Print depth statistics periodically
-                    if step_count % 60 == 0:  # Every second at 60 FPS
-                        # Filter out -inf values for better statistics
-                        valid_depths = depth_img[depth_img != -np.inf]
-                        if len(valid_depths) > 0:
-                            # Use absolute values for meaningful distance measurements
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = depth_img.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            print(f"Step {step_count}: Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-                        else:
-                            print(f"Step {step_count}: No valid depth data (all -inf)")
-                        
-                        unique_segs = len(np.unique(seg_img))
-                        print(f"  Segmentation: {unique_segs} unique values")
-                
-            # Handle viewer events
-            if not self.headless:
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                if self.gym.query_viewer_has_closed(self.viewer):
-                    break
-            
-            # Check for ESC key press in OpenCV window
-            key = cv2.waitKey(1) & 0xFF
-            if key == 27:  # ESC key
-                print("ESC pressed, exiting visualization")
-                break
-            
-            step_count += 1
-        
-        cv2.destroyAllWindows()
-        print("Visualization loop completed")
-    
-    def print_environment_info(self):
-        """Print information about the environment."""
-        print("\n" + "="*50)
-        print("ENVIRONMENT INFORMATION")
-        print("="*50)
-        print(f"Number of environments: {self.num_envs}")
-        print(f"Device: {self.device}")
-        print(f"Gate asset: {gate_asset_params.file}")
-        print(f"X500 robot asset: {X500Cfg.robot_asset.file}")
-        print(f"Camera setup success: {self.camera_setup_success}")
-        print(f"Number of cameras: {len(self.camera_handles)}")
-        print(f"Number of trees: {len(self.tree_handles)}")
-        print(f"Number of X500 robots: {len(self.x500_handles)}")
-        
-        if self.camera_setup_success:
-            print(f"Camera position: (0, -3, 1.5)")
-            print(f"Camera target: (0, 0, 1.5) - gate center")
-            print(f"Gate position: (0, 0, 0) - rotated 90°")
-            print(f"X500 position: (-1.5, 0, 1.0) - left of gate, 1m above ground")
-            print(f"Setup: Camera faces gate directly, X500 visible to left, trees behind gate")
-        
-        print("="*50)
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        cv2.destroyAllWindows()
-        
-        if hasattr(self, 'viewer') and self.viewer is not None:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if hasattr(self, 'sim') and self.sim is not None:
-            self.gym.destroy_sim(self.sim)
-
-        print("✓ Cleanup completed")
-
-def main():
-    """Main function."""
-    try:
-        print("🚁 Starting Gate Visualization with Native Isaac Gym Camera...")
-        
-        # Create environment
-        env = GateEnvironmentWithNativeCameraAndX500(headless=False)
-        
-        # Print environment information
-        env.print_environment_info()
-        
-        # Run visualization
-        env.run_visualization(duration=120.0, save_images=False)
-        
-    except KeyboardInterrupt:
-        print("\n⚠️ Interrupted by user")
-    except Exception as e:
-        print(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        if 'env' in locals():
-            env.cleanup()
-        print("👋 Goodbye!")
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_with_camera_background_trees_X500_camera.py b/examples/simple_gate_visualization_with_camera_background_trees_X500_camera.py
deleted file mode 100644
index 94025a4..0000000
--- a/examples/simple_gate_visualization_with_camera_background_trees_X500_camera.py
+++ /dev/null
@@ -1,774 +0,0 @@
-"""
-Simple Gate Visualization with Static Camera and X500 Robot with D455 Camera
-===========================================================================
-
-This script creates a simple visualization of a gate environment with:
-1. A static depth camera using Isaac Gym native API
-2. An X500 quadrotor robot with D455 depth camera sensor
-3. Real-time visualization of both camera outputs side-by-side
-
-Key features:
-- Gate environment with optional background trees
-- X500 quadrotor robot with onboard D455 camera
-- Static world-mounted camera positioned 3m from gate
-- Real-time depth and segmentation image display from both cameras
-- Dual camera system: Static + Agent camera
-"""
-
-import os
-import sys
-import time
-import cv2
-import numpy as np
-
-# Isaac Gym must be imported first
-from isaacgym import gymapi, gymtorch, gymutil
-
-# Aerial Gym components
-from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-from aerial_gym.config.robot_config.x500_config import X500Cfg
-from aerial_gym.config.sensor_config.camera_config.d455_depth_config import RsD455Config
-import torch
-
-# Create X500 config with D455 camera enabled
-class X500WithD455Cfg(X500Cfg):
-    """X500 configuration with D455 camera sensor enabled."""
-    
-    class sensor_config(X500Cfg.sensor_config):
-        enable_camera = True
-        camera_config = RsD455Config
-    
-    class robot_asset(X500Cfg.robot_asset):
-        name = "x500_with_d455"
-
-class GateEnvironmentWithDualCameras:
-    """
-    Gate environment with static camera and X500 robot with D455 camera.
-    """
-    
-    def __init__(self, headless=False):
-        """Initialize the environment."""
-        print("🚁 Initializing Gate Environment with Dual Cameras (Static + X500 D455)...")
-        
-        self.headless = headless
-        self.device = "cuda" if torch.cuda.is_available() else "cpu"
-        self.num_envs = 1
-        
-        # Environment handles (Isaac Gym)
-        self.env_handles = []
-        self.gate_handles = []
-        self.tree_handles = []
-        self.x500_handles = []  # Add X500 robot handles
-        
-        # Static camera handles and setup
-        self.camera_handles = []
-        self.camera_setup_success = False
-        
-        # X500 camera handles
-        self.x500_camera_handles = []
-        
-        # Initialize gym
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        self._setup_static_camera()
-        self._setup_x500_with_camera()
-        
-        if not self.headless:
-            self._create_viewer()
-        
-        # Prepare simulation for rendering
-        self.gym.prepare_sim(self.sim)
-        
-        print("✅ Environment initialization complete!")
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Parse arguments
-        custom_parameters = [
-            {"name": "--headless", "action": "store_true", "help": "Run headless without viewer"},
-        ]
-        args = gymutil.parse_arguments(custom_parameters=custom_parameters)
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        print("✓ Isaac Gym initialized")
-    
-    def _create_sim(self):
-        """Create simulation."""
-        print("Creating simulation...")
-        
-        # Simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        
-        # Physics backend
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 4
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.contact_offset = 0.01
-        sim_params.physx.rest_offset = 0.0
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)
-        if self.sim is None:
-            raise Exception("Failed to create simulation")
-        
-        print("✓ Simulation created")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
-        plane_params.distance = 0.0
-        self.gym.add_ground(self.sim, plane_params)
-    
-        print("✓ Ground plane created")
-    
-    def _load_gate_asset(self):
-        """Load gate asset."""
-        print(f"Loading gate asset from: {gate_asset_params.file}")
-        
-        # Asset loading options
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        
-        # Load asset
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise Exception(f"Failed to load gate asset: {gate_asset_params.file}")
-        
-        print("✓ Gate asset loaded successfully")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create environment with gate and optional trees."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Gate on ground level
-        
-        # Rotate gate by 90 degrees around Z-axis so trees are directly behind it
-        import math
-        gate_pose.r = gymapi.Quat(0.0, 0.0, math.sin(math.pi/4), math.cos(math.pi/4))  # 90° rotation around Z-axis
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Set gate color for better visibility
-        self.gym.set_rigid_body_color(
-            env_handle, gate_handle, 0, 
-            gymapi.MESH_VISUAL, gymapi.Vec3(0.2, 0.2, 0.8)  # blue-ish
-        )
-        
-        # Add some trees behind the gate for better visualization
-        self._add_background_trees(env_handle)
-        
-        print("✓ Environment created with gate!")
-    
-    def _add_background_trees(self, env_handle):
-        """Add some trees behind the gate for better camera visualization."""
-        print("Adding background trees...")
-        
-        try:
-            # Load a tree asset from the existing tree models
-            tree_asset_folder = f"{gate_asset_params.asset_folder}/../trees"
-            available_trees = ["tree_0.urdf", "tree_1.urdf", "tree_2.urdf", "tree_3.urdf", "tree_4.urdf"]
-            
-            # Add trees at various positions behind the gate (negative Y from camera perspective)
-            tree_positions = [
-                (-2.0, 3.0, 0.0),   # Left behind gate
-                (0.0, 4.0, 0.0),    # Directly behind gate
-                (2.0, 3.0, 0.0),    # Right behind gate
-                (-1.0, 5.0, 0.0),   # Further behind, left
-                (1.0, 5.0, 0.0),    # Further behind, right
-            ]
-            
-            for i, (x, y, z) in enumerate(tree_positions):
-                if i >= len(available_trees):
-                    break
-                    
-                tree_file = available_trees[i]
-                tree_path = f"{tree_asset_folder}/{tree_file}"
-                
-                # Check if tree file exists
-                if not os.path.exists(tree_path):
-                    print(f"Tree file not found: {tree_path}, skipping...")
-                    continue
-                
-                # Load tree asset
-                tree_asset_options = gymapi.AssetOptions()
-                tree_asset_options.fix_base_link = True
-                tree_asset_options.collapse_fixed_joints = True
-                tree_asset_options.disable_gravity = True
-                tree_asset_options.replace_cylinder_with_capsule = True
-                tree_asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-                
-                tree_asset = self.gym.load_asset(
-                    self.sim, 
-                    tree_asset_folder, 
-                    tree_file, 
-                    tree_asset_options
-                )
-                
-                if tree_asset is None:
-                    print(f"Failed to load tree asset: {tree_file}")
-                    continue
-                
-                # Create tree actor
-                tree_pose = gymapi.Transform()
-                tree_pose.p = gymapi.Vec3(x, y, z)
-                tree_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
-                
-                tree_handle = self.gym.create_actor(
-                    env_handle,
-                    tree_asset,
-                    tree_pose,
-                    f"tree_{i}",
-                    0,  # Collision group
-                    1   # Collision filter
-                )
-                
-                self.tree_handles.append(tree_handle)
-                
-                # Set tree color for variety
-                colors = [
-                    gymapi.Vec3(0.2, 0.6, 0.2),  # Green
-                    gymapi.Vec3(0.4, 0.8, 0.2),  # Light green
-                    gymapi.Vec3(0.1, 0.4, 0.1),  # Dark green
-                    gymapi.Vec3(0.3, 0.7, 0.3),  # Medium green
-                    gymapi.Vec3(0.5, 0.9, 0.1),  # Yellow-green
-                ]
-                color = colors[i % len(colors)]
-                self.gym.set_rigid_body_color(
-                    env_handle, tree_handle, 0, 
-                    gymapi.MESH_VISUAL, color
-                )
-                
-                print(f"Added tree {i+1} at position ({x}, {y}, {z})")
-                
-        except Exception as e:
-            print(f"Warning: Failed to add background trees: {e}")
-            print("Continuing without trees...")
-    
-    def _setup_static_camera(self):
-        """Setup static camera using Isaac Gym native camera API."""
-        print("Setting up static camera using Isaac Gym native API...")
-        
-        try:
-            # Camera properties (D455 depth camera specifications)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = 1280  # D455 depth resolution
-            camera_props.height = 720  # D455 depth resolution
-            camera_props.horizontal_fov = 87.0  # D455 FOV
-            camera_props.near_plane = 0.4  # D455 minimum depth distance
-            camera_props.far_plane = 20.0  # D455 maximum range
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"Static camera properties (D455 specs): {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"Static camera depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-        
-            # Create camera sensor in each environment
-            self.camera_handles = []
-            for i, env_handle in enumerate(self.env_handles):
-                cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-                self.camera_handles.append(cam_handle)
-                print(f"Created static camera sensor {i} in environment {i}")
-            
-            # Position camera to face the gate directly (gate now rotated 90°)
-            camera_pos = gymapi.Vec3(0.0, -3.0, 1.5)  # 3m in front of gate, at gate center height
-            camera_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look directly at gate center
-            
-            # Set camera transform for each environment using look_at
-            for i, (env_handle, cam_handle) in enumerate(zip(self.env_handles, self.camera_handles)):
-                # Use Isaac Gym's camera look_at functionality
-                self.gym.set_camera_location(cam_handle, env_handle, camera_pos, camera_target)
-                print(f"Set static camera {i} to look from ({camera_pos.x}, {camera_pos.y}, {camera_pos.z}) toward ({camera_target.x}, {camera_target.y}, {camera_target.z})")
-            
-            print(f"✓ Static cameras positioned to face gate directly")
-            
-            self.camera_setup_success = True
-            
-        except Exception as e:
-            print(f"❌ ERROR: Isaac Gym static camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.camera_setup_success = False
-    
-    def _load_x500_asset(self):
-        """Load X500 robot asset with D455 camera."""
-        print(f"Loading X500 robot asset from: {X500WithD455Cfg.robot_asset.file}")
-        
-        # Asset loading options for X500
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = X500WithD455Cfg.robot_asset.fix_base_link
-        asset_options.collapse_fixed_joints = X500WithD455Cfg.robot_asset.collapse_fixed_joints
-        asset_options.disable_gravity = X500WithD455Cfg.robot_asset.disable_gravity
-        asset_options.replace_cylinder_with_capsule = X500WithD455Cfg.robot_asset.replace_cylinder_with_capsule
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        asset_options.flip_visual_attachments = X500WithD455Cfg.robot_asset.flip_visual_attachments
-        asset_options.density = X500WithD455Cfg.robot_asset.density
-        asset_options.angular_damping = X500WithD455Cfg.robot_asset.angular_damping
-        asset_options.linear_damping = X500WithD455Cfg.robot_asset.linear_damping
-        asset_options.max_angular_velocity = X500WithD455Cfg.robot_asset.max_angular_velocity
-        asset_options.max_linear_velocity = X500WithD455Cfg.robot_asset.max_linear_velocity
-        asset_options.armature = X500WithD455Cfg.robot_asset.armature
-        
-        # Load X500 asset
-        x500_asset = self.gym.load_asset(
-            self.sim, 
-            X500WithD455Cfg.robot_asset.asset_folder, 
-            X500WithD455Cfg.robot_asset.file, 
-            asset_options
-        )
-        
-        if x500_asset is None:
-            raise Exception(f"Failed to load X500 robot asset: {X500WithD455Cfg.robot_asset.file}")
-        
-        print("✓ X500 robot asset loaded successfully")
-        return x500_asset
-
-    def _setup_x500_with_camera(self):
-        """Setup X500 drone with D455 camera in the same environment."""
-        print("Setting up X500 drone with D455 camera...")
-        
-        try:
-            # Load X500 asset
-            x500_asset = self._load_x500_asset()
-            
-            # Get the first environment handle
-            env_handle = self.env_handles[0]
-            
-            # Create X500 robot actor
-            x500_pose = gymapi.Transform()
-            x500_pose.p = gymapi.Vec3(-2.5, 0.0, 1.0)  # Position X500 further left of gate, 1m above ground
-            x500_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # Default orientation
-            
-            x500_handle = self.gym.create_actor(
-                env_handle,
-                x500_asset,
-                x500_pose,
-                "x500",
-                0,  # Collision group
-                1   # Collision filter
-            )
-            self.x500_handles = [x500_handle]
-            
-            # Set X500 color for better visibility
-            self.gym.set_rigid_body_color(
-                env_handle, x500_handle, 0, 
-                gymapi.MESH_VISUAL, gymapi.Vec3(0.8, 0.8, 0.2)  # Yellow X500
-            )
-            
-            # Setup D455 camera on X500
-            self._setup_x500_camera(env_handle, x500_handle)
-            
-            print("✓ X500 with D455 camera setup complete")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 with camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_handles = []
-    
-    def _setup_x500_camera(self, env_handle, x500_handle):
-        """Setup D455 camera on X500 drone."""
-        print("Setting up D455 camera on X500...")
-        
-        try:
-            # Camera properties (D455 specifications from config)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = RsD455Config.width  # 480
-            camera_props.height = RsD455Config.height  # 270
-            camera_props.horizontal_fov = RsD455Config.horizontal_fov_deg  # 87.0
-            camera_props.near_plane = RsD455Config.min_range  # 0.2
-            camera_props.far_plane = RsD455Config.max_range  # 15.0
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"X500 D455 camera properties: {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"X500 D455 depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-            
-            # Create camera sensor attached to X500
-            x500_cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-            print(f"Debug: Created X500 camera sensor with handle: {x500_cam_handle}")
-            
-            if x500_cam_handle is None:
-                raise Exception("Failed to create X500 camera sensor")
-            
-            # Attach camera to X500 base_link with forward-facing orientation
-            # Camera position relative to X500 base_link (slightly forward and up)
-            cam_pos = gymapi.Vec3(0.10, 0.0, 0.03)  # 10cm forward, 3cm up from center
-            
-            # Attach camera to X500
-            self.gym.attach_camera_to_body(
-                x500_cam_handle, env_handle, x500_handle,
-                gymapi.Transform(p=cam_pos), gymapi.FOLLOW_TRANSFORM
-            )
-            print(f"Debug: Attached camera to X500 body at position ({cam_pos.x}, {cam_pos.y}, {cam_pos.z})")
-            
-            # Store camera handle
-            self.x500_camera_handles = [x500_cam_handle]
-            
-            print("✓ D455 camera attached to X500")
-            print(f"Debug: X500 camera handles stored: {self.x500_camera_handles}")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_camera_handles = []
-    
-    def _create_viewer(self):
-        """Create viewer."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Viewer camera properties
-        cam_props = gymapi.CameraProperties()
-        viewer = self.gym.create_viewer(self.sim, cam_props)
-        
-        if viewer is None:
-            raise Exception("Failed to create viewer")
-        
-        # Set viewer camera
-        cam_pos = gymapi.Vec3(-5.0, -5.0, 3.0)
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.0)
-        self.gym.viewer_camera_look_at(viewer, None, cam_pos, cam_target)
-        
-        self.viewer = viewer
-        print("✓ Viewer created")
-    
-    def capture_all_camera_images(self):
-        """Capture depth and segmentation images from both cameras."""
-        static_depth, static_seg = None, None
-        x500_depth, x500_seg = None, None
-        
-        try:
-            # Step graphics and render all cameras once
-            self.gym.step_graphics(self.sim)
-            self.gym.render_all_camera_sensors(self.sim)
-            self.gym.start_access_image_tensors(self.sim)
-            
-            env_handle = self.env_handles[0]
-            
-            # Capture static camera images
-            if self.camera_setup_success and len(self.camera_handles) > 0:
-                try:
-                    cam_handle = self.camera_handles[0]
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    static_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    static_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    
-                except Exception as e:
-                    print(f"Error capturing static camera: {e}")
-            
-            # Capture X500 camera images
-            if len(self.x500_camera_handles) > 0:
-                try:
-                    x500_cam_handle = self.x500_camera_handles[0]
-                    print(f"Debug: Attempting to capture from X500 camera handle: {x500_cam_handle}")
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    x500_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    print(f"Debug: X500 depth image shape: {x500_depth.shape}, range: {x500_depth.min():.2f} to {x500_depth.max():.2f}")
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    x500_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    print(f"Debug: X500 seg image shape: {x500_seg.shape}, unique values: {len(np.unique(x500_seg))}")
-                    
-                except Exception as e:
-                    print(f"Error capturing X500 camera: {e}")
-                    import traceback
-                    traceback.print_exc()
-            else:
-                print("Debug: No X500 camera handles available")
-            
-            # End access to image tensors
-            self.gym.end_access_image_tensors(self.sim)
-            
-            return (static_depth, static_seg), (x500_depth, x500_seg)
-                
-        except Exception as e:
-            print(f"Error in capture_all_camera_images: {e}")
-            import traceback
-            traceback.print_exc()
-            return (None, None), (None, None)
-    
-    def create_combined_image(self, depth_img, seg_img, title="Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-        # Take absolute value to handle negative depths (coordinate system issue)
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 10 meters for D455 range)
-        depth_norm = np.clip(depth_norm, 0, 10.0)  
-        depth_norm = (depth_norm / 10.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 10.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 10.0)
-            pseudo_seg = (pseudo_seg / 10.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-    def run_visualization(self, duration=60.0):
-        """Run the visualization loop."""
-        print(f"Starting visualization for {duration} seconds...")
-        print("Press ESC to exit early")
-        
-        start_time = time.time()
-        step_count = 0
-        
-        # OpenCV windows for camera displays
-        cv2.namedWindow("Static Camera View", cv2.WINDOW_NORMAL)
-        cv2.resizeWindow("Static Camera View", 2560, 720)  # Side-by-side 1280x720 images
-        
-        if len(self.x500_camera_handles) > 0:
-            cv2.namedWindow("X500 D455 Camera View", cv2.WINDOW_NORMAL)
-            cv2.resizeWindow("X500 D455 Camera View", 960, 540)  # D455 resolution scaled
-        
-        while True:
-            current_time = time.time()
-            elapsed_time = current_time - start_time
-            
-            # Check if duration exceeded
-            if elapsed_time > duration:
-                print(f"Visualization completed after {duration} seconds")
-                break
-            
-            # Step simulation
-            self.gym.simulate(self.sim)
-            self.gym.fetch_results(self.sim, True)
-            
-            # Capture all camera images at once
-            (static_depth, static_seg), (x500_depth, x500_seg) = self.capture_all_camera_images()
-            
-            # Display static camera images
-            if static_depth is not None and static_seg is not None:
-                # Create combined visualization for static camera
-                static_combined = self.create_combined_image(static_depth, static_seg, "Static Camera")
-                
-                if static_combined is not None:
-                    # Display static camera images
-                    cv2.imshow("Static Camera View", static_combined)
-                    
-                    # Print depth statistics periodically
-                    if step_count % 60 == 0:  # Every second at 60 FPS
-                        # Filter out -inf values for better statistics
-                        valid_depths = static_depth[static_depth != -np.inf]
-                        if len(valid_depths) > 0:
-                            # Use absolute values for meaningful distance measurements
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = static_depth.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            print(f"Step {step_count}: Static Camera - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-            
-            # Display X500 camera images
-            if x500_depth is not None and x500_seg is not None:
-                # Create combined visualization for X500 camera
-                x500_combined = self.create_combined_image(x500_depth, x500_seg, "X500 D455")
-                
-                if x500_combined is not None:
-                    # Display X500 camera images
-                    cv2.imshow("X500 D455 Camera View", x500_combined)
-                    
-                    # Print X500 camera statistics periodically
-                    if step_count % 60 == 0:
-                        valid_depths = x500_depth[x500_depth != -np.inf]
-                        if len(valid_depths) > 0:
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = x500_depth.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            print(f"          X500 D455 - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-            elif step_count % 60 == 0:
-                print(f"          X500 D455 - No camera data available")
-            
-            # Handle viewer events
-            if not self.headless:
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                if self.gym.query_viewer_has_closed(self.viewer):
-                    break
-            
-            # Check for ESC key press in OpenCV window
-            key = cv2.waitKey(1) & 0xFF
-            if key == 27:  # ESC key
-                print("ESC pressed, exiting visualization")
-                break
-            
-            step_count += 1
-        
-        cv2.destroyAllWindows()
-        print("Visualization loop completed")
-    
-    def print_environment_info(self):
-        """Print information about the environment."""
-        print("\n" + "="*50)
-        print("DUAL CAMERA ENVIRONMENT INFORMATION")
-        print("="*50)
-        print(f"Number of environments: {self.num_envs}")
-        print(f"Device: {self.device}")
-        print(f"Gate asset: {gate_asset_params.file}")
-        print(f"Static camera setup success: {self.camera_setup_success}")
-        print(f"Number of static cameras: {len(self.camera_handles)}")
-        print(f"Number of trees: {len(self.tree_handles)}")
-        print(f"Number of X500 robots: {len(self.x500_handles)}")
-        print(f"X500 with D455 setup: {'Success' if len(self.x500_handles) > 0 else 'Failed'}")
-        
-        if self.camera_setup_success:
-            print(f"Static camera position: (0, -3, 1.5)")
-            print(f"Static camera target: (0, 0, 1.5) - gate center")
-            print(f"Gate position: (0, 0, 0) - rotated 90°")
-        
-        if len(self.x500_handles) > 0:
-            print(f"X500 position: (-2.5, 0, 1.0) - further left of gate, 1m above ground")
-            print(f"X500 with D455 camera: Active")
-            print(f"X500 camera handles: {len(self.x500_camera_handles)} cameras")
-            print(f"X500 camera specs: D455 (270x480, 87° FOV, 0.2-15m range)")
-            if len(self.x500_camera_handles) > 0:
-                print(f"X500 camera handle IDs: {self.x500_camera_handles}")
-            else:
-                print("⚠️  WARNING: X500 created but no camera handles found!")
-        
-        print("="*50)
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        cv2.destroyAllWindows()
-        
-        if hasattr(self, 'viewer') and self.viewer is not None:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if hasattr(self, 'sim') and self.sim is not None:
-            self.gym.destroy_sim(self.sim)
-
-        print("✓ Cleanup completed")
-
-def main():
-    """Main function."""
-    try:
-        print("🚁 Starting Gate Visualization with Dual Cameras...")
-        
-        # Create environment
-        env = GateEnvironmentWithDualCameras(headless=False)
-        
-        # Print environment information
-        env.print_environment_info()
-        
-        # Run visualization
-        env.run_visualization(duration=120.0)
-        
-    except KeyboardInterrupt:
-        print("\n⚠️ Interrupted by user")
-    except Exception as e:
-        print(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        if 'env' in locals():
-            env.cleanup()
-        print("👋 Goodbye!")
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_with_camera_background_trees_X500_camera_control.py b/examples/simple_gate_visualization_with_camera_background_trees_X500_camera_control.py
deleted file mode 100644
index 94025a4..0000000
--- a/examples/simple_gate_visualization_with_camera_background_trees_X500_camera_control.py
+++ /dev/null
@@ -1,774 +0,0 @@
-"""
-Simple Gate Visualization with Static Camera and X500 Robot with D455 Camera
-===========================================================================
-
-This script creates a simple visualization of a gate environment with:
-1. A static depth camera using Isaac Gym native API
-2. An X500 quadrotor robot with D455 depth camera sensor
-3. Real-time visualization of both camera outputs side-by-side
-
-Key features:
-- Gate environment with optional background trees
-- X500 quadrotor robot with onboard D455 camera
-- Static world-mounted camera positioned 3m from gate
-- Real-time depth and segmentation image display from both cameras
-- Dual camera system: Static + Agent camera
-"""
-
-import os
-import sys
-import time
-import cv2
-import numpy as np
-
-# Isaac Gym must be imported first
-from isaacgym import gymapi, gymtorch, gymutil
-
-# Aerial Gym components
-from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-from aerial_gym.config.robot_config.x500_config import X500Cfg
-from aerial_gym.config.sensor_config.camera_config.d455_depth_config import RsD455Config
-import torch
-
-# Create X500 config with D455 camera enabled
-class X500WithD455Cfg(X500Cfg):
-    """X500 configuration with D455 camera sensor enabled."""
-    
-    class sensor_config(X500Cfg.sensor_config):
-        enable_camera = True
-        camera_config = RsD455Config
-    
-    class robot_asset(X500Cfg.robot_asset):
-        name = "x500_with_d455"
-
-class GateEnvironmentWithDualCameras:
-    """
-    Gate environment with static camera and X500 robot with D455 camera.
-    """
-    
-    def __init__(self, headless=False):
-        """Initialize the environment."""
-        print("🚁 Initializing Gate Environment with Dual Cameras (Static + X500 D455)...")
-        
-        self.headless = headless
-        self.device = "cuda" if torch.cuda.is_available() else "cpu"
-        self.num_envs = 1
-        
-        # Environment handles (Isaac Gym)
-        self.env_handles = []
-        self.gate_handles = []
-        self.tree_handles = []
-        self.x500_handles = []  # Add X500 robot handles
-        
-        # Static camera handles and setup
-        self.camera_handles = []
-        self.camera_setup_success = False
-        
-        # X500 camera handles
-        self.x500_camera_handles = []
-        
-        # Initialize gym
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        self._setup_static_camera()
-        self._setup_x500_with_camera()
-        
-        if not self.headless:
-            self._create_viewer()
-        
-        # Prepare simulation for rendering
-        self.gym.prepare_sim(self.sim)
-        
-        print("✅ Environment initialization complete!")
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Parse arguments
-        custom_parameters = [
-            {"name": "--headless", "action": "store_true", "help": "Run headless without viewer"},
-        ]
-        args = gymutil.parse_arguments(custom_parameters=custom_parameters)
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        print("✓ Isaac Gym initialized")
-    
-    def _create_sim(self):
-        """Create simulation."""
-        print("Creating simulation...")
-        
-        # Simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        
-        # Physics backend
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 4
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.contact_offset = 0.01
-        sim_params.physx.rest_offset = 0.0
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)
-        if self.sim is None:
-            raise Exception("Failed to create simulation")
-        
-        print("✓ Simulation created")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
-        plane_params.distance = 0.0
-        self.gym.add_ground(self.sim, plane_params)
-    
-        print("✓ Ground plane created")
-    
-    def _load_gate_asset(self):
-        """Load gate asset."""
-        print(f"Loading gate asset from: {gate_asset_params.file}")
-        
-        # Asset loading options
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        
-        # Load asset
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise Exception(f"Failed to load gate asset: {gate_asset_params.file}")
-        
-        print("✓ Gate asset loaded successfully")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create environment with gate and optional trees."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Gate on ground level
-        
-        # Rotate gate by 90 degrees around Z-axis so trees are directly behind it
-        import math
-        gate_pose.r = gymapi.Quat(0.0, 0.0, math.sin(math.pi/4), math.cos(math.pi/4))  # 90° rotation around Z-axis
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Set gate color for better visibility
-        self.gym.set_rigid_body_color(
-            env_handle, gate_handle, 0, 
-            gymapi.MESH_VISUAL, gymapi.Vec3(0.2, 0.2, 0.8)  # blue-ish
-        )
-        
-        # Add some trees behind the gate for better visualization
-        self._add_background_trees(env_handle)
-        
-        print("✓ Environment created with gate!")
-    
-    def _add_background_trees(self, env_handle):
-        """Add some trees behind the gate for better camera visualization."""
-        print("Adding background trees...")
-        
-        try:
-            # Load a tree asset from the existing tree models
-            tree_asset_folder = f"{gate_asset_params.asset_folder}/../trees"
-            available_trees = ["tree_0.urdf", "tree_1.urdf", "tree_2.urdf", "tree_3.urdf", "tree_4.urdf"]
-            
-            # Add trees at various positions behind the gate (negative Y from camera perspective)
-            tree_positions = [
-                (-2.0, 3.0, 0.0),   # Left behind gate
-                (0.0, 4.0, 0.0),    # Directly behind gate
-                (2.0, 3.0, 0.0),    # Right behind gate
-                (-1.0, 5.0, 0.0),   # Further behind, left
-                (1.0, 5.0, 0.0),    # Further behind, right
-            ]
-            
-            for i, (x, y, z) in enumerate(tree_positions):
-                if i >= len(available_trees):
-                    break
-                    
-                tree_file = available_trees[i]
-                tree_path = f"{tree_asset_folder}/{tree_file}"
-                
-                # Check if tree file exists
-                if not os.path.exists(tree_path):
-                    print(f"Tree file not found: {tree_path}, skipping...")
-                    continue
-                
-                # Load tree asset
-                tree_asset_options = gymapi.AssetOptions()
-                tree_asset_options.fix_base_link = True
-                tree_asset_options.collapse_fixed_joints = True
-                tree_asset_options.disable_gravity = True
-                tree_asset_options.replace_cylinder_with_capsule = True
-                tree_asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-                
-                tree_asset = self.gym.load_asset(
-                    self.sim, 
-                    tree_asset_folder, 
-                    tree_file, 
-                    tree_asset_options
-                )
-                
-                if tree_asset is None:
-                    print(f"Failed to load tree asset: {tree_file}")
-                    continue
-                
-                # Create tree actor
-                tree_pose = gymapi.Transform()
-                tree_pose.p = gymapi.Vec3(x, y, z)
-                tree_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
-                
-                tree_handle = self.gym.create_actor(
-                    env_handle,
-                    tree_asset,
-                    tree_pose,
-                    f"tree_{i}",
-                    0,  # Collision group
-                    1   # Collision filter
-                )
-                
-                self.tree_handles.append(tree_handle)
-                
-                # Set tree color for variety
-                colors = [
-                    gymapi.Vec3(0.2, 0.6, 0.2),  # Green
-                    gymapi.Vec3(0.4, 0.8, 0.2),  # Light green
-                    gymapi.Vec3(0.1, 0.4, 0.1),  # Dark green
-                    gymapi.Vec3(0.3, 0.7, 0.3),  # Medium green
-                    gymapi.Vec3(0.5, 0.9, 0.1),  # Yellow-green
-                ]
-                color = colors[i % len(colors)]
-                self.gym.set_rigid_body_color(
-                    env_handle, tree_handle, 0, 
-                    gymapi.MESH_VISUAL, color
-                )
-                
-                print(f"Added tree {i+1} at position ({x}, {y}, {z})")
-                
-        except Exception as e:
-            print(f"Warning: Failed to add background trees: {e}")
-            print("Continuing without trees...")
-    
-    def _setup_static_camera(self):
-        """Setup static camera using Isaac Gym native camera API."""
-        print("Setting up static camera using Isaac Gym native API...")
-        
-        try:
-            # Camera properties (D455 depth camera specifications)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = 1280  # D455 depth resolution
-            camera_props.height = 720  # D455 depth resolution
-            camera_props.horizontal_fov = 87.0  # D455 FOV
-            camera_props.near_plane = 0.4  # D455 minimum depth distance
-            camera_props.far_plane = 20.0  # D455 maximum range
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"Static camera properties (D455 specs): {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"Static camera depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-        
-            # Create camera sensor in each environment
-            self.camera_handles = []
-            for i, env_handle in enumerate(self.env_handles):
-                cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-                self.camera_handles.append(cam_handle)
-                print(f"Created static camera sensor {i} in environment {i}")
-            
-            # Position camera to face the gate directly (gate now rotated 90°)
-            camera_pos = gymapi.Vec3(0.0, -3.0, 1.5)  # 3m in front of gate, at gate center height
-            camera_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look directly at gate center
-            
-            # Set camera transform for each environment using look_at
-            for i, (env_handle, cam_handle) in enumerate(zip(self.env_handles, self.camera_handles)):
-                # Use Isaac Gym's camera look_at functionality
-                self.gym.set_camera_location(cam_handle, env_handle, camera_pos, camera_target)
-                print(f"Set static camera {i} to look from ({camera_pos.x}, {camera_pos.y}, {camera_pos.z}) toward ({camera_target.x}, {camera_target.y}, {camera_target.z})")
-            
-            print(f"✓ Static cameras positioned to face gate directly")
-            
-            self.camera_setup_success = True
-            
-        except Exception as e:
-            print(f"❌ ERROR: Isaac Gym static camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.camera_setup_success = False
-    
-    def _load_x500_asset(self):
-        """Load X500 robot asset with D455 camera."""
-        print(f"Loading X500 robot asset from: {X500WithD455Cfg.robot_asset.file}")
-        
-        # Asset loading options for X500
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = X500WithD455Cfg.robot_asset.fix_base_link
-        asset_options.collapse_fixed_joints = X500WithD455Cfg.robot_asset.collapse_fixed_joints
-        asset_options.disable_gravity = X500WithD455Cfg.robot_asset.disable_gravity
-        asset_options.replace_cylinder_with_capsule = X500WithD455Cfg.robot_asset.replace_cylinder_with_capsule
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        asset_options.flip_visual_attachments = X500WithD455Cfg.robot_asset.flip_visual_attachments
-        asset_options.density = X500WithD455Cfg.robot_asset.density
-        asset_options.angular_damping = X500WithD455Cfg.robot_asset.angular_damping
-        asset_options.linear_damping = X500WithD455Cfg.robot_asset.linear_damping
-        asset_options.max_angular_velocity = X500WithD455Cfg.robot_asset.max_angular_velocity
-        asset_options.max_linear_velocity = X500WithD455Cfg.robot_asset.max_linear_velocity
-        asset_options.armature = X500WithD455Cfg.robot_asset.armature
-        
-        # Load X500 asset
-        x500_asset = self.gym.load_asset(
-            self.sim, 
-            X500WithD455Cfg.robot_asset.asset_folder, 
-            X500WithD455Cfg.robot_asset.file, 
-            asset_options
-        )
-        
-        if x500_asset is None:
-            raise Exception(f"Failed to load X500 robot asset: {X500WithD455Cfg.robot_asset.file}")
-        
-        print("✓ X500 robot asset loaded successfully")
-        return x500_asset
-
-    def _setup_x500_with_camera(self):
-        """Setup X500 drone with D455 camera in the same environment."""
-        print("Setting up X500 drone with D455 camera...")
-        
-        try:
-            # Load X500 asset
-            x500_asset = self._load_x500_asset()
-            
-            # Get the first environment handle
-            env_handle = self.env_handles[0]
-            
-            # Create X500 robot actor
-            x500_pose = gymapi.Transform()
-            x500_pose.p = gymapi.Vec3(-2.5, 0.0, 1.0)  # Position X500 further left of gate, 1m above ground
-            x500_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # Default orientation
-            
-            x500_handle = self.gym.create_actor(
-                env_handle,
-                x500_asset,
-                x500_pose,
-                "x500",
-                0,  # Collision group
-                1   # Collision filter
-            )
-            self.x500_handles = [x500_handle]
-            
-            # Set X500 color for better visibility
-            self.gym.set_rigid_body_color(
-                env_handle, x500_handle, 0, 
-                gymapi.MESH_VISUAL, gymapi.Vec3(0.8, 0.8, 0.2)  # Yellow X500
-            )
-            
-            # Setup D455 camera on X500
-            self._setup_x500_camera(env_handle, x500_handle)
-            
-            print("✓ X500 with D455 camera setup complete")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 with camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_handles = []
-    
-    def _setup_x500_camera(self, env_handle, x500_handle):
-        """Setup D455 camera on X500 drone."""
-        print("Setting up D455 camera on X500...")
-        
-        try:
-            # Camera properties (D455 specifications from config)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = RsD455Config.width  # 480
-            camera_props.height = RsD455Config.height  # 270
-            camera_props.horizontal_fov = RsD455Config.horizontal_fov_deg  # 87.0
-            camera_props.near_plane = RsD455Config.min_range  # 0.2
-            camera_props.far_plane = RsD455Config.max_range  # 15.0
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"X500 D455 camera properties: {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"X500 D455 depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-            
-            # Create camera sensor attached to X500
-            x500_cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-            print(f"Debug: Created X500 camera sensor with handle: {x500_cam_handle}")
-            
-            if x500_cam_handle is None:
-                raise Exception("Failed to create X500 camera sensor")
-            
-            # Attach camera to X500 base_link with forward-facing orientation
-            # Camera position relative to X500 base_link (slightly forward and up)
-            cam_pos = gymapi.Vec3(0.10, 0.0, 0.03)  # 10cm forward, 3cm up from center
-            
-            # Attach camera to X500
-            self.gym.attach_camera_to_body(
-                x500_cam_handle, env_handle, x500_handle,
-                gymapi.Transform(p=cam_pos), gymapi.FOLLOW_TRANSFORM
-            )
-            print(f"Debug: Attached camera to X500 body at position ({cam_pos.x}, {cam_pos.y}, {cam_pos.z})")
-            
-            # Store camera handle
-            self.x500_camera_handles = [x500_cam_handle]
-            
-            print("✓ D455 camera attached to X500")
-            print(f"Debug: X500 camera handles stored: {self.x500_camera_handles}")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_camera_handles = []
-    
-    def _create_viewer(self):
-        """Create viewer."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Viewer camera properties
-        cam_props = gymapi.CameraProperties()
-        viewer = self.gym.create_viewer(self.sim, cam_props)
-        
-        if viewer is None:
-            raise Exception("Failed to create viewer")
-        
-        # Set viewer camera
-        cam_pos = gymapi.Vec3(-5.0, -5.0, 3.0)
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.0)
-        self.gym.viewer_camera_look_at(viewer, None, cam_pos, cam_target)
-        
-        self.viewer = viewer
-        print("✓ Viewer created")
-    
-    def capture_all_camera_images(self):
-        """Capture depth and segmentation images from both cameras."""
-        static_depth, static_seg = None, None
-        x500_depth, x500_seg = None, None
-        
-        try:
-            # Step graphics and render all cameras once
-            self.gym.step_graphics(self.sim)
-            self.gym.render_all_camera_sensors(self.sim)
-            self.gym.start_access_image_tensors(self.sim)
-            
-            env_handle = self.env_handles[0]
-            
-            # Capture static camera images
-            if self.camera_setup_success and len(self.camera_handles) > 0:
-                try:
-                    cam_handle = self.camera_handles[0]
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    static_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    static_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    
-                except Exception as e:
-                    print(f"Error capturing static camera: {e}")
-            
-            # Capture X500 camera images
-            if len(self.x500_camera_handles) > 0:
-                try:
-                    x500_cam_handle = self.x500_camera_handles[0]
-                    print(f"Debug: Attempting to capture from X500 camera handle: {x500_cam_handle}")
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    x500_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    print(f"Debug: X500 depth image shape: {x500_depth.shape}, range: {x500_depth.min():.2f} to {x500_depth.max():.2f}")
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    x500_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    print(f"Debug: X500 seg image shape: {x500_seg.shape}, unique values: {len(np.unique(x500_seg))}")
-                    
-                except Exception as e:
-                    print(f"Error capturing X500 camera: {e}")
-                    import traceback
-                    traceback.print_exc()
-            else:
-                print("Debug: No X500 camera handles available")
-            
-            # End access to image tensors
-            self.gym.end_access_image_tensors(self.sim)
-            
-            return (static_depth, static_seg), (x500_depth, x500_seg)
-                
-        except Exception as e:
-            print(f"Error in capture_all_camera_images: {e}")
-            import traceback
-            traceback.print_exc()
-            return (None, None), (None, None)
-    
-    def create_combined_image(self, depth_img, seg_img, title="Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-        # Take absolute value to handle negative depths (coordinate system issue)
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 10 meters for D455 range)
-        depth_norm = np.clip(depth_norm, 0, 10.0)  
-        depth_norm = (depth_norm / 10.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 10.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 10.0)
-            pseudo_seg = (pseudo_seg / 10.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-    def run_visualization(self, duration=60.0):
-        """Run the visualization loop."""
-        print(f"Starting visualization for {duration} seconds...")
-        print("Press ESC to exit early")
-        
-        start_time = time.time()
-        step_count = 0
-        
-        # OpenCV windows for camera displays
-        cv2.namedWindow("Static Camera View", cv2.WINDOW_NORMAL)
-        cv2.resizeWindow("Static Camera View", 2560, 720)  # Side-by-side 1280x720 images
-        
-        if len(self.x500_camera_handles) > 0:
-            cv2.namedWindow("X500 D455 Camera View", cv2.WINDOW_NORMAL)
-            cv2.resizeWindow("X500 D455 Camera View", 960, 540)  # D455 resolution scaled
-        
-        while True:
-            current_time = time.time()
-            elapsed_time = current_time - start_time
-            
-            # Check if duration exceeded
-            if elapsed_time > duration:
-                print(f"Visualization completed after {duration} seconds")
-                break
-            
-            # Step simulation
-            self.gym.simulate(self.sim)
-            self.gym.fetch_results(self.sim, True)
-            
-            # Capture all camera images at once
-            (static_depth, static_seg), (x500_depth, x500_seg) = self.capture_all_camera_images()
-            
-            # Display static camera images
-            if static_depth is not None and static_seg is not None:
-                # Create combined visualization for static camera
-                static_combined = self.create_combined_image(static_depth, static_seg, "Static Camera")
-                
-                if static_combined is not None:
-                    # Display static camera images
-                    cv2.imshow("Static Camera View", static_combined)
-                    
-                    # Print depth statistics periodically
-                    if step_count % 60 == 0:  # Every second at 60 FPS
-                        # Filter out -inf values for better statistics
-                        valid_depths = static_depth[static_depth != -np.inf]
-                        if len(valid_depths) > 0:
-                            # Use absolute values for meaningful distance measurements
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = static_depth.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            print(f"Step {step_count}: Static Camera - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-            
-            # Display X500 camera images
-            if x500_depth is not None and x500_seg is not None:
-                # Create combined visualization for X500 camera
-                x500_combined = self.create_combined_image(x500_depth, x500_seg, "X500 D455")
-                
-                if x500_combined is not None:
-                    # Display X500 camera images
-                    cv2.imshow("X500 D455 Camera View", x500_combined)
-                    
-                    # Print X500 camera statistics periodically
-                    if step_count % 60 == 0:
-                        valid_depths = x500_depth[x500_depth != -np.inf]
-                        if len(valid_depths) > 0:
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = x500_depth.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            print(f"          X500 D455 - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-            elif step_count % 60 == 0:
-                print(f"          X500 D455 - No camera data available")
-            
-            # Handle viewer events
-            if not self.headless:
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                if self.gym.query_viewer_has_closed(self.viewer):
-                    break
-            
-            # Check for ESC key press in OpenCV window
-            key = cv2.waitKey(1) & 0xFF
-            if key == 27:  # ESC key
-                print("ESC pressed, exiting visualization")
-                break
-            
-            step_count += 1
-        
-        cv2.destroyAllWindows()
-        print("Visualization loop completed")
-    
-    def print_environment_info(self):
-        """Print information about the environment."""
-        print("\n" + "="*50)
-        print("DUAL CAMERA ENVIRONMENT INFORMATION")
-        print("="*50)
-        print(f"Number of environments: {self.num_envs}")
-        print(f"Device: {self.device}")
-        print(f"Gate asset: {gate_asset_params.file}")
-        print(f"Static camera setup success: {self.camera_setup_success}")
-        print(f"Number of static cameras: {len(self.camera_handles)}")
-        print(f"Number of trees: {len(self.tree_handles)}")
-        print(f"Number of X500 robots: {len(self.x500_handles)}")
-        print(f"X500 with D455 setup: {'Success' if len(self.x500_handles) > 0 else 'Failed'}")
-        
-        if self.camera_setup_success:
-            print(f"Static camera position: (0, -3, 1.5)")
-            print(f"Static camera target: (0, 0, 1.5) - gate center")
-            print(f"Gate position: (0, 0, 0) - rotated 90°")
-        
-        if len(self.x500_handles) > 0:
-            print(f"X500 position: (-2.5, 0, 1.0) - further left of gate, 1m above ground")
-            print(f"X500 with D455 camera: Active")
-            print(f"X500 camera handles: {len(self.x500_camera_handles)} cameras")
-            print(f"X500 camera specs: D455 (270x480, 87° FOV, 0.2-15m range)")
-            if len(self.x500_camera_handles) > 0:
-                print(f"X500 camera handle IDs: {self.x500_camera_handles}")
-            else:
-                print("⚠️  WARNING: X500 created but no camera handles found!")
-        
-        print("="*50)
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        cv2.destroyAllWindows()
-        
-        if hasattr(self, 'viewer') and self.viewer is not None:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if hasattr(self, 'sim') and self.sim is not None:
-            self.gym.destroy_sim(self.sim)
-
-        print("✓ Cleanup completed")
-
-def main():
-    """Main function."""
-    try:
-        print("🚁 Starting Gate Visualization with Dual Cameras...")
-        
-        # Create environment
-        env = GateEnvironmentWithDualCameras(headless=False)
-        
-        # Print environment information
-        env.print_environment_info()
-        
-        # Run visualization
-        env.run_visualization(duration=120.0)
-        
-    except KeyboardInterrupt:
-        print("\n⚠️ Interrupted by user")
-    except Exception as e:
-        print(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        if 'env' in locals():
-            env.cleanup()
-        print("👋 Goodbye!")
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_with_camera_background_trees_X500_camera_manual_without_simbuilder.py b/examples/simple_gate_visualization_with_camera_background_trees_X500_camera_manual_without_simbuilder.py
deleted file mode 100644
index 094e933..0000000
--- a/examples/simple_gate_visualization_with_camera_background_trees_X500_camera_manual_without_simbuilder.py
+++ /dev/null
@@ -1,972 +0,0 @@
-"""
-Simple Gate Visualization with Static Camera and X500 Robot with D455 Camera and Hover Control
-=============================================================================================
-
-This script creates a simple visualization of a gate environment with:
-1. A static depth camera using Isaac Gym native API
-2. An X500 quadrotor robot with D455 depth camera sensor
-3. Lee position controller to make X500 hover in place
-4. Real-time visualization of both camera outputs side-by-side
-
-Key features:
-- Gate environment with optional background trees
-- X500 quadrotor robot with onboard D455 camera
-- Lee position controller for hovering
-- Static world-mounted camera positioned 3m from gate
-- Real-time depth and segmentation image display from both cameras
-- Dual camera system: Static + Agent camera with control
-"""
-
-import os
-import sys
-import time
-import cv2
-import numpy as np
-
-# Isaac Gym must be imported first
-from isaacgym import gymapi, gymtorch, gymutil
-
-# Aerial Gym components
-from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-from aerial_gym.config.robot_config.x500_config import X500Cfg
-from aerial_gym.config.sensor_config.camera_config.d455_depth_config import RsD455Config
-from aerial_gym.config.controller_config.lee_controller_config import control as lee_controller_config
-
-# Controller imports
-from aerial_gym.control.controllers.position_control import LeePositionController
-from aerial_gym.control.control_allocation import ControlAllocator
-from aerial_gym.utils.math import *
-
-import torch
-
-# Create X500 config with D455 camera enabled
-class X500WithD455Cfg(X500Cfg):
-    """X500 configuration with D455 camera sensor enabled."""
-    
-    class sensor_config(X500Cfg.sensor_config):
-        enable_camera = True
-        camera_config = RsD455Config
-    
-    class robot_asset(X500Cfg.robot_asset):
-        name = "x500_with_d455"
-
-class GateEnvironmentWithDualCamerasAndControl:
-    """
-    Gate environment with static camera and X500 robot with D455 camera and hover control.
-    """
-    
-    def __init__(self, headless=False):
-        """Initialize the environment."""
-        print("🚁 Initializing Gate Environment with Dual Cameras and Hover Control...")
-        
-        self.headless = headless
-        self.device = "cuda" if torch.cuda.is_available() else "cpu"
-        self.num_envs = 1
-        self.dt = 1.0 / 60.0  # 60 FPS simulation
-        
-        # Environment handles (Isaac Gym)
-        self.env_handles = []
-        self.gate_handles = []
-        self.tree_handles = []
-        self.x500_handles = []  # Add X500 robot handles
-        
-        # Static camera handles and setup
-        self.camera_handles = []
-        self.camera_setup_success = False
-        
-        # X500 camera handles
-        self.x500_camera_handles = []
-        
-        # Control system
-        self.controller = None
-        self.control_allocator = None
-        self.hover_position = torch.tensor([[-2.5, 0.0, 1.0]], device=self.device)  # Hover position
-        self.hover_yaw = 0.0  # Hover yaw angle
-        
-        # Robot state tensors
-        self.robot_position = torch.zeros((self.num_envs, 3), device=self.device)
-        self.robot_orientation = torch.zeros((self.num_envs, 4), device=self.device)
-        self.robot_linvel = torch.zeros((self.num_envs, 3), device=self.device)
-        self.robot_angvel = torch.zeros((self.num_envs, 3), device=self.device)
-        
-        # Initialize gym
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        self._setup_static_camera()
-        self._setup_x500_with_camera()
-        self._setup_controller()
-        
-        if not self.headless:
-            self._create_viewer()
-        
-        # Prepare simulation for rendering
-        self.gym.prepare_sim(self.sim)
-        
-        print("✅ Environment initialization complete!")
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Parse arguments
-        custom_parameters = [
-            {"name": "--headless", "action": "store_true", "help": "Run headless without viewer"},
-        ]
-        args = gymutil.parse_arguments(custom_parameters=custom_parameters)
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        print("✓ Isaac Gym initialized")
-    
-    def _create_sim(self):
-        """Create simulation."""
-        print("Creating simulation...")
-        
-        # Simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        
-        # Physics backend
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 4
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.contact_offset = 0.01
-        sim_params.physx.rest_offset = 0.0
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)
-        if self.sim is None:
-            raise Exception("Failed to create simulation")
-        
-        print("✓ Simulation created")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
-        plane_params.distance = 0.0
-        self.gym.add_ground(self.sim, plane_params)
-    
-        print("✓ Ground plane created")
-    
-    def _load_gate_asset(self):
-        """Load gate asset."""
-        print(f"Loading gate asset from: {gate_asset_params.file}")
-        
-        # Asset loading options
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        
-        # Load asset
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise Exception(f"Failed to load gate asset: {gate_asset_params.file}")
-        
-        print("✓ Gate asset loaded successfully")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create environment with gate and optional trees."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Gate on ground level
-        
-        # Rotate gate by 90 degrees around Z-axis so trees are directly behind it
-        import math
-        gate_pose.r = gymapi.Quat(0.0, 0.0, math.sin(math.pi/4), math.cos(math.pi/4))  # 90° rotation around Z-axis
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Set gate color for better visibility
-        self.gym.set_rigid_body_color(
-            env_handle, gate_handle, 0, 
-            gymapi.MESH_VISUAL, gymapi.Vec3(0.2, 0.2, 0.8)  # blue-ish
-        )
-        
-        # Add some trees behind the gate for better visualization
-        self._add_background_trees(env_handle)
-        
-        print("✓ Environment created with gate!")
-    
-    def _add_background_trees(self, env_handle):
-        """Add some trees behind the gate for better camera visualization."""
-        print("Adding background trees...")
-        
-        try:
-            # Load a tree asset from the existing tree models
-            tree_asset_folder = f"{gate_asset_params.asset_folder}/../trees"
-            available_trees = ["tree_0.urdf", "tree_1.urdf", "tree_2.urdf", "tree_3.urdf", "tree_4.urdf"]
-            
-            # Add trees at various positions behind the gate (negative Y from camera perspective)
-            tree_positions = [
-                (-2.0, 3.0, 0.0),   # Left behind gate
-                (0.0, 4.0, 0.0),    # Directly behind gate
-                (2.0, 3.0, 0.0),    # Right behind gate
-                (-1.0, 5.0, 0.0),   # Further behind, left
-                (1.0, 5.0, 0.0),    # Further behind, right
-            ]
-            
-            for i, (x, y, z) in enumerate(tree_positions):
-                if i >= len(available_trees):
-                    break
-                    
-                tree_file = available_trees[i]
-                tree_path = f"{tree_asset_folder}/{tree_file}"
-                
-                # Check if tree file exists
-                if not os.path.exists(tree_path):
-                    print(f"Tree file not found: {tree_path}, skipping...")
-                    continue
-                
-                # Load tree asset
-                tree_asset_options = gymapi.AssetOptions()
-                tree_asset_options.fix_base_link = True
-                tree_asset_options.collapse_fixed_joints = True
-                tree_asset_options.disable_gravity = True
-                tree_asset_options.replace_cylinder_with_capsule = True
-                tree_asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-                
-                tree_asset = self.gym.load_asset(
-                    self.sim, 
-                    tree_asset_folder, 
-                    tree_file, 
-                    tree_asset_options
-                )
-                
-                if tree_asset is None:
-                    print(f"Failed to load tree asset: {tree_file}")
-                    continue
-                
-                # Create tree actor
-                tree_pose = gymapi.Transform()
-                tree_pose.p = gymapi.Vec3(x, y, z)
-                tree_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
-                
-                tree_handle = self.gym.create_actor(
-                    env_handle,
-                    tree_asset,
-                    tree_pose,
-                    f"tree_{i}",
-                    0,  # Collision group
-                    1   # Collision filter
-                )
-                
-                self.tree_handles.append(tree_handle)
-                
-                # Set tree color for variety
-                colors = [
-                    gymapi.Vec3(0.2, 0.6, 0.2),  # Green
-                    gymapi.Vec3(0.4, 0.8, 0.2),  # Light green
-                    gymapi.Vec3(0.1, 0.4, 0.1),  # Dark green
-                    gymapi.Vec3(0.3, 0.7, 0.3),  # Medium green
-                    gymapi.Vec3(0.5, 0.9, 0.1),  # Yellow-green
-                ]
-                color = colors[i % len(colors)]
-                self.gym.set_rigid_body_color(
-                    env_handle, tree_handle, 0, 
-                    gymapi.MESH_VISUAL, color
-                )
-                
-                print(f"Added tree {i+1} at position ({x}, {y}, {z})")
-                
-        except Exception as e:
-            print(f"Warning: Failed to add background trees: {e}")
-            print("Continuing without trees...")
-    
-    def _setup_static_camera(self):
-        """Setup static camera using Isaac Gym native camera API."""
-        print("Setting up static camera using Isaac Gym native API...")
-        
-        try:
-            # Camera properties (D455 depth camera specifications)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = 1280  # D455 depth resolution
-            camera_props.height = 720  # D455 depth resolution
-            camera_props.horizontal_fov = 87.0  # D455 FOV
-            camera_props.near_plane = 0.4  # D455 minimum depth distance
-            camera_props.far_plane = 20.0  # D455 maximum range
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"Static camera properties (D455 specs): {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"Static camera depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-        
-            # Create camera sensor in each environment
-            self.camera_handles = []
-            for i, env_handle in enumerate(self.env_handles):
-                cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-                self.camera_handles.append(cam_handle)
-                print(f"Created static camera sensor {i} in environment {i}")
-            
-            # Position camera to face the gate directly (gate now rotated 90°)
-            camera_pos = gymapi.Vec3(0.0, -3.0, 1.5)  # 3m in front of gate, at gate center height
-            camera_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look directly at gate center
-            
-            # Set camera transform for each environment using look_at
-            for i, (env_handle, cam_handle) in enumerate(zip(self.env_handles, self.camera_handles)):
-                # Use Isaac Gym's camera look_at functionality
-                self.gym.set_camera_location(cam_handle, env_handle, camera_pos, camera_target)
-                print(f"Set static camera {i} to look from ({camera_pos.x}, {camera_pos.y}, {camera_pos.z}) toward ({camera_target.x}, {camera_target.y}, {camera_target.z})")
-            
-            print(f"✓ Static cameras positioned to face gate directly")
-            
-            self.camera_setup_success = True
-            
-        except Exception as e:
-            print(f"❌ ERROR: Isaac Gym static camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.camera_setup_success = False
-    
-    def _load_x500_asset(self):
-        """Load X500 robot asset with D455 camera."""
-        print(f"Loading X500 robot asset from: {X500WithD455Cfg.robot_asset.file}")
-        
-        # Asset loading options for X500
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = X500WithD455Cfg.robot_asset.fix_base_link
-        asset_options.collapse_fixed_joints = X500WithD455Cfg.robot_asset.collapse_fixed_joints
-        asset_options.disable_gravity = X500WithD455Cfg.robot_asset.disable_gravity
-        asset_options.replace_cylinder_with_capsule = X500WithD455Cfg.robot_asset.replace_cylinder_with_capsule
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        asset_options.flip_visual_attachments = X500WithD455Cfg.robot_asset.flip_visual_attachments
-        asset_options.density = X500WithD455Cfg.robot_asset.density
-        asset_options.angular_damping = X500WithD455Cfg.robot_asset.angular_damping
-        asset_options.linear_damping = X500WithD455Cfg.robot_asset.linear_damping
-        asset_options.max_angular_velocity = X500WithD455Cfg.robot_asset.max_angular_velocity
-        asset_options.max_linear_velocity = X500WithD455Cfg.robot_asset.max_linear_velocity
-        asset_options.armature = X500WithD455Cfg.robot_asset.armature
-        
-        # Load X500 asset
-        x500_asset = self.gym.load_asset(
-            self.sim, 
-            X500WithD455Cfg.robot_asset.asset_folder, 
-            X500WithD455Cfg.robot_asset.file, 
-            asset_options
-        )
-        
-        if x500_asset is None:
-            raise Exception(f"Failed to load X500 robot asset: {X500WithD455Cfg.robot_asset.file}")
-        
-        print("✓ X500 robot asset loaded successfully")
-        return x500_asset
-
-    def _setup_x500_with_camera(self):
-        """Setup X500 drone with D455 camera in the same environment."""
-        print("Setting up X500 drone with D455 camera...")
-        
-        try:
-            # Load X500 asset
-            x500_asset = self._load_x500_asset()
-            
-            # Get the first environment handle
-            env_handle = self.env_handles[0]
-            
-            # Create X500 robot actor
-            x500_pose = gymapi.Transform()
-            x500_pose.p = gymapi.Vec3(-2.5, 0.0, 1.0)  # Position X500 further left of gate, 1m above ground
-            x500_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # Default orientation
-            
-            x500_handle = self.gym.create_actor(
-                env_handle,
-                x500_asset,
-                x500_pose,
-                "x500",
-                0,  # Collision group
-                1   # Collision filter
-            )
-            self.x500_handles = [x500_handle]
-            
-            # Set X500 color for better visibility
-            self.gym.set_rigid_body_color(
-                env_handle, x500_handle, 0, 
-                gymapi.MESH_VISUAL, gymapi.Vec3(0.8, 0.8, 0.2)  # Yellow X500
-            )
-            
-            # Setup D455 camera on X500
-            self._setup_x500_camera(env_handle, x500_handle)
-            
-            print("✓ X500 with D455 camera setup complete")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 with camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_handles = []
-    
-    def _setup_x500_camera(self, env_handle, x500_handle):
-        """Setup D455 camera on X500 drone."""
-        print("Setting up D455 camera on X500...")
-        
-        try:
-            # Camera properties (D455 specifications from config)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = RsD455Config.width  # 480
-            camera_props.height = RsD455Config.height  # 270
-            camera_props.horizontal_fov = RsD455Config.horizontal_fov_deg  # 87.0
-            camera_props.near_plane = RsD455Config.min_range  # 0.2
-            camera_props.far_plane = RsD455Config.max_range  # 15.0
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"X500 D455 camera properties: {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"X500 D455 depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-            
-            # Create camera sensor attached to X500
-            x500_cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-            print(f"Debug: Created X500 camera sensor with handle: {x500_cam_handle}")
-            
-            if x500_cam_handle is None:
-                raise Exception("Failed to create X500 camera sensor")
-            
-            # Attach camera to X500 base_link with forward-facing orientation
-            # Camera position relative to X500 base_link (slightly forward and up)
-            cam_pos = gymapi.Vec3(0.10, 0.0, 0.03)  # 10cm forward, 3cm up from center
-            
-            # Attach camera to X500
-            self.gym.attach_camera_to_body(
-                x500_cam_handle, env_handle, x500_handle,
-                gymapi.Transform(p=cam_pos), gymapi.FOLLOW_TRANSFORM
-            )
-            print(f"Debug: Attached camera to X500 body at position ({cam_pos.x}, {cam_pos.y}, {cam_pos.z})")
-            
-            # Store camera handle
-            self.x500_camera_handles = [x500_cam_handle]
-            
-            print("✓ D455 camera attached to X500")
-            print(f"Debug: X500 camera handles stored: {self.x500_camera_handles}")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_camera_handles = []
-    
-    def _create_viewer(self):
-        """Create viewer."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Viewer camera properties
-        cam_props = gymapi.CameraProperties()
-        viewer = self.gym.create_viewer(self.sim, cam_props)
-        
-        if viewer is None:
-            raise Exception("Failed to create viewer")
-        
-        # Set viewer camera
-        cam_pos = gymapi.Vec3(-5.0, -5.0, 3.0)
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.0)
-        self.gym.viewer_camera_look_at(viewer, None, cam_pos, cam_target)
-        
-        self.viewer = viewer
-        print("✓ Viewer created")
-    
-    def capture_all_camera_images(self):
-        """Capture depth and segmentation images from both cameras."""
-        static_depth, static_seg = None, None
-        x500_depth, x500_seg = None, None
-        
-        try:
-            # Step graphics and render all cameras once
-            self.gym.step_graphics(self.sim)
-            self.gym.render_all_camera_sensors(self.sim)
-            self.gym.start_access_image_tensors(self.sim)
-            
-            env_handle = self.env_handles[0]
-            
-            # Capture static camera images
-            if self.camera_setup_success and len(self.camera_handles) > 0:
-                try:
-                    cam_handle = self.camera_handles[0]
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    static_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    static_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    
-                except Exception as e:
-                    print(f"Error capturing static camera: {e}")
-            
-            # Capture X500 camera images
-            if len(self.x500_camera_handles) > 0:
-                try:
-                    x500_cam_handle = self.x500_camera_handles[0]
-                    print(f"Debug: Attempting to capture from X500 camera handle: {x500_cam_handle}")
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    x500_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    print(f"Debug: X500 depth image shape: {x500_depth.shape}, range: {x500_depth.min():.2f} to {x500_depth.max():.2f}")
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    x500_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    print(f"Debug: X500 seg image shape: {x500_seg.shape}, unique values: {len(np.unique(x500_seg))}")
-                    
-                except Exception as e:
-                    print(f"Error capturing X500 camera: {e}")
-                    import traceback
-                    traceback.print_exc()
-            else:
-                print("Debug: No X500 camera handles available")
-            
-            # End access to image tensors
-            self.gym.end_access_image_tensors(self.sim)
-            
-            return (static_depth, static_seg), (x500_depth, x500_seg)
-                
-        except Exception as e:
-            print(f"Error in capture_all_camera_images: {e}")
-            import traceback
-            traceback.print_exc()
-            return (None, None), (None, None)
-    
-    def create_combined_image(self, depth_img, seg_img, title="Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-        # Take absolute value to handle negative depths (coordinate system issue)
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 10 meters for D455 range)
-        depth_norm = np.clip(depth_norm, 0, 10.0)  
-        depth_norm = (depth_norm / 10.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 10.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 10.0)
-            pseudo_seg = (pseudo_seg / 10.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-    def _setup_controller(self):
-        """Setup Lee position controller for X500 hovering."""
-        print("Setting up Lee position controller for X500...")
-        
-        try:
-            # Initialize controller
-            self.controller = LeePositionController(
-                config=lee_controller_config,
-                num_envs=self.num_envs,
-                device=self.device
-            )
-            
-            # Initialize control allocator
-            self.control_allocator = ControlAllocator(
-                num_envs=self.num_envs,
-                dt=self.dt,
-                config=X500WithD455Cfg.control_allocator_config,
-                device=self.device
-            )
-            
-            # Create additional required tensors for controller
-            self.robot_euler_angles = torch.zeros((self.num_envs, 3), device=self.device)
-            self.robot_body_angvel = torch.zeros((self.num_envs, 3), device=self.device) 
-            self.robot_body_linvel = torch.zeros((self.num_envs, 3), device=self.device)
-            self.robot_vehicle_orientation = torch.zeros((self.num_envs, 4), device=self.device)
-            self.robot_vehicle_linvel = torch.zeros((self.num_envs, 3), device=self.device)
-            self.robot_inertia = torch.eye(3, device=self.device).unsqueeze(0).expand(self.num_envs, -1, -1)
-            self.robot_mass = torch.ones((self.num_envs,), device=self.device) * 1.5  # X500 mass ~1.5kg
-            self.gravity = torch.tensor([0, 0, -9.81], device=self.device).unsqueeze(0).expand(self.num_envs, -1)
-            
-            # Create global tensor dict for controller initialization
-            global_tensor_dict = {
-                "robot_position": self.robot_position,
-                "robot_orientation": self.robot_orientation,
-                "robot_euler_angles": self.robot_euler_angles,
-                "robot_linvel": self.robot_linvel,
-                "robot_angvel": self.robot_angvel,
-                "robot_body_angvel": self.robot_body_angvel,
-                "robot_body_linvel": self.robot_body_linvel,
-                "robot_vehicle_orientation": self.robot_vehicle_orientation,
-                "robot_vehicle_linvel": self.robot_vehicle_linvel,
-                "robot_inertia": self.robot_inertia,
-                "robot_mass": self.robot_mass,
-                "gravity": self.gravity,
-                "robot_force_tensor": torch.zeros((self.num_envs, 1, 3), device=self.device),
-                "robot_torque_tensor": torch.zeros((self.num_envs, 1, 3), device=self.device),
-            }
-            
-            # Initialize controller tensors
-            self.controller.init_tensors(global_tensor_dict)
-            
-            print("✓ Lee position controller initialized")
-            print(f"Hover target: {self.hover_position[0].cpu().numpy()}")
-            
-        except Exception as e:
-            print(f"❌ ERROR: Controller setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.controller = None
-            self.control_allocator = None
-
-    def _update_robot_state(self):
-        """Update robot state from Isaac Gym simulation."""
-        if len(self.x500_handles) == 0:
-            return
-            
-        try:
-            env_handle = self.env_handles[0]
-            x500_handle = self.x500_handles[0]
-            
-            # Get robot state from Isaac Gym using root state tensor
-            actor_root_state = self.gym.acquire_actor_root_state_tensor(self.sim)
-            root_states = gymtorch.wrap_tensor(actor_root_state)
-            
-            # X500 is the second actor (index 1, gate is index 0)
-            x500_state = root_states[1]  # [pos_x, pos_y, pos_z, quat_x, quat_y, quat_z, quat_w, vel_x, vel_y, vel_z, angvel_x, angvel_y, angvel_z]
-            
-            # Update position and orientation
-            self.robot_position[0] = x500_state[0:3]
-            self.robot_orientation[0] = x500_state[3:7]  # [qx, qy, qz, qw]
-            self.robot_linvel[0] = x500_state[7:10]
-            self.robot_angvel[0] = x500_state[10:13]
-            
-            # Update derived quantities
-            self.robot_vehicle_orientation[0] = self.robot_orientation[0]
-            self.robot_vehicle_linvel[0] = self.robot_linvel[0]
-            self.robot_body_angvel[0] = self.robot_angvel[0]
-            self.robot_body_linvel[0] = self.robot_linvel[0]  # Body linear velocity same as world linear velocity for simplicity
-            
-            # Convert quaternion to euler angles
-            from aerial_gym.utils.math import quat_to_euler_xyz
-            self.robot_euler_angles[0] = quat_to_euler_xyz(self.robot_orientation[0:1])[0]
-            
-        except Exception as e:
-            print(f"Error updating robot state: {e}")
-            import traceback
-            traceback.print_exc()
-
-    def _apply_control(self):
-        """Apply Lee position controller to make X500 hover."""
-        if self.controller is None or self.control_allocator is None:
-            return
-            
-        try:
-            # Update robot state
-            self._update_robot_state()
-            
-            # Create command actions for position control
-            # [x, y, z, yaw] in world frame
-            command_actions = torch.zeros((self.num_envs, 4), device=self.device)
-            command_actions[0, 0:3] = self.hover_position[0]  # Target position
-            command_actions[0, 3] = self.hover_yaw  # Target yaw
-            
-            # Compute control wrench using Lee controller
-            wrench_command = self.controller.update(command_actions)
-            
-            # Allocate control to motors
-            forces, torques = self.control_allocator.allocate_output(wrench_command, "wrench")
-            
-            # Apply forces and torques to X500 using direct tensor manipulation
-            if len(self.x500_handles) > 0:
-                try:
-                    # Get force and torque tensors
-                    force_tensor = self.gym.acquire_force_tensor(self.sim)
-                    forces = gymtorch.wrap_tensor(force_tensor)
-                    
-                    # X500 is actor index 1 (gate is 0), base link is index 0
-                    x500_actor_idx = 1
-                    base_link_idx = 0
-                    
-                    # Apply wrench to base link
-                    forces[x500_actor_idx, base_link_idx, 0:3] = wrench_command[0, 0:3]  # Force
-                    forces[x500_actor_idx, base_link_idx, 3:6] = wrench_command[0, 3:6]  # Torque
-                    
-                except Exception as e:
-                    print(f"Error applying forces via tensor: {e}")
-                    # Fallback: try direct API calls
-                    try:
-                        env_handle = self.env_handles[0]
-                        x500_handle = self.x500_handles[0]
-                        
-                        total_force = wrench_command[0, 0:3].cpu().numpy()
-                        total_torque = wrench_command[0, 3:6].cpu().numpy()
-                        
-                        # Simple force application
-                        force_vec = gymapi.Vec3(float(total_force[0]), float(total_force[1]), float(total_force[2]))
-                        
-                        # Apply upward force to counteract gravity
-                        self.gym.apply_rigid_body_force_tensors(
-                            env_handle, x500_handle, 0, force_vec, gymapi.ENV_SPACE
-                        )
-                        
-                    except Exception as e2:
-                        print(f"Error applying forces via API: {e2}")
-                        # Print debug info
-                        print(f"Debug: Wrench command: {wrench_command[0].cpu().numpy()}")
-                        print(f"Debug: Position error: {(self.hover_position[0] - self.robot_position[0]).cpu().numpy()}")
-                    
-        except Exception as e:
-            print(f"Error in control application: {e}")
-
-    def run_visualization(self, duration=60.0):
-        """Run the visualization loop with control."""
-        print(f"Starting visualization with hover control for {duration} seconds...")
-        print("Press ESC to exit early")
-        
-        start_time = time.time()
-        step_count = 0
-        
-        # OpenCV windows for camera displays
-        cv2.namedWindow("Static Camera View", cv2.WINDOW_NORMAL)
-        cv2.resizeWindow("Static Camera View", 2560, 720)  # Side-by-side 1280x720 images
-        
-        if len(self.x500_camera_handles) > 0:
-            cv2.namedWindow("X500 D455 Camera View", cv2.WINDOW_NORMAL)
-            cv2.resizeWindow("X500 D455 Camera View", 960, 540)  # D455 resolution scaled
-        
-        while True:
-            current_time = time.time()
-            elapsed_time = current_time - start_time
-            
-            # Check if duration exceeded
-            if elapsed_time > duration:
-                print(f"Visualization completed after {duration} seconds")
-                break
-            
-            # Apply control to make X500 hover
-            self._apply_control()
-            
-            # Step simulation
-            self.gym.simulate(self.sim)
-            self.gym.fetch_results(self.sim, True)
-            
-            # Capture all camera images at once
-            (static_depth, static_seg), (x500_depth, x500_seg) = self.capture_all_camera_images()
-            
-            # Display static camera images
-            if static_depth is not None and static_seg is not None:
-                # Create combined visualization for static camera
-                static_combined = self.create_combined_image(static_depth, static_seg, "Static Camera")
-                
-                if static_combined is not None:
-                    # Display static camera images
-                    cv2.imshow("Static Camera View", static_combined)
-                    
-                    # Print depth statistics periodically
-                    if step_count % 60 == 0:  # Every second at 60 FPS
-                        # Filter out -inf values for better statistics
-                        valid_depths = static_depth[static_depth != -np.inf]
-                        if len(valid_depths) > 0:
-                            # Use absolute values for meaningful distance measurements
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = static_depth.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            print(f"Step {step_count}: Static Camera - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-                            
-                            # Print X500 position for control monitoring
-                            if len(self.x500_handles) > 0:
-                                pos = self.robot_position[0].cpu().numpy()
-                                target = self.hover_position[0].cpu().numpy()
-                                error = np.linalg.norm(pos - target)
-                                print(f"          X500 Position: ({pos[0]:.2f}, {pos[1]:.2f}, {pos[2]:.2f}), "
-                                      f"Target: ({target[0]:.2f}, {target[1]:.2f}, {target[2]:.2f}), "
-                                      f"Error: {error:.3f}m")
-            
-            # Display X500 camera images
-            if x500_depth is not None and x500_seg is not None:
-                # Create combined visualization for X500 camera
-                x500_combined = self.create_combined_image(x500_depth, x500_seg, "X500 D455")
-                
-                if x500_combined is not None:
-                    # Display X500 camera images
-                    cv2.imshow("X500 D455 Camera View", x500_combined)
-                    
-                    # Print X500 camera statistics periodically
-                    if step_count % 60 == 0:
-                        valid_depths = x500_depth[x500_depth != -np.inf]
-                        if len(valid_depths) > 0:
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = x500_depth.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            print(f"          X500 D455 - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-            elif step_count % 60 == 0:
-                print(f"          X500 D455 - No camera data available")
-            
-            # Handle viewer events
-            if not self.headless:
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                if self.gym.query_viewer_has_closed(self.viewer):
-                    break
-            
-            # Check for ESC key press in OpenCV window
-            key = cv2.waitKey(1) & 0xFF
-            if key == 27:  # ESC key
-                print("ESC pressed, exiting visualization")
-                break
-            
-            step_count += 1
-        
-        cv2.destroyAllWindows()
-        print("Visualization loop completed")
-    
-    def print_environment_info(self):
-        """Print information about the environment."""
-        print("\n" + "="*50)
-        print("DUAL CAMERA ENVIRONMENT WITH HOVER CONTROL")
-        print("="*50)
-        print(f"Number of environments: {self.num_envs}")
-        print(f"Device: {self.device}")
-        print(f"Gate asset: {gate_asset_params.file}")
-        print(f"Static camera setup success: {self.camera_setup_success}")
-        print(f"Number of static cameras: {len(self.camera_handles)}")
-        print(f"Number of trees: {len(self.tree_handles)}")
-        print(f"Number of X500 robots: {len(self.x500_handles)}")
-        print(f"X500 with D455 setup: {'Success' if len(self.x500_handles) > 0 else 'Failed'}")
-        print(f"Lee position controller: {'Active' if self.controller is not None else 'Failed'}")
-        
-        if self.camera_setup_success:
-            print(f"Static camera position: (0, -3, 1.5)")
-            print(f"Static camera target: (0, 0, 1.5) - gate center")
-            print(f"Gate position: (0, 0, 0) - rotated 90°")
-        
-        if len(self.x500_handles) > 0:
-            print(f"X500 initial position: (-2.5, 0, 1.0) - further left of gate, 1m above ground")
-            print(f"X500 hover target: {self.hover_position[0].cpu().numpy()}")
-            print(f"X500 with D455 camera: Active")
-            print(f"X500 camera handles: {len(self.x500_camera_handles)} cameras")
-            print(f"X500 camera specs: D455 (270x480, 87° FOV, 0.2-15m range)")
-            if len(self.x500_camera_handles) > 0:
-                print(f"X500 camera handle IDs: {self.x500_camera_handles}")
-            else:
-                print("⚠️  WARNING: X500 created but no camera handles found!")
-        
-        print("="*50)
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        cv2.destroyAllWindows()
-        
-        if hasattr(self, 'viewer') and self.viewer is not None:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if hasattr(self, 'sim') and self.sim is not None:
-            self.gym.destroy_sim(self.sim)
-
-        print("✓ Cleanup completed")
-
-def main():
-    """Main function."""
-    try:
-        print("🚁 Starting Gate Visualization with Dual Cameras and Hover Control...")
-        
-        # Create environment
-        env = GateEnvironmentWithDualCamerasAndControl(headless=False)
-        
-        # Print environment information
-        env.print_environment_info()
-        
-        # Run visualization with control
-        env.run_visualization(duration=120.0)
-        
-    except KeyboardInterrupt:
-        print("\n⚠️ Interrupted by user")
-    except Exception as e:
-        print(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        if 'env' in locals():
-            env.cleanup()
-        print("👋 Goodbye!")
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_with_camera_background_trees_X500_position_control.py b/examples/simple_gate_visualization_with_camera_background_trees_X500_position_control.py
deleted file mode 100644
index 9935aeb..0000000
--- a/examples/simple_gate_visualization_with_camera_background_trees_X500_position_control.py
+++ /dev/null
@@ -1,1293 +0,0 @@
-"""
-Simple Gate Visualization with Static Camera, X500 Robot with D455 Camera, and Position Control
-===============================================================================================
-
-This script creates a simple visualization of a gate environment with:
-1. A static depth camera using Isaac Gym native API
-2. An X500 quadrotor robot with D455 depth camera sensor
-3. Lee position controller for X500 hovering at a target position
-4. Real-time visualization of both camera outputs side-by-side
-
-Key features:
-- Gate environment with optional background trees
-- X500 quadrotor robot with onboard D455 camera
-- Static world-mounted camera positioned 3m from gate
-- Lee position controller for stable hovering
-- Real-time depth and segmentation image display from both cameras
-- Dual camera system: Static + Agent camera
-"""
-
-import os
-import sys
-import time
-import cv2
-import numpy as np
-
-# Isaac Gym must be imported first
-from isaacgym import gymapi, gymtorch, gymutil
-
-# Aerial Gym components
-from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-from aerial_gym.config.robot_config.x500_config import X500Cfg
-from aerial_gym.config.sensor_config.camera_config.d455_depth_config import RsD455Config
-from aerial_gym.config.controller_config.lee_controller_config import control as lee_controller_config
-from aerial_gym.control.controllers.position_control import LeePositionController
-from aerial_gym.control.control_allocation import ControlAllocator
-from aerial_gym.utils.math import *
-
-import torch
-
-# Create X500 config with D455 camera enabled and fixed control allocation
-class X500WithD455Cfg(X500Cfg):
-    """X500 configuration with D455 camera sensor enabled."""
-    
-    class sensor_config(X500Cfg.sensor_config):
-        enable_camera = True
-        camera_config = RsD455Config
-    
-    class robot_asset(X500Cfg.robot_asset):
-        name = "x500_with_d455"
-
-class GateEnvironmentWithPositionControl:
-    """
-    Gate environment with static camera, X500 robot with D455 camera, and Lee position controller for hovering.
-    """
-    
-    def __init__(self, headless=False):
-        """Initialize the environment."""
-        print("🚁 Initializing Gate Environment with Position Control...")
-        
-        self.headless = headless
-        self.device = "cuda" if torch.cuda.is_available() else "cpu"
-        self.num_envs = 1
-        self.dt = 1.0 / 60.0  # 60 FPS simulation
-        
-        # Environment handles (Isaac Gym)
-        self.env_handles = []
-        self.gate_handles = []
-        self.tree_handles = []
-        self.x500_handles = []
-        
-        # Static camera handles
-        self.camera_handles = []
-        self.camera_setup_success = False
-        
-        # X500 camera handles
-        self.x500_camera_handles = []
-        
-        # Control system
-        self.lee_controller = None
-        self.control_allocator = None
-        
-        # Set hover target (just slightly above starting position for testing)
-        self.hover_target = torch.tensor([-2.5, 0.0, 1.2], device=self.device)  # 20cm above start
-        self.current_target = self.hover_target.clone()
-        
-        # Robot state tensors (for Isaac Gym rigid body states)
-        self.x500_rigid_body_states = None
-        
-        # Controller state tensors (derived from rigid body states)
-        self.robot_position = torch.zeros((self.num_envs, 3), device=self.device)
-        self.robot_orientation = torch.zeros((self.num_envs, 4), device=self.device)
-        self.robot_linvel = torch.zeros((self.num_envs, 3), device=self.device)
-        self.robot_angvel = torch.zeros((self.num_envs, 3), device=self.device)
-        
-        # Initialize gym
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        self._setup_static_camera()
-        self._setup_x500_with_camera()
-        self._setup_lee_position_controller()
-        
-        if not self.headless:
-            self._create_viewer()
-        
-        # Prepare simulation for rendering
-        self.gym.prepare_sim(self.sim)
-        
-        print("✅ Environment initialization complete!")
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Parse arguments
-        custom_parameters = [
-            {"name": "--headless", "action": "store_true", "help": "Run headless without viewer"},
-        ]
-        args = gymutil.parse_arguments(custom_parameters=custom_parameters)
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        print("✓ Isaac Gym initialized")
-    
-    def _create_sim(self):
-        """Create simulation."""
-        print("Creating simulation...")
-        
-        # Simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = self.dt
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        
-        # Physics backend
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 4
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.contact_offset = 0.01
-        sim_params.physx.rest_offset = 0.0
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)
-        if self.sim is None:
-            raise Exception("Failed to create simulation")
-        
-        print("✓ Simulation created")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
-        plane_params.distance = 0.0
-        self.gym.add_ground(self.sim, plane_params)
-    
-        print("✓ Ground plane created")
-    
-    def _load_gate_asset(self):
-        """Load gate asset."""
-        print(f"Loading gate asset from: {gate_asset_params.file}")
-        
-        # Asset loading options
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        
-        # Load asset
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise Exception(f"Failed to load gate asset: {gate_asset_params.file}")
-        
-        print("✓ Gate asset loaded successfully")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create environment with gate and optional trees."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Gate on ground level
-        
-        # Rotate gate by 90 degrees around Z-axis so trees are directly behind it
-        import math
-        gate_pose.r = gymapi.Quat(0.0, 0.0, math.sin(math.pi/4), math.cos(math.pi/4))  # 90° rotation around Z-axis
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Set gate color for better visibility
-        self.gym.set_rigid_body_color(
-            env_handle, gate_handle, 0, 
-            gymapi.MESH_VISUAL, gymapi.Vec3(0.2, 0.2, 0.8)  # blue-ish
-        )
-        
-        # Add some trees behind the gate for better visualization
-        self._add_background_trees(env_handle)
-        
-        print("✓ Environment created with gate!")
-    
-    def _add_background_trees(self, env_handle):
-        """Add some trees behind the gate for better camera visualization."""
-        print("Adding background trees...")
-        
-        try:
-            # Load a tree asset from the existing tree models
-            tree_asset_folder = f"{gate_asset_params.asset_folder}/../trees"
-            available_trees = ["tree_0.urdf", "tree_1.urdf", "tree_2.urdf", "tree_3.urdf", "tree_4.urdf"]
-            
-            # Add trees at various positions behind the gate (negative Y from camera perspective)
-            tree_positions = [
-                (-2.0, 3.0, 0.0),   # Left behind gate
-                (0.0, 4.0, 0.0),    # Directly behind gate
-                (2.0, 3.0, 0.0),    # Right behind gate
-                (-1.0, 5.0, 0.0),   # Further behind, left
-                (1.0, 5.0, 0.0),    # Further behind, right
-            ]
-            
-            for i, (x, y, z) in enumerate(tree_positions):
-                if i >= len(available_trees):
-                    break
-                    
-                tree_file = available_trees[i]
-                tree_path = f"{tree_asset_folder}/{tree_file}"
-                
-                # Check if tree file exists
-                if not os.path.exists(tree_path):
-                    print(f"Tree file not found: {tree_path}, skipping...")
-                    continue
-                
-                # Load tree asset
-                tree_asset_options = gymapi.AssetOptions()
-                tree_asset_options.fix_base_link = True
-                tree_asset_options.collapse_fixed_joints = True
-                tree_asset_options.disable_gravity = True
-                tree_asset_options.replace_cylinder_with_capsule = True
-                tree_asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-                
-                tree_asset = self.gym.load_asset(
-                    self.sim, 
-                    tree_asset_folder, 
-                    tree_file, 
-                    tree_asset_options
-                )
-                
-                if tree_asset is None:
-                    print(f"Failed to load tree asset: {tree_file}")
-                    continue
-                
-                # Create tree actor
-                tree_pose = gymapi.Transform()
-                tree_pose.p = gymapi.Vec3(x, y, z)
-                tree_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
-                
-                tree_handle = self.gym.create_actor(
-                    env_handle,
-                    tree_asset,
-                    tree_pose,
-                    f"tree_{i}",
-                    0,  # Collision group
-                    1   # Collision filter
-                )
-                
-                self.tree_handles.append(tree_handle)
-                
-                # Set tree color for variety
-                colors = [
-                    gymapi.Vec3(0.2, 0.6, 0.2),  # Green
-                    gymapi.Vec3(0.4, 0.8, 0.2),  # Light green
-                    gymapi.Vec3(0.1, 0.4, 0.1),  # Dark green
-                    gymapi.Vec3(0.3, 0.7, 0.3),  # Medium green
-                    gymapi.Vec3(0.5, 0.9, 0.1),  # Yellow-green
-                ]
-                color = colors[i % len(colors)]
-                self.gym.set_rigid_body_color(
-                    env_handle, tree_handle, 0, 
-                    gymapi.MESH_VISUAL, color
-                )
-                
-                print(f"Added tree {i+1} at position ({x}, {y}, {z})")
-                
-        except Exception as e:
-            print(f"Warning: Failed to add background trees: {e}")
-            print("Continuing without trees...") 
-    
-    def _setup_static_camera(self):
-        """Setup static camera using Isaac Gym native camera API."""
-        print("Setting up static camera using Isaac Gym native API...")
-        
-        try:
-            # Camera properties (D455 depth camera specifications)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = 1280  # D455 depth resolution
-            camera_props.height = 720  # D455 depth resolution
-            camera_props.horizontal_fov = 87.0  # D455 FOV
-            camera_props.near_plane = 0.4  # D455 minimum depth distance
-            camera_props.far_plane = 20.0  # D455 maximum range
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"Static camera properties (D455 specs): {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"Static camera depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-        
-            # Create camera sensor in each environment
-            self.camera_handles = []
-            for i, env_handle in enumerate(self.env_handles):
-                cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-                self.camera_handles.append(cam_handle)
-                print(f"Created static camera sensor {i} in environment {i}")
-            
-            # Position camera to face the gate directly (gate now rotated 90°)
-            camera_pos = gymapi.Vec3(0.0, -3.0, 1.5)  # 3m in front of gate, at gate center height
-            camera_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look directly at gate center
-            
-            # Set camera transform for each environment using look_at
-            for i, (env_handle, cam_handle) in enumerate(zip(self.env_handles, self.camera_handles)):
-                # Use Isaac Gym's camera look_at functionality
-                self.gym.set_camera_location(cam_handle, env_handle, camera_pos, camera_target)
-                print(f"Set static camera {i} to look from ({camera_pos.x}, {camera_pos.y}, {camera_pos.z}) toward ({camera_target.x}, {camera_target.y}, {camera_target.z})")
-            
-            print(f"✓ Static cameras positioned to face gate directly")
-            
-            self.camera_setup_success = True
-            
-        except Exception as e:
-            print(f"❌ ERROR: Isaac Gym static camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.camera_setup_success = False
-    
-    def _load_x500_asset(self):
-        """Load X500 robot asset with D455 camera."""
-        print(f"Loading X500 robot asset from: {X500WithD455Cfg.robot_asset.file}")
-        
-        # Asset loading options for X500
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = X500WithD455Cfg.robot_asset.fix_base_link
-        asset_options.collapse_fixed_joints = X500WithD455Cfg.robot_asset.collapse_fixed_joints
-        asset_options.disable_gravity = X500WithD455Cfg.robot_asset.disable_gravity
-        asset_options.replace_cylinder_with_capsule = X500WithD455Cfg.robot_asset.replace_cylinder_with_capsule
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        asset_options.flip_visual_attachments = X500WithD455Cfg.robot_asset.flip_visual_attachments
-        asset_options.density = X500WithD455Cfg.robot_asset.density
-        asset_options.angular_damping = X500WithD455Cfg.robot_asset.angular_damping
-        asset_options.linear_damping = X500WithD455Cfg.robot_asset.linear_damping
-        asset_options.max_angular_velocity = X500WithD455Cfg.robot_asset.max_angular_velocity
-        asset_options.max_linear_velocity = X500WithD455Cfg.robot_asset.max_linear_velocity
-        asset_options.armature = X500WithD455Cfg.robot_asset.armature
-        
-        # Load X500 asset
-        x500_asset = self.gym.load_asset(
-            self.sim, 
-            X500WithD455Cfg.robot_asset.asset_folder, 
-            X500WithD455Cfg.robot_asset.file, 
-            asset_options
-        )
-        
-        if x500_asset is None:
-            raise Exception(f"Failed to load X500 robot asset: {X500WithD455Cfg.robot_asset.file}")
-        
-        print("✓ X500 robot asset loaded successfully")
-        return x500_asset
-
-    def _setup_x500_with_camera(self):
-        """Setup X500 drone with D455 camera in the same environment."""
-        print("Setting up X500 drone with D455 camera...")
-        
-        try:
-            # Load X500 asset
-            x500_asset = self._load_x500_asset()
-            
-            # Get the first environment handle
-            env_handle = self.env_handles[0]
-            
-            # Set X500 initial position and orientation
-            x500_start_pos = gymapi.Vec3(-2.5, 0.0, 1.0)  # Start at hover target position
-            x500_start_rot = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # No rotation
-            x500_pose = gymapi.Transform(x500_start_pos, x500_start_rot)
-            
-            # Create X500 robot actor
-            x500_handle = self.gym.create_actor(
-                env_handle, x500_asset, x500_pose, "x500", 0, 0
-            )
-            
-            # Debug: Verify the actual spawn position
-            actual_pose = self.gym.get_actor_rigid_body_states(env_handle, x500_handle, gymapi.STATE_POS)
-            print(f"Debug: X500 actual spawn position: {actual_pose['pose']['p']}")
-            print(f"Debug: X500 intended spawn position: (-2.5, 0.0, 1.0)")
-            
-            # Enable actor DOF for control
-            self.gym.enable_actor_dof_force_sensors(env_handle, x500_handle)
-            
-            self.x500_handles = [x500_handle]
-            
-            # Set X500 color for better visibility
-            self.gym.set_rigid_body_color(
-                env_handle, x500_handle, 0, 
-                gymapi.MESH_VISUAL, gymapi.Vec3(0.8, 0.8, 0.2)  # Yellow X500
-            )
-            
-            # Setup D455 camera on X500
-            self._setup_x500_camera(env_handle, x500_handle)
-            
-            # Get rigid body state tensor for X500
-            self._setup_x500_state_tensors()
-            
-            print("✓ X500 with D455 camera setup complete")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 with camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_handles = []
-    
-    def _setup_x500_camera(self, env_handle, x500_handle):
-        """Setup D455 camera on X500 drone."""
-        print("Setting up D455 camera on X500...")
-        
-        try:
-            # Camera properties (D455 specifications from config)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = RsD455Config.width  # 480
-            camera_props.height = RsD455Config.height  # 270
-            camera_props.horizontal_fov = RsD455Config.horizontal_fov_deg  # 87.0
-            camera_props.near_plane = RsD455Config.min_range  # 0.2
-            camera_props.far_plane = RsD455Config.max_range  # 15.0
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"X500 D455 camera properties: {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"X500 D455 depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-            
-            # Create camera sensor attached to X500
-            x500_cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-            print(f"Debug: Created X500 camera sensor with handle: {x500_cam_handle}")
-            
-            if x500_cam_handle is None:
-                raise Exception("Failed to create X500 camera sensor")
-            
-            # Attach camera to X500 base_link with forward-facing orientation
-            # Camera position relative to X500 base_link (slightly forward and up)
-            cam_pos = gymapi.Vec3(0.10, 0.0, 0.03)  # 10cm forward, 3cm up from center
-            
-            # Attach camera to X500
-            self.gym.attach_camera_to_body(
-                x500_cam_handle, env_handle, x500_handle,
-                gymapi.Transform(p=cam_pos), gymapi.FOLLOW_TRANSFORM
-            )
-            print(f"Debug: Attached camera to X500 body at position ({cam_pos.x}, {cam_pos.y}, {cam_pos.z})")
-            
-            # Store camera handle
-            self.x500_camera_handles = [x500_cam_handle]
-            
-            print("✓ D455 camera attached to X500")
-            print(f"Debug: X500 camera handles stored: {self.x500_camera_handles}")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_camera_handles = []
-    
-    def _setup_x500_state_tensors(self):
-        """Set up state tensors for X500 robot control."""
-        try:
-            print("Debug: Setting up X500 state tensors...")
-            
-            # Initialize state tensors on CPU (Isaac Gym physics runs on CPU)
-            device = "cpu"  # Force CPU to match Isaac Gym physics
-            
-            # Robot state tensors (1 environment)
-            self.robot_position = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            self.robot_orientation = torch.zeros((1, 4), device=device, dtype=torch.float32)
-            self.robot_linvel = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            self.robot_angvel = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            self.robot_euler_angles = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            
-            # Body frame velocities
-            self.robot_body_linvel = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            self.robot_body_angvel = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            
-            # Vehicle frame states
-            self.robot_vehicle_orientation = torch.zeros((1, 4), device=device, dtype=torch.float32)
-            self.robot_vehicle_linvel = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            
-            # Get Isaac Gym actor root state tensor
-            actor_root_state = self.gym.acquire_actor_root_state_tensor(self.sim)
-            self.actor_root_states = gymtorch.wrap_tensor(actor_root_state)
-            
-            # CRITICAL: Refresh the tensor to get actual actor positions after simulation setup
-            self.gym.refresh_actor_root_state_tensor(self.sim)
-            
-            print(f"Debug: Total actors in root state tensor: {len(self.actor_root_states)}")
-            
-            # Debug: Print all actor positions to identify X500
-            for i in range(len(self.actor_root_states)):
-                pos = self.actor_root_states[i][:3]
-                print(f"Debug: Actor {i}: pos=[{pos[0]:.2f}, {pos[1]:.2f}, {pos[2]:.2f}]")
-            
-            # Find X500 actor by looking for the one closest to expected spawn position
-            expected_pos = torch.tensor([-2.5, 0.0, 1.0], device="cpu")
-            self.x500_actor_idx = None
-            min_distance = float('inf')
-            
-            for i in range(len(self.actor_root_states)):
-                actor_pos = self.actor_root_states[i][:3].cpu()
-                distance = torch.norm(actor_pos - expected_pos).item()
-                if distance < min_distance:
-                    min_distance = distance
-                    self.x500_actor_idx = i
-            
-            if self.x500_actor_idx is not None and min_distance < 1.0:  # Within 1m tolerance
-                x500_pos = self.actor_root_states[self.x500_actor_idx][:3].cpu()
-                print(f"✓ X500 actor found at index {self.x500_actor_idx}, position: {x500_pos}")
-                self._update_robot_state()  # Initial state update
-            else:
-                print(f"❌ Could not find X500 actor (closest distance: {min_distance:.2f}m)")
-                # Fallback: assume it's the last actor (often the case)
-                self.x500_actor_idx = len(self.actor_root_states) - 1
-                print(f"Using fallback X500 actor index: {self.x500_actor_idx}")
-                self._update_robot_state()
-                
-        except Exception as e:
-            print(f"❌ ERROR: X500 state tensor setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-    
-    def _update_robot_state(self):
-        """Update robot state tensors from simulation."""
-        try:
-            # Refresh all relevant tensors from simulation
-            self.gym.refresh_actor_root_state_tensor(self.sim)
-            self.gym.refresh_rigid_body_state_tensor(self.sim)
-            
-            # Update robot state from root state tensor
-            # Root state tensor format: [pos_x, pos_y, pos_z, quat_x, quat_y, quat_z, quat_w, vel_x, vel_y, vel_z, angvel_x, angvel_y, angvel_z]
-            x500_state = self.actor_root_states[self.x500_actor_idx]
-            
-            # Update position, orientation, and velocities
-            self.robot_position[0, :] = x500_state[0:3]
-            self.robot_orientation[0, :] = x500_state[3:7]  # quaternion
-            self.robot_linvel[0, :] = x500_state[7:10]
-            self.robot_angvel[0, :] = x500_state[10:13]
-            
-            # Convert quaternion to euler angles for controller
-            from aerial_gym.utils.math import get_euler_xyz_tensor
-            self.robot_euler_angles[0] = get_euler_xyz_tensor(self.robot_orientation[0].unsqueeze(0))[0]
-            
-            # Convert global velocities to body frame (simplified approach)
-            self.robot_body_linvel[0] = self.robot_linvel[0]
-            self.robot_body_angvel[0] = self.robot_angvel[0]
-            
-            # Update vehicle orientation and velocity for controller
-            self.robot_vehicle_orientation[0] = self.robot_orientation[0]
-            self.robot_vehicle_linvel[0] = self.robot_linvel[0]
-                
-        except Exception as e:
-            print(f"Error updating robot state: {e}")
-            import traceback
-            traceback.print_exc()
-    
-    def _step_physics_and_update_state(self):
-        """Step physics simulation and update robot state - following DCE RL pattern."""
-        try:
-            # Step the physics simulation
-            self.gym.simulate(self.sim)
-            self.gym.fetch_results(self.sim, True)
-            
-            # Update robot state from simulation (this is the key missing piece!)
-            self._update_robot_state()
-            
-        except Exception as e:
-            print(f"Error in physics step: {e}")
-            import traceback
-            traceback.print_exc()
-
-    def _setup_lee_position_controller(self):
-        """Set up Lee position controller for X500."""
-        print("Setting up Lee position controller for X500...")
-        
-        try:
-            # Import Lee position controller from the correct module
-            from aerial_gym.control.controllers.position_control import LeePositionController
-            from aerial_gym.control.control_allocation import ControlAllocator
-            from aerial_gym.config.controller_config.lee_controller_config import control as lee_controller_config
-            
-            # Initialize controller with proper device
-            device = "cpu"  # Match Isaac Gym physics device
-            dt = 1.0/60.0  # 60 Hz simulation
-            
-            # Create controller config
-            config = lee_controller_config()
-            
-            # Override controller gains for better waypoint tracking
-            config.K_pos_tensor_max = [5.0, 5.0, 4.0]  # Increased position gains (was [3.0, 3.0, 2.0])
-            config.K_vel_tensor_max = [4.0, 4.0, 4.0]  # Increased velocity gains (was [3.0, 3.0, 3.0])
-            
-            # Get X500 motor indices for application mask
-            env_handle = self.env_handles[0]
-            x500_handle = self.x500_handles[0]
-            
-            # X500 motor names in order
-            motor_names = ["front_right_prop", "back_left_prop", "front_left_prop", "back_right_prop"]
-            self.application_mask = []
-            
-            for motor_name in motor_names:
-                try:
-                    motor_idx = self.gym.find_actor_rigid_body_index(
-                        env_handle, x500_handle, motor_name, gymapi.DOMAIN_ACTOR
-                    )
-                    self.application_mask.append(motor_idx)
-                except:
-                    print(f"Warning: Could not find motor '{motor_name}', using fallback index")
-                    self.application_mask.append(len(self.application_mask) + 1)
-            
-            print(f"X500 motor application mask: {self.application_mask}")
-            
-            # Create control allocator config object (similar to X500Cfg.control_allocator_config)
-            class ControlAllocatorConfig:
-                def __init__(self):
-                    self.num_motors = 4
-                    self.force_application_level = "body_link"  # Apply forces at body level (more stable)
-                    self.motor_directions = [1, 1, -1, -1]  # X500 motor directions
-                    
-                    # X500 allocation matrix (improved for better rank)
-                    # Motor layout: 0=front_right, 1=back_left, 2=front_left, 3=back_right
-                    arm_length = 0.175  # X500 arm length in meters
-                    self.allocation_matrix = [
-                        [0.0, 0.0, 0.0, 0.0],           # Fx (no lateral thrust)
-                        [0.0, 0.0, 0.0, 0.0],           # Fy (no lateral thrust)  
-                        [1.0, 1.0, 1.0, 1.0],           # Fz (all motors provide upward thrust)
-                        [arm_length, -arm_length, -arm_length, arm_length],   # Mx (roll moment)
-                        [arm_length, arm_length, -arm_length, -arm_length],   # My (pitch moment)
-                        [-0.02, 0.02, -0.02, 0.02]      # Mz (yaw moment from prop direction)
-                    ]
-                    
-                    # Motor model config
-                    class MotorModelConfig:
-                        def __init__(self):
-                            self.use_rps = True
-                            self.motor_thrust_constant_min = 8.54858e-6
-                            self.motor_thrust_constant_max = 8.54858e-6
-                            self.motor_time_constant_increasing_min = 0.0125
-                            self.motor_time_constant_increasing_max = 0.0125
-                            self.motor_time_constant_decreasing_min = 0.025
-                            self.motor_time_constant_decreasing_max = 0.025
-                            self.max_thrust = 20.0
-                            self.min_thrust = 0.0
-                            self.max_thrust_rate = 100000.0
-                            self.thrust_to_torque_ratio = 0.025
-                            self.use_discrete_approximation = False
-                    
-                    self.motor_model_config = MotorModelConfig()
-            
-            # Create control allocator config and set application mask
-            control_alloc_config = ControlAllocatorConfig()
-            control_alloc_config.application_mask = self.application_mask
-            
-            # Initialize Lee position controller
-            self.lee_controller = LeePositionController(config, 1, device)  # config, num_envs, device
-            
-            # Set up target position tensor
-            self.target_position = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            
-            # Initialize control allocator for X500 with proper config
-            self.control_allocator = ControlAllocator(
-                num_envs=1,
-                dt=dt,
-                config=control_alloc_config,
-                device=device
-            )
-            
-            # Initialize robot mass and inertia for controller
-            self.robot_mass = torch.tensor([1.5], device=device, dtype=torch.float32)  # X500 mass ~1.5kg
-            
-            # X500 inertia matrix (approximate values for quadrotor)
-            self.robot_inertia = torch.tensor([
-                [0.029, 0.0, 0.0],
-                [0.0, 0.029, 0.0], 
-                [0.0, 0.0, 0.055]
-            ], device=device, dtype=torch.float32).unsqueeze(0)  # Add batch dimension
-            
-            # Initialize controller tensors with global tensor dict
-            global_tensor_dict = {
-                "robot_position": self.robot_position,
-                "robot_orientation": self.robot_orientation,
-                "robot_euler_angles": self.robot_euler_angles,
-                "robot_linvel": self.robot_linvel,
-                "robot_angvel": self.robot_angvel,
-                "robot_body_angvel": self.robot_body_angvel,
-                "robot_body_linvel": self.robot_body_linvel,
-                "robot_vehicle_orientation": self.robot_vehicle_orientation,
-                "robot_vehicle_linvel": self.robot_vehicle_linvel,
-                "robot_inertia": self.robot_inertia,
-                "robot_mass": self.robot_mass,
-                "gravity": torch.tensor([0.0, 0.0, -9.81], device=device).expand(1, 3),
-            }
-            
-            self.lee_controller.init_tensors(global_tensor_dict)
-            
-            print("✓ Lee position controller initialized")
-            print(f"Controller gains - Position: {config.K_pos_tensor_max}")
-            print(f"Controller gains - Velocity: {config.K_vel_tensor_max}")
-            print(f"Current hover target: {self.target_position[0].cpu().numpy()}")
-            
-        except Exception as e:
-            print(f"❌ Failed to setup Lee position controller: {e}")
-            import traceback
-            traceback.print_exc()
-            raise
-
-    def _create_viewer(self):
-        """Create viewer."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Viewer camera properties
-        cam_props = gymapi.CameraProperties()
-        viewer = self.gym.create_viewer(self.sim, cam_props)
-        
-        if viewer is None:
-            raise Exception("Failed to create viewer")
-        
-        # Set viewer camera
-        cam_pos = gymapi.Vec3(-5.0, -5.0, 3.0)
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.0)
-        self.gym.viewer_camera_look_at(viewer, None, cam_pos, cam_target)
-        
-        self.viewer = viewer
-        print("✓ Viewer created")
-    
-    def _apply_control(self):
-        """Apply Lee position controller to make X500 follow waypoints."""
-        # This method is now integrated into the main control loop in run_navigation
-        # Remove this method to avoid confusion
-        pass
-
-    def _render_frame(self):
-        """Render the current frame."""
-        if not self.headless:
-            # Step graphics
-            self.gym.step_graphics(self.sim)
-            self.gym.draw_viewer(self.viewer, self.sim, True)
-            
-            # Handle viewer events
-            if self.gym.query_viewer_has_closed(self.viewer):
-                return False
-        return True
-
-    def capture_all_camera_images(self):
-        """Capture depth and segmentation images from both cameras."""
-        static_depth, static_seg = None, None
-        x500_depth, x500_seg = None, None
-        
-        try:
-            # Step graphics and render all cameras once
-            self.gym.step_graphics(self.sim)
-            self.gym.render_all_camera_sensors(self.sim)
-            self.gym.start_access_image_tensors(self.sim)
-            
-            env_handle = self.env_handles[0]
-            
-            # Capture static camera images
-            if self.camera_setup_success and len(self.camera_handles) > 0:
-                try:
-                    cam_handle = self.camera_handles[0]
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    static_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    static_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    
-                except Exception as e:
-                    print(f"Error capturing static camera: {e}")
-            
-            # Capture X500 camera images
-            if len(self.x500_camera_handles) > 0:
-                try:
-                    x500_cam_handle = self.x500_camera_handles[0]
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    x500_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    x500_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    
-                except Exception as e:
-                    print(f"Error capturing X500 camera: {e}")
-            
-            # End access to image tensors
-            self.gym.end_access_image_tensors(self.sim)
-            
-            return (static_depth, static_seg), (x500_depth, x500_seg)
-                
-        except Exception as e:
-            print(f"Error in capture_all_camera_images: {e}")
-            import traceback
-            traceback.print_exc()
-            return (None, None), (None, None) 
-
-    def create_combined_image(self, depth_img, seg_img, title="Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-        # Take absolute value to handle negative depths (coordinate system issue)
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 10 meters for D455 range)
-        depth_norm = np.clip(depth_norm, 0, 10.0)  
-        depth_norm = (depth_norm / 10.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 10.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 10.0)
-            pseudo_seg = (pseudo_seg / 10.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-    def run_navigation(self, duration_seconds=180.0):
-        """Main navigation loop with waypoint navigation."""
-        print(f"Starting navigation and visualization for {duration_seconds} seconds...")
-        print("Press ESC to exit early")
-        
-        # Initialize step counter for debug output
-        self.debug_step_count = 0
-        
-        # Define waypoints for navigation through the gate
-        waypoints = [
-            torch.tensor([-2.5, 0.0, 0.8], device="cpu"),  # Start position (closer to actual hover height)
-            torch.tensor([-1.0, 0.0, 1.2], device="cpu"),  # Approach gate
-            torch.tensor([0.0, 0.0, 1.2], device="cpu"),   # Gate center
-            torch.tensor([1.0, 0.0, 1.2], device="cpu"),   # Exit gate
-            torch.tensor([2.5, 0.0, 0.8], device="cpu"),   # End position
-            torch.tensor([2.5, 2.0, 1.5], device="cpu"),   # Move to side and up
-            torch.tensor([0.0, 2.0, 1.8], device="cpu"),   # Above gate from side
-            torch.tensor([-2.5, 0.0, 0.8], device="cpu"),  # Return to start
-        ]
-        
-        # Waypoint navigation parameters
-        current_waypoint_idx = 0
-        waypoint_reach_threshold = 0.5  # 50cm threshold to consider waypoint reached (increased from 30cm)
-        waypoint_hold_time = 2.0  # Hold at each waypoint for 2 seconds (reduced from 3)
-        waypoint_reached_time = None
-        
-        print(f"🎯 Waypoint Navigation: X500 will navigate through {len(waypoints)} waypoints")
-        print(f"   Waypoints: Start → Approach Gate → Through Gate → Exit → Side → Above → Return")
-        
-        start_time = time.time()
-        
-        while not self.gym.query_viewer_has_closed(self.viewer):
-            current_time = time.time()
-            if current_time - start_time > duration_seconds:
-                break
-                
-            # Get current robot position
-            current_pos = self.robot_position[0].clone()
-            
-            # Get current target waypoint
-            current_target = waypoints[current_waypoint_idx]
-            
-            # Store current target for display function
-            self.current_navigation_target = current_target
-            self.current_waypoint_idx = current_waypoint_idx
-            
-            # Check if current waypoint is reached
-            distance_to_waypoint = torch.norm(current_pos - current_target).item()
-            
-            # Safety mechanism: if drone is very far from current waypoint, find closest waypoint
-            if distance_to_waypoint > 2.0:  # If more than 2 meters away
-                closest_waypoint_idx = 0
-                min_distance = float('inf')
-                for i, waypoint in enumerate(waypoints):
-                    dist = torch.norm(current_pos - waypoint).item()
-                    if dist < min_distance:
-                        min_distance = dist
-                        closest_waypoint_idx = i
-                
-                if closest_waypoint_idx != current_waypoint_idx:
-                    print(f"🔄 Drone too far from waypoint {current_waypoint_idx + 1}, switching to closest waypoint {closest_waypoint_idx + 1}")
-                    current_waypoint_idx = closest_waypoint_idx
-                    current_target = waypoints[current_waypoint_idx]
-                    waypoint_reached_time = None
-                    distance_to_waypoint = min_distance
-            
-            if distance_to_waypoint <= waypoint_reach_threshold:
-                if waypoint_reached_time is None:
-                    waypoint_reached_time = current_time
-                    print(f"🎯 Reached waypoint {current_waypoint_idx + 1}/{len(waypoints)}: [{current_target[0]:.2f}, {current_target[1]:.2f}, {current_target[2]:.2f}]")
-                
-                # Check if we've held at this waypoint long enough
-                if current_time - waypoint_reached_time >= waypoint_hold_time:
-                    # Move to next waypoint
-                    current_waypoint_idx = (current_waypoint_idx + 1) % len(waypoints)
-                    waypoint_reached_time = None
-                    next_target = waypoints[current_waypoint_idx]
-                    print(f"🚁 Moving to waypoint {current_waypoint_idx + 1}/{len(waypoints)}: [{next_target[0]:.2f}, {next_target[1]:.2f}, {next_target[2]:.2f}]")
-            else:
-                waypoint_reached_time = None  # Reset if we move away from waypoint
-            
-            # Debug control output every 300 steps (5 seconds at 60 FPS)
-            if self.debug_step_count % 300 == 0:
-                pos_np = current_pos.cpu().numpy()
-                target_np = current_target.cpu().numpy()
-                error = current_target - current_pos
-                distance = torch.norm(error).item()
-                print(f"Debug Control - Pos: [{pos_np[0]:.2f}, {pos_np[1]:.2f}, {pos_np[2]:.2f}], Target: [{target_np[0]:.2f}, {target_np[1]:.2f}, {target_np[2]:.2f}]")
-                print(f"Debug Control - Error: [{error[0]:.2f}, {error[1]:.2f}, {error[2]:.2f}], Distance: {distance:.2f}m, Waypoint: {current_waypoint_idx + 1}/{len(waypoints)}")
-            
-            # Run Lee position controller
-            try:
-                # Set target position to current waypoint
-                self.target_position[0] = current_target
-                
-                # Create command actions for Lee controller: [x, y, z, yaw]
-                command_actions = torch.zeros((1, 4), device="cpu")
-                command_actions[0, 0:3] = current_target  # Target position
-                command_actions[0, 3] = 0.0  # Target yaw (face forward)
-                
-                # Ensure Lee controller exists
-                if self.lee_controller is None:
-                    print("❌ Lee controller not initialized, skipping control step")
-                    continue
-                
-                # Compute control wrench using Lee position controller
-                wrench = self.lee_controller.update(command_actions)
-                
-                # Validate wrench
-                if wrench is None or torch.isnan(wrench).any() or torch.isinf(wrench).any():
-                    print(f"❌ Invalid wrench generated: {wrench}")
-                    continue
-                
-                # Debug wrench every 300 steps (5 seconds at 60 FPS)
-                if self.debug_step_count % 300 == 0:
-                    wrench_np = wrench[0].cpu().numpy()
-                    print(f"Debug Control - Wrench: [{wrench_np[0]:.2f}, {wrench_np[1]:.2f}, {wrench_np[2]:.2f}, {wrench_np[3]:.2f}, {wrench_np[4]:.2f}, {wrench_np[5]:.2f}]")
-                
-                # Allocate motor forces using control allocator
-                try:
-                    # Use the correct method name and parameters for ControlAllocator
-                    # Since we have a wrench from Lee controller, use "wrench" mode to convert wrench -> motor thrusts -> motor forces
-                    motor_forces, motor_torques = self.control_allocator.allocate_output(wrench, "wrench")
-                    
-                    # Validate motor forces
-                    if motor_forces is None or torch.isnan(motor_forces).any() or torch.isinf(motor_forces).any():
-                        print(f"❌ Invalid motor forces generated: {motor_forces}")
-                        continue
-                    
-                    # Debug motor forces every 300 steps (5 seconds at 60 FPS)
-                    if self.debug_step_count % 300 == 0:
-                        motor_forces_np = motor_forces[0].cpu().numpy()
-                        motor_torques_np = motor_torques[0].cpu().numpy()
-                        print(f"Debug Motor Forces (N): {motor_forces_np}")
-                        print(f"Debug Motor Torques (Nm): {motor_torques_np}")
-                        
-                        # Check if forces are reasonable magnitude
-                        total_thrust = torch.sum(motor_forces[0, :, 2]).item()  # Sum Z forces
-                        print(f"Debug Total Thrust: {total_thrust:.2f}N (need ~{1.5*9.81:.1f}N to hover)")
-                        
-                    # Apply motor forces to X500
-                    self._apply_motor_forces(motor_forces)
-                    
-                except Exception as e:
-                    print(f"Control allocation error: {e}")
-                    import traceback
-                    traceback.print_exc()
-                
-            except Exception as e:
-                print(f"Lee controller error: {e}")
-                import traceback
-                traceback.print_exc()
-            
-            # Step physics and update state (this is the crucial missing piece!)
-            self._step_physics_and_update_state()
-            
-            # Update cameras and visualization
-            self._update_cameras()
-            self._render_frame()
-            
-            self.debug_step_count += 1
-        
-        print(f"\n✅ Navigation completed after {current_time - start_time:.1f} seconds")
-    
-    def print_environment_info(self):
-        """Print information about the environment."""
-        print("\n" + "="*60)
-        print("DUAL CAMERA POSITION CONTROL ENVIRONMENT INFORMATION")
-        print("="*60)
-        print(f"Number of environments: {self.num_envs}")
-        print(f"Device: {self.device}")
-        print(f"Gate asset: {gate_asset_params.file}")
-        print(f"Static camera setup success: {self.camera_setup_success}")
-        print(f"Number of static cameras: {len(self.camera_handles)}")
-        print(f"Number of trees: {len(self.tree_handles)}")
-        print(f"Number of X500 robots: {len(self.x500_handles)}")
-        print(f"X500 with D455 setup: {'Success' if len(self.x500_handles) > 0 else 'Failed'}")
-        print(f"Lee Position Controller: {'Active' if self.lee_controller is not None else 'Failed'}")  
-        
-        if hasattr(self, 'x500_actor_idx') and self.x500_actor_idx is not None:
-            print(f"X500 actor index: {self.x500_actor_idx}")
-            current_pos = self.robot_position[0].cpu().numpy()
-            print(f"X500 current position: [{current_pos[0]:.2f}, {current_pos[1]:.2f}, {current_pos[2]:.2f}]")
-        
-        if self.camera_setup_success:
-            print(f"Static camera position: (0, -3, 1.5)")
-            print(f"Static camera target: (0, 0, 1.5) - gate center")
-            print(f"Gate position: (0, 0, 0) - rotated 90°")
-        
-        if len(self.x500_handles) > 0:
-            print(f"X500 start position: (-2.5, 0, 1.0)")
-            print(f"X500 with D455 camera: Active")
-            print(f"X500 camera handles: {len(self.x500_camera_handles)} cameras")
-            print(f"X500 camera specs: D455 (270x480, 87° FOV, 0.2-15m range)")
-            if len(self.x500_camera_handles) > 0:
-                print(f"X500 camera handle IDs: {self.x500_camera_handles}")
-            else:
-                print("⚠️  WARNING: X500 created but no camera handles found!")
-        
-        if hasattr(self, 'lee_controller') and self.lee_controller is not None:
-            print(f"Navigation mode: Waypoint Navigation")
-            if hasattr(self, 'current_navigation_target'):
-                target_pos = self.current_navigation_target.cpu().numpy()
-                waypoint_num = getattr(self, 'current_waypoint_idx', 0) + 1
-                print(f"Current target: [{target_pos[0]:6.2f}, {target_pos[1]:6.2f}, {target_pos[2]:6.2f}] (Waypoint {waypoint_num})")
-            else:
-                print(f"Navigation targets: Start → Gate → Exit → Side → Above → Return")
-        
-        print("="*60)
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        cv2.destroyAllWindows()
-        
-        if hasattr(self, 'viewer') and self.viewer is not None:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if hasattr(self, 'sim') and self.sim is not None:
-            self.gym.destroy_sim(self.sim)
-
-        print("✓ Cleanup completed")
-
-    def _update_cameras(self):
-        """Update camera images and capture data."""
-        # Capture all camera images at once
-        (static_depth, static_seg), (x500_depth, x500_seg) = self.capture_all_camera_images()
-        
-        # Store for display
-        self.static_depth = static_depth
-        self.static_seg = static_seg  
-        self.x500_depth = x500_depth
-        self.x500_seg = x500_seg
-        
-    def _update_display(self):
-        """Update display and handle viewer events."""
-        # Display static camera images
-        if hasattr(self, 'static_depth') and self.static_depth is not None and self.static_seg is not None:
-            # Create combined visualization for static camera
-            static_combined = self.create_combined_image(self.static_depth, self.static_seg, "Static Camera")
-            
-            if static_combined is not None:
-                # Display static camera images
-                cv2.imshow("Static Camera View", static_combined)
-                
-                # Print depth statistics periodically
-                if hasattr(self, 'debug_step_count') and self.debug_step_count % 300 == 0:  # Every 5 seconds at 60 FPS
-                    # Filter out -inf values for better statistics
-                    valid_depths = self.static_depth[self.static_depth != -np.inf]
-                    if len(valid_depths) > 0:
-                        # Use absolute values for meaningful distance measurements
-                        abs_valid_depths = np.abs(valid_depths)
-                        min_depth = np.min(abs_valid_depths)
-                        max_depth = np.max(abs_valid_depths)
-                        mean_depth = np.mean(abs_valid_depths)
-                        total_pixels = self.static_depth.size
-                        valid_ratio = len(valid_depths) / total_pixels * 100
-                        
-                        # Print robot position and target
-                        current_pos = self.robot_position[0].cpu().numpy()
-                        if hasattr(self, 'current_navigation_target'):
-                            target_pos = self.current_navigation_target.cpu().numpy()
-                            distance_to_target = torch.norm(self.robot_position[0] - self.current_navigation_target).item()
-                            target_desc = f"Waypoint {getattr(self, 'current_waypoint_idx', 0) + 1}"
-                        else:
-                            target_pos = current_pos  # Fallback
-                            distance_to_target = 0.0
-                            target_desc = "Unknown"
-                        
-                        print(f"Step {self.debug_step_count}: Static Camera - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                              f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-                        print(f"          X500 Pos: [{current_pos[0]:.2f}, {current_pos[1]:.2f}, {current_pos[2]:.2f}], "
-                              f"Target: [{target_pos[0]:.2f}, {target_pos[1]:.2f}, {target_pos[2]:.2f}], "
-                              f"Dist: {distance_to_target:.2f}m, {target_desc}")
-        
-        # Display X500 camera images
-        if hasattr(self, 'x500_depth') and self.x500_depth is not None and self.x500_seg is not None:
-            # Create combined visualization for X500 camera
-            x500_combined = self.create_combined_image(self.x500_depth, self.x500_seg, "X500 D455")
-            
-            if x500_combined is not None:
-                # Display X500 camera images
-                cv2.imshow("X500 D455 Camera View", x500_combined)
-                
-                # Print X500 camera statistics periodically
-                if hasattr(self, 'debug_step_count') and self.debug_step_count % 300 == 0:
-                    valid_depths = self.x500_depth[self.x500_depth != -np.inf]
-                    if len(valid_depths) > 0:
-                        abs_valid_depths = np.abs(valid_depths)
-                        min_depth = np.min(abs_valid_depths)
-                        max_depth = np.max(abs_valid_depths)
-                        mean_depth = np.mean(abs_valid_depths)
-                        total_pixels = self.x500_depth.size
-                        valid_ratio = len(valid_depths) / total_pixels * 100
-                        print(f"          X500 D455 - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                              f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-        elif hasattr(self, 'debug_step_count') and self.debug_step_count % 300 == 0:
-            print(f"          X500 D455 - No camera data available")
-        
-        # Handle viewer events
-        if not self.headless:
-            self.gym.step_graphics(self.sim)
-            self.gym.draw_viewer(self.viewer, self.sim, True)
-            if self.gym.query_viewer_has_closed(self.viewer):
-                return False  # Signal to exit
-        
-        # Check for ESC key press in OpenCV window
-        key = cv2.waitKey(1) & 0xFF
-        if key == 27:  # ESC key
-            print("ESC pressed, exiting navigation and visualization")
-            return False  # Signal to exit
-            
-        return True  # Continue running
-
-    def _apply_motor_forces(self, motor_forces):
-        """Apply computed motor forces to X500 using Isaac Gym DOF force application."""
-        try:
-            # Use DOF force application instead of rigid body forces
-            env_handle = self.env_handles[0]
-            x500_handle = self.x500_handles[0]
-            
-            # Get DOF forces tensor
-            dof_forces = torch.zeros(4, device="cpu", dtype=torch.float32)
-            
-            # Convert motor forces to DOF forces (take Z component for thrust)
-            for i in range(min(4, motor_forces.shape[1])):
-                # Extract thrust force (Z component) from motor force
-                thrust_force = motor_forces[0, i, 2].cpu()  # Z component
-                dof_forces[i] = thrust_force
-            
-            # Apply DOF forces directly to the X500 actor
-            self.gym.apply_actor_dof_efforts(env_handle, x500_handle, dof_forces.numpy())
-            
-            # Debug output every 300 steps
-            if hasattr(self, 'debug_step_count') and self.debug_step_count % 300 == 0:
-                print(f"Debug DOF Forces applied: {dof_forces.numpy()}")
-                
-        except Exception as e:
-            print(f"Error applying motor forces via DOF: {e}")
-            # Fallback to direct force application on center of mass
-            try:
-                env_handle = self.env_handles[0]
-                x500_handle = self.x500_handles[0]
-                
-                # Sum all motor forces to get net force
-                net_force = torch.sum(motor_forces[0], dim=0).cpu()  # Sum over all motors
-                
-                # Apply net force to the base link (center of mass)
-                force_vec = gymapi.Vec3(net_force[0].item(), net_force[1].item(), net_force[2].item())
-                
-                # Apply force at center of mass
-                self.gym.apply_rigid_body_force_at_pos(
-                    env_handle, x500_handle, 0,  # Base link index
-                    force_vec, gymapi.Vec3(0, 0, 0),  # Force at center of mass
-                    gymapi.ENV_SPACE
-                )
-                
-                if hasattr(self, 'debug_step_count') and self.debug_step_count % 300 == 0:
-                    print(f"Debug Fallback Force applied: [{net_force[0]:.2f}, {net_force[1]:.2f}, {net_force[2]:.2f}]")
-                    
-            except Exception as e2:
-                print(f"Error in fallback force application: {e2}")
-                import traceback
-                traceback.print_exc()
-    
-
-
-def main():
-    """Main function."""
-    try:
-        print("🚁 Starting Gate Navigation with Dual Cameras and Position Control...")
-        
-        # Create environment
-        env = GateEnvironmentWithPositionControl(headless=False)
-        
-        # Print environment information
-        env.print_environment_info()
-        
-        # Run navigation and visualization
-        env.run_navigation(duration_seconds=180.0)  # 3 minutes
-        
-    except KeyboardInterrupt:
-        print("\n⚠️ Interrupted by user")
-    except Exception as e:
-        print(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        if 'env' in locals():
-            env.cleanup()
-        print("👋 Goodbye!")
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_with_camera_background_trees_X500_position_control_tilting.py b/examples/simple_gate_visualization_with_camera_background_trees_X500_position_control_tilting.py
deleted file mode 100644
index a5f903e..0000000
--- a/examples/simple_gate_visualization_with_camera_background_trees_X500_position_control_tilting.py
+++ /dev/null
@@ -1,1172 +0,0 @@
-"""
-Simple Gate Visualization with Static Camera, X500 Robot with D455 Camera, and Position Control
-===============================================================================================
-
-This script creates a simple visualization of a gate environment with:
-1. A static depth camera using Isaac Gym native API
-2. An X500 quadrotor robot with D455 depth camera sensor
-3. Lee position controller for X500 hovering at a target position
-4. Real-time visualization of both camera outputs side-by-side
-
-Key features:
-- Gate environment with optional background trees
-- X500 quadrotor robot with onboard D455 camera
-- Static world-mounted camera positioned 3m from gate
-- Lee position controller for stable hovering
-- Real-time depth and segmentation image display from both cameras
-- Dual camera system: Static + Agent camera
-"""
-
-import os
-import sys
-import time
-import cv2
-import numpy as np
-
-# Isaac Gym must be imported first
-from isaacgym import gymapi, gymtorch, gymutil
-
-# Aerial Gym components
-from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-from aerial_gym.config.robot_config.x500_config import X500Cfg
-from aerial_gym.config.sensor_config.camera_config.d455_depth_config import RsD455Config
-from aerial_gym.config.controller_config.lee_controller_config import control as lee_controller_config
-from aerial_gym.control.controllers.position_control import LeePositionController
-from aerial_gym.control.control_allocation import ControlAllocator
-from aerial_gym.utils.math import *
-
-import torch
-
-# Create X500 config with D455 camera enabled and fixed control allocation
-class X500WithD455Cfg(X500Cfg):
-    """X500 configuration with D455 camera sensor enabled."""
-    
-    class sensor_config(X500Cfg.sensor_config):
-        enable_camera = True
-        camera_config = RsD455Config
-    
-    class robot_asset(X500Cfg.robot_asset):
-        name = "x500_with_d455"
-
-class GateEnvironmentWithPositionControl:
-    """
-    Gate environment with static camera, X500 robot with D455 camera, and Lee position controller for hovering.
-    """
-    
-    def __init__(self, headless=False):
-        """Initialize the environment."""
-        print("🚁 Initializing Gate Environment with Position Control...")
-        
-        self.headless = headless
-        self.device = "cuda" if torch.cuda.is_available() else "cpu"
-        self.num_envs = 1
-        self.dt = 1.0 / 60.0  # 60 FPS simulation
-        
-        # Environment handles (Isaac Gym)
-        self.env_handles = []
-        self.gate_handles = []
-        self.tree_handles = []
-        self.x500_handles = []
-        
-        # Static camera handles
-        self.camera_handles = []
-        self.camera_setup_success = False
-        
-        # X500 camera handles
-        self.x500_camera_handles = []
-        
-        # Control system
-        self.controller = None
-        self.control_allocator = None
-        
-        # Simple hovering task - hover at the start position
-        self.hover_target = torch.tensor([-2.5, 0.0, 1.0], device=self.device)
-        self.current_target = self.hover_target.clone()
-        
-        # Robot state tensors (for Isaac Gym rigid body states)
-        self.x500_rigid_body_states = None
-        
-        # Controller state tensors (derived from rigid body states)
-        self.robot_position = torch.zeros((self.num_envs, 3), device=self.device)
-        self.robot_orientation = torch.zeros((self.num_envs, 4), device=self.device)
-        self.robot_linvel = torch.zeros((self.num_envs, 3), device=self.device)
-        self.robot_angvel = torch.zeros((self.num_envs, 3), device=self.device)
-        
-        # Initialize gym
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        self._setup_static_camera()
-        self._setup_x500_with_camera()
-        self._setup_controller()
-        
-        if not self.headless:
-            self._create_viewer()
-        
-        # Prepare simulation for rendering
-        self.gym.prepare_sim(self.sim)
-        
-        print("✅ Environment initialization complete!")
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Parse arguments
-        custom_parameters = [
-            {"name": "--headless", "action": "store_true", "help": "Run headless without viewer"},
-        ]
-        args = gymutil.parse_arguments(custom_parameters=custom_parameters)
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        print("✓ Isaac Gym initialized")
-    
-    def _create_sim(self):
-        """Create simulation."""
-        print("Creating simulation...")
-        
-        # Simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = self.dt
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        
-        # Physics backend
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 4
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.contact_offset = 0.01
-        sim_params.physx.rest_offset = 0.0
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)
-        if self.sim is None:
-            raise Exception("Failed to create simulation")
-        
-        print("✓ Simulation created")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
-        plane_params.distance = 0.0
-        self.gym.add_ground(self.sim, plane_params)
-    
-        print("✓ Ground plane created")
-    
-    def _load_gate_asset(self):
-        """Load gate asset."""
-        print(f"Loading gate asset from: {gate_asset_params.file}")
-        
-        # Asset loading options
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        
-        # Load asset
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise Exception(f"Failed to load gate asset: {gate_asset_params.file}")
-        
-        print("✓ Gate asset loaded successfully")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create environment with gate and optional trees."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Gate on ground level
-        
-        # Rotate gate by 90 degrees around Z-axis so trees are directly behind it
-        import math
-        gate_pose.r = gymapi.Quat(0.0, 0.0, math.sin(math.pi/4), math.cos(math.pi/4))  # 90° rotation around Z-axis
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Set gate color for better visibility
-        self.gym.set_rigid_body_color(
-            env_handle, gate_handle, 0, 
-            gymapi.MESH_VISUAL, gymapi.Vec3(0.2, 0.2, 0.8)  # blue-ish
-        )
-        
-        # Add some trees behind the gate for better visualization
-        self._add_background_trees(env_handle)
-        
-        print("✓ Environment created with gate!")
-    
-    def _add_background_trees(self, env_handle):
-        """Add some trees behind the gate for better camera visualization."""
-        print("Adding background trees...")
-        
-        try:
-            # Load a tree asset from the existing tree models
-            tree_asset_folder = f"{gate_asset_params.asset_folder}/../trees"
-            available_trees = ["tree_0.urdf", "tree_1.urdf", "tree_2.urdf", "tree_3.urdf", "tree_4.urdf"]
-            
-            # Add trees at various positions behind the gate (negative Y from camera perspective)
-            tree_positions = [
-                (-2.0, 3.0, 0.0),   # Left behind gate
-                (0.0, 4.0, 0.0),    # Directly behind gate
-                (2.0, 3.0, 0.0),    # Right behind gate
-                (-1.0, 5.0, 0.0),   # Further behind, left
-                (1.0, 5.0, 0.0),    # Further behind, right
-            ]
-            
-            for i, (x, y, z) in enumerate(tree_positions):
-                if i >= len(available_trees):
-                    break
-                    
-                tree_file = available_trees[i]
-                tree_path = f"{tree_asset_folder}/{tree_file}"
-                
-                # Check if tree file exists
-                if not os.path.exists(tree_path):
-                    print(f"Tree file not found: {tree_path}, skipping...")
-                    continue
-                
-                # Load tree asset
-                tree_asset_options = gymapi.AssetOptions()
-                tree_asset_options.fix_base_link = True
-                tree_asset_options.collapse_fixed_joints = True
-                tree_asset_options.disable_gravity = True
-                tree_asset_options.replace_cylinder_with_capsule = True
-                tree_asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-                
-                tree_asset = self.gym.load_asset(
-                    self.sim, 
-                    tree_asset_folder, 
-                    tree_file, 
-                    tree_asset_options
-                )
-                
-                if tree_asset is None:
-                    print(f"Failed to load tree asset: {tree_file}")
-                    continue
-                
-                # Create tree actor
-                tree_pose = gymapi.Transform()
-                tree_pose.p = gymapi.Vec3(x, y, z)
-                tree_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
-                
-                tree_handle = self.gym.create_actor(
-                    env_handle,
-                    tree_asset,
-                    tree_pose,
-                    f"tree_{i}",
-                    0,  # Collision group
-                    1   # Collision filter
-                )
-                
-                self.tree_handles.append(tree_handle)
-                
-                # Set tree color for variety
-                colors = [
-                    gymapi.Vec3(0.2, 0.6, 0.2),  # Green
-                    gymapi.Vec3(0.4, 0.8, 0.2),  # Light green
-                    gymapi.Vec3(0.1, 0.4, 0.1),  # Dark green
-                    gymapi.Vec3(0.3, 0.7, 0.3),  # Medium green
-                    gymapi.Vec3(0.5, 0.9, 0.1),  # Yellow-green
-                ]
-                color = colors[i % len(colors)]
-                self.gym.set_rigid_body_color(
-                    env_handle, tree_handle, 0, 
-                    gymapi.MESH_VISUAL, color
-                )
-                
-                print(f"Added tree {i+1} at position ({x}, {y}, {z})")
-                
-        except Exception as e:
-            print(f"Warning: Failed to add background trees: {e}")
-            print("Continuing without trees...") 
-    
-    def _setup_static_camera(self):
-        """Setup static camera using Isaac Gym native camera API."""
-        print("Setting up static camera using Isaac Gym native API...")
-        
-        try:
-            # Camera properties (D455 depth camera specifications)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = 1280  # D455 depth resolution
-            camera_props.height = 720  # D455 depth resolution
-            camera_props.horizontal_fov = 87.0  # D455 FOV
-            camera_props.near_plane = 0.4  # D455 minimum depth distance
-            camera_props.far_plane = 20.0  # D455 maximum range
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"Static camera properties (D455 specs): {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"Static camera depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-        
-            # Create camera sensor in each environment
-            self.camera_handles = []
-            for i, env_handle in enumerate(self.env_handles):
-                cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-                self.camera_handles.append(cam_handle)
-                print(f"Created static camera sensor {i} in environment {i}")
-            
-            # Position camera to face the gate directly (gate now rotated 90°)
-            camera_pos = gymapi.Vec3(0.0, -3.0, 1.5)  # 3m in front of gate, at gate center height
-            camera_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look directly at gate center
-            
-            # Set camera transform for each environment using look_at
-            for i, (env_handle, cam_handle) in enumerate(zip(self.env_handles, self.camera_handles)):
-                # Use Isaac Gym's camera look_at functionality
-                self.gym.set_camera_location(cam_handle, env_handle, camera_pos, camera_target)
-                print(f"Set static camera {i} to look from ({camera_pos.x}, {camera_pos.y}, {camera_pos.z}) toward ({camera_target.x}, {camera_target.y}, {camera_target.z})")
-            
-            print(f"✓ Static cameras positioned to face gate directly")
-            
-            self.camera_setup_success = True
-            
-        except Exception as e:
-            print(f"❌ ERROR: Isaac Gym static camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.camera_setup_success = False
-    
-    def _load_x500_asset(self):
-        """Load X500 robot asset with D455 camera."""
-        print(f"Loading X500 robot asset from: {X500WithD455Cfg.robot_asset.file}")
-        
-        # Asset loading options for X500
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = X500WithD455Cfg.robot_asset.fix_base_link
-        asset_options.collapse_fixed_joints = X500WithD455Cfg.robot_asset.collapse_fixed_joints
-        asset_options.disable_gravity = X500WithD455Cfg.robot_asset.disable_gravity
-        asset_options.replace_cylinder_with_capsule = X500WithD455Cfg.robot_asset.replace_cylinder_with_capsule
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        asset_options.flip_visual_attachments = X500WithD455Cfg.robot_asset.flip_visual_attachments
-        asset_options.density = X500WithD455Cfg.robot_asset.density
-        asset_options.angular_damping = X500WithD455Cfg.robot_asset.angular_damping
-        asset_options.linear_damping = X500WithD455Cfg.robot_asset.linear_damping
-        asset_options.max_angular_velocity = X500WithD455Cfg.robot_asset.max_angular_velocity
-        asset_options.max_linear_velocity = X500WithD455Cfg.robot_asset.max_linear_velocity
-        asset_options.armature = X500WithD455Cfg.robot_asset.armature
-        
-        # Load X500 asset
-        x500_asset = self.gym.load_asset(
-            self.sim, 
-            X500WithD455Cfg.robot_asset.asset_folder, 
-            X500WithD455Cfg.robot_asset.file, 
-            asset_options
-        )
-        
-        if x500_asset is None:
-            raise Exception(f"Failed to load X500 robot asset: {X500WithD455Cfg.robot_asset.file}")
-        
-        print("✓ X500 robot asset loaded successfully")
-        return x500_asset
-
-    def _setup_x500_with_camera(self):
-        """Setup X500 drone with D455 camera in the same environment."""
-        print("Setting up X500 drone with D455 camera...")
-        
-        try:
-            # Load X500 asset
-            x500_asset = self._load_x500_asset()
-            
-            # Get the first environment handle
-            env_handle = self.env_handles[0]
-            
-            # Create X500 robot actor
-            x500_pose = gymapi.Transform()
-            x500_pose.p = gymapi.Vec3(-2.5, 0.0, 1.0)  # Start position
-            x500_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # Default orientation
-            
-            x500_handle = self.gym.create_actor(
-                env_handle,
-                x500_asset,
-                x500_pose,
-                "x500",
-                0,  # Collision group
-                1   # Collision filter
-            )
-            self.x500_handles = [x500_handle]
-            
-            # Set X500 color for better visibility
-            self.gym.set_rigid_body_color(
-                env_handle, x500_handle, 0, 
-                gymapi.MESH_VISUAL, gymapi.Vec3(0.8, 0.8, 0.2)  # Yellow X500
-            )
-            
-            # Setup D455 camera on X500
-            self._setup_x500_camera(env_handle, x500_handle)
-            
-            # Get rigid body state tensor for X500
-            self._setup_x500_state_tensors()
-            
-            print("✓ X500 with D455 camera setup complete")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 with camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_handles = []
-    
-    def _setup_x500_camera(self, env_handle, x500_handle):
-        """Setup D455 camera on X500 drone."""
-        print("Setting up D455 camera on X500...")
-        
-        try:
-            # Camera properties (D455 specifications from config)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = RsD455Config.width  # 480
-            camera_props.height = RsD455Config.height  # 270
-            camera_props.horizontal_fov = RsD455Config.horizontal_fov_deg  # 87.0
-            camera_props.near_plane = RsD455Config.min_range  # 0.2
-            camera_props.far_plane = RsD455Config.max_range  # 15.0
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"X500 D455 camera properties: {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"X500 D455 depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-            
-            # Create camera sensor attached to X500
-            x500_cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-            print(f"Debug: Created X500 camera sensor with handle: {x500_cam_handle}")
-            
-            if x500_cam_handle is None:
-                raise Exception("Failed to create X500 camera sensor")
-            
-            # Attach camera to X500 base_link with forward-facing orientation
-            # Camera position relative to X500 base_link (slightly forward and up)
-            cam_pos = gymapi.Vec3(0.10, 0.0, 0.03)  # 10cm forward, 3cm up from center
-            
-            # Attach camera to X500
-            self.gym.attach_camera_to_body(
-                x500_cam_handle, env_handle, x500_handle,
-                gymapi.Transform(p=cam_pos), gymapi.FOLLOW_TRANSFORM
-            )
-            print(f"Debug: Attached camera to X500 body at position ({cam_pos.x}, {cam_pos.y}, {cam_pos.z})")
-            
-            # Store camera handle
-            self.x500_camera_handles = [x500_cam_handle]
-            
-            print("✓ D455 camera attached to X500")
-            print(f"Debug: X500 camera handles stored: {self.x500_camera_handles}")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_camera_handles = []
-    
-    def _setup_x500_state_tensors(self):
-        """Setup tensors to access X500 rigid body states from Isaac Gym."""
-        try:
-            # Get actor root state tensor (contains position, orientation, linear/angular velocities)
-            actor_root_state_tensor = self.gym.acquire_actor_root_state_tensor(self.sim)
-            
-            # Setup state tensors for X500
-            self.actor_root_states = gymtorch.wrap_tensor(actor_root_state_tensor)
-            
-            # X500 is the second actor created (after gate), so it's at index 1
-            # We can verify this by checking the actor names if needed
-            self.x500_actor_idx = 1  # Gate=0, X500=1
-            print(f"X500 actor index: {self.x500_actor_idx}")
-            print(f"Actor root states shape: {self.actor_root_states.shape}")
-            
-            print("✓ X500 state tensors setup complete")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 state tensor setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-    
-    def _setup_controller(self):
-        """Setup Lee position controller and control allocation for X500."""
-        print("Setting up Lee position controller for X500...")
-        
-        try:
-            # Import controller and control allocation
-            from aerial_gym.control.controllers.position_control import LeePositionController
-            from aerial_gym.control.control_allocation import ControlAllocator
-            
-            # Setup Lee position controller
-            from aerial_gym.config.controller_config.lee_controller_config import control as lee_controller_config
-            
-            # Find X500 motor indices first
-            self.x500_motor_indices = self._find_x500_motor_indices()
-            
-            # Create a copy of the X500 control allocator config to modify
-            import copy
-            control_alloc_config = copy.deepcopy(X500WithD455Cfg.control_allocator_config)
-            
-            # Update the application mask with correct motor indices
-            # The X500 config expects local indices relative to the actor
-            env_handle = self.env_handles[0]
-            x500_handle = self.x500_handles[0]
-            
-            # Get base link indices
-            base_link_idx = self.gym.find_actor_rigid_body_index(
-                env_handle, x500_handle, "base_link", gymapi.DOMAIN_ACTOR
-            )
-            
-            # Calculate local indices relative to base link for each motor
-            # Motor order in X500 config: front_right, back_left, front_left, back_right
-            motor_names_ordered = ["front_right_prop", "back_left_prop", "front_left_prop", "back_right_prop"]
-            local_motor_indices = []
-            
-            for motor_name in motor_names_ordered:
-                try:
-                    motor_link_idx = self.gym.find_actor_rigid_body_index(
-                        env_handle, x500_handle, motor_name, gymapi.DOMAIN_ACTOR
-                    )
-                    local_motor_indices.append(motor_link_idx)
-                except:
-                    raise Exception(f"Could not find motor link '{motor_name}'")
-            
-            # Update the application mask
-            control_alloc_config.application_mask = local_motor_indices
-            
-            print(f"X500 motor order: {motor_names_ordered}")
-            print(f"Updated application mask: {control_alloc_config.application_mask}")
-            print(f"Motor global indices: {self.x500_motor_indices}")
-            
-            # Store the application mask for later use
-            self.application_mask = local_motor_indices
-            
-            # Create controller
-            self.controller = LeePositionController(
-                config=lee_controller_config,
-                num_envs=self.num_envs,
-                device=self.device
-            )
-            
-            # Setup control allocation with updated config
-            self.control_allocator = ControlAllocator(
-                config=control_alloc_config,
-                num_envs=self.num_envs,
-                dt=self.dt,
-                device=self.device
-            )
-            
-            # Create additional required tensors for controller (matching aerial gym structure)
-            self.robot_euler_angles = torch.zeros((self.num_envs, 3), device=self.device)
-            self.robot_body_angvel = torch.zeros((self.num_envs, 3), device=self.device) 
-            self.robot_body_linvel = torch.zeros((self.num_envs, 3), device=self.device)
-            self.robot_vehicle_orientation = torch.zeros((self.num_envs, 4), device=self.device)
-            self.robot_vehicle_linvel = torch.zeros((self.num_envs, 3), device=self.device)
-            
-            # Physical parameters for X500 (approximately 1.5 kg)
-            self.robot_mass = torch.tensor([1.5], device=self.device).expand(self.num_envs)
-            self.robot_inertia = torch.tensor([
-                [0.029125, 0.0, 0.0],
-                [0.0, 0.029125, 0.0], 
-                [0.0, 0.0, 0.055225]
-            ], device=self.device).expand(self.num_envs, 3, 3)
-            self.gravity = torch.tensor([0.0, 0.0, -9.81], device=self.device).expand(self.num_envs, 3)
-            
-            # Create global tensor dict for controller initialization (matching aerial gym format)
-            global_tensor_dict = {
-                "robot_position": self.robot_position,
-                "robot_orientation": self.robot_orientation,
-                "robot_euler_angles": self.robot_euler_angles,
-                "robot_linvel": self.robot_linvel,
-                "robot_angvel": self.robot_angvel,
-                "robot_body_angvel": self.robot_body_angvel,
-                "robot_body_linvel": self.robot_body_linvel,
-                "robot_vehicle_orientation": self.robot_vehicle_orientation,
-                "robot_vehicle_linvel": self.robot_vehicle_linvel,
-                "robot_inertia": self.robot_inertia,
-                "robot_mass": self.robot_mass,
-                "gravity": self.gravity,
-                "robot_force_tensor": torch.zeros((self.num_envs, 1, 3), device=self.device),
-                "robot_torque_tensor": torch.zeros((self.num_envs, 1, 3), device=self.device),
-            }
-            
-            # Initialize controller tensors
-            self.controller.init_tensors(global_tensor_dict)
-            
-            print("✓ Lee position controller initialized")
-            print(f"Controller gains - Position: {self.controller.K_pos_tensor_current[0].cpu().numpy()}")
-            print(f"Controller gains - Velocity: {self.controller.K_linvel_tensor_current[0].cpu().numpy()}")
-            print(f"Current hover target: {self.hover_target.cpu().numpy()}")
-            
-        except Exception as e:
-            print(f"❌ ERROR: Controller setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.controller = None
-            self.control_allocator = None
-    
-    def _create_viewer(self):
-        """Create viewer."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Viewer camera properties
-        cam_props = gymapi.CameraProperties()
-        viewer = self.gym.create_viewer(self.sim, cam_props)
-        
-        if viewer is None:
-            raise Exception("Failed to create viewer")
-        
-        # Set viewer camera
-        cam_pos = gymapi.Vec3(-5.0, -5.0, 3.0)
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.0)
-        self.gym.viewer_camera_look_at(viewer, None, cam_pos, cam_target)
-        
-        self.viewer = viewer
-        print("✓ Viewer created")
-    
-    def _update_robot_state(self):
-        """Update robot state tensors from simulation."""
-        try:
-            # Refresh actor root state tensor from simulation
-            self.gym.refresh_actor_root_state_tensor(self.sim)
-            
-            # Update robot state from root state tensor
-            # Root state tensor format: [pos_x, pos_y, pos_z, quat_x, quat_y, quat_z, quat_w, vel_x, vel_y, vel_z, angvel_x, angvel_y, angvel_z]
-            x500_state = self.actor_root_states[self.x500_actor_idx]  # X500 is the second actor (index 1, gate is index 0)
-            
-            # Update position, orientation, and velocities
-            self.robot_position[0, :] = x500_state[0:3]
-            self.robot_orientation[0, :] = x500_state[3:7]  # quaternion
-            self.robot_linvel[0, :] = x500_state[7:10]
-            self.robot_angvel[0, :] = x500_state[10:13]
-            
-            # Convert quaternion to euler angles for controller
-            from aerial_gym.utils.math import get_euler_xyz_tensor
-            self.robot_euler_angles[0] = get_euler_xyz_tensor(self.robot_orientation[0].unsqueeze(0))[0]
-            
-            # Convert global velocities to body frame
-            # For now, use global velocities (this is a simplification)
-            self.robot_body_linvel[0] = self.robot_linvel[0]
-            self.robot_body_angvel[0] = self.robot_angvel[0]
-            
-            # Update vehicle orientation and velocity for controller
-            self.robot_vehicle_orientation[0] = self.robot_orientation[0]
-            self.robot_vehicle_linvel[0] = self.robot_linvel[0]
-            
-            # Debug: Print position update every 60 steps
-            if hasattr(self, 'debug_step_count') and self.debug_step_count % 60 == 0:
-                pos = self.robot_position[0].cpu().numpy()
-                print(f"Debug State Update - Position: [{pos[0]:.2f}, {pos[1]:.2f}, {pos[2]:.2f}]")
-            
-        except Exception as e:
-            print(f"Error updating robot state: {e}")
-            import traceback
-            traceback.print_exc()
-    
-    def _apply_control(self):
-        """Apply Lee position controller to make X500 follow waypoints."""
-        if self.controller is None or self.control_allocator is None:
-            return
-            
-        try:
-            # Update robot state
-            self._update_robot_state()
-            
-            # Get current position and distance to target (for hovering)
-            current_pos = self.robot_position[0]
-            distance_to_target = torch.norm(current_pos - self.current_target)
-            
-            # Create command actions for position control
-            # [x, y, z, yaw] in world frame
-            command_actions = torch.zeros((self.num_envs, 4), device=self.device)
-            command_actions[0, 0:3] = self.current_target  # Target position
-            command_actions[0, 3] = 0.0  # Target yaw (face forward)
-            
-            # Compute control wrench using Lee controller
-            wrench_command = self.controller.update(command_actions)
-            
-            # Debug: Print control values every 60 steps
-            if hasattr(self, 'debug_step_count'):
-                self.debug_step_count += 1
-            else:
-                self.debug_step_count = 0
-                
-            if self.debug_step_count % 60 == 0:
-                pos_error = self.current_target - current_pos
-                pos_np = current_pos.cpu().numpy()
-                target_np = self.current_target.cpu().numpy()
-                error_np = pos_error.cpu().numpy()
-                wrench_np = wrench_command[0].cpu().numpy()
-                print(f"Debug Control - Pos: [{pos_np[0]:.2f}, {pos_np[1]:.2f}, {pos_np[2]:.2f}], Target: [{target_np[0]:.2f}, {target_np[1]:.2f}, {target_np[2]:.2f}]")
-                print(f"Debug Control - Error: [{error_np[0]:.2f}, {error_np[1]:.2f}, {error_np[2]:.2f}], Distance: {distance_to_target:.2f}m")
-                print(f"Debug Control - Wrench: [{wrench_np[0]:.2f}, {wrench_np[1]:.2f}, {wrench_np[2]:.2f}, {wrench_np[3]:.2f}, {wrench_np[4]:.2f}, {wrench_np[5]:.2f}]")
-            
-            # Allocate control to motors
-            forces, torques = self.control_allocator.allocate_output(wrench_command, "wrench")
-            
-            # Debug: Print motor forces and torques every 60 steps
-            if self.debug_step_count % 60 == 0:
-                try:
-                    forces_np = forces[0].cpu().numpy()  # Shape: [4, 3]
-                    torques_np = torques[0].cpu().numpy()  # Shape: [4, 3]
-                    print(f"Debug Motors - Forces Z: [{forces_np[0,2]:.2f}, {forces_np[1,2]:.2f}, {forces_np[2,2]:.2f}, {forces_np[3,2]:.2f}]")
-                    print(f"Debug Motors - Torques Z: [{torques_np[0,2]:.2f}, {torques_np[1,2]:.2f}, {torques_np[2,2]:.2f}, {torques_np[3,2]:.2f}]")
-                except Exception as e:
-                    print(f"Debug print error: {e}")
-            
-            # Apply forces and torques to X500
-            self._apply_forces_torques_to_x500(forces, torques)
-            
-        except Exception as e:
-            print(f"Error in control application: {e}")
-            import traceback
-            traceback.print_exc()
-    
-    def _apply_forces_torques_to_x500(self, forces, torques):
-        """Apply computed forces and torques to X500 using motor-level application."""
-        try:
-            # Use tensor-based force/torque application at motor level (as used in Aerial Gym)
-            if not hasattr(self, 'force_tensors_initialized'):
-                self._init_force_tensors()
-            
-            # Clear existing forces and torques
-            self.global_force_tensor.zero_()
-            self.global_torque_tensor.zero_()
-            
-            # Apply forces and torques to X500 motors (as per X500 config application_mask)
-            # X500 has 4 motors with application_mask [4,1,3,2] (motor link indices)
-            application_mask = self.application_mask
-            
-            # Debug: Print force application details every 60 steps
-            if hasattr(self, 'debug_step_count') and self.debug_step_count % 60 == 0:
-                print(f"Debug Force Application:")
-                print(f"  Application mask: {application_mask}")
-                print(f"  Motor global indices: {self.x500_motor_indices}")
-                print(f"  Forces shape: {forces.shape}, Torques shape: {torques.shape}")
-            
-            for i, motor_idx in enumerate(application_mask):
-                if i < forces.shape[1] and i < torques.shape[1]:
-                    # Find global rigid body index for this motor
-                    motor_global_idx = self.x500_motor_indices[i]
-                    
-                    # Apply motor forces and torques (forces and torques are 3D vectors)
-                    motor_force_vec = forces[0, i].cpu()  # 3D force vector
-                    motor_torque_vec = torques[0, i].cpu()  # 3D torque vector
-                    
-                    # Apply the full 3D force and torque vectors
-                    self.global_force_tensor[motor_global_idx, 0:3] = motor_force_vec
-                    self.global_torque_tensor[motor_global_idx, 0:3] = motor_torque_vec
-                    
-                    # Debug: Print individual motor forces
-                    if hasattr(self, 'debug_step_count') and self.debug_step_count % 60 == 0:
-                        print(f"  Motor {i} (global_idx {motor_global_idx}): Force=[{motor_force_vec[0]:.2f}, {motor_force_vec[1]:.2f}, {motor_force_vec[2]:.2f}]N")
-                        print(f"                                         Torque=[{motor_torque_vec[0]:.3f}, {motor_torque_vec[1]:.3f}, {motor_torque_vec[2]:.3f}]Nm")
-            
-            # Apply tensors to simulation using Isaac Gym's tensor-based API
-            self.gym.apply_rigid_body_force_tensors(
-                self.sim,
-                gymtorch.unwrap_tensor(self.global_force_tensor),
-                gymtorch.unwrap_tensor(self.global_torque_tensor),
-                gymapi.LOCAL_SPACE  # Forces in body frame
-            )
-            
-        except Exception as e:
-            print(f"Error applying forces/torques: {e}")
-            import traceback
-            traceback.print_exc()
-    
-    def _init_force_tensors(self):
-        """Initialize force and torque tensors for Isaac Gym."""
-        try:
-            # Get rigid body state tensor to determine dimensions
-            rigid_body_tensor = self.gym.acquire_rigid_body_state_tensor(self.sim)
-            rb_states = gymtorch.wrap_tensor(rigid_body_tensor)
-            num_rigid_bodies = rb_states.shape[0]
-            
-            # Create force and torque tensors on CPU (Isaac Gym physics runs on CPU)
-            self.global_force_tensor = torch.zeros((num_rigid_bodies, 3), 
-                                                 device="cpu", requires_grad=False)
-            self.global_torque_tensor = torch.zeros((num_rigid_bodies, 3), 
-                                                  device="cpu", requires_grad=False)
-            
-            # Find X500 motor indices for force application
-            self.x500_motor_indices = self._find_x500_motor_indices()
-            
-            self.force_tensors_initialized = True
-            print(f"✓ Force tensors initialized on CPU, X500 motor indices: {self.x500_motor_indices}")
-            
-        except Exception as e:
-            print(f"Error initializing force tensors: {e}")
-            import traceback
-            traceback.print_exc()
-            self.force_tensors_initialized = False
-            
-    def _find_x500_motor_indices(self):
-        """Find the rigid body indices for X500 motor links."""
-        try:
-            env_handle = self.env_handles[0]
-            x500_handle = self.x500_handles[0]
-            
-            # X500 motor link names (based on URDF structure)
-            motor_link_names = ["front_right_prop", "back_right_prop", "back_left_prop", "front_left_prop"]
-            motor_indices = []
-            
-            for motor_name in motor_link_names:
-                try:
-                    # Get the rigid body index for this motor link
-                    motor_link_idx = self.gym.find_actor_rigid_body_index(
-                        env_handle, x500_handle, motor_name, gymapi.DOMAIN_ACTOR
-                    )
-                    
-                    # Get global rigid body index
-                    global_idx = self.gym.get_actor_rigid_body_index(
-                        env_handle, x500_handle, motor_link_idx, gymapi.DOMAIN_SIM
-                    )
-                    
-                    motor_indices.append(global_idx)
-                    
-                except Exception as e:
-                    print(f"Warning: Could not find motor link '{motor_name}': {e}")
-                    # Fallback: use base_link index + motor offset
-                    base_link_idx = self.gym.find_actor_rigid_body_index(
-                        env_handle, x500_handle, "base_link", gymapi.DOMAIN_ACTOR
-                    )
-                    base_global_idx = self.gym.get_actor_rigid_body_index(
-                        env_handle, x500_handle, base_link_idx, gymapi.DOMAIN_SIM
-                    )
-                    motor_indices.append(base_global_idx + len(motor_indices) + 1)
-            
-            return motor_indices
-            
-        except Exception as e:
-            print(f"Error finding X500 motor indices: {e}")
-            # Fallback: assume consecutive indices starting from base_link + 1
-            return [2, 3, 4, 5]  # Educated guess
-    
-    def capture_all_camera_images(self):
-        """Capture depth and segmentation images from both cameras."""
-        static_depth, static_seg = None, None
-        x500_depth, x500_seg = None, None
-        
-        try:
-            # Step graphics and render all cameras once
-            self.gym.step_graphics(self.sim)
-            self.gym.render_all_camera_sensors(self.sim)
-            self.gym.start_access_image_tensors(self.sim)
-            
-            env_handle = self.env_handles[0]
-            
-            # Capture static camera images
-            if self.camera_setup_success and len(self.camera_handles) > 0:
-                try:
-                    cam_handle = self.camera_handles[0]
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    static_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    static_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    
-                except Exception as e:
-                    print(f"Error capturing static camera: {e}")
-            
-            # Capture X500 camera images
-            if len(self.x500_camera_handles) > 0:
-                try:
-                    x500_cam_handle = self.x500_camera_handles[0]
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    x500_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    x500_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    
-                except Exception as e:
-                    print(f"Error capturing X500 camera: {e}")
-            
-            # End access to image tensors
-            self.gym.end_access_image_tensors(self.sim)
-            
-            return (static_depth, static_seg), (x500_depth, x500_seg)
-                
-        except Exception as e:
-            print(f"Error in capture_all_camera_images: {e}")
-            import traceback
-            traceback.print_exc()
-            return (None, None), (None, None) 
-
-    def create_combined_image(self, depth_img, seg_img, title="Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-        # Take absolute value to handle negative depths (coordinate system issue)
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 10 meters for D455 range)
-        depth_norm = np.clip(depth_norm, 0, 10.0)  
-        depth_norm = (depth_norm / 10.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 10.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 10.0)
-            pseudo_seg = (pseudo_seg / 10.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-    def run_navigation_and_visualization(self, duration=120.0):
-        """Run the navigation and visualization loop."""
-        print(f"Starting navigation and visualization for {duration} seconds...")
-        print("Press ESC to exit early")
-        print(f"Hovering task: X500 will hover at target position {self.hover_target.cpu().numpy()}")
-        
-        start_time = time.time()
-        step_count = 0
-        
-        # OpenCV windows for camera displays
-        cv2.namedWindow("Static Camera View", cv2.WINDOW_NORMAL)
-        cv2.resizeWindow("Static Camera View", 2560, 720)  # Side-by-side 1280x720 images
-        
-        if len(self.x500_camera_handles) > 0:
-            cv2.namedWindow("X500 D455 Camera View", cv2.WINDOW_NORMAL)
-            cv2.resizeWindow("X500 D455 Camera View", 960, 540)  # D455 resolution scaled
-        
-        while True:
-            current_time = time.time()
-            elapsed_time = current_time - start_time
-            
-            # Check if duration exceeded
-            if elapsed_time > duration:
-                print(f"Navigation and visualization completed after {duration} seconds")
-                break
-            
-            # Apply position control
-            self._apply_control()
-            
-            # Step simulation
-            self.gym.simulate(self.sim)
-            self.gym.fetch_results(self.sim, True)
-            
-            # Capture all camera images at once
-            (static_depth, static_seg), (x500_depth, x500_seg) = self.capture_all_camera_images()
-            
-            # Display static camera images
-            if static_depth is not None and static_seg is not None:
-                # Create combined visualization for static camera
-                static_combined = self.create_combined_image(static_depth, static_seg, "Static Camera")
-                
-                if static_combined is not None:
-                    # Display static camera images
-                    cv2.imshow("Static Camera View", static_combined)
-                    
-                    # Print depth statistics periodically
-                    if step_count % 60 == 0:  # Every second at 60 FPS
-                        # Filter out -inf values for better statistics
-                        valid_depths = static_depth[static_depth != -np.inf]
-                        if len(valid_depths) > 0:
-                            # Use absolute values for meaningful distance measurements
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = static_depth.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            
-                            # Print robot position and target
-                            current_pos = self.robot_position[0].cpu().numpy()
-                            target_pos = self.current_target.cpu().numpy()
-                            distance_to_target = torch.norm(self.robot_position[0] - self.current_target).item()
-                            
-                            print(f"Step {step_count}: Static Camera - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-                            print(f"          X500 Pos: [{current_pos[0]:.2f}, {current_pos[1]:.2f}, {current_pos[2]:.2f}], "
-                                  f"Target: [{target_pos[0]:.2f}, {target_pos[1]:.2f}, {target_pos[2]:.2f}], "
-                                  f"Dist: {distance_to_target:.2f}m, Hover Target")
-            
-            # Display X500 camera images
-            if x500_depth is not None and x500_seg is not None:
-                # Create combined visualization for X500 camera
-                x500_combined = self.create_combined_image(x500_depth, x500_seg, "X500 D455")
-                
-                if x500_combined is not None:
-                    # Display X500 camera images
-                    cv2.imshow("X500 D455 Camera View", x500_combined)
-                    
-                    # Print X500 camera statistics periodically
-                    if step_count % 60 == 0:
-                        valid_depths = x500_depth[x500_depth != -np.inf]
-                        if len(valid_depths) > 0:
-                            abs_valid_depths = np.abs(valid_depths)
-                            min_depth = np.min(abs_valid_depths)
-                            max_depth = np.max(abs_valid_depths)
-                            mean_depth = np.mean(abs_valid_depths)
-                            total_pixels = x500_depth.size
-                            valid_ratio = len(valid_depths) / total_pixels * 100
-                            print(f"          X500 D455 - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                                  f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-            elif step_count % 60 == 0:
-                print(f"          X500 D455 - No camera data available")
-            
-            # Handle viewer events
-            if not self.headless:
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                if self.gym.query_viewer_has_closed(self.viewer):
-                    break
-            
-            # Check for ESC key press in OpenCV window
-            key = cv2.waitKey(1) & 0xFF
-            if key == 27:  # ESC key
-                print("ESC pressed, exiting navigation and visualization")
-                break
-            
-            step_count += 1
-        
-        cv2.destroyAllWindows()
-        print("Navigation and visualization loop completed")
-    
-    def print_environment_info(self):
-        """Print information about the environment."""
-        print("\n" + "="*60)
-        print("DUAL CAMERA POSITION CONTROL ENVIRONMENT INFORMATION")
-        print("="*60)
-        print(f"Number of environments: {self.num_envs}")
-        print(f"Device: {self.device}")
-        print(f"Gate asset: {gate_asset_params.file}")
-        print(f"Static camera setup success: {self.camera_setup_success}")
-        print(f"Number of static cameras: {len(self.camera_handles)}")
-        print(f"Number of trees: {len(self.tree_handles)}")
-        print(f"Number of X500 robots: {len(self.x500_handles)}")
-        print(f"X500 with D455 setup: {'Success' if len(self.x500_handles) > 0 else 'Failed'}")
-        print(f"Lee Position Controller: {'Active' if self.controller is not None else 'Failed'}")
-        
-        if self.camera_setup_success:
-            print(f"Static camera position: (0, -3, 1.5)")
-            print(f"Static camera target: (0, 0, 1.5) - gate center")
-            print(f"Gate position: (0, 0, 0) - rotated 90°")
-        
-        if len(self.x500_handles) > 0:
-            print(f"X500 start position: (-2.5, 0, 1.0)")
-            print(f"X500 with D455 camera: Active")
-            print(f"X500 camera handles: {len(self.x500_camera_handles)} cameras")
-            print(f"X500 camera specs: D455 (270x480, 87° FOV, 0.2-15m range)")
-            if len(self.x500_camera_handles) > 0:
-                print(f"X500 camera handle IDs: {self.x500_camera_handles}")
-            else:
-                print("⚠️  WARNING: X500 created but no camera handles found!")
-        
-        if self.controller is not None:
-            hover_pos = self.hover_target.cpu().numpy()
-            print(f"Hover target position: [{hover_pos[0]:6.2f}, {hover_pos[1]:6.2f}, {hover_pos[2]:6.2f}]")
-        
-        print("="*60)
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        cv2.destroyAllWindows()
-        
-        if hasattr(self, 'viewer') and self.viewer is not None:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if hasattr(self, 'sim') and self.sim is not None:
-            self.gym.destroy_sim(self.sim)
-
-        print("✓ Cleanup completed")
-
-def main():
-    """Main function."""
-    try:
-        print("🚁 Starting Gate Navigation with Dual Cameras and Position Control...")
-        
-        # Create environment
-        env = GateEnvironmentWithPositionControl(headless=False)
-        
-        # Print environment information
-        env.print_environment_info()
-        
-        # Run navigation and visualization
-        env.run_navigation_and_visualization(duration=180.0)  # 3 minutes
-        
-    except KeyboardInterrupt:
-        print("\n⚠️ Interrupted by user")
-    except Exception as e:
-        print(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        if 'env' in locals():
-            env.cleanup()
-        print("👋 Goodbye!")
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/simple_gate_visualization_with_camera_background_trees_X500_position_hover.py b/examples/simple_gate_visualization_with_camera_background_trees_X500_position_hover.py
deleted file mode 100644
index 5af7ba7..0000000
--- a/examples/simple_gate_visualization_with_camera_background_trees_X500_position_hover.py
+++ /dev/null
@@ -1,1228 +0,0 @@
-"""
-Simple Gate Visualization with Static Camera, X500 Robot with D455 Camera, and Position Control
-===============================================================================================
-
-This script creates a simple visualization of a gate environment with:
-1. A static depth camera using Isaac Gym native API
-2. An X500 quadrotor robot with D455 depth camera sensor
-3. Lee position controller for X500 hovering at a target position
-4. Real-time visualization of both camera outputs side-by-side
-
-Key features:
-- Gate environment with optional background trees
-- X500 quadrotor robot with onboard D455 camera
-- Static world-mounted camera positioned 3m from gate
-- Lee position controller for stable hovering
-- Real-time depth and segmentation image display from both cameras
-- Dual camera system: Static + Agent camera
-"""
-
-import os
-import sys
-import time
-import cv2
-import numpy as np
-
-# Isaac Gym must be imported first
-from isaacgym import gymapi, gymtorch, gymutil
-
-# Aerial Gym components
-from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-from aerial_gym.config.robot_config.x500_config import X500Cfg
-from aerial_gym.config.sensor_config.camera_config.d455_depth_config import RsD455Config
-from aerial_gym.config.controller_config.lee_controller_config import control as lee_controller_config
-from aerial_gym.control.controllers.position_control import LeePositionController
-from aerial_gym.control.control_allocation import ControlAllocator
-from aerial_gym.utils.math import *
-
-import torch
-
-# Create X500 config with D455 camera enabled and fixed control allocation
-class X500WithD455Cfg(X500Cfg):
-    """X500 configuration with D455 camera sensor enabled."""
-    
-    class sensor_config(X500Cfg.sensor_config):
-        enable_camera = True
-        camera_config = RsD455Config
-    
-    class robot_asset(X500Cfg.robot_asset):
-        name = "x500_with_d455"
-
-class GateEnvironmentWithPositionControl:
-    """
-    Gate environment with static camera, X500 robot with D455 camera, and Lee position controller for hovering.
-    """
-    
-    def __init__(self, headless=False):
-        """Initialize the environment."""
-        print("🚁 Initializing Gate Environment with Position Control...")
-        
-        self.headless = headless
-        self.device = "cuda" if torch.cuda.is_available() else "cpu"
-        self.num_envs = 1
-        self.dt = 1.0 / 60.0  # 60 FPS simulation
-        
-        # Environment handles (Isaac Gym)
-        self.env_handles = []
-        self.gate_handles = []
-        self.tree_handles = []
-        self.x500_handles = []
-        
-        # Static camera handles
-        self.camera_handles = []
-        self.camera_setup_success = False
-        
-        # X500 camera handles
-        self.x500_camera_handles = []
-        
-        # Control system
-        self.controller = None
-        self.control_allocator = None
-        
-        # Set hover target (just slightly above starting position for testing)
-        self.hover_target = torch.tensor([-2.5, 0.0, 1.2], device=self.device)  # 20cm above start
-        self.current_target = self.hover_target.clone()
-        
-        # Robot state tensors (for Isaac Gym rigid body states)
-        self.x500_rigid_body_states = None
-        
-        # Controller state tensors (derived from rigid body states)
-        self.robot_position = torch.zeros((self.num_envs, 3), device=self.device)
-        self.robot_orientation = torch.zeros((self.num_envs, 4), device=self.device)
-        self.robot_linvel = torch.zeros((self.num_envs, 3), device=self.device)
-        self.robot_angvel = torch.zeros((self.num_envs, 3), device=self.device)
-        
-        # Initialize gym
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        self._setup_static_camera()
-        self._setup_x500_with_camera()
-        self._setup_lee_position_controller()
-        
-        if not self.headless:
-            self._create_viewer()
-        
-        # Prepare simulation for rendering
-        self.gym.prepare_sim(self.sim)
-        
-        print("✅ Environment initialization complete!")
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Parse arguments
-        custom_parameters = [
-            {"name": "--headless", "action": "store_true", "help": "Run headless without viewer"},
-        ]
-        args = gymutil.parse_arguments(custom_parameters=custom_parameters)
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        print("✓ Isaac Gym initialized")
-    
-    def _create_sim(self):
-        """Create simulation."""
-        print("Creating simulation...")
-        
-        # Simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = self.dt
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        
-        # Physics backend
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 4
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.contact_offset = 0.01
-        sim_params.physx.rest_offset = 0.0
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)
-        if self.sim is None:
-            raise Exception("Failed to create simulation")
-        
-        print("✓ Simulation created")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
-        plane_params.distance = 0.0
-        self.gym.add_ground(self.sim, plane_params)
-    
-        print("✓ Ground plane created")
-    
-    def _load_gate_asset(self):
-        """Load gate asset."""
-        print(f"Loading gate asset from: {gate_asset_params.file}")
-        
-        # Asset loading options
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        
-        # Load asset
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise Exception(f"Failed to load gate asset: {gate_asset_params.file}")
-        
-        print("✓ Gate asset loaded successfully")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create environment with gate and optional trees."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Gate on ground level
-        
-        # Rotate gate by 90 degrees around Z-axis so trees are directly behind it
-        import math
-        gate_pose.r = gymapi.Quat(0.0, 0.0, math.sin(math.pi/4), math.cos(math.pi/4))  # 90° rotation around Z-axis
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Set gate color for better visibility
-        self.gym.set_rigid_body_color(
-            env_handle, gate_handle, 0, 
-            gymapi.MESH_VISUAL, gymapi.Vec3(0.2, 0.2, 0.8)  # blue-ish
-        )
-        
-        # Add some trees behind the gate for better visualization
-        self._add_background_trees(env_handle)
-        
-        print("✓ Environment created with gate!")
-    
-    def _add_background_trees(self, env_handle):
-        """Add some trees behind the gate for better camera visualization."""
-        print("Adding background trees...")
-        
-        try:
-            # Load a tree asset from the existing tree models
-            tree_asset_folder = f"{gate_asset_params.asset_folder}/../trees"
-            available_trees = ["tree_0.urdf", "tree_1.urdf", "tree_2.urdf", "tree_3.urdf", "tree_4.urdf"]
-            
-            # Add trees at various positions behind the gate (negative Y from camera perspective)
-            tree_positions = [
-                (-2.0, 3.0, 0.0),   # Left behind gate
-                (0.0, 4.0, 0.0),    # Directly behind gate
-                (2.0, 3.0, 0.0),    # Right behind gate
-                (-1.0, 5.0, 0.0),   # Further behind, left
-                (1.0, 5.0, 0.0),    # Further behind, right
-            ]
-            
-            for i, (x, y, z) in enumerate(tree_positions):
-                if i >= len(available_trees):
-                    break
-                    
-                tree_file = available_trees[i]
-                tree_path = f"{tree_asset_folder}/{tree_file}"
-                
-                # Check if tree file exists
-                if not os.path.exists(tree_path):
-                    print(f"Tree file not found: {tree_path}, skipping...")
-                    continue
-                
-                # Load tree asset
-                tree_asset_options = gymapi.AssetOptions()
-                tree_asset_options.fix_base_link = True
-                tree_asset_options.collapse_fixed_joints = True
-                tree_asset_options.disable_gravity = True
-                tree_asset_options.replace_cylinder_with_capsule = True
-                tree_asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-                
-                tree_asset = self.gym.load_asset(
-                    self.sim, 
-                    tree_asset_folder, 
-                    tree_file, 
-                    tree_asset_options
-                )
-                
-                if tree_asset is None:
-                    print(f"Failed to load tree asset: {tree_file}")
-                    continue
-                
-                # Create tree actor
-                tree_pose = gymapi.Transform()
-                tree_pose.p = gymapi.Vec3(x, y, z)
-                tree_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
-                
-                tree_handle = self.gym.create_actor(
-                    env_handle,
-                    tree_asset,
-                    tree_pose,
-                    f"tree_{i}",
-                    0,  # Collision group
-                    1   # Collision filter
-                )
-                
-                self.tree_handles.append(tree_handle)
-                
-                # Set tree color for variety
-                colors = [
-                    gymapi.Vec3(0.2, 0.6, 0.2),  # Green
-                    gymapi.Vec3(0.4, 0.8, 0.2),  # Light green
-                    gymapi.Vec3(0.1, 0.4, 0.1),  # Dark green
-                    gymapi.Vec3(0.3, 0.7, 0.3),  # Medium green
-                    gymapi.Vec3(0.5, 0.9, 0.1),  # Yellow-green
-                ]
-                color = colors[i % len(colors)]
-                self.gym.set_rigid_body_color(
-                    env_handle, tree_handle, 0, 
-                    gymapi.MESH_VISUAL, color
-                )
-                
-                print(f"Added tree {i+1} at position ({x}, {y}, {z})")
-                
-        except Exception as e:
-            print(f"Warning: Failed to add background trees: {e}")
-            print("Continuing without trees...") 
-    
-    def _setup_static_camera(self):
-        """Setup static camera using Isaac Gym native camera API."""
-        print("Setting up static camera using Isaac Gym native API...")
-        
-        try:
-            # Camera properties (D455 depth camera specifications)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = 1280  # D455 depth resolution
-            camera_props.height = 720  # D455 depth resolution
-            camera_props.horizontal_fov = 87.0  # D455 FOV
-            camera_props.near_plane = 0.4  # D455 minimum depth distance
-            camera_props.far_plane = 20.0  # D455 maximum range
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"Static camera properties (D455 specs): {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"Static camera depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-        
-            # Create camera sensor in each environment
-            self.camera_handles = []
-            for i, env_handle in enumerate(self.env_handles):
-                cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-                self.camera_handles.append(cam_handle)
-                print(f"Created static camera sensor {i} in environment {i}")
-            
-            # Position camera to face the gate directly (gate now rotated 90°)
-            camera_pos = gymapi.Vec3(0.0, -3.0, 1.5)  # 3m in front of gate, at gate center height
-            camera_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look directly at gate center
-            
-            # Set camera transform for each environment using look_at
-            for i, (env_handle, cam_handle) in enumerate(zip(self.env_handles, self.camera_handles)):
-                # Use Isaac Gym's camera look_at functionality
-                self.gym.set_camera_location(cam_handle, env_handle, camera_pos, camera_target)
-                print(f"Set static camera {i} to look from ({camera_pos.x}, {camera_pos.y}, {camera_pos.z}) toward ({camera_target.x}, {camera_target.y}, {camera_target.z})")
-            
-            print(f"✓ Static cameras positioned to face gate directly")
-            
-            self.camera_setup_success = True
-            
-        except Exception as e:
-            print(f"❌ ERROR: Isaac Gym static camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.camera_setup_success = False
-    
-    def _load_x500_asset(self):
-        """Load X500 robot asset with D455 camera."""
-        print(f"Loading X500 robot asset from: {X500WithD455Cfg.robot_asset.file}")
-        
-        # Asset loading options for X500
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = X500WithD455Cfg.robot_asset.fix_base_link
-        asset_options.collapse_fixed_joints = X500WithD455Cfg.robot_asset.collapse_fixed_joints
-        asset_options.disable_gravity = X500WithD455Cfg.robot_asset.disable_gravity
-        asset_options.replace_cylinder_with_capsule = X500WithD455Cfg.robot_asset.replace_cylinder_with_capsule
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET
-        asset_options.flip_visual_attachments = X500WithD455Cfg.robot_asset.flip_visual_attachments
-        asset_options.density = X500WithD455Cfg.robot_asset.density
-        asset_options.angular_damping = X500WithD455Cfg.robot_asset.angular_damping
-        asset_options.linear_damping = X500WithD455Cfg.robot_asset.linear_damping
-        asset_options.max_angular_velocity = X500WithD455Cfg.robot_asset.max_angular_velocity
-        asset_options.max_linear_velocity = X500WithD455Cfg.robot_asset.max_linear_velocity
-        asset_options.armature = X500WithD455Cfg.robot_asset.armature
-        
-        # Load X500 asset
-        x500_asset = self.gym.load_asset(
-            self.sim, 
-            X500WithD455Cfg.robot_asset.asset_folder, 
-            X500WithD455Cfg.robot_asset.file, 
-            asset_options
-        )
-        
-        if x500_asset is None:
-            raise Exception(f"Failed to load X500 robot asset: {X500WithD455Cfg.robot_asset.file}")
-        
-        print("✓ X500 robot asset loaded successfully")
-        return x500_asset
-
-    def _setup_x500_with_camera(self):
-        """Setup X500 drone with D455 camera in the same environment."""
-        print("Setting up X500 drone with D455 camera...")
-        
-        try:
-            # Load X500 asset
-            x500_asset = self._load_x500_asset()
-            
-            # Get the first environment handle
-            env_handle = self.env_handles[0]
-            
-            # Set X500 initial position and orientation
-            x500_start_pos = gymapi.Vec3(-2.5, 0.0, 1.0)  # Start at hover target position
-            x500_start_rot = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # No rotation
-            x500_pose = gymapi.Transform(x500_start_pos, x500_start_rot)
-            
-            # Create X500 robot actor
-            x500_handle = self.gym.create_actor(
-                env_handle, x500_asset, x500_pose, "x500", 0, 0
-            )
-            
-            # Debug: Verify the actual spawn position
-            actual_pose = self.gym.get_actor_rigid_body_states(env_handle, x500_handle, gymapi.STATE_POS)
-            print(f"Debug: X500 actual spawn position: {actual_pose['pose']['p']}")
-            print(f"Debug: X500 intended spawn position: (-2.5, 0.0, 1.0)")
-            
-            # Enable actor DOF for control
-            self.gym.enable_actor_dof_force_sensors(env_handle, x500_handle)
-            
-            self.x500_handles = [x500_handle]
-            
-            # Set X500 color for better visibility
-            self.gym.set_rigid_body_color(
-                env_handle, x500_handle, 0, 
-                gymapi.MESH_VISUAL, gymapi.Vec3(0.8, 0.8, 0.2)  # Yellow X500
-            )
-            
-            # Setup D455 camera on X500
-            self._setup_x500_camera(env_handle, x500_handle)
-            
-            # Get rigid body state tensor for X500
-            self._setup_x500_state_tensors()
-            
-            print("✓ X500 with D455 camera setup complete")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 with camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_handles = []
-    
-    def _setup_x500_camera(self, env_handle, x500_handle):
-        """Setup D455 camera on X500 drone."""
-        print("Setting up D455 camera on X500...")
-        
-        try:
-            # Camera properties (D455 specifications from config)
-            camera_props = gymapi.CameraProperties()
-            camera_props.width = RsD455Config.width  # 480
-            camera_props.height = RsD455Config.height  # 270
-            camera_props.horizontal_fov = RsD455Config.horizontal_fov_deg  # 87.0
-            camera_props.near_plane = RsD455Config.min_range  # 0.2
-            camera_props.far_plane = RsD455Config.max_range  # 15.0
-            camera_props.enable_tensors = True  # Enable GPU tensor access
-            
-            print(f"X500 D455 camera properties: {camera_props.width}x{camera_props.height}, FOV: {camera_props.horizontal_fov}°")
-            print(f"X500 D455 depth range: {camera_props.near_plane}m - {camera_props.far_plane}m")
-            
-            # Create camera sensor attached to X500
-            x500_cam_handle = self.gym.create_camera_sensor(env_handle, camera_props)
-            print(f"Debug: Created X500 camera sensor with handle: {x500_cam_handle}")
-            
-            if x500_cam_handle is None:
-                raise Exception("Failed to create X500 camera sensor")
-            
-            # Attach camera to X500 base_link with forward-facing orientation
-            # Camera position relative to X500 base_link (slightly forward and up)
-            cam_pos = gymapi.Vec3(0.10, 0.0, 0.03)  # 10cm forward, 3cm up from center
-            
-            # Attach camera to X500
-            self.gym.attach_camera_to_body(
-                x500_cam_handle, env_handle, x500_handle,
-                gymapi.Transform(p=cam_pos), gymapi.FOLLOW_TRANSFORM
-            )
-            print(f"Debug: Attached camera to X500 body at position ({cam_pos.x}, {cam_pos.y}, {cam_pos.z})")
-            
-            # Store camera handle
-            self.x500_camera_handles = [x500_cam_handle]
-            
-            print("✓ D455 camera attached to X500")
-            print(f"Debug: X500 camera handles stored: {self.x500_camera_handles}")
-            
-        except Exception as e:
-            print(f"❌ ERROR: X500 camera setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-            self.x500_camera_handles = []
-    
-    def _setup_x500_state_tensors(self):
-        """Set up state tensors for X500 robot control."""
-        try:
-            print("Debug: Setting up X500 state tensors...")
-            
-            # Initialize state tensors on CPU (Isaac Gym physics runs on CPU)
-            device = "cpu"  # Force CPU to match Isaac Gym physics
-            
-            # Robot state tensors (1 environment)
-            self.robot_position = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            self.robot_orientation = torch.zeros((1, 4), device=device, dtype=torch.float32)
-            self.robot_linvel = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            self.robot_angvel = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            self.robot_euler_angles = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            
-            # Body frame velocities
-            self.robot_body_linvel = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            self.robot_body_angvel = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            
-            # Vehicle frame states
-            self.robot_vehicle_orientation = torch.zeros((1, 4), device=device, dtype=torch.float32)
-            self.robot_vehicle_linvel = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            
-            # Get Isaac Gym actor root state tensor
-            actor_root_state = self.gym.acquire_actor_root_state_tensor(self.sim)
-            self.actor_root_states = gymtorch.wrap_tensor(actor_root_state)
-            
-            # CRITICAL: Refresh the tensor to get actual actor positions after simulation setup
-            self.gym.refresh_actor_root_state_tensor(self.sim)
-            
-            print(f"Debug: Total actors in root state tensor: {len(self.actor_root_states)}")
-            
-            # Debug: Print initial actor positions AFTER refresh
-            for i in range(min(3, len(self.actor_root_states))):
-                pos = self.actor_root_states[i][:3]
-                print(f"Debug: Actor {i}: pos=[{pos[0]:.2f}, {pos[1]:.2f}, {pos[2]:.2f}]")
-            
-            # Find X500 actor index - it should be the second actor (gate=0, X500=1, trees=2-6)
-            self.x500_actor_idx = 1
-            
-            # Verify X500 position matches expected spawn location
-            if len(self.actor_root_states) > self.x500_actor_idx:
-                x500_state = self.actor_root_states[self.x500_actor_idx]
-                x500_pos = x500_state[:3].cpu()  # Convert to CPU for comparison
-                expected_pos = torch.tensor([-2.5, 0.0, 1.0], device="cpu")
-                
-                # Check if position is close to expected (within 0.5m tolerance)
-                pos_diff = torch.norm(x500_pos - expected_pos).item()
-                if pos_diff < 0.5:
-                    print(f"✓ X500 actor found at index {self.x500_actor_idx}, position: {x500_pos}")
-                    self._update_robot_state()  # Initial state update
-                else:
-                    print(f"⚠️  Actor {self.x500_actor_idx} position {x500_pos} doesn't match expected X500 position {expected_pos}")
-                    # Try to find the correct X500 actor
-                    for i in range(len(self.actor_root_states)):
-                        actor_pos = self.actor_root_states[i][:3].cpu()
-                        if torch.norm(actor_pos - expected_pos).item() < 0.5:
-                            self.x500_actor_idx = i
-                            print(f"✓ Found X500 at actor index {i}")
-                            self._update_robot_state()
-                            break
-                    else:
-                        print("❌ Could not find X500 actor in state tensor")
-            else:
-                print(f"❌ Not enough actors in state tensor (expected at least {self.x500_actor_idx + 1})")
-                
-        except Exception as e:
-            print(f"❌ ERROR: X500 state tensor setup failed: {e}")
-            import traceback
-            traceback.print_exc()
-    
-    def _update_robot_state(self):
-        """Update robot state tensors from simulation."""
-        try:
-            # Refresh all relevant tensors from simulation
-            self.gym.refresh_actor_root_state_tensor(self.sim)
-            self.gym.refresh_rigid_body_state_tensor(self.sim)
-            
-            # Debug: Check raw tensor values every 60 steps
-            if hasattr(self, 'debug_step_count') and self.debug_step_count % 60 == 0:
-                x500_raw = self.actor_root_states[self.x500_actor_idx]
-                print(f"Debug Raw Tensor - X500 state: pos=[{x500_raw[0]:.2f}, {x500_raw[1]:.2f}, {x500_raw[2]:.2f}]")
-            
-            # Update robot state from root state tensor
-            # Root state tensor format: [pos_x, pos_y, pos_z, quat_x, quat_y, quat_z, quat_w, vel_x, vel_y, vel_z, angvel_x, angvel_y, angvel_z]
-            x500_state = self.actor_root_states[self.x500_actor_idx]
-            
-            # Update position, orientation, and velocities
-            self.robot_position[0, :] = x500_state[0:3]
-            self.robot_orientation[0, :] = x500_state[3:7]  # quaternion
-            self.robot_linvel[0, :] = x500_state[7:10]
-            self.robot_angvel[0, :] = x500_state[10:13]
-            
-            # Convert quaternion to euler angles for controller
-            from aerial_gym.utils.math import get_euler_xyz_tensor
-            self.robot_euler_angles[0] = get_euler_xyz_tensor(self.robot_orientation[0].unsqueeze(0))[0]
-            
-            # Convert global velocities to body frame (simplified approach)
-            self.robot_body_linvel[0] = self.robot_linvel[0]
-            self.robot_body_angvel[0] = self.robot_angvel[0]
-            
-            # Update vehicle orientation and velocity for controller
-            self.robot_vehicle_orientation[0] = self.robot_orientation[0]
-            self.robot_vehicle_linvel[0] = self.robot_linvel[0]
-            
-            # Debug: Print position update every 60 steps
-            if hasattr(self, 'debug_step_count') and self.debug_step_count % 60 == 0:
-                pos = self.robot_position[0].cpu().numpy()
-                print(f"Debug State Update - Position: [{pos[0]:.2f}, {pos[1]:.2f}, {pos[2]:.2f}]")
-                
-        except Exception as e:
-            print(f"Error updating robot state: {e}")
-            import traceback
-            traceback.print_exc()
-    
-    def _step_physics_and_update_state(self):
-        """Step physics simulation and update robot state - following DCE RL pattern."""
-        try:
-            # Step the physics simulation
-            self.gym.simulate(self.sim)
-            self.gym.fetch_results(self.sim, True)
-            
-            # Update robot state from simulation (this is the key missing piece!)
-            self._update_robot_state()
-            
-        except Exception as e:
-            print(f"Error in physics step: {e}")
-            import traceback
-            traceback.print_exc()
-
-    def _setup_lee_position_controller(self):
-        """Set up Lee position controller for X500."""
-        print("Setting up Lee position controller for X500...")
-        
-        try:
-            # Import Lee position controller from the correct module
-            from aerial_gym.control.controllers.position_control import LeePositionController
-            from aerial_gym.control.control_allocation import ControlAllocator
-            from aerial_gym.config.controller_config.lee_controller_config import control as lee_controller_config
-            
-            # Initialize controller with proper device
-            device = "cpu"  # Match Isaac Gym physics device
-            dt = 1.0/60.0  # 60 Hz simulation
-            
-            # Create controller config
-            config = lee_controller_config()
-            
-            # Get X500 motor indices for application mask
-            env_handle = self.env_handles[0]
-            x500_handle = self.x500_handles[0]
-            
-            # X500 motor names in order
-            motor_names = ["front_right_prop", "back_left_prop", "front_left_prop", "back_right_prop"]
-            self.application_mask = []
-            
-            for motor_name in motor_names:
-                try:
-                    motor_idx = self.gym.find_actor_rigid_body_index(
-                        env_handle, x500_handle, motor_name, gymapi.DOMAIN_ACTOR
-                    )
-                    self.application_mask.append(motor_idx)
-                except:
-                    print(f"Warning: Could not find motor '{motor_name}', using fallback index")
-                    self.application_mask.append(len(self.application_mask) + 1)
-            
-            print(f"X500 motor application mask: {self.application_mask}")
-            
-            # Create control allocator config object (similar to X500Cfg.control_allocator_config)
-            class ControlAllocatorConfig:
-                def __init__(self):
-                    self.num_motors = 4
-                    self.force_application_level = "motor_link"  # Apply forces at motor level
-                    self.motor_directions = [1, 1, -1, -1]  # X500 motor directions
-                    
-                    # X500 allocation matrix (from X500 config)
-                    self.allocation_matrix = [
-                        [0.0, 0.0, 0.0, 0.0],  # Fx
-                        [0.0, 0.0, 0.0, 0.0],  # Fy
-                        [1.0, 1.0, 1.0, 1.0],  # Fz (thrust)
-                        [-0.13, 0.13, 0.13, -0.13],  # Mx (roll)
-                        [-0.13, 0.13, -0.13, 0.13],   # My (pitch)
-                        [-0.025, 0.025, -0.025, 0.025]  # Mz (yaw)
-                    ]
-                    
-                    # Motor model config
-                    class MotorModelConfig:
-                        def __init__(self):
-                            self.use_rps = True
-                            self.motor_thrust_constant_min = 8.54858e-6
-                            self.motor_thrust_constant_max = 8.54858e-6
-                            self.motor_time_constant_increasing_min = 0.0125
-                            self.motor_time_constant_increasing_max = 0.0125
-                            self.motor_time_constant_decreasing_min = 0.025
-                            self.motor_time_constant_decreasing_max = 0.025
-                            self.max_thrust = 20.0
-                            self.min_thrust = 0.0
-                            self.max_thrust_rate = 100000.0
-                            self.thrust_to_torque_ratio = 0.025
-                            self.use_discrete_approximation = False
-                    
-                    self.motor_model_config = MotorModelConfig()
-            
-            # Create control allocator config and set application mask
-            control_alloc_config = ControlAllocatorConfig()
-            control_alloc_config.application_mask = self.application_mask
-            
-            # Initialize Lee position controller
-            self.lee_controller = LeePositionController(config, 1, device)  # config, num_envs, device
-            
-            # Set up target position tensor
-            self.target_position = torch.zeros((1, 3), device=device, dtype=torch.float32)
-            
-            # Initialize control allocator for X500 with proper config
-            self.control_allocator = ControlAllocator(
-                num_envs=1,
-                dt=dt,
-                config=control_alloc_config,
-                device=device
-            )
-            
-            # Initialize robot mass and inertia for controller
-            self.robot_mass = torch.tensor([1.5], device=device, dtype=torch.float32)  # X500 mass ~1.5kg
-            
-            # X500 inertia matrix (approximate values for quadrotor)
-            self.robot_inertia = torch.tensor([
-                [0.029, 0.0, 0.0],
-                [0.0, 0.029, 0.0], 
-                [0.0, 0.0, 0.055]
-            ], device=device, dtype=torch.float32).unsqueeze(0)  # Add batch dimension
-            
-            # Initialize controller tensors with global tensor dict
-            global_tensor_dict = {
-                "robot_position": self.robot_position,
-                "robot_orientation": self.robot_orientation,
-                "robot_euler_angles": self.robot_euler_angles,
-                "robot_linvel": self.robot_linvel,
-                "robot_angvel": self.robot_angvel,
-                "robot_body_angvel": self.robot_body_angvel,
-                "robot_body_linvel": self.robot_body_linvel,
-                "robot_vehicle_orientation": self.robot_vehicle_orientation,
-                "robot_vehicle_linvel": self.robot_vehicle_linvel,
-                "robot_inertia": self.robot_inertia,
-                "robot_mass": self.robot_mass,
-                "gravity": torch.tensor([0.0, 0.0, -9.81], device=device).expand(1, 3),
-            }
-            
-            self.lee_controller.init_tensors(global_tensor_dict)
-            
-            print("✓ Lee position controller initialized")
-            print(f"Controller gains - Position: {config.K_pos_tensor_max}")
-            print(f"Controller gains - Velocity: {config.K_vel_tensor_max}")
-            print(f"Current hover target: {self.target_position[0].cpu().numpy()}")
-            
-        except Exception as e:
-            print(f"❌ Failed to setup Lee position controller: {e}")
-            import traceback
-            traceback.print_exc()
-            raise
-
-    def _create_viewer(self):
-        """Create viewer."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Viewer camera properties
-        cam_props = gymapi.CameraProperties()
-        viewer = self.gym.create_viewer(self.sim, cam_props)
-        
-        if viewer is None:
-            raise Exception("Failed to create viewer")
-        
-        # Set viewer camera
-        cam_pos = gymapi.Vec3(-5.0, -5.0, 3.0)
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.0)
-        self.gym.viewer_camera_look_at(viewer, None, cam_pos, cam_target)
-        
-        self.viewer = viewer
-        print("✓ Viewer created")
-    
-    def _apply_control(self):
-        """Apply Lee position controller to make X500 follow waypoints."""
-        # This method is now integrated into the main control loop in run_navigation
-        # Remove this method to avoid confusion
-        pass
-
-    def _render_frame(self):
-        """Render the current frame."""
-        if not self.headless:
-            # Step graphics
-            self.gym.step_graphics(self.sim)
-            self.gym.draw_viewer(self.viewer, self.sim, True)
-            
-            # Handle viewer events
-            if self.gym.query_viewer_has_closed(self.viewer):
-                return False
-        return True
-
-    def capture_all_camera_images(self):
-        """Capture depth and segmentation images from both cameras."""
-        static_depth, static_seg = None, None
-        x500_depth, x500_seg = None, None
-        
-        try:
-            # Step graphics and render all cameras once
-            self.gym.step_graphics(self.sim)
-            self.gym.render_all_camera_sensors(self.sim)
-            self.gym.start_access_image_tensors(self.sim)
-            
-            env_handle = self.env_handles[0]
-            
-            # Capture static camera images
-            if self.camera_setup_success and len(self.camera_handles) > 0:
-                try:
-                    cam_handle = self.camera_handles[0]
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    static_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    static_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    
-                except Exception as e:
-                    print(f"Error capturing static camera: {e}")
-            
-            # Capture X500 camera images
-            if len(self.x500_camera_handles) > 0:
-                try:
-                    x500_cam_handle = self.x500_camera_handles[0]
-                    
-                    # Get depth image
-                    depth_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_DEPTH
-                    )
-                    x500_depth = gymtorch.wrap_tensor(depth_tensor).cpu().numpy()
-                    
-                    # Get segmentation image
-                    seg_tensor = self.gym.get_camera_image_gpu_tensor(
-                        self.sim, env_handle, x500_cam_handle, gymapi.IMAGE_SEGMENTATION
-                    )
-                    x500_seg = gymtorch.wrap_tensor(seg_tensor).cpu().numpy()
-                    
-                except Exception as e:
-                    print(f"Error capturing X500 camera: {e}")
-            
-            # End access to image tensors
-            self.gym.end_access_image_tensors(self.sim)
-            
-            return (static_depth, static_seg), (x500_depth, x500_seg)
-                
-        except Exception as e:
-            print(f"Error in capture_all_camera_images: {e}")
-            import traceback
-            traceback.print_exc()
-            return (None, None), (None, None) 
-
-    def create_combined_image(self, depth_img, seg_img, title="Camera"):
-        """Create combined visualization of depth and segmentation images."""
-        if depth_img is None or seg_img is None:
-            return None
-        
-        # Normalize depth image for visualization
-        depth_norm = depth_img.copy()
-        
-        # Replace -inf with maximum depth value
-        depth_norm[depth_norm == -np.inf] = 10.0
-        
-        # Take absolute value to handle negative depths (coordinate system issue)
-        depth_norm = np.abs(depth_norm)
-        
-        # Clip to reasonable range (0 to 10 meters for D455 range)
-        depth_norm = np.clip(depth_norm, 0, 10.0)  
-        depth_norm = (depth_norm / 10.0 * 255).astype(np.uint8)
-        depth_colored = cv2.applyColorMap(depth_norm, cv2.COLORMAP_JET)
-        
-        # Normalize segmentation image for visualization
-        seg_norm = seg_img.copy()
-        
-        # If segmentation has limited values, enhance the contrast
-        unique_segs = np.unique(seg_norm)
-        if len(unique_segs) > 1:
-            # Map each unique segment to a distinct value
-            seg_enhanced = np.zeros_like(seg_norm)
-            for i, val in enumerate(unique_segs):
-                seg_enhanced[seg_norm == val] = i * (255 // len(unique_segs))
-            seg_colored = cv2.applyColorMap(seg_enhanced.astype(np.uint8), cv2.COLORMAP_PLASMA)
-        else:
-            # If only one segment, create a depth-based pseudo-segmentation
-            pseudo_seg = np.abs(depth_img).copy()
-            pseudo_seg[pseudo_seg == np.inf] = 10.0
-            pseudo_seg = np.clip(pseudo_seg, 0, 10.0)
-            pseudo_seg = (pseudo_seg / 10.0 * 255).astype(np.uint8)
-            seg_colored = cv2.applyColorMap(pseudo_seg, cv2.COLORMAP_PLASMA)
-        
-        # Create combined image (side by side)
-        h, w = depth_colored.shape[:2]
-        combined = np.zeros((h, w * 2, 3), dtype=np.uint8)
-        combined[:, :w] = depth_colored
-        combined[:, w:] = seg_colored
-        
-        # Add labels
-        font = cv2.FONT_HERSHEY_SIMPLEX
-        cv2.putText(combined, "Depth", (10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, "Segmentation", (w + 10, 30), font, 0.7, (255, 255, 255), 2)
-        cv2.putText(combined, title, (w // 2 - 50, h - 20), font, 0.5, (255, 255, 255), 1)
-        
-        return combined
-    
-    def run_navigation(self, duration_seconds=180.0):
-        """Main navigation loop with position control."""
-        print(f"Starting navigation and visualization for {duration_seconds} seconds...")
-        print("Press ESC to exit early")
-        
-        # Initialize step counter for debug output
-        self.debug_step_count = 0
-        
-        # Initialize hover task
-        hover_target = torch.tensor([-2.5, 0.0, 1.2], device="cpu")  # 20cm above spawn position
-        print(f"Hovering task: X500 will hover at target position {hover_target.numpy()}")
-        
-        start_time = time.time()
-        
-        while not self.gym.query_viewer_has_closed(self.viewer):
-            current_time = time.time()
-            if current_time - start_time > duration_seconds:
-                break
-                
-            # Get current robot position
-            current_pos = self.robot_position[0].clone()
-            
-            # Debug control output every 60 steps
-            if self.debug_step_count % 60 == 0:
-                pos_np = current_pos.cpu().numpy()
-                target_np = hover_target.cpu().numpy()
-                error = hover_target - current_pos
-                distance = torch.norm(error).item()
-                print(f"Debug Control - Pos: [{pos_np[0]:.2f}, {pos_np[1]:.2f}, {pos_np[2]:.2f}], Target: [{target_np[0]:.2f}, {target_np[1]:.2f}, {target_np[2]:.2f}]")
-                print(f"Debug Control - Error: [{error[0]:.2f}, {error[1]:.2f}, {error[2]:.2f}], Distance: {distance:.2f}m")
-            
-            # Run Lee position controller
-            try:
-                # Set target position
-                self.target_position[0] = hover_target
-                
-                # Create command actions for Lee controller: [x, y, z, yaw]
-                command_actions = torch.zeros((1, 4), device="cpu")
-                command_actions[0, 0:3] = hover_target  # Target position
-                command_actions[0, 3] = 0.0  # Target yaw (face forward)
-                
-                # Compute control wrench using Lee position controller
-                wrench = self.lee_controller.update(command_actions)
-                
-                # Debug wrench every 60 steps
-                if self.debug_step_count % 60 == 0:
-                    wrench_np = wrench[0].cpu().numpy()
-                    print(f"Debug Control - Wrench: [{wrench_np[0]:.2f}, {wrench_np[1]:.2f}, {wrench_np[2]:.2f}, {wrench_np[3]:.2f}, {wrench_np[4]:.2f}, {wrench_np[5]:.2f}]")
-                
-                # Allocate motor forces using control allocator
-                try:
-                    # Use the correct method name and parameters for ControlAllocator
-                    # Since we have a wrench from Lee controller, use "wrench" mode to convert wrench -> motor thrusts -> motor forces
-                    motor_forces, motor_torques = self.control_allocator.allocate_output(wrench, "wrench")
-                    
-                    # Debug motor forces every 60 steps
-                    if self.debug_step_count % 60 == 0:
-                        motor_forces_np = motor_forces[0].cpu().numpy()
-                        motor_torques_np = motor_torques[0].cpu().numpy()
-                        print(f"Debug Motor Forces (N): {motor_forces_np}")
-                        print(f"Debug Motor Torques (Nm): {motor_torques_np}")
-                        
-                        # Check if forces are reasonable magnitude
-                        total_thrust = torch.sum(motor_forces[0, :, 2]).item()  # Sum Z forces
-                        print(f"Debug Total Thrust: {total_thrust:.2f}N (need ~{1.5*9.81:.1f}N to hover)")
-                        
-                    # Apply motor forces to X500
-                    self._apply_motor_forces(motor_forces)
-                    
-                except Exception as e:
-                    print(f"Control allocation error: {e}")
-                    import traceback
-                    traceback.print_exc()
-                
-            except Exception as e:
-                print(f"Lee controller error: {e}")
-                import traceback
-                traceback.print_exc()
-            
-            # Step physics and update state (this is the crucial missing piece!)
-            self._step_physics_and_update_state()
-            
-            # Update cameras and visualization
-            self._update_cameras()
-            self._render_frame()
-            
-            self.debug_step_count += 1
-        
-        print(f"\n✅ Navigation completed after {current_time - start_time:.1f} seconds")
-    
-    def print_environment_info(self):
-        """Print information about the environment."""
-        print("\n" + "="*60)
-        print("DUAL CAMERA POSITION CONTROL ENVIRONMENT INFORMATION")
-        print("="*60)
-        print(f"Number of environments: {self.num_envs}")
-        print(f"Device: {self.device}")
-        print(f"Gate asset: {gate_asset_params.file}")
-        print(f"Static camera setup success: {self.camera_setup_success}")
-        print(f"Number of static cameras: {len(self.camera_handles)}")
-        print(f"Number of trees: {len(self.tree_handles)}")
-        print(f"Number of X500 robots: {len(self.x500_handles)}")
-        print(f"X500 with D455 setup: {'Success' if len(self.x500_handles) > 0 else 'Failed'}")
-        print(f"Lee Position Controller: {'Active' if self.controller is not None else 'Failed'}")
-        
-        if self.camera_setup_success:
-            print(f"Static camera position: (0, -3, 1.5)")
-            print(f"Static camera target: (0, 0, 1.5) - gate center")
-            print(f"Gate position: (0, 0, 0) - rotated 90°")
-        
-        if len(self.x500_handles) > 0:
-            print(f"X500 start position: (-2.5, 0, 1.0)")
-            print(f"X500 with D455 camera: Active")
-            print(f"X500 camera handles: {len(self.x500_camera_handles)} cameras")
-            print(f"X500 camera specs: D455 (270x480, 87° FOV, 0.2-15m range)")
-            if len(self.x500_camera_handles) > 0:
-                print(f"X500 camera handle IDs: {self.x500_camera_handles}")
-            else:
-                print("⚠️  WARNING: X500 created but no camera handles found!")
-        
-        if self.controller is not None:
-            hover_pos = self.hover_target.cpu().numpy()
-            print(f"Hover target position: [{hover_pos[0]:6.2f}, {hover_pos[1]:6.2f}, {hover_pos[2]:6.2f}]")
-        
-        print("="*60)
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        cv2.destroyAllWindows()
-        
-        if hasattr(self, 'viewer') and self.viewer is not None:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if hasattr(self, 'sim') and self.sim is not None:
-            self.gym.destroy_sim(self.sim)
-
-        print("✓ Cleanup completed")
-
-    def _update_cameras(self):
-        """Update camera images and capture data."""
-        # Capture all camera images at once
-        (static_depth, static_seg), (x500_depth, x500_seg) = self.capture_all_camera_images()
-        
-        # Store for display
-        self.static_depth = static_depth
-        self.static_seg = static_seg  
-        self.x500_depth = x500_depth
-        self.x500_seg = x500_seg
-        
-    def _update_display(self):
-        """Update display and handle viewer events."""
-        # Display static camera images
-        if hasattr(self, 'static_depth') and self.static_depth is not None and self.static_seg is not None:
-            # Create combined visualization for static camera
-            static_combined = self.create_combined_image(self.static_depth, self.static_seg, "Static Camera")
-            
-            if static_combined is not None:
-                # Display static camera images
-                cv2.imshow("Static Camera View", static_combined)
-                
-                # Print depth statistics periodically
-                if hasattr(self, 'debug_step_count') and self.debug_step_count % 60 == 0:  # Every second at 60 FPS
-                    # Filter out -inf values for better statistics
-                    valid_depths = self.static_depth[self.static_depth != -np.inf]
-                    if len(valid_depths) > 0:
-                        # Use absolute values for meaningful distance measurements
-                        abs_valid_depths = np.abs(valid_depths)
-                        min_depth = np.min(abs_valid_depths)
-                        max_depth = np.max(abs_valid_depths)
-                        mean_depth = np.mean(abs_valid_depths)
-                        total_pixels = self.static_depth.size
-                        valid_ratio = len(valid_depths) / total_pixels * 100
-                        
-                        # Print robot position and target
-                        current_pos = self.robot_position[0].cpu().numpy()
-                        target_pos = self.current_target.cpu().numpy()
-                        distance_to_target = torch.norm(self.robot_position[0] - self.current_target).item()
-                        
-                        print(f"Step {self.debug_step_count}: Static Camera - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                              f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-                        print(f"          X500 Pos: [{current_pos[0]:.2f}, {current_pos[1]:.2f}, {current_pos[2]:.2f}], "
-                              f"Target: [{target_pos[0]:.2f}, {target_pos[1]:.2f}, {target_pos[2]:.2f}], "
-                              f"Dist: {distance_to_target:.2f}m, Hover Target")
-        
-        # Display X500 camera images
-        if hasattr(self, 'x500_depth') and self.x500_depth is not None and self.x500_seg is not None:
-            # Create combined visualization for X500 camera
-            x500_combined = self.create_combined_image(self.x500_depth, self.x500_seg, "X500 D455")
-            
-            if x500_combined is not None:
-                # Display X500 camera images
-                cv2.imshow("X500 D455 Camera View", x500_combined)
-                
-                # Print X500 camera statistics periodically
-                if hasattr(self, 'debug_step_count') and self.debug_step_count % 60 == 0:
-                    valid_depths = self.x500_depth[self.x500_depth != -np.inf]
-                    if len(valid_depths) > 0:
-                        abs_valid_depths = np.abs(valid_depths)
-                        min_depth = np.min(abs_valid_depths)
-                        max_depth = np.max(abs_valid_depths)
-                        mean_depth = np.mean(abs_valid_depths)
-                        total_pixels = self.x500_depth.size
-                        valid_ratio = len(valid_depths) / total_pixels * 100
-                        print(f"          X500 D455 - Depth range: {min_depth:.2f}-{max_depth:.2f}m, "
-                              f"Mean: {mean_depth:.2f}m, Valid pixels: {valid_ratio:.1f}%")
-        elif hasattr(self, 'debug_step_count') and self.debug_step_count % 60 == 0:
-            print(f"          X500 D455 - No camera data available")
-        
-        # Handle viewer events
-        if not self.headless:
-            self.gym.step_graphics(self.sim)
-            self.gym.draw_viewer(self.viewer, self.sim, True)
-            if self.gym.query_viewer_has_closed(self.viewer):
-                return False  # Signal to exit
-        
-        # Check for ESC key press in OpenCV window
-        key = cv2.waitKey(1) & 0xFF
-        if key == 27:  # ESC key
-            print("ESC pressed, exiting navigation and visualization")
-            return False  # Signal to exit
-            
-        return True  # Continue running
-
-    def _apply_motor_forces(self, motor_forces):
-        """Apply computed motor forces to X500 motors in the simulation."""
-        try:
-            # Initialize force tensors if not already done
-            if not hasattr(self, 'force_tensors_initialized'):
-                self._init_force_tensors()
-            
-            # Clear existing forces
-            self.global_force_tensor.zero_()
-            
-            # Apply forces to X500 motors
-            for i, motor_local_idx in enumerate(self.application_mask):
-                if i < motor_forces.shape[1]:
-                    # Get the global rigid body index for this motor
-                    env_handle = self.env_handles[0]
-                    x500_handle = self.x500_handles[0]
-                    
-                    motor_global_idx = self.gym.get_actor_rigid_body_index(
-                        env_handle, x500_handle, motor_local_idx, gymapi.DOMAIN_SIM
-                    )
-                    
-                    # Apply motor force (motor_forces shape: [1, 4, 3])
-                    motor_force = motor_forces[0, i].cpu()  # 3D force vector
-                    self.global_force_tensor[motor_global_idx, :] = motor_force
-                    
-                    # Debug: Print motor forces every 60 steps
-                    if hasattr(self, 'debug_step_count') and self.debug_step_count % 60 == 0:
-                        print(f"  Motor {i} (local_idx {motor_local_idx}, global_idx {motor_global_idx}): Force=[{motor_force[0]:.2f}, {motor_force[1]:.2f}, {motor_force[2]:.2f}]N")
-            
-            # Apply forces to simulation
-            self.gym.apply_rigid_body_force_tensors(
-                self.sim,
-                gymtorch.unwrap_tensor(self.global_force_tensor),
-                None,  # No torques for now
-                gymapi.ENV_SPACE
-            )
-            
-            # Debug: Print total force magnitude
-            if hasattr(self, 'debug_step_count') and self.debug_step_count % 60 == 0:
-                total_force = torch.sum(torch.abs(self.global_force_tensor)).item()
-                print(f"Debug: Total force magnitude applied to simulation: {total_force:.2f}N")
-                
-        except Exception as e:
-            print(f"Error applying motor forces: {e}")
-            import traceback
-            traceback.print_exc()
-    
-    def _init_force_tensors(self):
-        """Initialize force tensors for Isaac Gym."""
-        try:
-            # Get rigid body state tensor to determine dimensions
-            rigid_body_tensor = self.gym.acquire_rigid_body_state_tensor(self.sim)
-            rb_states = gymtorch.wrap_tensor(rigid_body_tensor)
-            num_rigid_bodies = rb_states.shape[0]
-            
-            # Create force tensor on CPU (Isaac Gym physics runs on CPU)
-            self.global_force_tensor = torch.zeros((num_rigid_bodies, 3), 
-                                                 device="cpu", requires_grad=False)
-            
-            self.force_tensors_initialized = True
-            print(f"✓ Force tensors initialized on CPU for {num_rigid_bodies} rigid bodies")
-            
-        except Exception as e:
-            print(f"Error initializing force tensors: {e}")
-            import traceback
-            traceback.print_exc()
-            self.force_tensors_initialized = False
-
-def main():
-    """Main function."""
-    try:
-        print("🚁 Starting Gate Navigation with Dual Cameras and Position Control...")
-        
-        # Create environment
-        env = GateEnvironmentWithPositionControl(headless=False)
-        
-        # Print environment information
-        env.print_environment_info()
-        
-        # Run navigation and visualization
-        env.run_navigation(duration_seconds=180.0)  # 3 minutes
-        
-    except KeyboardInterrupt:
-        print("\n⚠️ Interrupted by user")
-    except Exception as e:
-        print(f"❌ Error: {e}")
-        import traceback
-        traceback.print_exc()
-    finally:
-        # Cleanup
-        if 'env' in locals():
-            env.cleanup()
-        print("👋 Goodbye!")
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/static_camera_example.py b/examples/static_camera_example.py
deleted file mode 100644
index bc7830e..0000000
--- a/examples/static_camera_example.py
+++ /dev/null
@@ -1,242 +0,0 @@
-#!/usr/bin/env python3
-
-"""
-Example: Static Environment Camera with Multi-Agent Navigation
-
-This example demonstrates how to integrate a static environment camera 
-using the Warp rendering pipeline to observe multi-agent drone training.
-"""
-
-import torch
-import numpy as np
-import cv2
-import os
-from datetime import datetime
-
-def main():
-    print("=" * 60)
-    print("STATIC ENVIRONMENT CAMERA EXAMPLE")
-    print("=" * 60)
-    
-    # Import Aerial Gym components FIRST (before torch) to avoid IsaacGym conflicts
-    print("Importing Aerial Gym components...")
-    from aerial_gym.envs.navigation_task.multi_agent_navigation_task_config import MultiAgentFormationTaskConfigLight
-    from aerial_gym.algorithms.multi_agent_wrapper import create_multi_agent_env
-    from aerial_gym.sensors.warp.static_environment_camera import (
-        StaticEnvironmentCamera,
-        OverheadCameraConfig,
-        SideViewCameraConfig,
-        MultiAngleCameraConfig
-    )
-    
-    print("All imports successful!")
-    
-    # Create multi-agent environment
-    print("Creating multi-agent environment...")
-    
-    def create_config():
-        config = MultiAgentFormationTaskConfigLight()
-        config.task_config["num_envs"] = 1  # Single environment for demonstration
-        config.env_config["num_envs"] = 1
-        config.task_config["num_robots_per_env"] = 3
-        config.env_config["num_robots_per_env"] = 3
-        
-        # Enable Warp rendering (required for static cameras)
-        config.task_config["use_warp"] = True
-        config.sim_config["use_warp"] = True
-        
-        # Override environment to use better bounds
-        config.task_config["env_name"] = "env_with_obstacles"
-        config.sim_config["env_name"] = "env_with_obstacles"
-        
-        # Disable robot cameras to focus on static environment cameras
-        # You could also enable them for comparison
-        config.task_config["enable_onboard_cameras"] = False
-        
-        return config
-    
-    env = create_multi_agent_env(
-        task_config_class=create_config,
-        algorithm="mappo",
-        device="cuda" if torch.cuda.is_available() else "cpu",
-        headless=True,  # Use headless mode since we have our own camera
-        num_envs=1
-    )
-    
-    print("Environment created successfully!")
-    
-    # Get mesh IDs for Warp rendering (required for static cameras)
-    mesh_ids = env.task.sim_env.global_tensor_dict.get("CONST_WARP_MESH_ID_LIST")
-    if mesh_ids is None:
-        raise ValueError("Warp mesh IDs not available. Make sure use_warp=True in config.")
-    
-    device = env.task.device
-    
-    # Create different types of static cameras
-    print("Creating static environment cameras...")
-    
-    # 1. Overhead camera for bird's eye view
-    overhead_config = OverheadCameraConfig()
-    overhead_camera = StaticEnvironmentCamera(
-        camera_config=overhead_config,
-        num_envs=1,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    
-    # Set up overhead view 15m above the environment center
-    overhead_camera.set_overhead_view(height=15.0)
-    
-    # Create image tensors for overhead camera
-    overhead_pixels = torch.zeros(
-        (1, 1, overhead_config.height, overhead_config.width),
-        device=device, requires_grad=False
-    )
-    overhead_segmentation = torch.zeros(
-        (1, 1, overhead_config.height, overhead_config.width),
-        dtype=torch.int32, device=device, requires_grad=False
-    )
-    overhead_camera.set_image_tensors(overhead_pixels, overhead_segmentation)
-    
-    # 2. Side view camera
-    side_config = SideViewCameraConfig()
-    side_camera = StaticEnvironmentCamera(
-        camera_config=side_config,
-        num_envs=1,
-        mesh_ids_array=mesh_ids,
-        device=device
-    )
-    
-    # Set up side view 20m away, 8m high, looking from the side
-    side_camera.set_side_view(distance=20.0, height=8.0, angle_degrees=45.0)
-    
-    # Create image tensors for side camera
-    side_pixels = torch.zeros(
-        (1, 1, side_config.height, side_config.width),
-        device=device, requires_grad=False
-    )
-    side_segmentation = torch.zeros(
-        (1, 1, side_config.height, side_config.width),
-        dtype=torch.int32, device=device, requires_grad=False
-    )
-    side_camera.set_image_tensors(side_pixels, side_segmentation)
-    
-    print("Static cameras created and configured!")
-    
-    # Create output directory for captured images
-    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
-    output_dir = f"static_camera_output_{timestamp}"
-    os.makedirs(output_dir, exist_ok=True)
-    print(f"Images will be saved to: {output_dir}")
-    
-    # Simple policy for demonstration
-    class SimplePolicy(torch.nn.Module):
-        def __init__(self, obs_dim, action_dim):
-            super().__init__()
-            self.network = torch.nn.Sequential(
-                torch.nn.Linear(obs_dim, 64),
-                torch.nn.ReLU(),
-                torch.nn.Linear(64, 64),
-                torch.nn.ReLU(),
-                torch.nn.Linear(64, action_dim),
-                torch.nn.Tanh()
-            )
-            
-        def forward(self, x):
-            return self.network(x)
-    
-    # Get dimensions and create policies
-    obs_dim = list(env.observation_spaces.values())[0].shape[0]
-    action_dim = list(env.action_spaces.values())[0].shape[0]
-    
-    policies = {}
-    for agent_id in env.agent_ids:
-        policies[agent_id] = SimplePolicy(obs_dim, action_dim).to(device)
-    
-    print(f"Running demonstration with static camera recording...")
-    print(f"Agent IDs: {env.agent_ids}")
-    
-    # Run demonstration with camera recording
-    num_steps = 200  # Number of steps to record
-    
-    for step in range(num_steps):
-        # Reset environment if needed
-        if step == 0:
-            obs_dict = env.reset()
-            
-        # Get actions from policies
-        actions_dict = {}
-        for agent_env_key, obs in obs_dict.items():
-            agent_id = agent_env_key.split('_env_')[0]
-            obs_tensor = torch.FloatTensor(obs).unsqueeze(0).to(device)
-            
-            with torch.no_grad():
-                action = policies[agent_id](obs_tensor).squeeze(0).cpu().numpy()
-                actions_dict[agent_env_key] = action
-        
-        # Step environment
-        obs_dict, reward_dict, done_dict, _, info_dict = env.step(actions_dict)
-        
-        # Capture images from static cameras
-        overhead_camera.capture()
-        side_camera.capture()
-        
-        # Save images every 10 steps
-        if step % 10 == 0:
-            # Convert overhead camera image to numpy and save
-            overhead_img = overhead_pixels[0, 0].cpu().numpy()
-            overhead_img_normalized = (overhead_img * 255).astype(np.uint8)
-            cv2.imwrite(
-                os.path.join(output_dir, f"overhead_step_{step:04d}.png"),
-                overhead_img_normalized
-            )
-            
-            # Convert side camera image to numpy and save
-            side_img = side_pixels[0, 0].cpu().numpy()
-            side_img_normalized = (side_img * 255).astype(np.uint8)
-            cv2.imwrite(
-                os.path.join(output_dir, f"side_view_step_{step:04d}.png"),
-                side_img_normalized
-            )
-            
-            # Save segmentation images
-            overhead_seg = overhead_segmentation[0, 0].cpu().numpy().astype(np.uint8)
-            side_seg = side_segmentation[0, 0].cpu().numpy().astype(np.uint8)
-            
-            cv2.imwrite(
-                os.path.join(output_dir, f"overhead_seg_step_{step:04d}.png"),
-                overhead_seg * 50  # Scale for visibility
-            )
-            cv2.imwrite(
-                os.path.join(output_dir, f"side_seg_step_{step:04d}.png"),
-                side_seg * 50  # Scale for visibility
-            )
-            
-            print(f"Step {step}: Captured and saved images")
-            
-            # Print some statistics
-            if step % 50 == 0:
-                avg_rewards = {aid.split('_env_')[0]: reward_dict[aid] for aid in reward_dict.keys()}
-                print(f"Step {step}: Rewards = {avg_rewards}")
-        
-        # Check if episode ended
-        if any(done_dict.values()):
-            print(f"Episode ended at step {step}")
-            obs_dict = env.reset()
-    
-    print("\n" + "=" * 60)
-    print("STATIC CAMERA DEMONSTRATION COMPLETE")
-    print("=" * 60)
-    print(f"Images saved to: {output_dir}")
-    print("Files created:")
-    print("  - overhead_step_XXXX.png: Overhead depth images")
-    print("  - side_view_step_XXXX.png: Side view depth images") 
-    print("  - overhead_seg_step_XXXX.png: Overhead segmentation images")
-    print("  - side_seg_step_XXXX.png: Side view segmentation images")
-    print("\nYou can create videos from these images using:")
-    print(f"  ffmpeg -r 10 -i {output_dir}/overhead_step_%04d.png -vcodec libx264 overhead_video.mp4")
-    print(f"  ffmpeg -r 10 -i {output_dir}/side_view_step_%04d.png -vcodec libx264 side_video.mp4")
-
-
-if __name__ == "__main__":
-    main() 
\ No newline at end of file
diff --git a/examples/static_camera_gate_visualization.py b/examples/static_camera_gate_visualization.py
deleted file mode 100644
index 75b756f..0000000
--- a/examples/static_camera_gate_visualization.py
+++ /dev/null
@@ -1,344 +0,0 @@
-"""
-Simple Gate Visualization Demo
-
-This script creates and visualizes the gate environment using Isaac Gym.
-It spawns a gate in the environment and allows you to view it interactively.
-"""
-
-import sys
-import os
-import numpy as np
-import time
-
-# Add the aerial_gym path
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
-
-try:
-    # Import Isaac Gym and Aerial Gym components
-    import isaacgym
-    from isaacgym import gymapi, gymtorch, gymutil
-    
-    # Import aerial gym components
-    from aerial_gym.config.env_config.gate_env import GateEnvCfg
-    from aerial_gym.config.asset_config.gate_asset_config import gate_asset_params
-    from aerial_gym.env_manager.asset_manager import AssetManager
-    from aerial_gym.sim.sim_builder import SimBuilder
-    
-    print("✓ Successfully imported all required modules!")
-    
-except ImportError as e:
-    print(f"❌ Import error: {e}")
-    print("This might be due to missing dependencies or Python environment issues.")
-    sys.exit(1)
-
-
-class GateEnvironmentVisualizer:
-    """
-    A simple visualizer for the gate environment.
-    """
-    
-    def __init__(self, headless=False):
-        """
-        Initialize the gate environment visualizer.
-        
-        Args:
-            headless (bool): Whether to run in headless mode (no graphics)
-        """
-        self.headless = headless
-        self.gym = None
-        self.sim = None
-        self.viewer = None
-        self.env_handles = []
-        self.gate_handles = []
-        
-        # Environment parameters
-        self.num_envs = 1  # Single environment for visualization
-        self.env_spacing = 10.0  # Spacing between environments
-        
-        # Initialize the environment
-        self._initialize_gym()
-        self._create_sim()
-        self._create_ground_plane()
-        self._create_environments()
-        
-        if not self.headless:
-            self._create_viewer()
-            self._setup_camera()
-    
-    def _initialize_gym(self):
-        """Initialize Isaac Gym."""
-        print("Initializing Isaac Gym...")
-        
-        # Create gym instance
-        self.gym = gymapi.acquire_gym()
-        
-        # Configure simulation parameters
-        sim_params = gymapi.SimParams()
-        sim_params.dt = 1.0 / 60.0  # 60 FPS
-        sim_params.substeps = 2
-        sim_params.up_axis = gymapi.UP_AXIS_Z
-        sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.81)
-        
-        # Physics engine settings
-        sim_params.physx.solver_type = 1
-        sim_params.physx.num_position_iterations = 8
-        sim_params.physx.num_velocity_iterations = 1
-        sim_params.physx.rest_offset = 0.0
-        sim_params.physx.contact_offset = 0.001
-        sim_params.physx.friction_offset_threshold = 0.001
-        sim_params.physx.friction_correlation_distance = 0.0005
-        sim_params.physx.num_threads = 0
-        sim_params.physx.use_gpu = True
-        
-        # GPU settings
-        self.device = 'cuda:0'
-        sim_params.use_gpu_pipeline = True
-        
-        self.sim_params = sim_params
-        
-    def _create_sim(self):
-        """Create the simulation."""
-        print("Creating simulation...")
-        
-        # Create simulation
-        self.sim = self.gym.create_sim(
-            compute_device=0,
-            graphics_device=0 if not self.headless else -1,
-            type=gymapi.SIM_PHYSX,
-            params=self.sim_params
-        )
-        
-        if self.sim is None:
-            raise RuntimeError("Failed to create simulation")
-    
-    def _create_ground_plane(self):
-        """Create ground plane."""
-        print("Creating ground plane...")
-        
-        plane_params = gymapi.PlaneParams()
-        plane_params.normal = gymapi.Vec3(0, 0, 1)
-        plane_params.distance = 0
-        plane_params.static_friction = 1.0
-        plane_params.dynamic_friction = 1.0
-        plane_params.restitution = 0.0
-        
-        self.gym.add_ground(self.sim, plane_params)
-    
-    def _load_gate_asset(self):
-        """Load the gate asset."""
-        print("Loading gate asset...")
-        
-        # Asset loading options - simplified for static gate
-        asset_options = gymapi.AssetOptions()
-        asset_options.fix_base_link = True  # Gate is fixed in place
-        asset_options.collapse_fixed_joints = True
-        asset_options.disable_gravity = True  # Static object doesn't need gravity
-        asset_options.replace_cylinder_with_capsule = True
-        asset_options.mesh_normal_mode = gymapi.FROM_ASSET  # Use normals from asset
-        
-        # Load gate asset
-        gate_asset_path = f"{gate_asset_params.asset_folder}/{gate_asset_params.file}"
-        
-        if not os.path.exists(gate_asset_path):
-            print(f"❌ Gate URDF not found at: {gate_asset_path}")
-            print("Please ensure the gate URDF file exists!")
-            sys.exit(1)
-        
-        print(f"Loading gate from: {gate_asset_path}")
-        gate_asset = self.gym.load_asset(
-            self.sim, 
-            gate_asset_params.asset_folder, 
-            gate_asset_params.file, 
-            asset_options
-        )
-        
-        if gate_asset is None:
-            raise RuntimeError(f"Failed to load gate asset from {gate_asset_path}")
-        
-        print("✓ Gate asset loaded successfully!")
-        return gate_asset
-    
-    def _create_environments(self):
-        """Create the environments with gates."""
-        print("Creating environments...")
-        
-        # Load gate asset
-        gate_asset = self._load_gate_asset()
-        
-        # Environment bounds
-        env_lower = gymapi.Vec3(-8.0, -8.0, 0.0)
-        env_upper = gymapi.Vec3(8.0, 8.0, 8.0)
-        
-        # Create environment
-        env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
-        self.env_handles.append(env_handle)
-        
-        # Gate pose (center of environment)
-        gate_pose = gymapi.Transform()
-        gate_pose.p = gymapi.Vec3(0.0, 0.0, 0.0)  # Center position
-        gate_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)  # No rotation
-        
-        # Create gate actor
-        gate_handle = self.gym.create_actor(
-            env_handle,
-            gate_asset,
-            gate_pose,
-            "gate",
-            0,  # Collision group
-            1   # Collision filter
-        )
-        self.gate_handles.append(gate_handle)
-        
-        # Note: Gate color is set in the URDF material properties
-        # Isaac Gym will use the default material colors from the URDF
-        
-        print("✓ Environment created with gate!")
-    
-    def _create_viewer(self):
-        """Create the viewer for visualization."""
-        if self.headless:
-            return
-        
-        print("Creating viewer...")
-        
-        # Create viewer
-        self.viewer = self.gym.create_viewer(self.sim, gymapi.CameraProperties())
-        
-        if self.viewer is None:
-            raise RuntimeError("Failed to create viewer")
-    
-    def _setup_camera(self):
-        """Setup camera position for good gate viewing."""
-        if self.headless or self.viewer is None:
-            return
-        
-        print("Setting up camera...")
-        
-        # Position camera to get a good view of the gate
-        cam_pos = gymapi.Vec3(8.0, -8.0, 4.0)  # Position for angled view
-        cam_target = gymapi.Vec3(0.0, 0.0, 1.5)  # Look at center of gate
-        
-        self.gym.viewer_camera_look_at(self.viewer, None, cam_pos, cam_target)
-    
-    def run_visualization(self, duration=60.0, physics_mode=True):
-        """
-        Run the visualization loop.
-        
-        Args:
-            duration (float): How long to run the visualization in seconds
-            physics_mode (bool): Whether to run physics simulation or just render
-        """
-        print(f"Starting visualization for {duration} seconds...")
-        print("Controls:")
-        print("  - Mouse: Look around")
-        print("  - W/A/S/D: Move camera")
-        print("  - Q/E: Move camera up/down")
-        print("  - ESC: Exit")
-        
-        if physics_mode:
-            print("Running with physics simulation...")
-            # Prepare simulation
-            self.gym.prepare_sim(self.sim)
-        else:
-            print("Running in render-only mode (no physics)...")
-        
-        start_time = time.time()
-        
-        try:
-            while not self.gym.query_viewer_has_closed(self.viewer):
-                if physics_mode:
-                    # Step simulation - use simpler approach for static objects
-                    self.gym.simulate(self.sim)
-                    self.gym.fetch_results(self.sim, True)
-                
-                # Update viewer (this works even without physics)
-                self.gym.step_graphics(self.sim)
-                self.gym.draw_viewer(self.viewer, self.sim, True)
-                
-                # Check if duration exceeded
-                if time.time() - start_time > duration:
-                    print(f"Visualization completed after {duration} seconds.")
-                    break
-                
-                # Small delay to prevent excessive CPU usage
-                time.sleep(0.016)  # ~60 FPS
-                
-        except KeyboardInterrupt:
-            print("Visualization interrupted by user.")
-        except Exception as e:
-            print(f"Error during visualization loop: {e}")
-            print("Trying render-only mode...")
-            if physics_mode:
-                # Retry without physics
-                self.run_visualization(duration, physics_mode=False)
-    
-    def print_environment_info(self):
-        """Print information about the created environment."""
-        print("\n" + "="*60)
-        print("GATE ENVIRONMENT INFORMATION")
-        print("="*60)
-        
-        print(f"Number of environments: {len(self.env_handles)}")
-        print(f"Number of gates: {len(self.gate_handles)}")
-        print(f"Environment bounds: -8m to +8m in X,Y and 0m to +8m in Z")
-        print(f"Gate position: Center of environment (0, 0, 0)")
-        print(f"Gate dimensions: ~3m wide × 3m tall opening")
-        
-        if self.viewer:
-            print(f"Viewer: Active (interactive)")
-        else:
-            print(f"Viewer: Headless mode")
-        
-        print(f"Physics: Isaac Gym PhysX")
-        print(f"Simulation timestep: {self.sim_params.dt:.4f}s")
-    
-    def cleanup(self):
-        """Clean up resources."""
-        print("Cleaning up...")
-        
-        if self.viewer:
-            self.gym.destroy_viewer(self.viewer)
-        
-        if self.sim:
-            self.gym.destroy_sim(self.sim)
-
-
-def main():
-    """Main function to run the gate visualization."""
-    
-    print("GATE ENVIRONMENT VISUALIZATION")
-    print("="*60)
-    
-    # Check if gate URDF exists
-    gate_urdf_path = f"{gate_asset_params.asset_folder}/{gate_asset_params.file}"
-    if not os.path.exists(gate_urdf_path):
-        print(f"❌ Gate URDF file not found: {gate_urdf_path}")
-        print("Please create the gate URDF file first!")
-        return 1
-    
-    try:
-        # Create visualizer
-        visualizer = GateEnvironmentVisualizer(headless=False)
-        
-        # Print environment information
-        visualizer.print_environment_info()
-        
-        # Run visualization
-        visualizer.run_visualization(duration=300.0)  # 5 minutes
-        
-        # Cleanup
-        visualizer.cleanup()
-        
-        print("✓ Gate visualization completed successfully!")
-        return 0
-        
-    except Exception as e:
-        print(f"❌ Error during visualization: {e}")
-        import traceback
-        traceback.print_exc()
-        return 1
-
-
-if __name__ == "__main__":
-    exit_code = main()
-    sys.exit(exit_code) 
\ No newline at end of file
diff --git a/examples/validate_gate_config.py b/examples/validate_gate_config.py
deleted file mode 100644
index a726db5..0000000
--- a/examples/validate_gate_config.py
+++ /dev/null
@@ -1,269 +0,0 @@
-"""
-Gate Configuration Validation
-
-This script validates the gate configuration files without importing Isaac Gym.
-It directly checks the configuration files we created to ensure they're properly structured.
-
-This avoids the Python 3.8 vs 3.12 compatibility issue with Isaac Gym.
-"""
-
-import os
-import sys
-
-
-def check_gate_urdf():
-    """Check if the gate URDF file exists and validate its structure."""
-    
-    print("GATE URDF FILE VALIDATION")
-    print("=" * 40)
-    
-    # Construct the expected path
-    script_dir = os.path.dirname(os.path.abspath(__file__))
-    project_root = os.path.dirname(script_dir)
-    urdf_path = os.path.join(project_root, "resources/models/environment_assets/objects/gate.urdf")
-    
-    print(f"Looking for URDF at: {urdf_path}")
-    
-    if os.path.exists(urdf_path):
-        print("✓ Gate URDF file found!")
-        
-        # Read and validate URDF content
-        try:
-            with open(urdf_path, 'r') as f:
-                content = f.read()
-                
-            print(f"✓ URDF file size: {len(content)} characters")
-            
-            # Check for required XML structure
-            if content.startswith('<?xml version="1.0"?>'):
-                print("✓ Valid XML header found")
-            else:
-                print("❌ Missing XML header")
-                
-            # Check for robot definition
-            if '<robot name="gate">' in content:
-                print("✓ Robot definition found")
-            else:
-                print("❌ Missing robot definition")
-                
-            # Count components
-            link_count = content.count('<link name=')
-            joint_count = content.count('<joint name=')
-            
-            print(f"✓ URDF structure:")
-            print(f"  - {link_count} links found")
-            print(f"  - {joint_count} joints found")
-            
-            # Check for specific gate components
-            required_components = ['left_post', 'right_post', 'top_beam', 'base_link']
-            for component in required_components:
-                if component in content:
-                    print(f"  - ✓ {component} component found")
-                else:
-                    print(f"  - ❌ {component} component MISSING")
-                    
-            # Check for physics properties
-            if '<collision>' in content:
-                print("  - ✓ Collision geometry defined")
-            if '<visual>' in content:
-                print("  - ✓ Visual geometry defined")
-            if '<inertial>' in content:
-                print("  - ✓ Inertial properties defined")
-                
-            return True
-            
-        except Exception as e:
-            print(f"❌ Error reading URDF: {e}")
-            return False
-            
-    else:
-        print("❌ Gate URDF file NOT found!")
-        print("Expected location:", urdf_path)
-        return False
-
-
-def check_gate_asset_config():
-    """Check if the gate asset configuration file exists."""
-    
-    print("\nGATE ASSET CONFIGURATION VALIDATION")
-    print("=" * 45)
-    
-    script_dir = os.path.dirname(os.path.abspath(__file__))
-    project_root = os.path.dirname(script_dir)
-    config_path = os.path.join(project_root, "aerial_gym/config/asset_config/gate_asset_config.py")
-    
-    print(f"Looking for config at: {config_path}")
-    
-    if os.path.exists(config_path):
-        print("✓ Gate asset configuration file found!")
-        
-        try:
-            with open(config_path, 'r') as f:
-                content = f.read()
-                
-            print(f"✓ Configuration file size: {len(content)} characters")
-            
-            # Check for required classes and imports
-            checks = [
-                ('BaseAssetParams', 'Base class import'),
-                ('AERIAL_GYM_DIRECTORY', 'Directory constant'),
-                ('GATE_SEMANTIC_ID', 'Semantic ID definition'),
-                ('GateAssetConfig', 'Main config class'),
-                ('gate_asset_params', 'Asset parameters class'),
-                ('num_assets', 'Asset count parameter'),
-                ('asset_folder', 'Asset folder path'),
-                ('file = "gate.urdf"', 'URDF file reference'),
-                ('min_position_ratio', 'Position configuration'),
-                ('collision_mask', 'Collision settings'),
-                ('semantic_id', 'Semantic labeling')
-            ]
-            
-            for check_item, description in checks:
-                if check_item in content:
-                    print(f"  - ✓ {description} found")
-                else:
-                    print(f"  - ❌ {description} MISSING")
-                    
-            return True
-            
-        except Exception as e:
-            print(f"❌ Error reading config file: {e}")
-            return False
-            
-    else:
-        print("❌ Gate asset configuration file NOT found!")
-        return False
-
-
-def check_gate_env_config():
-    """Check if the gate environment configuration file exists."""
-    
-    print("\nGATE ENVIRONMENT CONFIGURATION VALIDATION")
-    print("=" * 50)
-    
-    script_dir = os.path.dirname(os.path.abspath(__file__))
-    project_root = os.path.dirname(script_dir)
-    config_path = os.path.join(project_root, "aerial_gym/config/env_config/gate_env.py")
-    
-    print(f"Looking for config at: {config_path}")
-    
-    if os.path.exists(config_path):
-        print("✓ Gate environment configuration file found!")
-        
-        try:
-            with open(config_path, 'r') as f:
-                content = f.read()
-                
-            print(f"✓ Configuration file size: {len(content)} characters")
-            
-            # Check for required environment configurations
-            env_checks = [
-                ('GateEnvCfg', 'Basic gate environment'),
-                ('GateEnvWithObstaclesCfg', 'Gate with obstacles environment'),
-                ('GateEnvRandomizedCfg', 'Randomized gate environment'),
-                ('class env:', 'Environment parameters class'),
-                ('class env_config:', 'Environment config class'),
-                ('include_asset_type', 'Asset inclusion settings'),
-                ('asset_type_to_dict_map', 'Asset type mapping'),
-                ('"gate": True', 'Gate asset enabled'),
-                ('num_envs', 'Environment count'),
-                ('env_spacing', 'Environment spacing'),
-                ('collision_force_threshold', 'Collision detection'),
-                ('lower_bound_min', 'Environment bounds'),
-                ('upper_bound_max', 'Environment bounds')
-            ]
-            
-            for check_item, description in env_checks:
-                if check_item in content:
-                    print(f"  - ✓ {description} found")
-                else:
-                    print(f"  - ❌ {description} MISSING")
-                    
-            return True
-            
-        except Exception as e:
-            print(f"❌ Error reading environment config: {e}")
-            return False
-            
-    else:
-        print("❌ Gate environment configuration file NOT found!")
-        return False
-
-
-def validate_file_structure():
-    """Validate the overall file structure."""
-    
-    print("\nFILE STRUCTURE VALIDATION")
-    print("=" * 30)
-    
-    script_dir = os.path.dirname(os.path.abspath(__file__))
-    project_root = os.path.dirname(script_dir)
-    
-    # Expected files and directories
-    expected_structure = [
-        "resources/models/environment_assets/objects/gate.urdf",
-        "aerial_gym/config/asset_config/gate_asset_config.py", 
-        "aerial_gym/config/env_config/gate_env.py",
-        "examples/simple_gate_demo.py",
-        "examples/simple_gate_visualization.py"
-    ]
-    
-    all_exist = True
-    
-    for file_path in expected_structure:
-        full_path = os.path.join(project_root, file_path)
-        if os.path.exists(full_path):
-            print(f"✓ {file_path}")
-        else:
-            print(f"❌ {file_path} - MISSING")
-            all_exist = False
-            
-    return all_exist
-
-
-def main():
-    """Main validation function."""
-    
-    print("GATE ENVIRONMENT VALIDATION")
-    print("This validates our gate configuration without Isaac Gym dependencies")
-    print("=" * 70)
-    
-    # Run all validation checks
-    urdf_ok = check_gate_urdf()
-    asset_config_ok = check_gate_asset_config()
-    env_config_ok = check_gate_env_config()
-    structure_ok = validate_file_structure()
-    
-    print("\n" + "=" * 70)
-    print("VALIDATION SUMMARY")
-    print("=" * 70)
-    
-    if all([urdf_ok, asset_config_ok, env_config_ok, structure_ok]):
-        print("🎉 ALL VALIDATIONS PASSED!")
-        print("\nYour gate environment is properly configured!")
-        print("\nWhat's working:")
-        print("✓ Gate URDF model is properly structured")
-        print("✓ Asset configuration is complete") 
-        print("✓ Environment configuration is ready")
-        print("✓ All required files are in place")
-        
-        print("\nNext steps to fix Isaac Gym compatibility:")
-        print("1. Create a Python 3.8 conda environment")
-        print("2. Install Isaac Gym in that environment")
-        print("3. Install other required packages (torch, etc.)")
-        print("4. Run the full simulation demo")
-        
-        print("\nAlternatively, you can:")
-        print("- Use the configuration files with a different simulator")
-        print("- Wait for Isaac Lab compatibility (mentioned in README)")
-        
-        return 0
-    else:
-        print("❌ SOME VALIDATIONS FAILED")
-        print("Please check the missing components above.")
-        return 1
-
-
-if __name__ == "__main__":
-    exit_code = main()
-    sys.exit(exit_code) 
\ No newline at end of file
