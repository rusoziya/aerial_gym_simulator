[2025-07-01 09:01:11,689][16238] Saving configuration to /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/config.json...
[2025-07-01 09:01:11,740][16238] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-07-01 09:01:11,741][16238] Rollout worker 0 uses device cuda:0
[2025-07-01 09:01:12,288][16238] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-07-01 09:01:12,288][16238] InferenceWorker_p0-w0: min num requests: 1
[2025-07-01 09:01:12,288][16238] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-07-01 09:01:12,289][16238] Starting seed is not provided
[2025-07-01 09:01:12,289][16238] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-07-01 09:01:12,289][16238] Initializing actor-critic model on device cuda:0
[2025-07-01 09:01:12,289][16238] RunningMeanStd input shape: (1, 135, 240)
[2025-07-01 09:01:12,290][16238] RunningMeanStd input shape: (81,)
[2025-07-01 09:01:12,290][16238] RunningMeanStd input shape: (1,)
[2025-07-01 09:01:12,299][16238] ConvEncoder: input_channels=1
[2025-07-01 09:01:12,382][16238] Conv encoder output size: 512
[2025-07-01 09:01:12,396][16238] Created Actor Critic model with architecture:
[2025-07-01 09:01:12,396][16238] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (image_obs): RunningMeanStdInPlace()
        (observations): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (image_obs): ConvEncoder(
        (enc): RecursiveScriptModule(
          original_name=ConvEncoderImpl
          (conv_head): RecursiveScriptModule(
            original_name=Sequential
            (0): RecursiveScriptModule(original_name=Conv2d)
            (1): RecursiveScriptModule(original_name=ELU)
            (2): RecursiveScriptModule(original_name=Conv2d)
            (3): RecursiveScriptModule(original_name=ELU)
            (4): RecursiveScriptModule(original_name=Conv2d)
            (5): RecursiveScriptModule(original_name=ELU)
          )
          (mlp_layers): RecursiveScriptModule(
            original_name=Sequential
            (0): RecursiveScriptModule(original_name=Linear)
            (1): RecursiveScriptModule(original_name=ELU)
          )
        )
      )
      (observations): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
          (4): RecursiveScriptModule(original_name=Linear)
          (5): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(576, 64)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=64, out_features=8, bias=True)
  )
)
[2025-07-01 09:01:12,872][16238] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-07-01 09:01:12,873][16238] No checkpoints found
[2025-07-01 09:01:12,873][16238] Did not load from checkpoint, starting from scratch!
[2025-07-01 09:01:12,873][16238] Initialized policy 0 weights for model version 0
[2025-07-01 09:01:12,873][16238] LearnerWorker_p0 finished initialization!
[2025-07-01 09:01:12,874][16238] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-07-01 09:01:13,490][16238] Inference worker 0-0 is ready!
[2025-07-01 09:01:13,491][16238] All inference workers are ready! Signal rollout workers to start!
[2025-07-01 09:01:13,491][16238] EnvRunner 0-0 uses policy 0
[2025-07-01 09:01:18,339][16238] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-07-01 09:01:18,339][16238] Avg episode reward: [(0, '-100.000')]
[2025-07-01 09:01:20,944][16238] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 18.4. Samples: 48. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-07-01 09:01:20,944][16238] Avg episode reward: [(0, '-92.843')]
[2025-07-01 09:01:26,184][16238] Fps is (10 sec: 261.1, 60 sec: 261.1, 300 sec: 261.1). Total num frames: 2048. Throughput: 0: 252.9. Samples: 1984. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[2025-07-01 09:01:26,184][16238] Avg episode reward: [(0, '-92.258')]
[2025-07-01 09:01:30,919][16238] Fps is (10 sec: 205.3, 60 sec: 162.8, 300 sec: 162.8). Total num frames: 2048. Throughput: 0: 314.1. Samples: 3952. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[2025-07-01 09:01:30,919][16238] Avg episode reward: [(0, '-96.684')]
[2025-07-01 09:01:32,348][16238] Heartbeat connected on Batcher_0
[2025-07-01 09:01:32,348][16238] Heartbeat connected on LearnerWorker_p0
[2025-07-01 09:01:32,348][16238] Heartbeat connected on InferenceWorker_p0-w0
[2025-07-01 09:01:32,348][16238] Heartbeat connected on RolloutWorker_w0
[2025-07-01 09:01:35,907][16238] Fps is (10 sec: 210.6, 60 sec: 233.2, 300 sec: 233.2). Total num frames: 4096. Throughput: 0: 269.6. Samples: 4736. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:01:35,907][16238] Avg episode reward: [(0, '-95.837')]
[2025-07-01 09:01:40,923][16238] Fps is (10 sec: 409.4, 60 sec: 272.1, 300 sec: 272.1). Total num frames: 6144. Throughput: 0: 291.2. Samples: 6576. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:01:40,923][16238] Avg episode reward: [(0, '-97.555')]
[2025-07-01 09:01:45,944][16238] Fps is (10 sec: 408.1, 60 sec: 296.8, 300 sec: 296.8). Total num frames: 8192. Throughput: 0: 302.0. Samples: 8336. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2025-07-01 09:01:45,944][16238] Avg episode reward: [(0, '-99.102')]
[2025-07-01 09:01:50,943][16238] Fps is (10 sec: 204.4, 60 sec: 251.3, 300 sec: 251.3). Total num frames: 8192. Throughput: 0: 276.8. Samples: 9024. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2025-07-01 09:01:50,943][16238] Avg episode reward: [(0, '-97.010')]
[2025-07-01 09:01:55,910][16238] Fps is (10 sec: 205.5, 60 sec: 272.5, 300 sec: 272.5). Total num frames: 10240. Throughput: 0: 289.2. Samples: 10864. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2025-07-01 09:01:55,911][16238] Avg episode reward: [(0, '-96.212')]
[2025-07-01 09:02:00,913][16238] Fps is (10 sec: 410.8, 60 sec: 288.6, 300 sec: 288.6). Total num frames: 12288. Throughput: 0: 275.9. Samples: 11744. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:00,913][16238] Avg episode reward: [(0, '-92.963')]
[2025-07-01 09:02:05,945][16238] Fps is (10 sec: 204.1, 60 sec: 258.1, 300 sec: 258.1). Total num frames: 12288. Throughput: 0: 298.7. Samples: 13488. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:05,945][16238] Avg episode reward: [(0, '-93.623')]
[2025-07-01 09:02:10,986][16238] Fps is (10 sec: 203.3, 60 sec: 272.3, 300 sec: 272.3). Total num frames: 14336. Throughput: 0: 301.4. Samples: 15488. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:10,986][16238] Avg episode reward: [(0, '-90.668')]
[2025-07-01 09:02:15,934][16238] Fps is (10 sec: 410.1, 60 sec: 284.5, 300 sec: 284.5). Total num frames: 16384. Throughput: 0: 298.6. Samples: 17392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:15,934][16238] Avg episode reward: [(0, '-90.383')]
[2025-07-01 09:02:20,917][16238] Fps is (10 sec: 412.4, 60 sec: 307.3, 300 sec: 294.5). Total num frames: 18432. Throughput: 0: 302.5. Samples: 18352. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:20,917][16238] Avg episode reward: [(0, '-77.539')]
[2025-07-01 09:02:26,012][16238] Fps is (10 sec: 406.4, 60 sec: 308.1, 300 sec: 302.6). Total num frames: 20480. Throughput: 0: 303.8. Samples: 20272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:26,012][16238] Avg episode reward: [(0, '-69.719')]
[2025-07-01 09:02:30,916][16238] Fps is (10 sec: 204.8, 60 sec: 307.2, 300 sec: 282.2). Total num frames: 20480. Throughput: 0: 284.6. Samples: 21136. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:30,916][16238] Avg episode reward: [(0, '-54.221')]
[2025-07-01 09:02:35,911][16238] Fps is (10 sec: 206.9, 60 sec: 307.2, 300 sec: 290.4). Total num frames: 22528. Throughput: 0: 301.0. Samples: 22560. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:35,912][16238] Avg episode reward: [(0, '-46.160')]
[2025-07-01 09:02:40,908][16238] Fps is (10 sec: 409.9, 60 sec: 307.3, 300 sec: 297.6). Total num frames: 24576. Throughput: 0: 305.1. Samples: 24592. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:40,908][16238] Avg episode reward: [(0, '-40.093')]
[2025-07-01 09:02:45,902][16238] Fps is (10 sec: 205.0, 60 sec: 273.3, 300 sec: 280.7). Total num frames: 24576. Throughput: 0: 299.1. Samples: 25200. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:45,902][16238] Avg episode reward: [(0, '-28.704')]
[2025-07-01 09:02:50,943][16238] Fps is (10 sec: 204.1, 60 sec: 307.2, 300 sec: 287.5). Total num frames: 26624. Throughput: 0: 299.4. Samples: 26960. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:50,944][16238] Avg episode reward: [(0, '-22.324')]
[2025-07-01 09:02:55,903][16238] Fps is (10 sec: 409.6, 60 sec: 307.2, 300 sec: 293.9). Total num frames: 28672. Throughput: 0: 293.9. Samples: 28688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:02:55,903][16238] Avg episode reward: [(0, '-21.836')]
[2025-07-01 09:03:00,963][16238] Fps is (10 sec: 204.4, 60 sec: 272.8, 300 sec: 279.4). Total num frames: 28672. Throughput: 0: 287.5. Samples: 30336. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:03:00,963][16238] Avg episode reward: [(0, '-17.334')]
[2025-07-01 09:03:05,919][16238] Fps is (10 sec: 204.5, 60 sec: 307.3, 300 sec: 285.6). Total num frames: 30720. Throughput: 0: 282.3. Samples: 31056. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:03:05,919][16238] Avg episode reward: [(0, '-18.941')]
[2025-07-01 09:03:05,976][16238] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/checkpoint_p0/checkpoint_000000240_30720.pth...
[2025-07-01 09:03:10,967][16238] Fps is (10 sec: 409.4, 60 sec: 307.3, 300 sec: 290.9). Total num frames: 32768. Throughput: 0: 275.8. Samples: 32672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:03:10,970][16238] Avg episode reward: [(0, '-18.372')]
[2025-07-01 09:03:15,936][16238] Fps is (10 sec: 204.4, 60 sec: 273.1, 300 sec: 278.6). Total num frames: 32768. Throughput: 0: 294.3. Samples: 34384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:03:15,936][16238] Avg episode reward: [(0, '-27.868')]
[2025-07-01 09:03:20,954][16238] Fps is (10 sec: 205.1, 60 sec: 272.9, 300 sec: 283.9). Total num frames: 34816. Throughput: 0: 282.4. Samples: 35280. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[2025-07-01 09:03:20,954][16238] Avg episode reward: [(0, '-20.624')]
[2025-07-01 09:03:25,910][16238] Fps is (10 sec: 410.7, 60 sec: 273.5, 300 sec: 289.0). Total num frames: 36864. Throughput: 0: 276.6. Samples: 37040. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[2025-07-01 09:03:25,910][16238] Avg episode reward: [(0, '-17.731')]
[2025-07-01 09:03:30,919][16238] Fps is (10 sec: 205.5, 60 sec: 273.1, 300 sec: 278.1). Total num frames: 36864. Throughput: 0: 288.2. Samples: 38176. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[2025-07-01 09:03:30,920][16238] Avg episode reward: [(0, '-14.940')]
[2025-07-01 09:03:35,947][16238] Fps is (10 sec: 204.0, 60 sec: 272.9, 300 sec: 282.8). Total num frames: 38912. Throughput: 0: 287.3. Samples: 39888. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:03:35,947][16238] Avg episode reward: [(0, '-13.494')]
[2025-07-01 09:03:40,931][16238] Fps is (10 sec: 409.1, 60 sec: 273.0, 300 sec: 287.3). Total num frames: 40960. Throughput: 0: 280.7. Samples: 41328. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:03:40,931][16238] Avg episode reward: [(0, '-10.437')]
[2025-07-01 09:03:45,925][16238] Fps is (10 sec: 205.3, 60 sec: 273.0, 300 sec: 277.5). Total num frames: 40960. Throughput: 0: 259.4. Samples: 42000. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:03:45,926][16238] Avg episode reward: [(0, '-8.746')]
[2025-07-01 09:03:50,917][16238] Fps is (10 sec: 205.1, 60 sec: 273.2, 300 sec: 281.9). Total num frames: 43008. Throughput: 0: 275.2. Samples: 43440. Policy #0 lag: (min: 4.0, avg: 4.5, max: 20.0)
[2025-07-01 09:03:50,917][16238] Avg episode reward: [(0, '-1.907')]
[2025-07-01 09:03:55,939][16238] Fps is (10 sec: 204.5, 60 sec: 238.8, 300 sec: 272.9). Total num frames: 43008. Throughput: 0: 268.6. Samples: 44752. Policy #0 lag: (min: 4.0, avg: 4.5, max: 20.0)
[2025-07-01 09:03:55,939][16238] Avg episode reward: [(0, '-8.470')]
[2025-07-01 09:04:00,906][16238] Fps is (10 sec: 205.0, 60 sec: 273.3, 300 sec: 277.2). Total num frames: 45056. Throughput: 0: 243.7. Samples: 45344. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2025-07-01 09:04:00,906][16238] Avg episode reward: [(0, '-9.559')]
[2025-07-01 09:04:05,907][16238] Fps is (10 sec: 410.9, 60 sec: 273.1, 300 sec: 281.1). Total num frames: 47104. Throughput: 0: 260.9. Samples: 47008. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:04:05,907][16238] Avg episode reward: [(0, '-12.496')]
[2025-07-01 09:04:10,936][16238] Fps is (10 sec: 204.2, 60 sec: 239.1, 300 sec: 272.9). Total num frames: 47104. Throughput: 0: 262.6. Samples: 48864. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:04:10,937][16238] Avg episode reward: [(0, '-9.472')]
[2025-07-01 09:04:15,902][16238] Fps is (10 sec: 204.9, 60 sec: 273.2, 300 sec: 276.8). Total num frames: 49152. Throughput: 0: 254.7. Samples: 49632. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:04:15,903][16238] Avg episode reward: [(0, '-12.325')]
[2025-07-01 09:04:20,921][16238] Fps is (10 sec: 410.2, 60 sec: 273.2, 300 sec: 280.4). Total num frames: 51200. Throughput: 0: 255.8. Samples: 51392. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:04:20,921][16238] Avg episode reward: [(0, '-5.646')]
[2025-07-01 09:04:25,905][16238] Fps is (10 sec: 409.5, 60 sec: 273.1, 300 sec: 283.9). Total num frames: 53248. Throughput: 0: 265.8. Samples: 53280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:04:25,905][16238] Avg episode reward: [(0, '-6.088')]
[2025-07-01 09:04:30,928][16238] Fps is (10 sec: 409.3, 60 sec: 307.2, 300 sec: 287.1). Total num frames: 55296. Throughput: 0: 299.7. Samples: 55488. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:04:30,928][16238] Avg episode reward: [(0, '0.348')]
[2025-07-01 09:04:35,913][16238] Fps is (10 sec: 204.6, 60 sec: 273.2, 300 sec: 279.9). Total num frames: 55296. Throughput: 0: 294.4. Samples: 56688. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:04:35,913][16238] Avg episode reward: [(0, '4.438')]
[2025-07-01 09:04:40,901][16238] Fps is (10 sec: 205.4, 60 sec: 273.2, 300 sec: 283.1). Total num frames: 57344. Throughput: 0: 307.8. Samples: 58592. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2025-07-01 09:04:40,901][16238] Avg episode reward: [(0, '6.205')]
[2025-07-01 09:04:45,956][16238] Fps is (10 sec: 407.8, 60 sec: 307.0, 300 sec: 286.1). Total num frames: 59392. Throughput: 0: 312.5. Samples: 59424. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:04:45,956][16238] Avg episode reward: [(0, '12.470')]
[2025-07-01 09:04:50,954][16238] Fps is (10 sec: 407.4, 60 sec: 307.0, 300 sec: 289.0). Total num frames: 61440. Throughput: 0: 321.1. Samples: 61472. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:04:50,955][16238] Avg episode reward: [(0, '18.304')]
[2025-07-01 09:04:55,970][16238] Fps is (10 sec: 409.0, 60 sec: 341.2, 300 sec: 291.7). Total num frames: 63488. Throughput: 0: 320.1. Samples: 63280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:04:55,970][16238] Avg episode reward: [(0, '24.222')]
[2025-07-01 09:05:00,925][16238] Fps is (10 sec: 205.4, 60 sec: 307.1, 300 sec: 285.2). Total num frames: 63488. Throughput: 0: 323.4. Samples: 64192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:05:00,925][16238] Avg episode reward: [(0, '7.973')]
[2025-07-01 09:05:05,922][16238] Fps is (10 sec: 205.8, 60 sec: 307.1, 300 sec: 288.0). Total num frames: 65536. Throughput: 0: 327.5. Samples: 66128. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:05:05,923][16238] Avg episode reward: [(0, '12.882')]
[2025-07-01 09:05:05,963][16238] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/checkpoint_p0/checkpoint_000000512_65536.pth...
[2025-07-01 09:05:10,926][16238] Fps is (10 sec: 409.6, 60 sec: 341.4, 300 sec: 290.6). Total num frames: 67584. Throughput: 0: 329.1. Samples: 68096. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:05:10,926][16238] Avg episode reward: [(0, '14.182')]
[2025-07-01 09:05:15,921][16238] Fps is (10 sec: 409.7, 60 sec: 341.2, 300 sec: 293.1). Total num frames: 69632. Throughput: 0: 305.8. Samples: 69248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:05:15,921][16238] Avg episode reward: [(0, '13.982')]
[2025-07-01 09:05:20,914][16238] Fps is (10 sec: 410.1, 60 sec: 341.4, 300 sec: 295.5). Total num frames: 71680. Throughput: 0: 322.5. Samples: 71200. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2025-07-01 09:05:20,914][16238] Avg episode reward: [(0, '9.384')]
[2025-07-01 09:05:25,918][16238] Fps is (10 sec: 204.9, 60 sec: 307.1, 300 sec: 289.5). Total num frames: 71680. Throughput: 0: 325.9. Samples: 73264. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2025-07-01 09:05:25,918][16238] Avg episode reward: [(0, '19.761')]
[2025-07-01 09:05:30,924][16238] Fps is (10 sec: 204.6, 60 sec: 307.2, 300 sec: 291.9). Total num frames: 73728. Throughput: 0: 328.4. Samples: 74192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:05:30,925][16238] Avg episode reward: [(0, '25.538')]
[2025-07-01 09:05:35,923][16238] Fps is (10 sec: 409.4, 60 sec: 341.3, 300 sec: 294.2). Total num frames: 75776. Throughput: 0: 323.1. Samples: 76000. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[2025-07-01 09:05:35,923][16238] Avg episode reward: [(0, '17.037')]
[2025-07-01 09:05:40,899][16238] Fps is (10 sec: 410.6, 60 sec: 341.3, 300 sec: 296.4). Total num frames: 77824. Throughput: 0: 329.8. Samples: 78096. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2025-07-01 09:05:40,900][16238] Avg episode reward: [(0, '15.412')]
[2025-07-01 09:05:45,939][16238] Fps is (10 sec: 408.9, 60 sec: 341.4, 300 sec: 298.5). Total num frames: 79872. Throughput: 0: 350.8. Samples: 79984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:05:45,939][16238] Avg episode reward: [(0, '13.301')]
[2025-07-01 09:05:50,920][16238] Fps is (10 sec: 204.4, 60 sec: 307.4, 300 sec: 293.0). Total num frames: 79872. Throughput: 0: 334.6. Samples: 81184. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:05:50,920][16238] Avg episode reward: [(0, '6.801')]
[2025-07-01 09:05:55,898][16238] Fps is (10 sec: 205.6, 60 sec: 307.6, 300 sec: 295.1). Total num frames: 81920. Throughput: 0: 337.6. Samples: 83280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:05:55,898][16238] Avg episode reward: [(0, '7.966')]
[2025-07-01 09:06:00,925][16238] Fps is (10 sec: 409.4, 60 sec: 341.3, 300 sec: 297.1). Total num frames: 83968. Throughput: 0: 357.7. Samples: 85344. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[2025-07-01 09:06:00,925][16238] Avg episode reward: [(0, '14.625')]
[2025-07-01 09:06:05,904][16238] Fps is (10 sec: 409.4, 60 sec: 341.4, 300 sec: 299.1). Total num frames: 86016. Throughput: 0: 335.0. Samples: 86272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:06:05,904][16238] Avg episode reward: [(0, '15.179')]
[2025-07-01 09:06:10,930][16238] Fps is (10 sec: 409.4, 60 sec: 341.3, 300 sec: 301.0). Total num frames: 88064. Throughput: 0: 330.6. Samples: 88144. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2025-07-01 09:06:10,930][16238] Avg episode reward: [(0, '28.509')]
[2025-07-01 09:06:15,926][16238] Fps is (10 sec: 204.3, 60 sec: 307.2, 300 sec: 298.5). Total num frames: 88064. Throughput: 0: 325.3. Samples: 88832. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2025-07-01 09:06:15,927][16238] Avg episode reward: [(0, '34.704')]
[2025-07-01 09:06:20,982][16238] Fps is (10 sec: 203.7, 60 sec: 306.9, 300 sec: 298.7). Total num frames: 90112. Throughput: 0: 318.9. Samples: 90368. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[2025-07-01 09:06:20,982][16238] Avg episode reward: [(0, '46.419')]
[2025-07-01 09:06:25,918][16238] Fps is (10 sec: 410.0, 60 sec: 341.3, 300 sec: 305.5). Total num frames: 92160. Throughput: 0: 311.0. Samples: 92096. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[2025-07-01 09:06:25,918][16238] Avg episode reward: [(0, '49.356')]
[2025-07-01 09:06:30,961][16238] Fps is (10 sec: 205.2, 60 sec: 307.0, 300 sec: 298.5). Total num frames: 92160. Throughput: 0: 302.1. Samples: 93584. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[2025-07-01 09:06:30,961][16238] Avg episode reward: [(0, '51.919')]
[2025-07-01 09:06:35,911][16238] Fps is (10 sec: 204.9, 60 sec: 307.3, 300 sec: 298.5). Total num frames: 94208. Throughput: 0: 290.2. Samples: 94240. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:06:35,912][16238] Avg episode reward: [(0, '53.089')]
[2025-07-01 09:06:40,929][16238] Fps is (10 sec: 205.4, 60 sec: 272.9, 300 sec: 291.6). Total num frames: 94208. Throughput: 0: 277.1. Samples: 95760. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:06:40,930][16238] Avg episode reward: [(0, '41.429')]
[2025-07-01 09:06:45,943][16238] Fps is (10 sec: 204.2, 60 sec: 273.1, 300 sec: 298.5). Total num frames: 96256. Throughput: 0: 271.9. Samples: 97584. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:06:45,943][16238] Avg episode reward: [(0, '41.673')]
[2025-07-01 09:06:50,915][16238] Fps is (10 sec: 410.2, 60 sec: 307.2, 300 sec: 298.5). Total num frames: 98304. Throughput: 0: 269.1. Samples: 98384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:06:50,915][16238] Avg episode reward: [(0, '40.065')]
[2025-07-01 09:06:55,899][16238] Fps is (10 sec: 411.4, 60 sec: 307.2, 300 sec: 298.5). Total num frames: 100352. Throughput: 0: 274.3. Samples: 100480. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:06:55,899][16238] Avg episode reward: [(0, '42.993')]
[2025-07-01 09:07:01,274][16238] Fps is (10 sec: 395.4, 60 sec: 305.4, 300 sec: 305.1). Total num frames: 102400. Throughput: 0: 281.9. Samples: 101616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:07:01,275][16238] Avg episode reward: [(0, '45.278')]
[2025-07-01 09:07:05,903][16238] Fps is (10 sec: 204.7, 60 sec: 273.1, 300 sec: 298.6). Total num frames: 102400. Throughput: 0: 287.8. Samples: 103296. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:07:05,903][16238] Avg episode reward: [(0, '56.034')]
[2025-07-01 09:07:05,962][16238] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/checkpoint_p0/checkpoint_000000800_102400.pth...
[2025-07-01 09:07:06,031][16238] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/checkpoint_p0/checkpoint_000000240_30720.pth
[2025-07-01 09:07:10,913][16238] Fps is (10 sec: 212.5, 60 sec: 273.1, 300 sec: 298.5). Total num frames: 104448. Throughput: 0: 282.3. Samples: 104800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:07:10,914][16238] Avg episode reward: [(0, '58.656')]
[2025-07-01 09:07:15,927][16238] Fps is (10 sec: 408.6, 60 sec: 307.2, 300 sec: 298.5). Total num frames: 106496. Throughput: 0: 270.4. Samples: 105744. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:07:15,927][16238] Avg episode reward: [(0, '55.737')]
[2025-07-01 09:07:20,920][16238] Fps is (10 sec: 204.7, 60 sec: 273.4, 300 sec: 291.7). Total num frames: 106496. Throughput: 0: 295.1. Samples: 107520. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:07:20,920][16238] Avg episode reward: [(0, '60.368')]
[2025-07-01 09:07:25,932][16238] Fps is (10 sec: 204.7, 60 sec: 273.0, 300 sec: 298.5). Total num frames: 108544. Throughput: 0: 289.1. Samples: 108768. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[2025-07-01 09:07:25,932][16238] Avg episode reward: [(0, '61.099')]
[2025-07-01 09:07:30,956][16238] Fps is (10 sec: 204.1, 60 sec: 273.1, 300 sec: 291.5). Total num frames: 108544. Throughput: 0: 280.4. Samples: 110208. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[2025-07-01 09:07:30,957][16238] Avg episode reward: [(0, '49.349')]
[2025-07-01 09:07:35,970][16238] Fps is (10 sec: 204.0, 60 sec: 272.8, 300 sec: 291.5). Total num frames: 110592. Throughput: 0: 275.6. Samples: 110800. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[2025-07-01 09:07:35,971][16238] Avg episode reward: [(0, '61.509')]
[2025-07-01 09:07:40,912][16238] Fps is (10 sec: 205.7, 60 sec: 273.1, 300 sec: 291.6). Total num frames: 110592. Throughput: 0: 260.2. Samples: 112192. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[2025-07-01 09:07:40,912][16238] Avg episode reward: [(0, '58.474')]
[2025-07-01 09:07:45,922][16238] Fps is (10 sec: 205.8, 60 sec: 273.2, 300 sec: 291.6). Total num frames: 112640. Throughput: 0: 251.2. Samples: 112832. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[2025-07-01 09:07:45,922][16238] Avg episode reward: [(0, '62.495')]
[2025-07-01 09:07:51,220][16238] Fps is (10 sec: 397.3, 60 sec: 271.7, 300 sec: 291.3). Total num frames: 114688. Throughput: 0: 242.2. Samples: 114272. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:07:51,221][16238] Avg episode reward: [(0, '65.554')]
[2025-07-01 09:07:55,981][16238] Fps is (10 sec: 203.6, 60 sec: 238.6, 300 sec: 291.6). Total num frames: 114688. Throughput: 0: 237.5. Samples: 115504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:07:55,981][16238] Avg episode reward: [(0, '56.624')]
[2025-07-01 09:08:00,911][16238] Fps is (10 sec: 211.3, 60 sec: 240.4, 300 sec: 291.6). Total num frames: 116736. Throughput: 0: 233.0. Samples: 116224. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[2025-07-01 09:08:00,911][16238] Avg episode reward: [(0, '55.207')]
[2025-07-01 09:08:05,940][16238] Fps is (10 sec: 205.6, 60 sec: 238.8, 300 sec: 284.7). Total num frames: 116736. Throughput: 0: 230.3. Samples: 117888. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[2025-07-01 09:08:05,941][16238] Avg episode reward: [(0, '57.483')]
[2025-07-01 09:08:10,901][16238] Fps is (10 sec: 205.0, 60 sec: 239.0, 300 sec: 291.6). Total num frames: 118784. Throughput: 0: 235.9. Samples: 119376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:08:10,901][16238] Avg episode reward: [(0, '55.709')]
[2025-07-01 09:08:15,914][16238] Fps is (10 sec: 410.7, 60 sec: 239.0, 300 sec: 291.6). Total num frames: 120832. Throughput: 0: 226.7. Samples: 120400. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[2025-07-01 09:08:15,914][16238] Avg episode reward: [(0, '45.507')]
[2025-07-01 09:08:20,916][16238] Fps is (10 sec: 204.5, 60 sec: 238.9, 300 sec: 284.6). Total num frames: 120832. Throughput: 0: 246.7. Samples: 121888. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[2025-07-01 09:08:20,916][16238] Avg episode reward: [(0, '43.648')]
[2025-07-01 09:08:25,920][16238] Fps is (10 sec: 204.7, 60 sec: 239.0, 300 sec: 291.6). Total num frames: 122880. Throughput: 0: 252.8. Samples: 123568. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[2025-07-01 09:08:25,920][16238] Avg episode reward: [(0, '49.588')]
[2025-07-01 09:08:30,935][16238] Fps is (10 sec: 408.8, 60 sec: 273.2, 300 sec: 291.6). Total num frames: 124928. Throughput: 0: 260.9. Samples: 124576. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[2025-07-01 09:08:30,935][16238] Avg episode reward: [(0, '46.207')]
[2025-07-01 09:08:35,942][16238] Fps is (10 sec: 408.7, 60 sec: 273.2, 300 sec: 291.6). Total num frames: 126976. Throughput: 0: 276.2. Samples: 126624. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:08:35,942][16238] Avg episode reward: [(0, '50.371')]
[2025-07-01 09:08:41,259][16238] Fps is (10 sec: 396.7, 60 sec: 305.4, 300 sec: 298.2). Total num frames: 129024. Throughput: 0: 291.9. Samples: 128720. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:08:41,259][16238] Avg episode reward: [(0, '47.844')]
[2025-07-01 09:08:45,934][16238] Fps is (10 sec: 204.9, 60 sec: 273.0, 300 sec: 291.6). Total num frames: 129024. Throughput: 0: 297.4. Samples: 129616. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:08:45,935][16238] Avg episode reward: [(0, '49.430')]
[2025-07-01 09:08:50,935][16238] Fps is (10 sec: 211.7, 60 sec: 274.4, 300 sec: 298.5). Total num frames: 131072. Throughput: 0: 306.2. Samples: 131664. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2025-07-01 09:08:50,935][16238] Avg episode reward: [(0, '44.147')]
[2025-07-01 09:08:55,901][16238] Fps is (10 sec: 411.0, 60 sec: 307.6, 300 sec: 298.5). Total num frames: 133120. Throughput: 0: 317.5. Samples: 133664. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2025-07-01 09:08:55,901][16238] Avg episode reward: [(0, '55.305')]
[2025-07-01 09:09:00,929][16238] Fps is (10 sec: 409.8, 60 sec: 307.1, 300 sec: 298.5). Total num frames: 135168. Throughput: 0: 342.6. Samples: 135824. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:09:00,929][16238] Avg episode reward: [(0, '52.927')]
[2025-07-01 09:09:05,930][16238] Fps is (10 sec: 408.4, 60 sec: 341.4, 300 sec: 305.5). Total num frames: 137216. Throughput: 0: 334.8. Samples: 136960. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:09:05,930][16238] Avg episode reward: [(0, '52.844')]
[2025-07-01 09:09:05,974][16238] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/checkpoint_p0/checkpoint_000001072_137216.pth...
[2025-07-01 09:09:06,044][16238] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/checkpoint_p0/checkpoint_000000512_65536.pth
[2025-07-01 09:09:10,915][16238] Fps is (10 sec: 410.2, 60 sec: 341.3, 300 sec: 305.5). Total num frames: 139264. Throughput: 0: 347.1. Samples: 139184. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2025-07-01 09:09:10,916][16238] Avg episode reward: [(0, '57.613')]
[2025-07-01 09:09:16,136][16238] Fps is (10 sec: 401.3, 60 sec: 340.1, 300 sec: 305.2). Total num frames: 141312. Throughput: 0: 346.9. Samples: 140256. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:09:16,136][16238] Avg episode reward: [(0, '64.399')]
[2025-07-01 09:09:20,925][16238] Fps is (10 sec: 204.6, 60 sec: 341.3, 300 sec: 298.5). Total num frames: 141312. Throughput: 0: 350.0. Samples: 142368. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:09:20,925][16238] Avg episode reward: [(0, '63.329')]
[2025-07-01 09:09:25,908][16238] Fps is (10 sec: 209.6, 60 sec: 341.4, 300 sec: 298.5). Total num frames: 143360. Throughput: 0: 353.7. Samples: 144512. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[2025-07-01 09:09:25,908][16238] Avg episode reward: [(0, '63.724')]
[2025-07-01 09:09:30,920][16238] Fps is (10 sec: 409.8, 60 sec: 341.4, 300 sec: 305.5). Total num frames: 145408. Throughput: 0: 378.4. Samples: 146640. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:09:30,920][16238] Avg episode reward: [(0, '75.336')]
[2025-07-01 09:09:35,919][16238] Fps is (10 sec: 409.1, 60 sec: 341.5, 300 sec: 305.4). Total num frames: 147456. Throughput: 0: 357.1. Samples: 147728. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:09:35,920][16238] Avg episode reward: [(0, '73.821')]
[2025-07-01 09:09:40,912][16238] Fps is (10 sec: 409.9, 60 sec: 343.3, 300 sec: 305.5). Total num frames: 149504. Throughput: 0: 359.0. Samples: 149824. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[2025-07-01 09:09:40,912][16238] Avg episode reward: [(0, '77.115')]
[2025-07-01 09:09:45,932][16238] Fps is (10 sec: 409.1, 60 sec: 375.5, 300 sec: 305.5). Total num frames: 151552. Throughput: 0: 359.8. Samples: 152016. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2025-07-01 09:09:45,932][16238] Avg episode reward: [(0, '73.869')]
[2025-07-01 09:09:50,905][16238] Fps is (10 sec: 409.9, 60 sec: 375.7, 300 sec: 305.5). Total num frames: 153600. Throughput: 0: 359.7. Samples: 153136. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2025-07-01 09:09:50,905][16238] Avg episode reward: [(0, '79.506')]
[2025-07-01 09:09:55,901][16238] Fps is (10 sec: 205.4, 60 sec: 341.3, 300 sec: 305.5). Total num frames: 153600. Throughput: 0: 355.7. Samples: 155184. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2025-07-01 09:09:55,901][16238] Avg episode reward: [(0, '71.069')]
[2025-07-01 09:10:00,937][16238] Fps is (10 sec: 204.1, 60 sec: 341.3, 300 sec: 305.4). Total num frames: 155648. Throughput: 0: 375.4. Samples: 157072. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:10:00,937][16238] Avg episode reward: [(0, '60.120')]
[2025-07-01 09:10:05,942][16238] Fps is (10 sec: 407.9, 60 sec: 341.3, 300 sec: 305.4). Total num frames: 157696. Throughput: 0: 346.2. Samples: 157952. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:10:05,943][16238] Avg episode reward: [(0, '66.572')]
[2025-07-01 09:10:10,903][16238] Fps is (10 sec: 411.0, 60 sec: 341.4, 300 sec: 305.5). Total num frames: 159744. Throughput: 0: 344.2. Samples: 160000. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2025-07-01 09:10:10,903][16238] Avg episode reward: [(0, '59.294')]
[2025-07-01 09:10:15,910][16238] Fps is (10 sec: 410.9, 60 sec: 342.6, 300 sec: 305.5). Total num frames: 161792. Throughput: 0: 323.3. Samples: 161184. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[2025-07-01 09:10:15,910][16238] Avg episode reward: [(0, '66.132')]
[2025-07-01 09:10:20,958][16238] Fps is (10 sec: 203.7, 60 sec: 341.1, 300 sec: 305.4). Total num frames: 161792. Throughput: 0: 338.2. Samples: 162960. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[2025-07-01 09:10:20,958][16238] Avg episode reward: [(0, '54.955')]
[2025-07-01 09:10:25,941][16238] Fps is (10 sec: 204.2, 60 sec: 341.1, 300 sec: 305.4). Total num frames: 163840. Throughput: 0: 327.6. Samples: 164576. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:10:25,941][16238] Avg episode reward: [(0, '57.457')]
[2025-07-01 09:10:30,991][16238] Fps is (10 sec: 408.2, 60 sec: 340.9, 300 sec: 305.4). Total num frames: 165888. Throughput: 0: 294.0. Samples: 165264. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2025-07-01 09:10:30,991][16238] Avg episode reward: [(0, '60.517')]
[2025-07-01 09:10:35,927][16238] Fps is (10 sec: 205.1, 60 sec: 307.2, 300 sec: 298.5). Total num frames: 165888. Throughput: 0: 303.5. Samples: 166800. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2025-07-01 09:10:35,928][16238] Avg episode reward: [(0, '64.727')]
[2025-07-01 09:10:40,929][16238] Fps is (10 sec: 206.1, 60 sec: 307.1, 300 sec: 298.5). Total num frames: 167936. Throughput: 0: 294.9. Samples: 168464. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2025-07-01 09:10:40,930][16238] Avg episode reward: [(0, '60.682')]
[2025-07-01 09:10:45,919][16238] Fps is (10 sec: 409.9, 60 sec: 307.3, 300 sec: 305.5). Total num frames: 169984. Throughput: 0: 289.2. Samples: 170080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:10:45,919][16238] Avg episode reward: [(0, '63.965')]
[2025-07-01 09:10:50,968][16238] Fps is (10 sec: 204.0, 60 sec: 272.8, 300 sec: 298.5). Total num frames: 169984. Throughput: 0: 286.4. Samples: 170848. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:10:50,968][16238] Avg episode reward: [(0, '62.938')]
[2025-07-01 09:10:55,914][16238] Fps is (10 sec: 204.9, 60 sec: 307.1, 300 sec: 298.5). Total num frames: 172032. Throughput: 0: 269.1. Samples: 172112. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:10:55,914][16238] Avg episode reward: [(0, '61.230')]
[2025-07-01 09:11:00,913][16238] Fps is (10 sec: 205.9, 60 sec: 273.2, 300 sec: 291.6). Total num frames: 172032. Throughput: 0: 255.3. Samples: 172672. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:11:00,914][16238] Avg episode reward: [(0, '56.495')]
[2025-07-01 09:11:05,933][16238] Fps is (10 sec: 204.4, 60 sec: 273.1, 300 sec: 291.6). Total num frames: 174080. Throughput: 0: 250.1. Samples: 174208. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[2025-07-01 09:11:05,933][16238] Avg episode reward: [(0, '61.957')]
[2025-07-01 09:11:06,003][16238] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/checkpoint_p0/checkpoint_000001360_174080.pth...
[2025-07-01 09:11:06,090][16238] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/checkpoint_p0/checkpoint_000000800_102400.pth
[2025-07-01 09:11:10,944][16238] Fps is (10 sec: 204.2, 60 sec: 238.8, 300 sec: 291.6). Total num frames: 174080. Throughput: 0: 243.5. Samples: 175536. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[2025-07-01 09:11:10,944][16238] Avg episode reward: [(0, '58.844')]
[2025-07-01 09:11:15,944][16238] Fps is (10 sec: 204.6, 60 sec: 238.8, 300 sec: 291.6). Total num frames: 176128. Throughput: 0: 249.9. Samples: 176496. Policy #0 lag: (min: 8.0, avg: 8.5, max: 24.0)
[2025-07-01 09:11:15,944][16238] Avg episode reward: [(0, '46.896')]
[2025-07-01 09:11:20,905][16238] Fps is (10 sec: 411.2, 60 sec: 273.3, 300 sec: 291.6). Total num frames: 178176. Throughput: 0: 253.6. Samples: 178208. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[2025-07-01 09:11:20,905][16238] Avg episode reward: [(0, '53.682')]
[2025-07-01 09:11:25,907][16238] Fps is (10 sec: 205.6, 60 sec: 239.1, 300 sec: 291.6). Total num frames: 178176. Throughput: 0: 250.4. Samples: 179728. Policy #0 lag: (min: 12.0, avg: 12.5, max: 28.0)
[2025-07-01 09:11:25,908][16238] Avg episode reward: [(0, '55.762')]
[2025-07-01 09:11:30,934][16238] Fps is (10 sec: 204.2, 60 sec: 239.2, 300 sec: 291.6). Total num frames: 180224. Throughput: 0: 250.9. Samples: 181376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:11:30,934][16238] Avg episode reward: [(0, '64.058')]
[2025-07-01 09:11:35,938][16238] Fps is (10 sec: 408.3, 60 sec: 273.0, 300 sec: 298.5). Total num frames: 182272. Throughput: 0: 254.7. Samples: 182304. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2025-07-01 09:11:35,939][16238] Avg episode reward: [(0, '69.137')]
[2025-07-01 09:11:40,925][16238] Fps is (10 sec: 409.9, 60 sec: 273.1, 300 sec: 298.5). Total num frames: 184320. Throughput: 0: 271.9. Samples: 184352. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[2025-07-01 09:11:40,925][16238] Avg episode reward: [(0, '68.270')]
[2025-07-01 09:11:45,915][16238] Fps is (10 sec: 205.3, 60 sec: 238.9, 300 sec: 291.6). Total num frames: 184320. Throughput: 0: 281.2. Samples: 185328. Policy #0 lag: (min: 14.0, avg: 14.0, max: 14.0)
[2025-07-01 09:11:45,915][16238] Avg episode reward: [(0, '65.720')]
[2025-07-01 09:11:50,947][16238] Fps is (10 sec: 204.3, 60 sec: 273.2, 300 sec: 291.5). Total num frames: 186368. Throughput: 0: 290.4. Samples: 187280. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:11:50,948][16238] Avg episode reward: [(0, '77.194')]
[2025-07-01 09:11:55,901][16238] Fps is (10 sec: 410.2, 60 sec: 273.1, 300 sec: 291.9). Total num frames: 188416. Throughput: 0: 306.4. Samples: 189312. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2025-07-01 09:11:55,901][16238] Avg episode reward: [(0, '72.845')]
[2025-07-01 09:12:00,925][16238] Fps is (10 sec: 410.5, 60 sec: 307.1, 300 sec: 298.5). Total num frames: 190464. Throughput: 0: 330.8. Samples: 191376. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:12:00,925][16238] Avg episode reward: [(0, '56.641')]
[2025-07-01 09:12:05,922][16238] Fps is (10 sec: 408.7, 60 sec: 307.3, 300 sec: 298.5). Total num frames: 192512. Throughput: 0: 318.1. Samples: 192528. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:12:05,923][16238] Avg episode reward: [(0, '59.513')]
[2025-07-01 09:12:10,906][16238] Fps is (10 sec: 410.4, 60 sec: 341.6, 300 sec: 298.5). Total num frames: 194560. Throughput: 0: 329.3. Samples: 194544. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[2025-07-01 09:12:10,906][16238] Avg episode reward: [(0, '54.578')]
[2025-07-01 09:12:15,936][16238] Fps is (10 sec: 409.0, 60 sec: 341.4, 300 sec: 305.4). Total num frames: 196608. Throughput: 0: 339.2. Samples: 196640. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:12:15,936][16238] Avg episode reward: [(0, '38.874')]
[2025-07-01 09:12:20,919][16238] Fps is (10 sec: 204.5, 60 sec: 307.1, 300 sec: 298.5). Total num frames: 196608. Throughput: 0: 345.0. Samples: 197824. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:12:20,919][16238] Avg episode reward: [(0, '47.150')]
[2025-07-01 09:12:25,956][16238] Fps is (10 sec: 204.4, 60 sec: 341.1, 300 sec: 305.5). Total num frames: 198656. Throughput: 0: 345.7. Samples: 199920. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:12:25,956][16238] Avg episode reward: [(0, '57.645')]
[2025-07-01 09:12:30,907][16238] Fps is (10 sec: 410.1, 60 sec: 341.5, 300 sec: 305.5). Total num frames: 200704. Throughput: 0: 343.2. Samples: 200768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:12:30,907][16238] Avg episode reward: [(0, '67.434')]
[2025-07-01 09:12:35,926][16238] Fps is (10 sec: 410.8, 60 sec: 341.4, 300 sec: 312.4). Total num frames: 202752. Throughput: 0: 345.1. Samples: 202800. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:12:35,926][16238] Avg episode reward: [(0, '54.496')]
[2025-07-01 09:12:40,901][16238] Fps is (10 sec: 409.9, 60 sec: 341.5, 300 sec: 312.4). Total num frames: 204800. Throughput: 0: 345.6. Samples: 204864. Policy #0 lag: (min: 0.0, avg: 0.5, max: 16.0)
[2025-07-01 09:12:40,901][16238] Avg episode reward: [(0, '66.569')]
[2025-07-01 09:12:45,931][16238] Fps is (10 sec: 409.4, 60 sec: 375.4, 300 sec: 312.7). Total num frames: 206848. Throughput: 0: 326.7. Samples: 206080. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:12:45,932][16238] Avg episode reward: [(0, '56.730')]
[2025-07-01 09:12:50,901][16238] Fps is (10 sec: 204.8, 60 sec: 341.6, 300 sec: 312.5). Total num frames: 206848. Throughput: 0: 348.3. Samples: 208192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:12:50,901][16238] Avg episode reward: [(0, '48.782')]
[2025-07-01 09:12:55,921][16238] Fps is (10 sec: 205.0, 60 sec: 341.2, 300 sec: 312.4). Total num frames: 208896. Throughput: 0: 350.1. Samples: 210304. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[2025-07-01 09:12:55,922][16238] Avg episode reward: [(0, '61.379')]
[2025-07-01 09:13:00,913][16238] Fps is (10 sec: 409.1, 60 sec: 341.4, 300 sec: 319.4). Total num frames: 210944. Throughput: 0: 324.8. Samples: 211248. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:13:00,913][16238] Avg episode reward: [(0, '73.334')]
[2025-07-01 09:13:05,901][16238] Fps is (10 sec: 410.4, 60 sec: 341.5, 300 sec: 319.3). Total num frames: 212992. Throughput: 0: 346.4. Samples: 213408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:13:05,901][16238] Avg episode reward: [(0, '82.453')]
[2025-07-01 09:13:05,942][16238] Saving /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/checkpoint_p0/checkpoint_000001664_212992.pth...
[2025-07-01 09:13:06,009][16238] Removing /home/ziyar/aerialgym/aerialgym_ws/src/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/16env_2nd_test_curriculum/checkpoint_p0/checkpoint_000001072_137216.pth
[2025-07-01 09:13:10,934][16238] Fps is (10 sec: 408.7, 60 sec: 341.2, 300 sec: 319.3). Total num frames: 215040. Throughput: 0: 344.7. Samples: 215424. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:13:10,935][16238] Avg episode reward: [(0, '91.746')]
[2025-07-01 09:13:15,938][16238] Fps is (10 sec: 408.1, 60 sec: 341.3, 300 sec: 326.3). Total num frames: 217088. Throughput: 0: 372.4. Samples: 217536. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[2025-07-01 09:13:15,938][16238] Avg episode reward: [(0, '99.281')]
[2025-07-01 09:13:20,898][16238] Fps is (10 sec: 411.1, 60 sec: 375.6, 300 sec: 326.3). Total num frames: 219136. Throughput: 0: 351.1. Samples: 218592. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2025-07-01 09:13:20,899][16238] Avg episode reward: [(0, '94.581')]
[2025-07-01 09:13:25,905][16238] Fps is (10 sec: 205.5, 60 sec: 341.6, 300 sec: 319.4). Total num frames: 219136. Throughput: 0: 352.7. Samples: 220736. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2025-07-01 09:13:25,905][16238] Avg episode reward: [(0, '84.061')]
[2025-07-01 09:13:30,939][16238] Fps is (10 sec: 204.0, 60 sec: 341.2, 300 sec: 319.4). Total num frames: 221184. Throughput: 0: 370.8. Samples: 222768. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:13:30,939][16238] Avg episode reward: [(0, '76.128')]
[2025-07-01 09:13:35,905][16238] Fps is (10 sec: 409.6, 60 sec: 341.4, 300 sec: 319.7). Total num frames: 223232. Throughput: 0: 345.6. Samples: 223744. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:13:35,906][16238] Avg episode reward: [(0, '72.055')]
[2025-07-01 09:13:40,906][16238] Fps is (10 sec: 410.9, 60 sec: 341.3, 300 sec: 326.3). Total num frames: 225280. Throughput: 0: 345.7. Samples: 225856. Policy #0 lag: (min: 13.0, avg: 13.0, max: 13.0)
[2025-07-01 09:13:40,907][16238] Avg episode reward: [(0, '74.661')]
[2025-07-01 09:13:45,925][16238] Fps is (10 sec: 408.8, 60 sec: 341.4, 300 sec: 326.3). Total num frames: 227328. Throughput: 0: 369.3. Samples: 227872. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:13:45,925][16238] Avg episode reward: [(0, '74.050')]
[2025-07-01 09:13:50,926][16238] Fps is (10 sec: 408.8, 60 sec: 375.3, 300 sec: 326.3). Total num frames: 229376. Throughput: 0: 346.8. Samples: 229024. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2025-07-01 09:13:50,927][16238] Avg episode reward: [(0, '72.911')]
[2025-07-01 09:13:55,913][16238] Fps is (10 sec: 205.0, 60 sec: 341.4, 300 sec: 319.4). Total num frames: 229376. Throughput: 0: 347.5. Samples: 231056. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2025-07-01 09:13:55,913][16238] Avg episode reward: [(0, '74.514')]
[2025-07-01 09:14:00,903][16238] Fps is (10 sec: 205.3, 60 sec: 341.4, 300 sec: 319.4). Total num frames: 231424. Throughput: 0: 321.3. Samples: 231984. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:14:00,903][16238] Avg episode reward: [(0, '81.034')]
[2025-07-01 09:14:05,903][16238] Fps is (10 sec: 410.0, 60 sec: 341.3, 300 sec: 319.4). Total num frames: 233472. Throughput: 0: 343.1. Samples: 234032. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:14:05,903][16238] Avg episode reward: [(0, '84.055')]
[2025-07-01 09:14:10,930][16238] Fps is (10 sec: 408.5, 60 sec: 341.4, 300 sec: 319.6). Total num frames: 235520. Throughput: 0: 343.3. Samples: 236192. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:14:10,930][16238] Avg episode reward: [(0, '98.833')]
[2025-07-01 09:14:15,929][16238] Fps is (10 sec: 408.5, 60 sec: 341.4, 300 sec: 326.3). Total num frames: 237568. Throughput: 0: 345.0. Samples: 238288. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-07-01 09:14:15,930][16238] Avg episode reward: [(0, '118.326')]
[2025-07-01 09:14:20,913][16238] Fps is (10 sec: 410.3, 60 sec: 341.2, 300 sec: 326.3). Total num frames: 239616. Throughput: 0: 346.6. Samples: 239344. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2025-07-01 09:14:20,913][16238] Avg episode reward: [(0, '109.629')]
[2025-07-01 09:14:24,445][16238] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 16238], exiting...
[2025-07-01 09:14:24,446][16238] Runner profile tree view:
main_loop: 792.1569
[2025-07-01 09:14:24,446][16238] Collected {0: 239616}, FPS: 302.5
